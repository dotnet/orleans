{
  "blog/announcing-orleans-2.0-tech-preview-3.html": {
    "href": "blog/announcing-orleans-2.0-tech-preview-3.html",
    "title": "Announcing Orleans 2.0 Tech Preview 3 | Microsoft Orleans Documentation",
    "keywords": "Announcing Orleans 2.0 Tech Preview 3 Julian Dominguez 9/13/2017 1:17:21 PM We just released a big update on the Orleans 2.0 tech preview train. The new binaries now target .NET Standard 2.0, so they have almost full parity with the .NET version of Orleans. This means that the current state is not only functional for people writing new applications in .NET Core, but also as an upgrade path for people with applications already running in .NET Framework. Are we done yet? This is an exciting milestone for our team, as it brings the 2.0 release a lot closer. There are a few remaining things we would like to do for this version before we release, such as: Enable build-time codegen for .NET Core apps (only runtime codegen is supported for .NET Core still) Migrate to Microsoft.Extensions.Logging for all of our logging Flesh out the silo builder APIs more Improve startup by scanning only the assemblies defined by the end user Restructure some of our types to have an Abstractions project that we don't version often Have an initial version of the Transactions feature working Provide a level of backwards compatibility for types commonly serialized and persisted to storage and some other minor things How can I try this? We just published the packages to MyGet: https://dotnet.myget.org/gallery/orleans-ci Please follow the link for instructions on how to configure NuGet to download packages from that feed. Please help us We plan to start releasing updated packages to the MyGet feed a lot more often, so please try the preview, and if there's issues, let us know, so that we can fix it and send an update your way shortly after. Is Orleans 2.0 TP3 production ready? Not yet. Big disclaimer: We do our CI testing in .NET (because our tests heavily rely on AppDomains to create an in-memory cluster of silos, and those are not supported in .NET Core, but we plan to tackle that soon). We have done some basic manual testing in .NET Core (both Windows and Linux), and we have some of our contributors using it to develop new services. Getting feedback (and PRs!) is one of the main goals of this release, and not to be used in production yet. Also, there is no guarantee that this technical preview is entirely backwards compatible with Orleans 1.5, even for the features that were fully ported. Once we are closer to a stable release, we’ll list all the breaking changes that we know of in case you are interested in upgrading your application from 1.X to 2.0. Notes If you were using an older tech preview, notice that assembly loading changed a little, and we expect to continue to change it. In the meantime, please note that in .NET Core you might be required to publish your app so that all the assemblies to scan are in the same folder (you can achieve this by calling ` dotnet publish ` on your silo host)."
  },
  "blog/announcing-orleans-2.1.html": {
    "href": "blog/announcing-orleans-2.1.html",
    "title": "Announcing Orleans 2.1 | Microsoft Orleans Documentation",
    "keywords": "Announcing Orleans 2.1 Reuben Bond 10/1/2018 7:17:59 PM Today, we announced Orleans 2.1. This release includes significant performance improvements over 2.0, a major refresh of distributed transaction support, a new code generator, and new functionality for co-hosting scenarios as well as smaller fixes & improvements. Read the release notes here . New Scheduler Starting with Orleans 2.1, we have a rewritten core scheduler which takes advantage of performance improvements to .NET Core's ThreadPool . The new scheduler uses work stealing queues with local queue affinity to reduce contention and improve throughput and latency. These improvements are available on all platforms/frameworks. Community members have reported significant responsiveness and throughput improvements in their services and our testing indicates up to 30% higher throughput. This new scheduler also exhibits much lower CPU usage during low-load periods, benefiting co-hosting scenarios and improving the CPU profiling experience. Special thanks to Dmytro Vakulenko from the community for driving this work from theory through to experimentation & completion. Distributed Transactions Orleans originated from Microsoft Research and we continue to partner with MSR and product teams to bring features such as scalable distributed transactions into production. Distributed transactions support was first introduced as an experimental feature in Orleans 2.0, and in 2.1 we are refreshing the release with a new, fully decentralized, transaction manager. Aside from the improvements to the transaction manager, the entire transactions system has continued to receive heavy investment in order to ready the code for production and a stable release in a future version of Orleans. We consider distributed transactions to be in \"release candidate\" quality in 2.1. Learn about distributed transactions in Orleans from Sergey's talk, Distributed Transactions are dead, long live distributed transactions! from J On the Beach 2018 . Read the research papers on transactions, actor-oriented database systems, and other topics from the Orleans Microsoft Research site . Direct Client Orleans 2.1 introduces a new way to interact with grains and interoperate with frameworks like ASP.NET or gRPC. The feature is called direct client and it allows co-hosting a client and silo in a way that let the client communicate more efficiently with not just the silo it's attached to, but the entire cluster. Once direct client is enabled, IClusterClient and IGrainFactory can be resolved from the silo container and used to create grain references which can be called. These calls use the local silo's knowledge of the cluster and grain placement to avoid unnecessary copying, serialization, and networking hops. In addition, because this feature shares the same internals as the silo itself, it provides a seamless experience when it comes to passing grain references between threads. In Orleans 2.1 we have made direct client an opt-in feature. Enable it by calling ISiloHostBuilder.EnableDirectClient() during silo configuration. New Code Generator This release includes a new code generation package, Microsoft.Orleans.CodeGenerator.MSBuild , an alternative to the existing package, Microsoft.Orleans.OrleansCodeGenerator.Build . The new code generator leverages Roslyn for code analysis to avoid loading application binaries. As a result, it avoids issues caused by clashing dependency versions and differing target frameworks. If you experience issues, please let us know by opening an issue on GitHub . The new code generator also improves support for incremental builds, which should result in shorter build times. Other Improvements Grain methods can return ValueTask<T> - thanks to @kutensky Removed per-call Timer allocation , reducing .NET Timer queue contention Fixes for silo shutdown behavior - thank you to @yevhen for reporting and investigating Configure grain collection idle time using [CollectionAgeLimit(Minutes = x)] - thanks to @aRajeshKumar Known Issues with .NET Core 2.1 User Sun Zhongfeng reported an issue running Orleans on .NET Core 2.1 with TieredCompilation enabled. We tracked this down to a JIT issue in CoreCLR , which the CoreCLR team quickly diagnosed and fixed. TieredCompilation is not enabled by default in .NET Core 2.1 and this fix is not expected to land in .NET Core 2.1, but will be included in .NET Core 2.2 . Do not enable TieredCompilation if you are running Orleans on .NET Core 2.1. We would like to thank everyone in the community who contributed to this release and helped testing the pre-release builds."
  },
  "blog/de-inventing-the-wheel.html": {
    "href": "blog/de-inventing-the-wheel.html",
    "title": "De-inventing the wheel | Microsoft Orleans Documentation",
    "keywords": "De-inventing the wheel Julian Dominguez 4/12/2017 2:49:11 PM The Microsoft Orleans project started many years ago in Microsoft Research, when not even the Task class existed. As the project matured, many non-core abstractions & functionality was needed to support its growth. These abstractions didn't exist as standards in .NET and .NET OSS was in its infancy. Examples of these pieces are cross-cutting concerns such as Logging, Configuration, and Dependency Injection. As time passed, some common abstractions and patterns emerged, and it reached a point where it makes sense to just adopt them. There are many reasons as to why: Developers are used to the standard patterns and abstractions, so newcomers do not need to learn these non-core abstractions just to use Orleans. Standard abstractions have an enormous level of adoption with almost every 3rd party component related to that abstraction. On the other hand, today it requires that the Orleans community builds integration packages to many 3rd party components (ie: to use Serilog, log4net, or push events to ETW), as the owners of these will just create integration packages for the common abstractions, but not for Orleans or any other non-standard abstraction. We created custom abstractions to be good enough to do the job, but we don't focus too much after that on usability, as it just goes into maintenance mode. Sometimes we find out that these abstractions were not good enough, so we must make breaking changes (for example our move to non-static clients and silos requires a non-static logging abstraction). These standard abstractions are very well thought out to do that specific job, and are generally very flexible, simple to use, and have a lot of documentation. We just stand on their shoulders. Deleting code that is not important to Orleans core functionality is always good. We already started using the Microsoft.Extensions.DependencyInjection abstractions for enabling DI, moving away for our poor man's object activation (and 2-step initialization) approach in many places. As we move forward, we plan to deprecate some of our custom abstractions in favor of standard ones. In particular we are already thinking of 2 upcoming changes: Migrate our logging abstractions to Microsoft.Extensions.Logging . Revamp our configuration and startup pattern to align with ASP.NET Core's. See dotnet/orleans#2936 for an initial design of this move. As always, we'll try to keep breaking changes to a minimum, but we don't strictly prevent breaking changes. Sometimes we make our new versions be source code compatible (meaning that developers can't simply use binding redirects on Orleans assemblies, but re-building their code might still compile) or require a few minimal fixes. Sometimes breaking changes are *bigger* if they would just affect a small feature or something that is typically not spread-out through the entire codebase of our users (such as extensibility points that do not affect grain code). Also, it seems like an appropriate time to look at these abstractions with a fresh mind, since that's what the .NET community seems to be doing when looking forward at things like ASP.NET and .NET Core."
  },
  "blog/dmitry-vakulenko.html": {
    "href": "blog/dmitry-vakulenko.html",
    "title": "Dmitry Vakulenko | Microsoft Orleans Documentation",
    "keywords": "Dmitry Vakulenko Sergey Bykov 11/19/2018 1:57:59 PM Dmitry Vakulenko joined the Orleans open source community three years ago, and started submitting pull requests that focused on improving performance of the Orleans codebase. He became the most prolific contributor outside of the current and former members of the core team. Dmitry also contributed other improvements, but his passion continued to be performance. Because of the compound nature of incremental optimizations, over time these improvements added up to a staggering aggregate factor. Our conservative estimate is that Dmitry's contributions combined increased performance of Orleans by about 2.6 times. Dmitry's latest contribution was the reimplemented Scheduler. Scheduler is the \"heart\" of the Orleans runtime that is responsible for efficient processing of incoming requests while ensuring the single-threaded execution of each of the many thousands of grain activations. The new version of the Scheduler contributed by Dmitry was 30% faster than the original one, yet simpler and much more debugging friendly. It became the key feature of the 2.1.0 release. After many months of waiting for his visa, Dmitry was finally scheduled to join the core team as a full-time Microsoft employee on October 15th. We later learned that he had passed away three days before that date. This is a big tragedy and an immense loss for us and the whole open source community around Orleans. We lost a very talented engineer who was so early in his career and had all roads open to him. We lost a colleague and a friend with whom we collaborated for years and were looking forward to work even closer. We are incredibly grateful to Dmitry for all he has done. It is still hard to believe that he is not with us anymore. He will be remember as a brilliant mind and an even-tempered human being always open to new ideas and ready to help. Thank you for everything, Dmitry!"
  },
  "blog/fix-visual-studio-2015-with-orleans-tools-for-visual-studio-1.4.0 installed.html": {
    "href": "blog/fix-visual-studio-2015-with-orleans-tools-for-visual-studio-1.4.0 installed.html",
    "title": "Fix Visual Studio 2015 with Orleans Tools for Visual Studio 1.4.0 installed | Microsoft Orleans Documentation",
    "keywords": "Fix Visual Studio 2015 with Orleans Tools for Visual Studio 1.4.0 installed Attila Hajdrik 3/10/2017 10:06:17 AM Today two community members was hit by an issue with Visual Studio 2015 if they've installed the 1.4.0 version of the Orleans VSIX package. We have an open issue to track this on GitHub . If you installed the extension on Visual Studio 2017, it will work, only 2015 has this problem. The issue we're seeing is that you cannot open the Tools & Extensions window, VS will show this error dialog: While we working on the solution we unpublished the problematic version and published an older version of the extension which does not work with Visual Studio 2017, but neither it renders Visual Studio 2015 unusable. If you were hit by this isse, here are the steps to fix it: 1) Exit all Visual Studio instances. 2) Open an Administrator Visual Studio developer command prompt. 3) cd /D \"%USERPROFILE%\\Local Settings\\Microsoft\\VisualStudio\\14.0\\Extensions\" 4) dir OrleansVSTools.dll /s You'll get a result like this: Directory of C:\\Users\\\\Local Settings\\Microsoft\\VisualStudio\\14.0\\Extensions\\pxzkggpq.50t 03/10/2017 02:36 PM 18,608 OrleansVSTools.dll 1 File(s) 18,608 bytes 5) Copy the full directory path to clipboard. 6) rmdir \"\" /q /s Make sure you're still in the Extensions directory. 7) del *.cache 8) devenv /setup This can run for a few minutes...be patient. Now you can start Visual Studio 2015 and verify that the Extensions dialog opens and everything works fine. If you've special root suffixes configured for Visual Studio 2015 then you've to execute these commands for that specific instance, so not in the 14.0, but maybe in the 14.0Exp directory. UPDATE 3/17/2017 We published an updated VSIX which works correctly with VS2013, VS2015, VS2017: Microsoft Orleans Tools for Visual Studio"
  },
  "blog/index.html": {
    "href": "blog/index.html",
    "title": "Orleans Blog | Microsoft Orleans Documentation",
    "keywords": "Solving a Transactions Performance Mystery Reuben Bond 12/7/2018 10:08:58 AM After arriving in Redmond and completing the mandatory New Employee Orientation, my first task on the Orleans team has been to assist with some ongoing performance investigations in order to ensure that Orleans' Transactions support is ready for internal users and hence release. We were seeing significant performance issues and a large number of transaction failures in the stress/load tests against our test cluster. A large fraction of transactions were stalling until timeout. Dmitry Vakulenko Sergey Bykov 11/19/2018 1:57:59 PM Dmitry Vakulenko joined the Orleans open source community three years ago, and started submitting pull requests that focused on improving performance of the Orleans codebase. He became the most prolific contributor outside of the current and former members of the core team. Dmitry also contributed other improvements, but his passion continued to be performance. Because of the compound nature of incremental optimizations, over time these improvements added up to a staggering aggregate factor. Our conservative estimate is that Dmitry's contributions combined increased performance of Orleans by about 2.6 times. Announcing Orleans 2.1 Reuben Bond 10/1/2018 7:17:59 PM Today, we announced Orleans 2.1. This release includes significant performance improvements over 2.0, a major refresh of distributed transaction support, a new code generator, and new functionality for co-hosting scenarios as well as smaller fixes & improvements. Read the release notes here ."
  },
  "blog/latest-release-1.3.1.html": {
    "href": "blog/latest-release-1.3.1.html",
    "title": "Latest release - 1.3.1 | Microsoft Orleans Documentation",
    "keywords": "Latest release - 1.3.1 Sergey Bykov 12/1/2016 5:48:39 PM On November 15th we published our latest release - 1.3.1 . It is a patch release with a number of bug fixes and improvements that have been merged into master since 1.3.0. There were two main reasons for 1.3.1. 343 Industries needed a release with a couple of improvements to streaming and the EventHub stream provider to simplify their migration from the pre-released version of the streaming stack they've been running since before Halo 5 launch. Orleankka needed a rather advanced feature that would allow them to control interleaving of requests on a per-message basis. @yevhen submitted a PR for that after a few design and implementation iterations. So, 1.3.1 isn't a pure patch release because it includes a new feature. We thought it was okay here because of how non-impactful to others the feature really is. If you are upgrading to 1.3.1 from a 1.2.x or earlier release, beware of the subtle breaking change that was made in 1.3.0. The 1.3.0 release notes called it out: NB: There is a subtle breaking change in this release, which is unfortunately easy to miss. If you are using AzureSilo.Start(ClusterConfiguration config, string deploymentId) in your code, that overload has been removed, but the new one that replaced it has the same argument signature with a different second argument: (ClusterConfiguration config, string connectionString) . Deployment ID now has to be passed as part of the config argument:config.Globals.DeploymentId. This removed the ambiguous possibility of passing two different Deployment IDs, but unfortunately at the cost of the breaking API change. 1.3.0 was a pretty big release with numerous improvements, bug fixes, and the major new feature of geo-distributed multi-clusters. Most of its content is listed in the 1.3.0-beta2 release notes . The geo-distribution functionality is described in the Multi-Cluster Support section of the docs."
  },
  "blog/orleans-1.4-and-2.0-tech-preview-2-for-.net-core-released.html": {
    "href": "blog/orleans-1.4-and-2.0-tech-preview-2-for-.net-core-released.html",
    "title": "Orleans 1.4 and 2.0 Tech Preview 2 for .NET Core released | Microsoft Orleans Documentation",
    "keywords": "Orleans 1.4 and 2.0 Tech Preview 2 for .NET Core released Julian Dominguez 3/2/2017 5:54:19 PM Orleans 1.4.0 A few weeks ago we release Orleans 1.4.0 to NuGet.org, where the main new themes were: Revamped JournaledGrain for event sourcing with support for geo-distributed log-based consistency providers. Abstraction of Grain Services with fixed-placed per-silo application components with their workload partitioned via cluster consistency ring. Support for heterogeneous silos with non-uniform distribution of available grain classes. Cluster membership provider for Service Fabric. Of course, there's a lot of other improvement and bug fixes, that you can read about here: Orleans v1.4.0 release notes Orleans 2.0 Tech Preview 2 for .NET Core In addition to our standard releases, we have been working in a vNext feature that supports .NET Standard (and .NET Core hosts). Similar to TP1, this new preview is not at complete full parity with the Orleans 1.X releases, but it's getting pretty close. We have done a lot of bug fixes since the last preview, and also this one is up to date with the latest version in our master branch (a little bit ahead of 1.4.0). Differences with Orleans 1.X Some notable differences or pending things in this pre-release: Orleans code generation Build time codegen (Microsoft.Orleans.OrleansCodeGenerator.Build nuget package) only works if building on Windows with either Visual Studio 2017 or the latest dotnet CLI. Nevertheless, runtime codegen is a viable alternative that works cross-platform (by referencing Microsoft.Orleans.OrleansCodeGenerator package in the Silo host and client projects). BinaryFormatter (built-in .NET Serialization) is not yet available in .NET Standard, and it was being used as the default fallback serializer in Orleans (and typically used mostly when serializing exceptions). Now we have a custom IL based fallback serializer that should be fast and powerful, but might behave somewhat differently if you have existing code relying on [Serializable] . System.Diagnostic.Trace.CorrelationManager.ActivityId is not supported in .NET Standard. If you were relying on this to correlate grain calls, consider using Orleans.Runtime.RequestContext.ActivityId instead. Is Orleans 2.0 TP2 production ready? Not yet. Big disclaimer: We do our CI testing in .NET (because our tests heavily rely on AppDomains to create an in-memory cluster of silos, and those are not supported in .NET Core, but we plan to tackle that soon). We have done some basic manual testing in .NET Core (both Windows and Linux), and we have some of our contributors using it to develop new services. Getting feedback (and PRs!) is one of the main goals of this release, and not to be used in production yet. Also, there is no guarantee that this technical preview is entirely backwards compatible with Orleans 1.4, even for the features that were fully ported. Once we are closer to a stable release, we’ll list all the breaking changes that we know of in case you are interested in upgrading your application from 1.X to 2.0. Where to get it Because this tech preview is not as full featured or stable as the 1.X releases is that we are only releasing in MyGet for now. You can get the NuGet packages by following the steps to configure the feed here: https://dotnet.myget.org/gallery/orleans-ci HelloWorld Sample We now have a very simple sample in our repo that you can use to try Orleans in .NET Core (whether that's in Windows, Linux or MacOS). The sample is located at https://github.com/dotnet/orleans/tree/master/Samples/HelloWorld.NetCore . Enjoy it, play with it, and lets us know what you think, either as GitHub issues, PRs or just come hang out in our Gitter channel."
  },
  "blog/orleans-2.0-tech-preview-supporting-.net-core.html": {
    "href": "blog/orleans-2.0-tech-preview-supporting-.net-core.html",
    "title": "Orleans 2.0 Tech Preview supporting .NET Core | Microsoft Orleans Documentation",
    "keywords": "Orleans 2.0 Tech Preview supporting .NET Core Julian Dominguez 12/5/2016 11:52:59 AM It's been a long migration to have Orleans be .NET Standard compatible, but we finally have a minimum viable release ready to start playing with in .NET Core! :) Orleans 2.0 Tech Preview 1 was just released to MyGet: https://dotnet.myget.org/gallery/orleans-ci (or https://dotnet.myget.org/F/orleans-ci/api/v3/index.json to configure the feed in NuGet) Differences with Orleans 1.X Orleans 2.0 Tech Preview is not as full featured as Orleans 1.X, as we ported the minimum needed to have a decent experience, and arguably the hardest/riskiest portion to port. We expect the rest of the extensions to be migrated much faster from now on. Some notable differences or pending things in this pre-release: Orleans code generation Build time codegen (Microsoft.Orleans.OrleansCodeGenerator.Build nuget package) only works if building on Windows with .NET 4.6.2 installed. It also requires .NET Core preview3 tooling or greater (VS2017 RC if building in VS). Nevertheless, runtime codegen is a viable alternative that works cross-platform (by referencing Microsoft.Orleans.OrleansCodeGenerator package in the Silo host and client projects). For reliable cluster membership, storage, and stream, only Azure Storage providers were migrated for now. The rest are coming soon (or feel free to contribute a port for them). BinaryFormatter (built-in .NET Serialization) is not yet available in .NET Standard, and it was being used as the default fallback serializer in Orleans (and typically used mostly when serializing exceptions). Now we have a custom IL based fallback serializer that should be fast and powerful, but might behave somewhat differently if you have existing code relying on [Serializable]. System.Diagnostic.Trace.CorrelationManager.ActivityId is not supported in .NET Standard. If you were relying on this to correlate grain calls, consider using Orleans.Runtime.RequestContext.ActivityId instead. Is it production ready? No. Big disclaimer: We do our CI testing in .NET (because our tests heavily rely on AppDomains to create an in-memory cluster of silos, and those are not supported in .NET Core, but we plan to tackle that soon). We have done some basic manual testing in .NET Core (both Windows and Linux), but expect some issues. Getting feedback (and PRs!) is one of the main goals of this release, and not to be used in production yet. Also, there is no guarantee that this technical preview is entirely backwards compatible with Orleans 1.3, even for the features that were fully ported. Once we are closer to a stable release, we'll list all the breaking changes that we know of in case you are interested in upgrading your application from 1.3 to 2.0. Because this tech preview is not as full featured as the 1.X releases is that we are only release in MyGet for now. Running sample I created a small Hello World sample app that runs in .NET Core, and you are welcome to use it as a starting point. The sample is located here: https://github.com/jdom/OrleansHelloWorldSample.Core Sample application running Orleans in Linux Enjoy it, play with it, and lets us know what you think, either as GitHub issues, PRs or just come hang out in our Gitter channel."
  },
  "blog/orleans-and-midori.html": {
    "href": "blog/orleans-and-midori.html",
    "title": "Orleans and Midori | Microsoft Orleans Documentation",
    "keywords": "Orleans and Midori Sergey Bykov 12/11/2016 10:56:13 PM Reading the epic Joe Duffy’s 15 Years of Concurrency post brought some old memories from the early days of Orleans. It even compelled me to dig up and try to compile the code from 2009. It was an entertaining exercise. When we were just starting the Orleans project, we would meet and talk with Midori people on a regular basis. That was natural not only because of some obvious overlap of the problem spaces, but also because Jim Larus who conceived Orleans was one of the creators of Singularity , the base from which Midori started. We immediately borrowed the promises library of Midori because we wanted to use the promise-based concurrency for safe execution and efficient RPC. We didn’t bother to try to integrate the code, and simply grabbed the binaries and checked them in into our source tree. We were at an early prototyping stage, and didn’t have to worry about the long term yet. At the time, grain interfaces looked like this: [Eventual] public interface ISimpleGrain : IEventual { [Eventual] PVoid SetA(int a); [Eventual] PVoid SetB(int b); [Eventual] PInt32 GetAxB(); } PVoid and Pint32 were moral equivalents of Task and Task<int> in TPL . Unlike Tasks, they had a bunch of static methods, with one of the simpler overloads taking two lambdas: one for success case and one to handle a thrown exception: public static PVoid When(PVoid target, Action fn, Action<Exception> catchFn); A trivial grain method looked like: public PVoid SetA(int a) { this.a = a; return PVoid.DONE; } You can see here where TaskDone.Done came from. A simple unit test method looked rather convoluted: [TestMethod] public void SimpleGrainDataFlow() { result = new ResultHandle(); Runner.Enqueue(new SimpleTodo(() => { Promise<SimpleGrainReference> clientPromise = SimpleGrainReference.GetReference(\"foo\"); PVoid.When(clientPromise, reference => { grain = reference; Assert.IsNotNull(grain); PVoid setPromise = grain.SetA(3); PVoid.When(setPromise, () => { setPromise = grain.SetB(4); PVoid.When(setPromise, () => { PInt32 intPromise = grain.GetAxB(); PVoid.When<Int32>(intPromise, x => { result.Result = x; result.Done = true; }, exc => { Assert.Fail(\"Exception thrown by GetAxB: \" + exc.Message); return PVoid.DONE; }); }, exc => { Assert.Fail(\"Exception thrown by SetB: \" + exc.Message); return PVoid.DONE; }); }, exc => { Assert.Fail(\"Exception thrown by SetA: \" + exc.Message); return PVoid.DONE; }); }, exc => { result.Exception = exc; result.Done = true; return PVoid.DONE; }); })); Assert.IsTrue(result.WaitForFinished(timeout)); Assert.IsNotNull(result.Result); Assert.AreEqual(12, result.Result); } The nested Whens were necessary to organize a data flow execution pipeline. Runner was an instance of ForeignTodoRunner , which was one of the ways of injecting asynchronous tasks ( ToDo s) into a TodoManager . TodoManager was a single-threaded execution manager a.k.a. a vat, the notion that came from E language . Initialization of the vat-based execution system was a few lines of code: todoManager = new TodoManager(); Thread t = new Thread(todoManager.Run); t.Name = \"Unit test TodoManager\"; t.Start(); runner = new ForeignTodoRunner(todoManager); Within a silo, we also used vats for managing single-threaded execution of grain turns. As part of silo startup we set up N of them to match the number of available CPU cores: for (int i = 0; i < nTodoManagers; i++) { todoManagers[i] = new TodoManager(); for (int j = 0; j < runnerFactor; j++) todoRunners[i \\* runnerFactor + j] = new ForeignTodoRunner(todoManagers[i]); Thread t = new Thread(todoManagers[i].Run); t.Name = String.Format(\"TodoManager: {0}\", i); t.Start(); } We argued with Dean Tribble at the time that using static methods on promises in our view was too inconvenient for most developers. We wanted them to be instance methods instead. A few months later we introduced our own promises, AsyncCompletion and AsyncValue . They were wrappers around Task and Task of TPL and had instance methods. This compressed the code by quite a bit: [TestMethod] public void SimpleGrainDataFlow() { ResultHandle result = new ResultHandle(); SimpleGrainReference grain = SimpleGrainReference.GetReference(\"foo\"); AsyncCompletion setPromise = grain.SetA(3); setPromise.ContinueWith(() => { setPromise = grain.SetB(4); setPromise.ContinueWith( () => { AsyncValue<int> intPromise = grain.GetAxB(); intPromise.ContinueWith( x => { result.Result = x; result.Done = true; }); }); }); Assert.IsTrue(result.WaitForFinished(timeout)); Assert.IsNotNull(result.Result); Assert.AreEqual(12, result.Result); } Initially, we allowed grain methods to be synchronous, and had grain references be their asynchronous proxies. public class SimpleGrain : GrainBase { public void SetA(int a) public void SetB(int b) public int GetAxB() } public class SimpleGrainReference : GrainReference { public AsyncCompletion SetA(int a) public AsyncCompletion SetB(int b) public AsyncValue<int> GetAxB() } We quickly realized that was a bad idea, and switched to grain methods returning AsyncCompletion / AsyncValue<T> . We went through and eventually discarded a number of other bad ideas. We supported properties on grain classes. Async setters were a problem, and in general, async properties were rather misleading and provided no benefit over explicit getter methods. We initially supported .NET events on grains. Had to scrap them because of the fundamentally synchronous nature of += and -= operations in .NET. Why didn’t we simply use Task / Task<T> instead of AsyncCompletion / AsyncValue<T> ? We needed to intercept every scheduling and continuation call in order to guarantee single-threaded execution. Task was a sealed class, and hence we couldn’t subclass it to override the key methods we needed. We didn’t have a custom TPL scheduler yet either. After we switched to using our own promises, we lost the opportunity to use some of the advanced features that Midori had for theirs. For example, they supported a three-party promise handoff protocol. If node A called node B and held a promise for that call, but B as part of processing the request made a call to C for the final value, B could hand off a reference to the promise held by A, so that C could reply directly to A instead of making an extra hop back to B. In this tradeoff between performance and complexity we chose to prioritize for simplicity. Another lesson we learned from talking to Midori people was that the source of some of the hardest to track down bugs in their codebase was interleaving of execution turns. Even though a vat had a single thread to execute all turns (synchronous pieces of code between yield points), it was totally legal for it to execute turns belonging to different requests in an arbitrary order. Imagine your component is processing a request and needs to call another component, for example, make an IO call in the middle of it. You make that IO call, receive a promise for its completion or its return value, and schedule a continuation with a When or ContinueWith call. The trap here is that when the IO call completes and the scheduled continuation starts executing, it is too easy to assume that the state of the component hasn’t changed since the IO call was issued. In fact, the component might have received and processed a number of other requests while asynchronously waiting for that IO call, and processing of those requests could have mutated the state of the component in a non-obvious way. The Midori team was very senior. At the time, the majority of them were principal and partner level engineers and architects. We wondered if interleaving was so perilous to people of that caliber and experience, it must be even worse for mere mortals like us. That lead to the later decision to make grains in Orleans non-reentrant by default. At around the same time, Niklas Gustafsson worked on project Maestro that was later renamed and released as Axum . We had an intern prototype one of the early Orleans applications on Axum to compare the programming experience with the promise-based one in spring of 2009. We concluded that the promises model was more attainable for developers. In parallel Niklas created a proposal and a prototype of what eventually, after he convinced Anders Hejlsberg and others, became the async / await keywords in C#. By now it propagated to even more languages. After .NET 4.5 with async and await was released, we finally abandoned AsyncCompletion / AsyncValue<T> in favor of Task / Task<T> to leverage the power of await. It was another tradeoff that made us rewrite our scheduler a couple of times (not a trivial task) and give up some of the nice features we had in our promises. For example, before we could easily detect if grain code tried to block the thread by calling Result or Wait() on an unresolved promise, and throw an InvalidOperationException to indicate that this was not allowed in the cooperative multi-tasking environment of a silo. We couldn’t do that anymore. But we gained the cleaner programming model that we have today: public interface ISimpleGrain : IGrainWithIntegerKey { Task SetA(int a); Task SetB(int b); Task<int> GetAxB(); } [Fact, TestCategory(\"BVT\"), TestCategory(\"Functional\")] public async Task SimpleGrainDataFlow() { var grain = GrainFactory.GetGrain<ISimpleGrain>(GetRandomGrainId()); Task setAPromise = grain.SetA(3); Task setBPromise = grain.SetB(4); await Task.WhenAll(setAPromise, setBPromise); var x = await grain.GetAxB(); Assert.Equal(12, x); } Midori was an interesting experiment of a significant scale, to try to build a ‘safe by construction’ OS with asynchrony and isolation top to bottom. It is always difficult to judge such efforts in terms of successes, failures, and missed opportunities. One thing is clear – Midori did influence early thinking and design about asynchrony and concurrency in Orleans, and helped bootstrap its initial prototypes."
  },
  "blog/refresh-of-orleans-2.0-tech-preview-with-orleanssqlutils-added.html": {
    "href": "blog/refresh-of-orleans-2.0-tech-preview-with-orleanssqlutils-added.html",
    "title": "Refresh of Orleans 2.0 Tech Preview with OrleansSQLUtils added | Microsoft Orleans Documentation",
    "keywords": "Refresh of Orleans 2.0 Tech Preview with OrleansSQLUtils added Sergey Bykov 12/15/2016 2:45:47 PM We published a refresh of the 2.0 Tech Preview, in which we added the Microsoft.Orleans.OrleansSqlUtils package. This enables using Microsoft SQL Server, MySQL, PosgreSQL, and other compatible SQL servers for cluster membership storage and grain state persistence. Big thanks to Gutemberg Ribeiro for helping with that! You can get packages from MyGet: https://dotnet.myget.org/gallery/orleans-ci (or https://dotnet.myget.org/F/orleans-ci/api/v3/index.json to configure the feed in NuGet)."
  },
  "blog/solving-a-transactions-performance-mystery.html": {
    "href": "blog/solving-a-transactions-performance-mystery.html",
    "title": "Solving a Transactions Performance Mystery | Microsoft Orleans Documentation",
    "keywords": "Solving a Transactions Performance Mystery Reuben Bond 12/7/2018 10:08:58 AM After arriving in Redmond and completing the mandatory New Employee Orientation, my first task on the Orleans team has been to assist with some ongoing performance investigations in order to ensure that Orleans' Transactions support is ready for internal users and hence release. We were seeing significant performance issues and a large number of transaction failures in the stress/load tests against our test cluster. A large fraction of transactions were stalling until timeout. Our initial investigations focused on the transaction management code. Maybe there was a deadlock somewhere. We took a divide-and-conquer approach, replacing internal transaction components with stubbed-out variants. The problem was more-or-less isolated to the ITransactionalState<T> implementation which sits on every grain. The transactional state is responsible for loading and modifying grain state and handling the various transaction phases (Start, Prepare, Abort, Commit, Confirm) as well as optimizing multiple overlapping transactions within the isolation guarantees using a reader-writer lock. You can see that it's not a small amount of code, but isolating the issue further was proving difficult for reasons not limited to the fact that taking out any one piece was not showing a dramatic improvement. Profiling data is critical for performance investigations, so after requesting obtaining permissions to directly access the machines in our test cluster, we collected ETW logs using PerfView using a command similar to this: PerfView.exe /acceptEULA /noGui /threadTime /zip /maxCollectSec:30 /dataFile:1.etl collect Analyzing the resulting .etl file locally, looking at a flame graph for the stack trace samples, the problem is immediately apparent. PerfView makes the cause of the issue apparent. The details are too small to read on that view, but by hovering the mouse over each of the bars we can see which method that stack frame represents. The arrows point to the stack frames where the CPU is waiting on a lock and in this case, that lock is on the global .NET Timer queue. The plateau towards the right is from the thread servicing the timer queue and firing the expired timers, which also needs to acquire the lock. Our load tests are running on .NET Framework 4.6.2 and therefore System.Threading.Timer is implemented using a global queue (linked list) of timers which is protected by a single lock object. Any operations on this queue must acquire that lock. This is something we were already aware of and Orleans 2.1.0 includes a PR which alleviates potential lock contention on this queue for our main source of timers (response timeout timers). The transactions code never uses Timer , so why is this a problem? Transactions makes use of Task.Delay for several kinds of tasks and it shows up in most components. This is why we couldn't narrow down the performance issues to one particular piece of code. Task.Delay uses a Timer under the hood, creating a Timer which might fire once (if it isn't canceled) and deregisters it once it's no longer needed. Our use of Task.Delay was causing this performance degradation under load. A .NET Core 3.0 user may never have seen such contention, since a good deal of work has gone into .NET Core to improve Timer and Task.Delay performance. See #14527 and #20302 . How do we fix this contention? After verifying that a fix here would actually remedy the problem (success!), I set to work implementing a hopefully simple replacement for Task.Delay . The result is in this PR . The gist of how it works is that it uses a single Timer instance to service thread-local timer collections. The firing of the timers does not need to be precise, so having a timer fire late is not a concern in these uses. Lock contention is largely avoided by using thread-local data structures, but safety is retained by using a light-weight reentrant Interlock.CompareExchange lock. See the PR for more details. The implementation is based on earlier work by @dVakulen in #2060 and resulted in an approximately 4x increase in throughput with failure rates dropping to zero. Mystery solved."
  },
  "blog/welcome-to-orleans-blog.html": {
    "href": "blog/welcome-to-orleans-blog.html",
    "title": "Welcome to Orleans Blog | Microsoft Orleans Documentation",
    "keywords": "Welcome to Orleans Blog Attila Hajdrik 12/1/2016 2:15:01 PM This post is written by Sergey Bykov. Better later than never - we finally started a blog for Orleans. Yes, it is somewhat ironic for a project that originated back in late 2008 and went open source nearly two years ago. We hope to compensate for the missed time with some quality content. We plan to share our thoughts, plans, learnings, tips and tricks, and ideas, crazy and otherwise, which don't easily fit the documentation format. We would also like to see here posts from the community members, sharing their experiences, ideas, and wisdom. So, welcome to Orleans Blog, both as a reader and as a blogger!"
  },
  "docs/benefits.html": {
    "href": "docs/benefits.html",
    "title": "Main Benefits | Microsoft Orleans Documentation",
    "keywords": "Benefits The main benefits of Orleans are: developer productivity , even for non-expert programmers, and transparent scalability by default with no special effort from the programmer. We expand on both of these benefits below. Developer Productivity The Orleans programming model raises productivity of both expert and non-expert programmers by providing the following key abstractions, guarantees, and system services. Familiar object-oriented programming (OOP) paradigm . Grains are .NET classes that implement declared .NET grain interfaces with asynchronous methods. Thus, grains appear to the programmer as remote objects whose methods can be directly invoked. This provides the programmer the familiar OOP paradigm by turning method calls into messages, routing them to the right endpoints, invoking the target grain's methods, and dealing with failures and corner cases in a completely transparent way. Single-threaded execution of grains . The runtime guarantees that a grain never executes on more than one thread at a time. Combined with the isolation from other grains, the programmer never faces concurrency at the grain level, and never needs to use locks or other synchronization mechanisms to control access to shared data. This feature alone makes development of distributed applications tractable for non-expert programmers. Transparent activation . The runtime activates a grain only when there is a message for it to process. This cleanly separates the notion of creating a reference to a grain, which is visible to and controlled by application code, and physical activation of the grain in memory, which is transparent to the application. In many ways, this is similar to virtual memory in that it decides when to “page out” (deactivate) or “page in” (activate) a grain; the application has uninterrupted access to the full “memory space” of logically created grains, whether or not they are in the physical memory at any particular point in time. Transparent activation enables dynamic, adaptive load balancing via placement and migration of grains across the pool of hardware resources. This features is a significant improvement on the traditional actor model, in which actor lifetime is application-managed. Location transparency . A grain reference (proxy object) that the programmer uses to invoke the grain's methods or pass to other components contains only the logical identity of the grain. The translation of the grain's logical identity to its physical location and the corresponding routing of messages are done transparently by the Orleans runtime. Application code communicates with grains while remaining oblivious to their physical location, which may change over time due to failures or resource management or because a grain is deactivated at the time it is called. Transparent integration with persistent store . Orleans allows for declarative mapping of a grain's in-memory state to a persistent store. It synchronizes updates, transparently guaranteeing that callers receive results only after the persistent state has been successfully updated. Extending and/or customizing the set of existing persistent storage providers available is straight-forward. Automatic propagation of errors . The runtime automatically propagates unhandled errors up the call chain with the semantics of asynchronous and distributed try/catch. As a result, errors do not get lost within an application. This allows the programmer to put error handling logic at the appropriate places, without the tedious work of manually propagating errors at each level. Transparent Scalability by Default The Orleans programming model is designed to guide the programmer down a path of likely success in scaling an application or service through several orders of magnitude. This is done by incorporating proven best practices and patterns and by providing an efficient implementation of the lower level system functionality. Here are some key factors that enable scalability and performance: Implicit fine grain partitioning of application state . By using grains as directly addressable entities, the programmer implicitly breaks down the overall state of their application. While the Orleans programming model does not prescribe how big or small a grain should be, in most cases it makes sense to have a relatively large number of grains – millions or more – with each representing a natural entity of the application, such as a user account or a purchase order. With grains being individually addressable and their physical location abstracted away by the runtime, Orleans has enormous flexibility in balancing load and dealing with hot spots in a transparent and generic way without any thought from the application developer. Adaptive resource management . Grains make no assumption about the locality of other grains as they interact with them. Because of this location transparency, the runtime can manage and adjust allocation of available hardware resources in a dynamic way. The runtime does this by making fine-grained decisions on placement and migration of grains across the compute cluster in reaction to load and communication patterns - without failing incoming requests. By creating multiple replicas of a particular grain, the runtime can increase throughput of the grain without making any changes to the application code. Multiplexed communication . Grains in Orleans have logical endpoints, and messaging among them is multiplexed across a fixed set of all-to-all physical connections (TCP sockets). This allows the runtime to host millions of addressable entities with low OS overhead per grain. In addition, activation and deactivation of a grain does not incur the cost of registering/unregistering of a physical endpoint, such as a TCP port or HTTP URL, or even closing a TCP connection. Efficient scheduling . The runtime schedules execution of a large number of single-threaded grains across a custom thread pool with a thread per physical processor core. With grain code written in the non-blocking, continuation-based style (a requirement of the Orleans programming model), application code runs in a very efficient “cooperative” multi-threaded manner with no contention. This allows the system to reach high throughput and run at very high CPU utilization (up to 90%+) with great stability. The fact that a growth in the number of grains in the system and an increase in the load does not lead to additional threads or other OS primitives helps scalability of individual nodes and the whole system. Explicit asynchrony . The Orleans programming model makes the asynchronous nature of a distributed application explicit and guides programmers to write non-blocking asynchronous code. Combined with asynchronous messaging and efficient scheduling, this enables a large degree of distributed parallelism and overall throughput without the explicit use of multi-threading."
  },
  "docs/deployment/azure_web_apps_with_azure_cloud_services.html": {
    "href": "docs/deployment/azure_web_apps_with_azure_cloud_services.html",
    "title": "Using Azure Web Apps with Azure Cloud Services | Microsoft Orleans Documentation",
    "keywords": "Using Azure Web Apps with Azure Cloud Services If you would like to connect to an Azure Cloud Services Silo from an Azure Web App rather than a Web Role hosted within the same cloud service you can. For this to work securely you will need to assign both the Azure Web App and the Worker Role hosting the Silo to an Azure Virtual Network . First we'll setup the Azure Web App, you can follow this guide which will create the virtual network and assign it to the Azure Web App. Now we can assign the cloud service to the virtual network by modifying the ServiceConfiguration file. <NetworkConfiguration> <VirtualNetworkSite name=\"virtual-network-name\" /> <AddressAssignments> <InstanceAddress roleName=\"role-name\"> <Subnets> <Subnet name=\"subnet-name\" /> </Subnets> </InstanceAddress> </AddressAssignments> </NetworkConfiguration> Also make sure the Silo endpoints are configured. <Endpoints> <InternalEndpoint name=\"OrleansSiloEndpoint\" protocol=\"tcp\" port=\"11111\" /> <InternalEndpoint name=\"OrleansProxyEndpoint\" protocol=\"tcp\" port=\"30000\" /> </Endpoints> You can now connect from the Web App to the rest of the cluster. Potential Issues If the Web App is having difficulty connecting to the Silo: Make sure you have at least two roles , or two instances of one role in your Azure Cloud Service, or the InternalEndpoint firewall rules may not be generated. Check that both the Web App and the Silo are using the same ClusterId and ServiceId . Make sure the network security group is set up to allow internal virtual network connections. If you haven't got one you can create and assign one easily using the following PowerShell : New-AzureNetworkSecurityGroup -Name \"Default\" -Location \"North Europe\" Get-AzureNetworkSecurityGroup -Name \"Default\" | Set-AzureNetworkSecurityGroupToSubnet -VirtualNetworkName \"virtual-network-name\" -SubnetName \"subnet-name\""
  },
  "docs/deployment/consul_deployment.html": {
    "href": "docs/deployment/consul_deployment.html",
    "title": "Using Consul as a Membership Provider | Microsoft Orleans Documentation",
    "keywords": "Using Consul as a Membership Provider Introduction to Consul Consul is a distributed, highly available and datacenter-aware service discovery platform which includes simple service registration, health checking, failure detection and key/value storage. It is built on the premise that every node in the datacenter is running a Consul agent which is either acting as a server or client which communicate via a scalable gossip protocol. There is a very detailed overview of Consul including comparisons with similar solutions here . Consul is written in GO and is open source ; compiled downloads are available for Mac OS X, FreeBSD, Linux, Solaris and Windows Why Choose Consul? As an Orleans Membership Provider , Consul is a good choice when you need to deliver an on-premise solution which does not require your potential customers to have existing infrastructure and a co-operative IT provider. Consul is a very lightweight single executable, has no dependencies and as such can easily be built into your own middleware solution. And when Consul is already your solution for discovering, checking and maintaining your microservices, it makes sense to fully integrate with Orleans membership for simplicity and ease of operation. We therefore implemented a membership table in Consul (also known as \"Orleans Custom System Store\"), which fully integrates with Orleans's Cluster Management . Setting up Consul There is very extensive documentation available on Consul.io about setting up a stable Consul cluster and it doesn't make sense to repeat that here; however for your convenience we include this guide so you can very quickly get Orleans running with a standalone Consul agent. 1) Create a folder to install Consul into, e.g. C:\\Consul 2) Create a subfolder: C:\\Consul\\Data (Consul will not create this if it doesn't exist) 3) Download and unzip Consul.exe into C:\\Consul\\ 4) Open a command prompt at C:\\Consul\\ 5) Enter Consul.exe agent -server -bootstrap -data-dir \"C:\\Consul\\Data\" -client=0.0.0.0 agent Instructs Consul to run the agent process that hosts the services. Without this the Consul process will attempt to use RPC to configure a running agent. -server Defines the agent as a server and not a client (A Consul client is an agent that hosts all the services and data, but does not have voting rights to decide, and cannot become, the cluster leader -bootstrap The first (and only the first!) node in a cluster must be bootstrapped so that it assumes the cluster leadership. -data-dir [path] Specifies the path where all Consul data is stored, including the cluster membership table -client=0.0.0.0 Informs Consul which IP to open the service on. There are many other parameters, and the option to use a json configuration file. Please consult the Consul documentation for a full listing of the options. 6) Verify that Consul is running and ready to accept membership requests from Orleans by opening the services endpoint in your browser. Configuration of Orleans Server There is currently a known issue with the \"Custom\" membership provider OrleansConfiguration.xml configuration file that will fail to parse correctly. For this reason you have to provide a placeholder SystemStore in the xml and then configure the provider in code before starting the Silo. OrleansConfiguration.xml <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <SystemStore SystemStoreType=\"None\" DataConnectionString=\"http://localhost:8500\" DeploymentId=\"MyOrleansDeployment\" /> </Globals> <Defaults> <Networking Address=\"localhost\" Port=\"22222\" /> <ProxyingGateway Address=\"localhost\" Port=\"30000\" /> </Defaults> </OrleansConfiguration> Code public void Start(ClusterConfiguration config) { _siloHost = new SiloHost(System.Net.Dns.GetHostName(), config); _siloHost.Config.Globals.LivenessType = GlobalConfiguration.LivenessProviderType.Custom; _siloHost.Config.Globals.MembershipTableAssembly = \"OrleansConsulUtils\"; _siloHost.Config.Globals.ReminderServiceType = GlobalConfiguration.ReminderServiceProviderType.Disabled; _siloHost.InitializeOrleansSilo(); var startedok = _siloHost.StartOrleansSilo(); if (!startedok) throw new SystemException(String.Format(\"Failed to start Orleans silo '{0}' as a {1} node\", _siloHost.Name, _siloHost.Type)); Log.Information(\"Orleans Silo is running.\\n\"); } Alternatively you could configure the silo entirely in code. Client The client configuration is much simpler ClientConfiguration.xml <ClientConfiguration xmlns=\"urn:orleans\"> <SystemStore SystemStoreType=\"Custom\" CustomGatewayProviderAssemblyName=\"OrleansConsulUtils\" DataConnectionString=\"http://192.168.1.26:8500\" DeploymentId=\"MyOrleansDeployment\" /> </ClientConfiguration> Client SDK If you are interested in using Consul for your own service discovery there are Client SDKs for most popular languages. Implementation Detail The Membership Table Provider makes use of Consul's Key/Value store functionality with CAS. When each Silo starts it registers two KV entries, one which contains the Silo details and one which holds the last time the Silo reported it was alive (the latter refers to diagnostics \"I am alive\" entries and not to failure detection hearbeats which are sent directly between the silos and are not written into the table). All writes to the table are performed with CAS to provide concurrency control, as necessitated by Orleans's Cluster Management Protocol . Once the Silo is running you can view these entries in your web browser here , this will display something like: [ \"orleans/MyOrleansDeployment/192.168.1.26:11111@191780753\", \"orleans/MyOrleansDeployment/192.168.1.26:11111@191780753/iamalive\" ] You will notice that the keys are prefixed with \"orleans/\" this is hard coded in the provider and is intended to avoid key space collision with other users of Consul. Each of these keys can be read by appending their key name (sans quotes of course) to the Consul KV root . Doing so will present you with the following: [ { \"LockIndex\": 0, \"Key\": \"orleans/MyOrleansDeployment/192.168.1.26:22222@191780753\", \"Flags\": 0, \"Value\": \"[BASE64 UTF8 Encoded String]\", \"CreateIndex\": 10, \"ModifyIndex\": 12 } ] Decoding the string will give you the actual Orleans Membership data: http://localhost:8500/v1/KV/orleans/MyOrleansDeployment/[SiloAddress] { \"Hostname\": \"[YOUR_MACHINE_NAME]\", \"ProxyPort\": 22222, \"StartTime\": \"2016-01-29T16:25:54.9538838Z\", \"Status\": 3, \"SuspectingSilos\": [] } http://localhost:8500/v1/KV/orleans/MyOrleansDeployment/[SiloAddress]/IAmAlive \"2016-01-29T16:35:58.9193803Z\" When the Clients connect, they read the KVs for all silos in the cluster in one HTTP GET by using the uri http://192.168.1.26:8500/v1/KV/orleans/MyOrleansDeployment/?recurse . Limitations Orleans Extended Membership Protocol (Table Version & ETag) Consul KV currrently does not currently support atomic updates. Therefore, the Orleans Consul Membership Provider only implements the the Orleans Basic Membership Protocol, as described here and does not support the Extended Membership Protocol. This Extended protocol was introduced as an additional, but not essential, silo connectivity validation and as a foundation to functionality that has not yet been implemented. Providing your infrastructure is correctly configured you will not experience any detrimental effect of the lack of support. Multiple Datacenters The Key Value Pairs in Consul are not currently replicated between Consul datacenters. There is a separate project to address this but it has not yet been proven to support Orleans. When running on Windows When Consul starts on Windows it logs the following message: ==> WARNING: Windows is not recommended as a Consul server. Do not use in production. This is displayed simply due to lack of focus on testing when running in a Windows environment and not because of any actual known issues. Read the discussion here before deciding if Consul is the right choice for you. Potential Future Enhanecements 1) Prove that the Consul KV replication project is able to support an Orleans cluster in a WAN environment between multiple Consul datacenters. 2) Implement the Reminder Table in Consul. 3) Implement the Extended Membership Protocol. The team behind Consul does plan on implementing atomic operations, once this functionality is available it will be possible to remove the limitations in the provider."
  },
  "docs/deployment/docker_deployment.html": {
    "href": "docs/deployment/docker_deployment.html",
    "title": "Docker Deployment | Microsoft Orleans Documentation",
    "keywords": "Docker Deployment Note : Even if you are very familiar with Docker and/or Orleans, as any other Orleans documentation, I recommend you to read it to the end in order to avoid problems you may face that we already worked around. Note : This article and its sample are a work in progress. Any feedback, PR or suggestion is very welcome. Deploying Orleans solutions to Docker Deploying Orleans to Docker can be tricky given the way Docker orchestrators and clustering stacks was designed. The most complicated thing is to understand the concept of Overlay Network from Docker Swarm and Kubernets Networking model. Docker containers and networking model were designed to run mostly stateless and immutable containers. So, spinning up a cluster running node.js or nginx applications, is pretty easy. However, if you try to use something more elaborate, like a real clustered or distributed application (like Orleans-based ones) you will eventually have trouble setting it up. It is possible, but not as simple as web-based applications. Docker clustering consists of putting together multiple hosts to work as a single pool of resources, managed using a Container Orchestrator . Docker Inc. provide Swarm as their option for Container Orchestration while Google has Kubernetes (aka K8s ). There are other Orchestrators like DC/OS , Mesos , etc., but in this document we will talk about Swarm and K8s as they are more widely used. The same grain interfaces and implementation which run anywhere Orleans is already supported, will run on Docker containers as well, so no special considerations are needed in order to be able to run your application in Docker containers. The Orleans-Docker sample provides a working example of how to run two console applications. One as Orleans Client and another as Silo, and the details are described below. The concepts discussed here, can be used on both .Net Core and .Net 4.6.1 flavors of Orleans but to ilustrate the cross-platform nature of Docker and .Net Core, we are going to focus on the example considering you are using .Net Core. Platform-specific (Windows/Linux/OSX) details may be provide along this article. Pre-requisites This article assume that you have the following prerequisites installed: Docker - Docker4X has a easy-to-use installer for the major supported platforms. It contains Docker engine and also Docker Swarm. Kubernetes (K8s) - Google's offer for Container Orchestration. It contains a guidance to install Minikube (a local deployment of K8s) and kubectl along with all its dependencies. .Net Core - Cross-platform flavor of .Net Visual Studio Code (VSCode) - You can use whatever IDE you want. VSCode is cross-platform so we are using it to ensure it works on all platforms. Once you installed VSCode, install the C# extension . Note : You are not required to have Kubernetes installed if you are not going to use it. Docker4X installer already includes Swarm so no extra installation is required to use it. Note for Windows Users : On Windows, Docker installer will enable Hyper-V at installation process. As this article and its examples are using .Net Core, the container images used are based on Windows Server NanoServer . If you don't plan to use .Net Core and will target .Net 4.6.1 full framework, the image used should be Windows Server Core and the 1.4+ version of Orleans (which supports only .net full framework). Creating Orleans Solution The following instructions show how to create a regular Orleans solution using the new dotnet tooling. Note : Please adapt the commands to whatever is appropriate in your platform. Also, the directory structure is just a suggestion. Please adapt it to your needs. mkdir Orleans-Docker cd Orleans-Docker dotnet new sln mkdir -p src/OrleansSilo mkdir -p src/OrleansClient mkdir -p src/OrleansGrains mkdir -p src/OrleansGrainInterfaces dotnet new console -o src/OrleansSilo --framework netcoreapp1.1 dotnet new console -o src/OrleansClient --framework netcoreapp1.1 dotnet new classlib -o src/OrleansGrains --framework netstandard1.5 dotnet new classlib -o src/OrleansGrainInterfaces --framework netstandard1.5 dotnet sln add src/OrleansSilo/OrleansSilo.csproj dotnet sln add src/OrleansClient/OrleansClient.csproj dotnet sln add src/OrleansGrains/OrleansGrains.csproj dotnet sln add src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansClient/OrleansClient.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansSilo/OrleansSilo.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansGrains/OrleansGrains.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansSilo/OrleansSilo.csproj reference src/OrleansGrains/OrleansGrains.csproj What we did so far was just boilerplate code to create the solution structure, projects, and add references between projects. Nothing different than a regular Orleans project. By the time this article was written, Orleans 2.0 (which is the only version which support .Net Core and cross-platform) is in Technology Preview so its nugets are hosted in a MyGet feed and not published to Nuget.org official feed. In order to install the preview nugets, we will use dotnet cli forcing the source feed and version from MyGet: dotnet add src/OrleansClient/OrleansClient.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansGrains/OrleansGrains.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansSilo/OrleansSilo.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansSilo/OrleansSilo.csproj package Microsoft.Orleans.OrleansRuntime -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet restore Ok, now you have all the basic dependencies to run a simple Orleans application. Note that so far, nothing changed from your regular Orleans application. Now, lets add some code so we can do something with it. Implementing your Orleans Application Assuming that you are using VSCode , from the solution directory, run code . . That will open the directory in VSCode and load the solution. This is the solution structure we just created previously. We also added Program.cs , OrleansHostWrapper , IGreetingGrain and GreetingGrain files to the interfaces and grain projects respectively and here is the code for those files: IGreetingGrain.cs : using System; using System.Threading.Tasks; using Orleans; namespace OrleansGrainInterfaces { public interface IGreetingGrain : IGrainWithGuidKey { Task<string> SayHello(string name); } } GreetingGrain.cs : using System; using System.Threading.Tasks; using OrleansGrainInterfaces; namespace OrleansGrains { public class GreetingGrain : Grain, IGreetingGrain { public Task<string> SayHello(string name) { return Task.FromResult($\"Hello from Orleans, {name}\"); } } } OrleansHostWrapper.cs : using System; using System.Net; using Orleans.Runtime; using Orleans.Runtime.Configuration; using Orleans.Runtime.Host; namespace OrleansSilo { public class OrleansHostWrapper { private readonly SiloHost siloHost; public OrleansHostWrapper(ClusterConfiguration config) { siloHost = new SiloHost(Dns.GetHostName(), config); siloHost.LoadOrleansConfig(); } public int Run() { if (siloHost == null) { return 1; } try { siloHost.InitializeOrleansSilo(); if (siloHost.StartOrleansSilo()) { Console.WriteLine($\"Successfully started Orleans silo '{siloHost.Name}' as a {siloHost.Type} node.\"); return 0; } else { throw new OrleansException($\"Failed to start Orleans silo '{siloHost.Name}' as a {siloHost.Type} node.\"); } } catch (Exception exc) { siloHost.ReportStartupError(exc); Console.Error.WriteLine(exc); return 1; } } public int Stop() { if (siloHost != null) { try { siloHost.StopOrleansSilo(); siloHost.Dispose(); Console.WriteLine($\"Orleans silo '{siloHost.Name}' shutdown.\"); } catch (Exception exc) { siloHost.ReportStartupError(exc); Console.Error.WriteLine(exc); return 1; } } return 0; } } } Program.cs (Silo): using System; using System.Collections.Generic; using System.Linq; using System.Net; using Orleans.Runtime.Configuration; namespace OrleansSilo { public class Program { private static OrleansHostWrapper hostWrapper; static int Main(string[] args) { int exitCode = InitializeOrleans(); Console.WriteLine(\"Press Enter to terminate...\"); Console.ReadLine(); exitCode += ShutdownSilo(); return exitCode; } private static int InitializeOrleans() { var config = new ClusterConfiguration(); config.Globals.DataConnectionString = \"[AZURE STORAGE CONNECTION STRING HERE]\"; config.Globals.DeploymentId = \"Orleans-Docker\"; config.Globals.LivenessType = GlobalConfiguration.LivenessProviderType.AzureTable; config.Globals.ReminderServiceType = GlobalConfiguration.ReminderServiceProviderType.AzureTable; config.Defaults.PropagateActivityId = true; config.Defaults.ProxyGatewayEndpoint = new IPEndPoint(IPAddress.Any, 10400); config.Defaults.Port = 10300; var ips = Dns.GetHostAddressesAsync(Dns.GetHostName()).Result; config.Defaults.HostNameOrIPAddress = ips.FirstOrDefault()?.ToString(); hostWrapper = new OrleansHostWrapper(config); return hostWrapper.Run(); } private static int ShutdownSilo() { if (hostWrapper != null) { return hostWrapper.Stop(); } return 0; } } } Program.cs (client): using System; using System.Net; using System.Threading; using System.Threading.Tasks; using Orleans; using Orleans.Runtime.Configuration; using OrleansGrainInterfaces; namespace OrleansClient { class Program { private static IClusterClient client; private static bool running; static void Main(string[] args) { Task.Run(() => InitializeOrleans()); Console.ReadLine(); running = false; } static async Task InitializeOrleans() { var config = new ClientConfiguration(); config.DeploymentId = \"Orleans-Docker\"; config.PropagateActivityId = true; var hostEntry = await Dns.GetHostEntryAsync(\"orleans-silo\"); var ip = hostEntry.AddressList[0]; config.Gateways.Add(new IPEndPoint(ip, 10400)); Console.WriteLine(\"Initializing...\"); client = new ClientBuilder().UseConfiguration(config).Build(); await client.Connect(); running = true; Console.WriteLine(\"Initialized!\"); var grain = client.GetGrain<IGreetingGrain>(Guid.Empty); while(running) { var response = await grain.SayHello(\"Gutemberg\"); Console.WriteLine($\"[{DateTime.UtcNow}] - {response}\"); await Task.Delay(1000); } client.Dispose(); } } } We are not going into details about the grain implementation here since it is out of the scope of this article. Please check other documents related to it. Those files are essentially a minimal Orleans application and we will start from it to move forward with the remaining of this article. Note : In this article we are using OrleansAzureUtils membership provider but you can use any other already supported by Orleans. Dockerfile In order to create your container, Docker uses images. For more details on how to create your own, you can check Docker documentation . In this article we are going to use official Microsoft images . Based on the target and development platforms, you need to pick the appropriate image. In this article, we are using microsoft/dotnet:1.1.2-sdk which is a linux-based image. You can use microsoft/dotnet:1.1.2-sdk-nanoserver for Windows for example. Pick one that suit your needs. Note for Windows users : As previously mentioned, to be cross-platform, we are using .Net Core and Orleans Technical preview 2.0 in this article. If you want to use Docker on Windows with the fully released Orleans 1.4+, you need to use the images that are based on Windows Server Core since NanoServer and Linux based images, only support .Net Core. Dockerfile.debug : FROM microsoft/dotnet:1.1.2-sdk ENV NUGET_XMLDOC_MODE skip WORKDIR /vsdbg RUN apt-get update \\ && apt-get install -y --no-install-recommends \\ unzip \\ && rm -rf /var/lib/apt/lists/* \\ && curl -sSL https://aka.ms/getvsdbgsh | bash /dev/stdin -v latest -l /vsdbg WORKDIR /app ENTRYPOINT [\"tail\", \"-f\", \"/dev/null\"] This dockerfile essentially downloads and installs the VSdbg debugger and starts an empty container, keeping it alive forever so we don't need tear down/up while debugging. Now, for production, the image is smaller since it contains only the .Net Core runtime and not the whole SDK, and the dockerfile is a bit simpler: Dockerfile : FROM microsoft/dotnet:1.1.2-runtime WORKDIR /app ENTRYPOINT [\"dotnet\", \"OrleansSilo.dll\"] COPY . /app docker-compose The docker-compose.yml file, essentially defines (within a project) a set of services and its dependencies at service level. Each service contains one or more instances of a given container, which is based on the images you selected on your Dockerfile. More details on the docker-compose can be found on docker-compose documentation . For an Orleans deployment, a common use case is to have a docker-compose.yml which contains two services. One for Orleans Silo, and other for Orleans Client. The Client would have a dependency on the Silo and that means, it will only start after the Silo service is up. Another case is to add a storage/database service/container, like for example SQL Server, which should start first before the client and the silo, so both services should take a dependency on it. Note : Before you read further (and eventually get crazy with it), please note that identation matters in docker-compose files. So pay attention to it if you have any problem. Here is how we will describe our services for this article: docker-compose.override.yml (Debug): version: '3.1' services: orleans-client: image: orleans-client:debug build: context: ./src/OrleansClient/bin/PublishOutput/ dockerfile: Dockerfile.Debug volumes: - ./src/OrleansClient/bin/PublishOutput/:/app - ~/.nuget/packages:/root/.nuget/packages:ro depends_on: - orleans-silo orleans-silo: image: orleans-silo:debug build: context: ./src/OrleansSilo/bin/PublishOutput/ dockerfile: Dockerfile.Debug volumes: - ./src/OrleansSilo/bin/PublishOutput/:/app - ~/.nuget/packages:/root/.nuget/packages:ro docker-compose.yml (production): version: '3.1' services: orleans-client: image: orleans-client depends_on: - orleans-silo orleans-silo: image: orleans-silo Note that in production, we don't map the local directory and neither we have the build: action. The reason is that in production, the images should be built and pushed to your own Docker Registry. Put everything together Now we have all the moving parts required to run your Orleans Application, we are going to put it together so we can run our Orleans solution inside Docker (Finally!). Note : The following commands should be performed from the solution directory. First, lets make sure we restore all NuGet packages from our solution. You only need to do it once. You are only required to do it again if you change any package dependency on your project. # dotnet restore Now, let's build our solution using dotnet CLI as usual and publish it to an output directory: # dotnet publish -o ./bin/PublishOutput Note : We are using publish here instead of build, to avoid problems with our dynamicaly loaded assemblied in Orleans. We are still looking for a better solution for it. With the application built and published, you need to build your Dockerfile images. This step is only required to be performed once per project and should be only performed again if you change the Dockerfile, docker-compose, or for any reason you cleaned up your local image registry. # docker-compose build All the images used in both Dockerfile and docker-compose.yml are pulled from the registry and cached on your development machine. Your images are built, and you are all set to run. Now lets run it! # docker-compose up -d Creating network \"orleansdocker_default\" with the default driver Creating orleansdocker_orleans-silo_1 ... Creating orleansdocker_orleans-silo_1 ... done Creating orleansdocker_orleans-client_1 ... Creating orleansdocker_orleans-client_1 ... done # Now if you run a docker-compose ps , you will see 2 containers running for the orleansdocker project: # docker-compose ps Name Command State Ports ------------------------------------------------------------------ orleansdocker_orleans-client_1 tail -f /dev/null Up orleansdocker_orleans-silo_1 tail -f /dev/null Up Note for Windows users : If you are on Windows, and your container is using a Windows image as base, the Command column will show you the Powershell relative command to a tail on *NIX systems so the container will keep up the same way. Now that you have your containers up, you don't need to stop it every time you want to start your Orleans application. All you need is to integrate your IDE to debug the application inside the container which was previously mapped in your docker-compose.yml . Scaling Once you have your compose project running, you can easily scale up or down your application using docker-compose scale command: # docker-compose scale orleans-silo=15 Starting orleansdocker_orleans-silo_1 ... done Creating orleansdocker_orleans-silo_2 ... Creating orleansdocker_orleans-silo_3 ... Creating orleansdocker_orleans-silo_4 ... Creating orleansdocker_orleans-silo_5 ... Creating orleansdocker_orleans-silo_6 ... Creating orleansdocker_orleans-silo_7 ... Creating orleansdocker_orleans-silo_8 ... Creating orleansdocker_orleans-silo_9 ... Creating orleansdocker_orleans-silo_10 ... Creating orleansdocker_orleans-silo_11 ... Creating orleansdocker_orleans-silo_12 ... Creating orleansdocker_orleans-silo_13 ... Creating orleansdocker_orleans-silo_14 ... Creating orleansdocker_orleans-silo_15 ... Creating orleansdocker_orleans-silo_6 Creating orleansdocker_orleans-silo_5 Creating orleansdocker_orleans-silo_3 Creating orleansdocker_orleans-silo_2 Creating orleansdocker_orleans-silo_4 Creating orleansdocker_orleans-silo_9 Creating orleansdocker_orleans-silo_7 Creating orleansdocker_orleans-silo_8 Creating orleansdocker_orleans-silo_10 Creating orleansdocker_orleans-silo_11 Creating orleansdocker_orleans-silo_15 Creating orleansdocker_orleans-silo_12 Creating orleansdocker_orleans-silo_14 Creating orleansdocker_orleans-silo_13 Few seconds later, you will see the services scaled to the specific number of instances you requested. # docker-compose ps Name Command State Ports ------------------------------------------------------------------ orleansdocker_orleans-client_1 tail -f /dev/null Up orleansdocker_orleans-silo_1 tail -f /dev/null Up orleansdocker_orleans-silo_10 tail -f /dev/null Up orleansdocker_orleans-silo_11 tail -f /dev/null Up orleansdocker_orleans-silo_12 tail -f /dev/null Up orleansdocker_orleans-silo_13 tail -f /dev/null Up orleansdocker_orleans-silo_14 tail -f /dev/null Up orleansdocker_orleans-silo_15 tail -f /dev/null Up orleansdocker_orleans-silo_2 tail -f /dev/null Up orleansdocker_orleans-silo_3 tail -f /dev/null Up orleansdocker_orleans-silo_4 tail -f /dev/null Up orleansdocker_orleans-silo_5 tail -f /dev/null Up orleansdocker_orleans-silo_6 tail -f /dev/null Up orleansdocker_orleans-silo_7 tail -f /dev/null Up orleansdocker_orleans-silo_8 tail -f /dev/null Up orleansdocker_orleans-silo_9 tail -f /dev/null Up Note : The Command column on those examples are showing the tail command just because we are using the debugger container. If we were in production, it would be showing dotnet OrleansSilo.dll for example. Docker Swarm Docker clustering stack is called Swarm and you can find more by reading its documentation here . To run this article in a Swarm cluster, you don't have any extra work. When you run docker-compose up -d in a Swarm node, it will schedule containers based on the configured rules. The same applies to other Swarm-based services like Docker Datacenter , Azure ACS (in Swarm mode), AWS ECS Container Service and so on. All you need to do is to deploy your Swarm cluster before deploy your dockerized Orleans application. Note : If you are using a Docker engine with the Swarm mode that already have support to stack , deploy and compose v3, a better approach to deploy your solution would be docker stack deploy -c docker-compose.yml <name> . Just keep in mind that it requires v3 compose file support at your Docker engine and the majority of hosted services like Azure and AWS still use v2 and older engines. Google Kubernetes (K8s) If you plan to use Kubernetes to host Orleans, there is a community-maintained clustering provider available at OrleansContrib\\Orleans.Clustering.Kubernetes and there you can find documentation and samples on how to host Orleans in Kubernetes seamlessly using the provider. [Bonus topic] Debugging Orleans inside Containers Well, now that you know how to run Orleans in a container from scratch, would be good to leverage one of the most important principles in Docker. Containers are immutable. And they should have (almost) the same image, dependencies, and runtime in development as in production. This ensures the good old statement \"It works on my machine!\" never happens again. To make that possible, you need to have a way to develop inside the container and that includes have a debugger attached to your application inside the container. There are multiple ways to achieve that using multiple tools. After evaluating several, by the time I wrote this article, I ended up choosing one that looks more simple and is less intrusive in the application. As mentioned ealier in this article, we are using VSCode to develop the sample, so here is how to get the debugger attached to your Orleans Application inside the container. First, change two files inside your .vscode directory in your solution: tasks.json : { \"version\": \"0.1.0\", \"command\": \"dotnet\", \"isShellCommand\": true, \"args\": [], \"tasks\": [ { \"taskName\": \"publish\", \"args\": [ \"${workspaceRoot}/Orleans-Docker.sln\", \"-c\", \"Debug\", \"-o\", \"./bin/PublishOutput\" ], \"isBuildCommand\": true, \"problemMatcher\": \"$msCompile\" } ] } This file essentially tells VSCode that whenever you build the project, it will actually execute the publish command as we manually did earlier. launch.json : { \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Silo\", \"type\": \"coreclr\", \"request\": \"launch\", \"cwd\": \"/app\", \"program\": \"/app/OrleansSilo.dll\", \"sourceFileMap\": { \"/app\": \"${workspaceRoot}/src/OrleansSilo\" }, \"pipeTransport\": { \"debuggerPath\": \"/vsdbg/vsdbg\", \"pipeProgram\": \"/bin/bash\", \"pipeCwd\": \"${workspaceRoot}\", \"pipeArgs\": [ \"-c\", \"docker exec -i orleansdocker_orleans-silo_1 /vsdbg/vsdbg --interpreter=vscode\" ] } }, { \"name\": \"Client\", \"type\": \"coreclr\", \"request\": \"launch\", \"cwd\": \"/app\", \"program\": \"/app/OrleansClient.dll\", \"sourceFileMap\": { \"/app\": \"${workspaceRoot}/src/OrleansClient\" }, \"pipeTransport\": { \"debuggerPath\": \"/vsdbg/vsdbg\", \"pipeProgram\": \"/bin/bash\", \"pipeCwd\": \"${workspaceRoot}\", \"pipeArgs\": [ \"-c\", \"docker exec -i orleansdocker_orleans-client_1 /vsdbg/vsdbg --interpreter=vscode\" ] } } ] } Now you can just build the solution from VSCode (which will publish) and start both the Silo and the Client. It will send a docker exec command to the running docker-compose service instance/container to start the debugger to the application and thats it. You have the debugger attached to the container and use it as if it was a locally running Orleans application. The difference now is that it is inside the container, and once you are done, you can just publish the container to your registry and pull it on your Docker hosts in production."
  },
  "docs/deployment/handling_failures.html": {
    "href": "docs/deployment/handling_failures.html",
    "title": "Handling Failures | Microsoft Orleans Documentation",
    "keywords": "Handling Failures Note: All of the following guidance in this document is provided to serve as examples and food for thought. You should not think of them as prescriptive solutions to your problems because failure handling is a rather application-specific subject. These patterns and others are only useful if applied with a good knowledge of the concrete case being worked on. The hardest thing in programming a distributed system is handling failures. The actor model and the way it works makes it much easier to deal with different kinds of failures, but as a developer, you are responsible for dealing with the failure possibilities and handling them in an appropriate way. Types of failures When you are coding your grains, all calls are asynchronous and have the potential to go over the network. Each grain call can possibly fail due to one of the following reasons. The grain was activated on a silo which is unavailable at the moment due to a network partition crash or some other reason. If the silo has not been declared dead yet, your request might time out. The grain method call can throw an exception signaling that it failed and can not continue its job. An activation of the grain doesn't exist and cannot be created because the OnActivateAsync method throws an exception or is dead-locked. Network failures don't let you to communicate with the grain before timeout. Other potential reasons Detection of failures Getting a reference to a grain always succeeds and is a local operation. However, method calls can fail, and when they do, you get an exception. You can catch the exception at any level you need and they are propagated even across silos. Recovering from failures Part of the recovery job is automatic in Orleans and if a grain is not accessible anymore, Orleans will reactivate it in the next method call. The thing you need to handle and make sure is correct in the context of your application is the state. A grain's state can be partially updated or the operation might be something which should be done across multiple grains and is carried on partially. After you see a grain operation fail you can do one or more of the following. Simply retry your action, especially if it doesn't involve any state changes which might be half done. This is by far the most typical case. Try to fix/reset the partially changed state by calling a method which resets the state to the last known correct state or just reads it from storage by calling ReadStateAsync . Reset the state of all related activations as well to ensure a clean state for all of them. Perform multi-grain state manipulations using a Process Manager or database transaction to make sure it's either done completely or nothing is changed to avoid the state being partially updated. Depending on your application, the retry logic might follow a simple or complex pattern, and you might have to do other stuff like notifying external systems and other things, but generally you either have to retry your action, restart the grain/grains involved, or stop responding until something which is not available becomes available. If you have a grain responsible for database saves and the database is not available, you simply have to fail any request until the database comes back online. If your operation can be retried at the user's will, like failure of saving a comment in a comment grain, you can retry when the user presses the retry button (until a certain number of times in order to not saturate the network). Specific details of how to do it are application specific, but the possible strategies are the same. Strategy parameters and choosing a good strategy As described in the section above, the strategy you choose depends on the application and context. Strategies usually have parameters which have to be decided at the application level. For example, if no other processes depend on an action, then you might decide to retry that action a maximum of 5 times per minute until it eventually completes. But you would have to process a user's Login grain request before processing any other requests from that user. If the login action is not working, then you cannot continue. There is a guide in the Azure documentation about good patterns and practices for the cloud which applies to Orleans as well, in most cases. A fairly complex example Because in Orleans grains are activated and deactivated automatically and you don't handle their life-cycle, you usually only deal with making sure that grain state is correct and actions are being started and finished correctly in relation to each other. Knowing the dependencies between grains and actions they perform is a big step toward understanding how to handle failure in any complex system. If you need to store relations among grains, you can simply do it and it is a widely followed practice, too. As an example, let's say we have a GameManager grain which starts and stops Game grains and adds Player grains to the games. If my GameManager grain fails to do its action regarding starting a game, the related game belonging to it should fail to do its Start() as well and the manager can do this for the game by doing orchestration. Managing memory in Orleans is automatic and the system deals with it, you only need to make sure that the game starts and only if manager can do its Start() as well. You can achieve this by either calling the related methods in a sequential manner or by doing them in parallel and resetting the state of all involved grains if any of them fail. If one of the games receives a call, it will be reactivated automatically, so if you need the manager to manage the game grains, then all calls to the game which are related to management should go through the GameManager . If you need orchestration among grains, Orleans doesn't solve it \"automagically\" for you and you need to do your orchestration. But the fact that you are not dealing with creating/destroying grains means you don't need to worry about resource management. You don't need to answer any of these questions: Where should I create my supervision tree? which grains should I register to be addressable by name? Is grain X alive so I can send it a message? ... So, the game start example can be summarized like this: GameManager asks the Game grain to start Game grain adds the Player grains to itself Game asks Player grains to add game to themselves Game sets its state to be started. GameManager adds the game to its list of games. Now, if a player fails to add the game to itself, you don't need to kill all players and the game and start over. You simply reset the state of the other players which added the game to themselves, reset the state of the Game and GameManager (if required), and redo your work or declare a failure. If you can deal with adding the game to the player later on, you can continue and retry doing that again in a reminder or at some other game call like the Finish() method of the game."
  },
  "docs/deployment/index.html": {
    "href": "docs/deployment/index.html",
    "title": "Running the Application | Microsoft Orleans Documentation",
    "keywords": "Orleans Application A typical Orleans application consists of a cluster of server processes (silos) where grains live, and a set of client processes, usually web servers, that receive external requests, turn them into grain method calls, and return results back. Hence, the first thing one needs to do to run an Orleans application is to start a cluster of silos. For testing purposes, a cluster can consist of a single silo. For a reliable production deployment, we obviously want more than one silos in a cluster for fault tolerance and scale. Once the cluster is running, we can start one or more client processes that connect to the cluster and can send requests to the grains. Clients connect to a special TCP endpoint on silos - gateway. By default, every silo in a cluster has a client gateway enabled. So clients can connect to all silos in parallel for better performance and resilience. Configuring and Starting a Silo A silo is configured programmatically via a ClusterConfiguration object. It can be instantiated and populated directly, load settings from a file, or created with several available helper methods for different deployment environments. For local testing, the easiest way to go is to use ClusterConfiguration.LocalhostPrimarySilo() helper method. The configuration object is then passed to a new instance of SiloHost class, that can be initialized and started after that. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for hosting a silo. Add the Microsoft.Orleans.Server NuGet meta-package to the project. PM> Install-Package Microsoft.Orleans.Server Here is an example of how a local silo can be started: var siloConfig = ClusterConfiguration.LocalhostPrimarySilo(); var silo = new SiloHost(\"Test Silo\", siloConfig); silo.InitializeOrleansSilo(); silo.StartOrleansSilo(); Console.WriteLine(\"Press Enter to close.\"); // wait here Console.ReadLine(); // shut the silo down after we are done. silo.ShutdownOrleansSilo(); Configuring and Connecting a Client Client for connecting to a cluster of silos and sending requests to grains is configured programmatically via a ClientConfiguration object and a ClientBuilder . ClientConfiguration object can be instantiated and populated directly, load settings from a file, or created with several available helper methods for different deployment environments. For local testing, the easiest way to go is to use ClientConfiguration.LocalhostSilo() helper method. The configuration object is then passed to a new instance of ClientBuilder class. ClientBuilder exposes more methods for configuring additional client features. After that Build method of the ClientBuilder object is called to get an implementation of IClusterClient interface. Finally, we call Connect() method on the returned object to connect to the cluster. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for running a client or reuse the console application project you created for hosting a silo. Add the Microsoft.Orleans.Client NuGet meta-package to the project. PM> Install-Package Microsoft.Orleans.Client Here is an example of how a client can connect to a local silo: var config = ClientConfiguration.LocalhostSilo(); var builder = new ClientBuilder().UseConfiguration(config). var client = builder.Build(); await client.Connect(); Production Configurations The configuration examples we used here are for testing silos and clients running on the same machine as localhost . In production, silos and clients usually run on different servers and are configured with one of the reliable cluster configuration options. You can find more about that in the Configuration Guide and in the description of Cluster Management ."
  },
  "docs/deployment/kubernetes.html": {
    "href": "docs/deployment/kubernetes.html",
    "title": "Kubernetes hosting | Microsoft Orleans Documentation",
    "keywords": "Kubernetes hosting Kubernetes is a popular choice for hosting Orleans applications. Orleans will run in Kubernetes without specific configuration, however it can also take advantage of extra knowledge which the hosting platform can provide. The Microsoft.Orleans.Hosting.Kubernetes package adds integration for hosting an Orleans application in a Kubernetes cluster. The package provides an extension method, ISiloBuilder.UseKubernetesHosting , which performs the following actions: SiloOptions.SiloName is set to the pod name. EndpointOptions.AdvertisedIPAddress is set to the pod IP. EndpointOptions.SiloListeningEndpoint & EndpointOptions.GatewayListeningEndpoint are configured to listen on any address, with the configured SiloPort and GatewayPort . Defaults port values of 11111 and 30000 are used if no values are set explicitly). ClusterOptions.ServiceId is set to the value of the pod label with the name orleans/serviceId . ClusterOptions.ClusterId is set to the value of the pod label with the name orleans/clusterId . Early in the startup process, the silo will probe Kubernetes to find which silos do not have corresponding pods and mark those silos as dead. The same process will occur at runtime for a subset of all silos, in order to remove the load on Kubernetes' API server. By default, 2 silos in the cluster will watch Kubernetes. Note that the Kubernetes hosting package does not use Kubernetes for clustering. For clustering, a separate clustering provider is still needed. For more information on configuring clustering, see the Server configuration documentation. This functionality imposes some requirements on how the service is deployed: Silo names must match pod names. Pods must have an orleans/serviceId and orleans/clusterId label which corresponds to the silo's ServiceId and ClusterId . The above-mentioned method will propagate those labels into the corresponding options in Orleans from environment variables. Pods must have the following environment variables set: POD_NAME , POD_NAMESPACE , POD_IP , ORLEANS_SERVICE_ID , ORLEANS_CLUSTER_ID . The following example shows how to configure these labels and environment variables correctly: apiVersion: apps/v1 kind: Deployment metadata: name: dictionary-app labels: orleans/serviceId: dictionary-app spec: selector: matchLabels: orleans/serviceId: dictionary-app replicas: 3 template: metadata: labels: # This label is used to identify the service to Orleans orleans/serviceId: dictionary-app # This label is used to identify an instance of a cluster to Orleans. # Typically, this will be the same value as the previous label, or any # fixed value. # In cases where you are not using rolling deployments (for example, # blue/green deployments), # this value can allow for distinct clusters which do not communicate # directly with each others, # but which still share the same storage and other resources. orleans/clusterId: dictionary-app spec: containers: - name: main image: my-registry.azurecr.io/my-image imagePullPolicy: Always ports: # Define the ports which Orleans uses - containerPort: 11111 - containerPort: 30000 env: # The Azure Storage connection string for clustering is injected as an # environment variable # It must be created separately using a command such as: # > kubectl create secret generic az-storage-acct ` # --from-file=key=./az-storage-acct.txt - name: STORAGE_CONNECTION_STRING valueFrom: secretKeyRef: name: az-storage-acct key: key # Configure settings to let Orleans know which cluster it belongs to # and which pod it is running in - name: ORLEANS_SERVICE_ID valueFrom: fieldRef: fieldPath: metadata.labels['orleans/serviceId'] - name: ORLEANS_CLUSTER_ID valueFrom: fieldRef: fieldPath: metadata.labels['orleans/clusterId'] - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_IP valueFrom: fieldRef: fieldPath: status.podIP - name: DOTNET_SHUTDOWNTIMEOUTSECONDS value: \"120\" request: # Set resource requests terminationGracePeriodSeconds: 180 imagePullSecrets: - name: my-image-pull-secret minReadySeconds: 60 strategy: rollingUpdate: maxUnavailable: 0 maxSurge: 1 For RBAC-enabled clusters, the Kubernetes service account for the pods may also need to be granted the required access: kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: pod-reader rules: - apiGroups: [ \"\" ] resources: [\"pods\"] verbs: [\"get\", \"watch\", \"list\"] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: pod-reader-binding subjects: - kind: ServiceAccount name: default apiGroup: '' roleRef: kind: Role name: pod-reader apiGroup: '' Liveness, Readiness, and Startup Probes Kubernetes is able to probe pods to determine the health of a service. For more information, see Configure Liveness, Readiness and Startup Probes in Kubernetes' documentation. Orleans uses a cluster membership protocol to promptly detect and recover from process or network failures. Each node monitors a subset of other nodes, sending periodic probes. If a node fails to respond to multiple successive probes from multiple other nodes, then it will be forcibly removed from the cluster. Once a failed node learns that is has been removed, it terminates immediately. Kubernetes will restart the terminated process and it will attempt to rejoin the cluster. Kubernetes' probes can help to determine whether a process in a pod is executing and is not stuck in a zombie state. probes do not verify inter-pod connectivity or responsiveness or perform any application-level functionality checks. If a pod fails to respond to a liveness probe, then Kubernetes may eventually terminate that pod and reschedule it. Kubernetes' probes and Orleans' probes are therefore complimentary. The recommended approach is to configure Liveness Probes in Kubernetes which perform a simple local-only check that the application is performing as intended. These probes serve to terminate the process in the event that there is a total freeze, for example due to a runtime fault or another unlikely event. Resource quotas Kubernetes works in conjunction with the operating system to implement resource quotas . This allows CPU and memory reservations and/or limits to be enforced. For a primary application which is serving interactive load, we recommend not implementing restrictive limits unless necessary. It is important to note that requests and limits are substantially different in their meaning and where they are implemented. Before setting requests or limits, take the time to gain a detailed understanding of how they are implemented and enforced. For example, memory may not be measured uniformly between Kubernetes, the Linux kernel, and your monitoring system. CPU quotas may not be enforced in the way that you expect. Troubleshooting Pods crash, complaining that KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT must be defined Full exception message: Unhandled exception. k8s.Exceptions.KubeConfigException: unable to load in-cluster configuration, KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT must be defined at k8s.KubernetesClientConfiguration.InClusterConfig() Check that KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT environment variables are set inside your Pod. You can check by executing the following command kubectl exec -it <pod_name> /bin/bash -c env . Ensure that automountServiceAccountToken set to true on your Kubernetes deployment.yaml . For more information, see Configure Service Accounts for Pods"
  },
  "docs/deployment/multi-cluster_support/GlobalSingleInstance.html": {
    "href": "docs/deployment/multi-cluster_support/GlobalSingleInstance.html",
    "title": "Global-Single-Instance Grains | Microsoft Orleans Documentation",
    "keywords": "Grain Coordination Attributes Developers can indicate when and how clusters should coordinate their grain directories with respect to a particular grain class. The [GlobalSingleInstance] attribute means we want the same behavior as when running Orleans in a single global cluster: that is, route all calls to a single activation of the grain. Conversely, the [OneInstancePerCluster] attribute indicates that each cluster can have its own independent activation. This is appropriate if communication between clusters is undesired. The attributes are placed on grain implementations. For example: using Orleans.MultiCluster; [GlobalSingleInstance] public class MyGlobalGrain : Orleans.Grain, IMyGrain { ... } [OneInstancePerCluster] public class MyLocalGrain : Orleans.Grain, IMyGrain { ... } If a grain class does not specify either one of those attributes, it defaults to [OneInstancePerCluster] , or [GlobalSingleInstance] if the configuration parameter UseGlobalSingleInstanceByDefault is set to true. Protocol for Global-Single-Instance Grains When a global-single-instance (GSI) grain is accessed, and no activation is known to exist, a special GSI activation protocol is executed before activating a new instance. Specifically, a request is sent to all other clusters in the current multi-cluster configuration to check if they already have an activation for this grain. If all responses are negative, a new activation is created in this cluster. Otherwise, the remote activation is used (and a reference to it is cached in the local directory). Protocol for One-Instance-Per-Cluster Grains There is no inter-cluster communication for One-Instance-Per-Cluster grains. They simply use the standard Orleans mechanism independently within each cluster. Inside the Orleans framework itself, the following grain classes are marked with the [OneInstancePerCluster] attribute: ManagementGrain , GrainBasedMembershipTable , and GrainBasedReminderTable . Doubtful Activations If the GSI protocol does not receive conclusive responses from all clusters after 3 retries (or whatever number is specified by the configuration parameter GlobalSingleInstanceNumberRetries ), it creates a new local \"doubtful\" activation optimistically, favoring availability over consistency. Doubtful activations may be duplicates (because some remote cluster that did not respond during the GSI protocol activation may nevertheless have an activation of this grain). Therefore, periodically every 30 seconds (or whatever interval is specified by the configuration parameter GlobalSingleInstanceRetryInterval ) the GSI protocol is run again for all doubtful activations. This ensures that once communication between clusters is restored, duplicate activations can be detected and removed."
  },
  "docs/deployment/multi-cluster_support/GossipChannels.html": {
    "href": "docs/deployment/multi-cluster_support/GossipChannels.html",
    "title": "Multi-Cluster Communication | Microsoft Orleans Documentation",
    "keywords": "Multi-Cluster Communication The network must be configured in such a way that any Orleans silo can connect to any other Orleans silo via TCP/IP, regardless of where in the world it is located. Exactly how this is achieved is outside of the scope of Orleans, as it depends on how and where silos are deployed. For example, on Windows Azure, we can use VNETs to connect muliple deployments within a region, and gateways to connect VNETs across different regions. Cluster Id Each cluster has its own unique cluster id. The cluster id must be specified in the global configuration. Cluster ids may not be empty, nor may they contain commas. Also, if using Azure Table Storage, cluster ids may not contain the characters forbidden for row keys (/, , #, ?). We recommend using very short strings for the cluster ids, because cluster ids are transmitted frequently and may be stored in storage by some log-view providers. Cluster Gateways Each cluster automatically designates a subset of its active silos to serve as cluster gateways . Cluster gateways directly advertise their IP addresses to other clusters, and can thus serve as \"points of first contact\". By default, at most 10 silos (or whatever number is configured as MaxMultiClusterGateways ) are designated as cluster gateways. Communication between silos in different clusters does not always pass through a gateway. Once a silo has learned and cached the location of a grain activation (no matter in what cluster), it sends messages to that silo directly, even if the silo is not a cluster gateway. Gossip Gossip is a mechanism for clusters to share configuration and status information. As the name suggests, gossip is decentralized and bidirectional: each silo communicates directly with other silos, both in the same cluster and in other clusters, to exchange information in both directions. Content . Gossip contains some or all of the following information: The current time-stamped multi-cluster configuration . A dictionary that contains information about cluster gateways. The key is the silo address, and the value contains (1) a timestamp, (2) the cluster id, and (3) a status, which is either active or inactive. Fast & Slow Propagation . When a gateway changes its status, or when an operator injects a new configuration, this gossip information is immediately sent to all silos, clusters, and gossip channels. This happens fast, but is not reliable. Should the message be lost due to any reasons (e.g. races, broken sockets, silo failures), our periodic background gossip ensures that the information eventually spreads, albeit more slowly. All information is eventually propagated everywhere, and is highly resilient to occasional message loss and failures. All gossip data is timestamped, which ensures that newer information replaces older information regardless of the relative timing of messages. For example, newer multi-cluster configurations replace older ones, and newer information about a gateway replaces older information about that gateway. For more details on the representation of gossip data, see the MultiClusterData class. It has a Merge method that combines gossip data, resolving conflicts using timestamps. Gossip Channels When a silo is first started, or when it is restarted after a failure, it needs to have a way to bootstrap the gossip . This is the role of the gossip channel , which can be configured in the Silo Configuration . On startup, a silo fetches all the information from the gossip channels. After startup, a silo keeps gossiping periodically, every 30 seconds or whatever is configured as BackgroundGossipInterval . Each time it synchronizes its gossip information with a partner randomly selected from all cluster gateways and gossip channels. Notes: Though not strictly required, we recommend to always configure at least two gossip channels, in distinct regions, for better availability. Latency of communication with gossip channels is not critical. Multiple different services can use the same gossip channel without interference, as long as the ServiceId Guid (as specified by their respective configuration) is distinct. There is no strict requirement that all silos use the same gossip channels, as long as the channels are sufficient to let a silo initially connect with the \"gossiping community\" when it starts up. But if a gossip channel is not part of a silo's configuration, and that silo is a gateway, it does not push its status updates to the channel (fast propagation), so it may take longer before those reach the channel via periodic background gossip (slow propagation). Azure-Table-Based Gossip Channel We have already implemented a gossip channel based on Azure Tables. The configuration specifies standard connection strings used for Azure accounts. For example, a configuration could specify two gossip channels with separate Azure storage accounts usa and europe as follows: var silo = new SiloHostBuilder() [...] .Configure<MultiClusterOptions>(options => { [...] options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=usa;AccountKey=...\"); options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=europe;AccountKey=...\") [...] }) [...] Multiple different services can use the same gossip channel without interference, as long as the ServiceId guid specified by their respective configuration is distinct. Other Gossip Channel Implementations We are working on other gossip channel providers, similar to how membership and reminders are packaged for many different storage back-ends."
  },
  "docs/deployment/multi-cluster_support/MultiClusterConfiguration.html": {
    "href": "docs/deployment/multi-cluster_support/MultiClusterConfiguration.html",
    "title": "Multi-Cluster Configuration | Microsoft Orleans Documentation",
    "keywords": "Multi-Cluster Configuration The multi-cluster configuration determines which clusters are currently part of the multi-cluster. It does not change automatically, but is controlled by the operator. Thus, it is quite different from the membership mechanism used within a cluster, which automatically determines the set of silos that are part of the cluster. We use the following terminology for the clusters in a service: A cluster is active if it has at least one active silo, and inactive otherwise A cluster is joined if it is part of the current multi-cluster configuration, and non-joined otherwise Being active/inactive is independent from being joined/non-joined: all four combinations are possible. All the clusters for a particular service are connected by a gossip network . The gossip network propagates configuration and status information. Injecting a configuration An operator issues configuration changes by injecting them into the multi-cluster network. The configurations can be injected into any cluster, and spread from there to all active clusters. Each new configuration consists of a list of cluster ids that form the multi-cluster. It also has a UTC timestamp that is used to track its propagation through the gossip network. Initially, the multi-cluster configuration is null, which means the multi-cluster list is empty (contains no clusters). Thus, the operator must initially inject a multi-cluster configuration. Once injected, this configuration persists in all connected silos (while running) and in all specified gossip channels (if those channels are persistent). We pose some restrictions on the injection of new configurations that an operator must follow: Each new configuration may add a number of clusters, or remove a number of clusters (but not both at the same time). An operator should not issue a new configuration while a previous configuration change is still being processed. These restrictions ensure that protocols such as the single-instance-protocol can correctly maintain mutual exclusion of activations even under configuration changes. Via Management Grain Multi-cluster configurations can be injected on any node in any cluster, using the Orleans Management Grain. For example, to inject a multi-cluster configuration that consists of the three clusters { us1, eu1, us2 }, we can pass a string enumerable to the management grain: var clusterlist = \"us1,eu1,us2\".Split(','); var mgtGrain = client.GetGrain<IManagementGrain>(0); mgtGrain.InjectMultiClusterConfiguration(clusterlist, \"my comment here\")); The first argument to InjectMultiClusterConfiguration is an enumerable of cluster ids, which is going to define the new multi-cluster configuration. The second argument is an (optional) comment string that can be used to tag configurations with arbitrary information, such as who injected them and why. There is an optional third argument, a boolean called checkForLaggingSilosFirst , which defaults to true. It means that the system performs a best-effort check to see if there are any silos anywhere that have not caught up to the current configuration yet, and rejects the change if it finds such a silo. This helps to detect violations of the restriction that only one configuration change should be pending at a time (though it cannot guarantee it under all circumstances). Via Default Configuration In situations where the multi-cluster configuration is known in advance and the deployment is fresh every time (e.g. for testing), we may want to supply a default configuration. The global configuration supports an optional attribute DefaultMultiCluster which takes a comma-separated list of cluster ids: var silo = new SiloHostBuilder() [...] .Configure<MultiClusterOptions>(options => { [...] options.DefaultMultiCluster = new[] { \"us1\", \"eu1\", \"us2\" }; [...] }) [...] After a silo is started with this setting, it checks to see if the current multi-cluster configuration is null, and if so, injects the given configuration with the current UTC timestamp. WARNING. Persistent multi-cluster gossip channels (e.g. based on AzureTable) retain the last injected configuration unless they are deleted explicitly. In that case, specifying a DefaultMulticluster has no effect when re-deploying a cluster because the configuration stored in the gossip channels is not null.> Via Gossip Channel An operator can also inject the configuration directly into the gossip channel. Changes in the channel are picked up and propagated automatically by the periodic background gossip, though possibly very slowly (using the management grain is much faster). A rough estimate on the propagation time is 30 seconds (or whatever gossip interval is specified in the global configuration) times the binary logarithm of the total number of silos in all clusters. But since the gossip pairs are selected randomly, it can be both much quicker or much slower. If using the Azure Table-Based Gossip Channel, operators can inject a new configuration simply by editing the configuration record in the OrleansGossipTable , e.g. using some tool for editing data in Azure tables. The configuration record has the following format: Name Type Value PartitionKey String the ServiceId RowKey String \"CONFIG\" Clusters String comma-separated list of cluster IDs, e.g. \"us1,eu1,us2\" Comment String optional comment GossipTimestamp DateTime UTC timestamp for the configuration NOTE . When editing this record in storage, the GossipTimestamp must also be set to a newer value than it has currently (otherwise the change is ignored). The most convenient and recommended way to do this is to delete the GossipTimestamp field - our gossip channel implementation then automatically replaces it with a correct, current Timestamp (it uses the Azure Table Timestamp). Cluster Addition/Removal Procedures Adding or removing a cluster from the multi-cluster often needs to be coordinated within some larger context. We recommend to always follow the procedures described below when adding/removing clusters from the multi-cluster. Procedure for adding a cluster Start a new Orleans cluster and wait till all silos are up and running. Inject a configuration that contains the new cluster. Start routing user requests to the new cluster. Procedure for removing a cluster Stop routing new user requests to the cluster. Inject a configuration that no longer contains the cluster. Stop all silos of the cluster. Once a cluster has been removed in this way, it can be re-added by following the procedure for adding a new cluster. Activity on Non-Joined Clusters There can be brief, temporary periods of time where a cluster is both active and non-joined: A freshly started cluster may start executing code before it is in the multicluster configuration (between steps 1 and 2 of the procedure for adding a cluster) A cluster that is being decommissioned may still execute code before the silos are shut down (between steps 2 and 3 of the procedure for removing a cluster). During those intermediate situations, the following are possible: For global-single-instance grains: A grain may have a duplicate activation on a non-joined cluster. For versioned grains: activations on non-joined clusters do not receive notifications when the grain state changes."
  },
  "docs/deployment/multi-cluster_support/Overview.html": {
    "href": "docs/deployment/multi-cluster_support/Overview.html",
    "title": "Multi-Cluster Support | Microsoft Orleans Documentation",
    "keywords": "Multi-Cluster Support Orleans v.1.3.0 added support for federating several Orleans clusters into a loosely connected multi-cluster that acts like a single service. Multi-clusters facilitate geo-distribution of a service, that is, make it easier to run an Orleans application in multiple data-centers around the world. Also, a multi-cluster can be run within a single datacenter to get better failure and performance isolation. All mechanisms are designed with particular attention to (1) minimize communication between clusters, and (2) let each cluster run autonomously even if other clusters fail or become unreachable. Configuration and Operation Below we document how to configure and operate a multi-cluster. Communication . Clusters communicate via the same silo-to-silo connections that are used within a cluster. To exchange status and configuration information, Clusters use a gossip mechanism and gossip channel implementations. Silo Configuration . Silos need to be configured so they know which cluster they belong to (each cluster is identified by a unique string). Also, each silo needs to be configured with connection strings that allow them to connect to one or more gossip channels on startup. Multi-Cluster Configuration Injection . At runtime, the service operator can specify and/or change the multi-cluster configuration , which contains a list of cluster ids, to specify which clusters are part of the current multi-cluster. This is done by calling the management grain in any one of the clusters. Multi-Cluster Grains Below we document how to use multi-cluster functionality at the application level. Global-Single-Instance Grains . Developers can indicate when and how clusters should coordinate their grain directories with respect to a particular grain class. The [GlobalSingleInstance] attribute means we want the same behavior as as when running Orleans in a single global cluster: that is, route all calls to a single activation of the grain. Conversely, the [OneInstancePerCluster] attribute indicates that each cluster can have its own independent activation. This is appropriate if communication between clusters is undesired. Log-View Grains (not in v.1.3.0) . A special type of grain that uses a new API, similar to event sourcing, for synchronizing or persisting grain state. It can be used to automatically and efficiently synchronize the state of a grain between clusters and with storage. Because its synchronization algorithms are safe to use with reentrant grains, and are optimized to use batching and replication, it can perform better than standard grains when a grain is frequently accessed in multiple clusters, and/or when it is written to storage frequently. Support for log-view grains is not part of the master branch yet. We have a prerelease including samples and a bit of documentation in the geo-orleans branch . It is currently being evaluated in production by an early adopter."
  },
  "docs/deployment/multi-cluster_support/SiloConfiguration.html": {
    "href": "docs/deployment/multi-cluster_support/SiloConfiguration.html",
    "title": "Multi-Cluster Silo Configuration | Microsoft Orleans Documentation",
    "keywords": "Orleans Silo Configuration To get a quick overview, we show all relevant configuration parameters (including optional ones) in XML syntax below: <?xml version=\"1.0\" encoding=\"utf-8\"?> <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <MultiClusterNetwork ClusterId=\"clusterid\" DefaultMultiCluster=\"uswest,europewest,useast\" BackgroundGossipInterval=\"30s\" UseGlobalSingleInstanceByDefault=\"false\" GlobalSingleInstanceRetryInterval=\"30s\" GlobalSingleInstanceNumberRetries=\"3\" MaxMultiClusterGateways=\"10\"> <GossipChannel Type=\"...\" ConnectionString=\"...\"/> <GossipChannel Type=\"...\" ConnectionString=\"...\"/> </MultiClusterNetwork> <SystemStore ... ServiceId=\"some-guid\" .../> </Globals> </OrleansConfiguration> var silo = new SiloHostBuilder() [...] .Configure<ClusterInfo>(options => { options.ClusterId = \"us3\"; options.ServiceId = \"myawesomeservice\"; }) .Configure<MultiClusterOptions>(options => { options.HasMultiClusterNetwork = true; options.DefaultMultiCluster = new[] { \"us1\", \"eu1\", \"us2\" }; options.BackgroundGossipInterval = TimeSpan.FromSeconds(30); options.UseGlobalSingleInstanceByDefault = false; options.GlobalSingleInstanceRetryInterval = TimeSpan.FromSeconds(30); options.GlobalSingleInstanceNumberRetries = 3; options.MaxMultiClusterGateways = 10; options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=usa;AccountKey=...\"); options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=europe;AccountKey=...\") [...] }) [...] As usual, all configuration settings can also be read and written programmatically, via the respective members of the GlobalConfiguration class. The Service Id is an arbitrary ID for identifying this service. It must be the same for all clusters and all silos. The MultiClusterNetwork section is optional - if not present, all multi-cluster support is disabled for this silo. The required parameters ClusterId and GossipChannel are explained in the section on Multi-Cluster Communication . The optional parameters MaxMultiClusterGateways and BackgroundGossipInterval are explained in the section on Multi-Cluster Communication . The optional parameter DefaultMultiCluster is explained in the section on Multi-Cluster Configuration . The optional parameters UseGlobalSingleInstanceByDefault , GlobalSingleInstanceRetryInterval and GlobalSingleInstanceNumberRetries are explained in the section on Global-Single-Instance Grains . Orleans Client Configuration No extra configuration is required for Orleans client. The same client may not connect to silos in different clusters (the silo refuses the connection in that situation)."
  },
  "docs/deployment/service_fabric.html": {
    "href": "docs/deployment/service_fabric.html",
    "title": "Service Fabric Hosting | Microsoft Orleans Documentation",
    "keywords": "Service Fabric Hosting Orleans can be hosted on Service Fabric using the Microsoft.Orleans.Hosting.ServiceFabric package. Silos should be hosted as unpartitioned, stateless services since Orleans manages distribution of grains itself using fine-grained, dynamic distribution. Other hosting options (partitioned, stateful) are currently untested and unsupported. A sample which demonstrates hosting on Service Fabric is available at Samples/2.0/ServiceFabric . Hosting support is available in the Microsoft.Orleans.Hosting.ServiceFabric package. It allows an Orleans Silo to run as a Service Fabric ICommunicationListener . The Silo lifecycle follows the typical communication listener lifecycle: it is initialized via the ICommunicationListener.OpenAsync method and is gracefully terminated via the ICommunicationListener.CloseAsync method or abruptly terminated via the ICommunicationListener.Abort method. Official clustering support is available from various packages including: Microsoft.Orleans.Clustering.AzureStorage Microsoft.Orleans.Clustering.AdoNet Microsoft.Orleans.Clustering.DynamoDB There are also several third-party packages available for other services such as CosmosDB, Kubernetes, Redis and Aerospike. More information about cluster management can be found here . This example makes use of the Microsoft.Orleans.Clustering.AzureStorage package to utilize Azure Storage. OrleansCommunicationListener provides the ICommunicationListener implementation. The recommended approach is to create the communication listener using OrleansServiceListener.CreateStateless(Action<StatelessServiceContext, ISiloHostBuilder> configure) in the Orleans.Hosting.ServiceFabric namespace. Each time the communication listener is opened, the configure delegate passed to CreateStateless is invoked to configure the new Silo. Example: Configuring Service Fabric hosting The following example demonstrates a Service Fabric StatelessService class which hosts an Orleans silo. The full sample can be found in the Samples/2.0/ServiceFabric directory of the Orleans repository. /// <summary> /// An instance of this class is created for each service instance by the Service Fabric runtime. /// </summary> internal sealed class StatelessCalculatorService : StatelessService { public StatelessCalculatorService(StatelessServiceContext context) : base(context) { } /// <summary> /// Optional override to create listeners (e.g., TCP, HTTP) for this service replica to handle /// client or user requests. /// </summary> /// <returns>A collection of listeners.</returns> protected override IEnumerable<ServiceInstanceListener> CreateServiceInstanceListeners() { // Listeners can be opened and closed multiple times over the lifetime of a service instance. // A new Orleans silo will be both created and initialized each time the listener is opened // and will be shutdown when the listener is closed. var listener = OrleansServiceListener.CreateStateless( (fabricServiceContext, builder) => { builder.Configure<ClusterOptions>(options => { // The service id is unique for the entire service over its lifetime. This is // used to identify persistent state such as reminders and grain state. options.ServiceId = fabricServiceContext.ServiceName.ToString(); // The cluster id identifies a deployed cluster. Since Service Fabric uses rolling // upgrades, the cluster id can be kept constant. This is used to identify which // silos belong to a particular cluster. options.ClusterId = \"development\"; }); // Configure clustering. Other clustering providers are available, but for the purpose // of this sample we will use Azure Storage. // TODO: Pick a clustering provider and configure it here. builder.UseAzureStorageClustering( options => options.ConnectionString = \"UseDevelopmentStorage=true\"); // Optional: configure logging. builder.ConfigureLogging(logging => logging.AddDebug()); builder.AddStartupTask<StartupTask>(); // Service Fabric manages port allocations, so update the configuration using those // ports. // Gather configuration from Service Fabric. var activation = fabricServiceContext.CodePackageActivationContext; var endpoints = activation.GetEndpoints(); // These endpoint names correspond to TCP endpoints specified in ServiceManifest.xml var siloEndpoint = endpoints[\"OrleansSiloEndpoint\"]; var gatewayEndpoint = endpoints[\"OrleansProxyEndpoint\"]; var hostname = fabricServiceContext.NodeContext.IPAddressOrFQDN; builder.ConfigureEndpoints(hostname, siloEndpoint.Port, gatewayEndpoint.Port); // Add your application assemblies. builder.ConfigureApplicationParts(parts => { parts.AddApplicationPart(typeof(CalculatorGrain).Assembly).WithReferences(); // Alternative: add all loadable assemblies in the current base path // (see AppDomain.BaseDirectory). parts.AddFromApplicationBaseDirectory(); }); }); return new[] { listener }; } /// <summary> /// This is the main entry point for your service instance. /// </summary> /// <param name=\"cancellationToken\"> /// Canceled when Service Fabric needs to shut down this service instance. /// </param> protected override async Task RunAsync(CancellationToken cancellationToken) { while (true) { cancellationToken.ThrowIfCancellationRequested(); await Task.Delay(TimeSpan.FromSeconds(10), cancellationToken); } } }"
  },
  "docs/deployment/troubleshooting_azure_cloud_services_deployments.html": {
    "href": "docs/deployment/troubleshooting_azure_cloud_services_deployments.html",
    "title": "Troubleshooting Deployments | Microsoft Orleans Documentation",
    "keywords": "Troubleshooting Deployments This page gives some general guidelines for troubleshooting any issues that occur while deploying to Azure Cloud Services. These are very common issues to watch out for. Be sure to check the logs for more information. Getting a SiloUnavailableException First check to make sure that you are actually starting the silos before attempting to initialize the client. Sometimes the silos take a long time to start so it can be beneficial to try to initialize the client multiple times. If it still throws an exception, then there might be another issue with the silos. Check the silo configuration and make sure that the silos are starting up properly. Common Connection String Issues Using the local connection string when deploying to Azure – the website will fail to connect Using different connection strings for the silos and the front end (web and worker roles) – the website will fail to initialize the client because it cannot connect to the silos The connection string configuration can be checked in the Azure Portal. The logs may not display properly if the connection strings are not set up correctly. Modifying the Configuration Files Improperly Make sure that the proper endpoints are configured in the ServiceDefinition.csdef file or else the deployment will not work. It will give errors saying that it cannot get the endpoint information. Missing Logs Make sure that the connection strings are set up properly. It is likely that the Web.config file in the web role or the app.config file in the worker role were modified improperly. Incorrect versions in these files can cause issues with the deployment. Be careful when dealing with updates. Version Issues Make sure that the same version of Orleans is used in every project in the solution. Not doing this can lead to the worker role recycling. Check the logs for more information. Visual Studio provides some silo startup error messages in the deployment history. Role Keeps Recycling Check that all the appropriate Orleans assemblies are in the solution and have Copy Local set to True. Check the logs to see if there is an unhandled exception while initializing. Make sure that the connection strings are correct. Check the Azure Cloud Services troubleshooting pages for more information. How to Check Logs Use the cloud explorer in Visual Studio to navigate to the appropriate storage table or blob in the storage account. The WADLogsTable is a good starting point for looking at the logs. You might only be logging errors. If you want informational logs as well, you will need to modify the configuration to set the logging severity level. Programmatic configuration: When creating a ClusterConfiguration object, set config.Defaults.DefaultTraceLevel = Severity.Info . When creating a ClientConfiguration object, set config.DefaultTraceLevel = Severity.Info . Declarative configuration: Add <Tracing DefaultTraceLevel=\"Info\" /> to the OrleansConfiguration.xml and/or the ClientConfiguration.xml files. In the diagnostics.wadcfgx file for the web and worker roles, make sure to set the scheduledTransferLogLevelFilter attribute in the Logs element to Information , as this is an additional layer of trace filtering that defines which traces are sent to the WADLogsTable in Azure Storage. You can find more information about this in the Configuration Guide. Compatibility with ASP.NET The razor view engine included in ASP.NET uses the same code generation assemblies as Orleans ( Microsoft.CodeAnalysis and Microsoft.CodeAnalysis.CSharp ). This can present a version compatibility problem at runtime. To resolve this, try upgrading Microsoft.CodeDom.Providers.DotNetCompilerPlatform (this is the NuGet package ASP.NET uses to include the above assemblies) to the latest version, and setting binding redirects like this: <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis.CSharp\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly> <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly>"
  },
  "docs/deployment/troubleshooting_deployments.html": {
    "href": "docs/deployment/troubleshooting_deployments.html",
    "title": "Troubleshooting Deployments | Microsoft Orleans Documentation",
    "keywords": "Troubleshooting Deployments This page gives some general guidelines for troubleshooting any issues that occur while deploying to Azure Cloud Services. These are very common issues to watch out for. Be sure to check the logs for more information. Getting a SiloUnavailableException First, check to make sure that you are actually starting the silos before attempting to initialize the client. Sometimes the silos take a long time to start so it can be beneficial to try to initialize the client multiple times. If it still throws an exception, then there might be another issue with the silos. Check the silo configuration and make sure that the silos are starting up properly. Common Connection String Issues Using the local connection string when deploying to Azure – the website will fail to connect Using different connection strings for the silos and the front end (web and worker roles) – the website will fail to initialize the client because it cannot connect to the silos The connection string configuration can be checked in the Azure Portal. The logs may not display properly if the connection strings are not set up correctly. Modifying the Configuration Files Improperly Make sure that the proper endpoints are configured in the ServiceDefinition.csdef file or else the deployment will not work. It will give errors saying that it cannot get the endpoint information. Missing Logs Make sure that the connection strings are set up properly. It is likely that the Web.config file in the web role or the app.config file in the worker role were modified improperly. Incorrect versions in these files can cause issues with the deployment. Be careful when dealing with updates. Version Issues Make sure that the same version of Orleans is used in every project in the solution. Not doing this can lead to the worker role recycling. Check the logs for more information. Visual Studio provides some silo startup error messages in the deployment history. Role Keeps Recycling Check that all the appropriate Orleans assemblies are in the solution and have Copy Local set to True . Check the logs to see if there is an unhandled exception while initializing. Make sure that the connection strings are correct. Check the Azure Cloud Services troubleshooting pages for more information. How to Check Logs Use the cloud explorer in Visual Studio to navigate to the appropriate storage table or blob in the storage account. The WADLogsTable is a good starting point for looking at the logs. You might only be logging errors. If you want informational logs as well, you will need to modify the configuration to set the logging severity level. Programmatic configuration: When creating a ClusterConfiguration object, set config.Defaults.DefaultTraceLevel = Severity.Info . When creating a ClientConfiguration object, set config.DefaultTraceLevel = Severity.Info . Declarative configuration: Add <Tracing DefaultTraceLevel=\"Info\" /> to the OrleansConfiguration.xml and/or the ClientConfiguration.xml files. In the diagnostics.wadcfgx file for the web and worker roles, make sure to set the scheduledTransferLogLevelFilter attribute in the Logs element to Information , as this is an additional layer of trace filtering that defines which traces are sent to the WADLogsTable in Azure Storage. You can find more information about this in the Configuration Guide . Compatibility with ASP.NET The razor view engine included in ASP.NET uses the same code generation assemblies as Orleans ( Microsoft.CodeAnalysis and Microsoft.CodeAnalysis.CSharp ). This can present a version compatibility problem at runtime. To resolve this, try upgrading Microsoft.CodeDom.Providers.DotNetCompilerPlatform (this is the NuGet package ASP.NET uses to include the above assemblies) to the latest version, and setting binding redirects like this: <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis.CSharp\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly> <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly>"
  },
  "docs/grains/cancellation_tokens.html": {
    "href": "docs/grains/cancellation_tokens.html",
    "title": "Grain cancellation tokens | Microsoft Orleans Documentation",
    "keywords": "Grain cancellation tokens The Orleans runtime provides mechanism called grain cancellation token, that enables the developer to cancel an executing grain operation. Description GrainCancellationToken is a wrapper around standard .NET System.Threading.CancellationToken , which enables cooperative cancellation between threads, thread pool work items or Task objects, and can be passed as grain method argument. A GrainCancellationTokenSource is a object that provides a cancellation token through its Token property and sends a cancellation message by calling its Cancel method. Usage Instantiate a CancellationTokenSource object, which manages and sends cancellation notification to the individual cancellation tokens. var tcs = new GrainCancellationTokenSource(); Pass the token returned by the GrainCancellationTokenSource.Token property to each grain method that listens for cancellation. var waitTask = grain.LongIoWork(tcs.Token, TimeSpan.FromSeconds(10)); A cancellable grain operation needs to handle underlying CancellationToken property of GrainCancellationToken just like it would do in any other .NET code. public async Task LongIoWork(GrainCancellationToken tc, TimeSpan delay) { while(!tc.CancellationToken.IsCancellationRequested) { await IoOperation(tc.CancellationToken); } } Call the GrainCancellationTokenSource.Cancel method to initiate cancellation. await tcs.Cancel(); Call the Dispose method when you are finished with the GrainCancellationTokenSource object. tcs.Dispose(); Important Considerations: The GrainCancellationTokenSource.Cancel method returns Task , and in order to ensure cancellation the cancel call must be retried in case of transient communication failure. Callbacks registered in underlying System.Threading.CancellationToken are subjects to single threaded execution guarantees within the grain activation on which they were registered. Each GrainCancellationToken can be passed through multiple methods invocations."
  },
  "docs/grains/code_generation.html": {
    "href": "docs/grains/code_generation.html",
    "title": "Code Generation | Microsoft Orleans Documentation",
    "keywords": "Code Generation The Orleans runtime makes use of generated code in order to ensure proper serialization of types that are used across the cluster as well as for generating boilerplate, which abstracts away the implementation details of method shipping, exception propagation, and other internal runtime concepts. Enabling Code Generation Code generation can be performed either when your projects are being built or when your application initializes. During Build The preferred method for performing code generation is at build time. Build time code generation could be enabled by using one of the following packages: Microsoft.Orleans.OrleansCodeGenerator.Build . A package that uses Roslyn for code generation and uses .NET Reflection for analysis. Microsoft.Orleans.CodeGenerator.MSBuild . A new code generation package that leverages Roslyn both for code generation and code analysis. It does not load application binaries, and as a result avoids issues caused by clashing dependency versions and differing target frameworks. The new code generator also improves support for incremental builds, which should result in shorter build times. One of these packages should be installed into all projects which contain grains, grain interfaces, custom serializers, or types which are sent between grains. Installing a package injects a target into the project which will generate code at build time. Both packages ( Microsoft.Orleans.CodeGenerator.MSBuild and Microsoft.Orleans.OrleansCodeGenerator.Build ) only support C# projects. Other languages are supported either using the Microsoft.Orleans.OrleansCodeGenerator package described below, or by creating a C# project which can act as the target for code generated from assemblies written in other languages. Additional diagnostics can be emitted at build time by specifying a value for OrleansCodeGenLogLevel in the target project's csproj file. For example, <OrleansCodeGenLogLevel>Trace</OrleansCodeGenLogLevel> . During Initialization Code generation can be performed during initialization on the client and silo by installing the Microsoft.Orleans.OrleansCodeGenerator package and using the IApplicationPartManager.WithCodeGeneration extension method: builder.ConfigureApplicationParts( parts => parts .AddApplicationPart(typeof(IRuntimeCodeGenGrain).Assembly) .WithCodeGeneration()); In the foregoing example, builder may be an instance of either ISiloHostBuilder or IClientBuilder . An optional ILoggerFactory instance can be passed to WithCodeGeneration to enable logging during code generation, for example: ILoggerFactory codeGenLoggerFactory = new LoggerFactory(); codeGenLoggerFactory.AddProvider(new ConsoleLoggerProvider()); builder.ConfigureApplicationParts( parts => parts .AddApplicationPart(typeof(IRuntimeCodeGenGrain).Assembly) .WithCodeGeneration(codeGenLoggerFactory)); Influencing Code Generation Generate code for a specific type Code is automatically generated for grain interfaces, grain classes, grain state, and types passed as arguments in grain methods. If a type does not fit this criteria, the following methods can be used to further guide code generation. Adding [Serializable] to a type instructs the code generator to generate a serializer for that type. Adding [assembly: GenerateSerializer(Type)] to a project instructs the code generator to treat that type as serializable, and will cause an error if a serializer could not be generated for that type, for example because the type is not accessible. This error will halt a build if code generation is enabled. This attribute also allows generating code for specific types from another assembly. [assembly: KnownType(Type)] also instructs the code generator to include a specific type (which may be from a referenced assembly), but does not cause an exception if the type is inaccessible. Generate serializers for all subtypes Adding [KnownBaseType] to an interface or class instructs the code generator to generate serialization code for all types which inherit/implement that type. Generate code for all types in another assembly There are cases where generated code cannot be included in a particular assembly at build time. For example, this can include shared libraries which do not reference Orleans, assemblies written in languages other than C#, and assemblies which the developer does not have the source code for. In these cases, generated code for those assemblies can be placed into a separate assembly which is referenced during initialization. In order to enable this for an assembly: Create a C# project. Install the Microsoft.Orleans.CodeGenerator.MSBuild or the Microsoft.Orleans.OrleansCodeGenerator.Build package. Add a reference to the target assembly. Add [assembly: KnownAssembly(\"OtherAssembly\")] at the top level of a C# file. The KnownAssembly attribute instructs the code generator to inspect the specified assembly and generate code for the types within it. The attribute can be used multiple times within a project. The generated assembly must then be added to the client/silo during initialization: builder.ConfigureApplicationParts( parts => parts.AddApplicationPart(\"CodeGenAssembly\")); In the foregoing example, builder may be an instance of either ISiloHostBuilder or IClientBuilder . KnownAssemblyAttribute has an optional property, TreatTypesAsSerializable , which can be set to true to instruct the code generator to act as though all types within that assembly are marked as serializable."
  },
  "docs/grains/event_sourcing/event_sourcing_configuration.html": {
    "href": "docs/grains/event_sourcing/event_sourcing_configuration.html",
    "title": "Configuration | Microsoft Orleans Documentation",
    "keywords": "Configuration Configuring Project References Grain Interfaces As before, interfaces depend only on the Microsoft.Orleans.Core package, because the grain interface is independent of the implementation. Grain Implementations JournaledGrains need to derive from JournaledGrain<S,E> or JournaledGrain<S> , which is defined in the Microsoft.Orleans.EventSourcing package. Log-Consistency Providers We currently include three log-consistency providers (for state storage, log storage, and custom storage). All three are contained in the Microsoft.Orleans.EventSourcing package as well. Therefore, all Journaled Grains already have access to those. For a description of what these providers do and how they differ, see Included Log-Consistency Providers . Cluster Configuration Log-consistency providers are configured just like any other Orleans providers. For example, to include all three providers (of course, you probably won't need all three), add this to the <Globals> element of the configuration file: <LogConsistencyProviders> <Provider Type=\"Orleans.EventSourcing.StateStorage.LogConsistencyProvider\" Name=\"StateStorage\" /> <Provider Type=\"Orleans.EventSourcing.LogStorage.LogConsistencyProvider\" Name=\"LogStorage\" /> <Provider Type=\"Orleans.EventSourcing.CustomStorage.LogConsistencyProvider\" Name=\"CustomStorage\" /> </LogConsistencyProviders> The same can be achieved programmatically. Moving forward to 2.0.0 stable, ClientConfiguration and ClusterConfiguration no longer exist! It has now been replaced by a ClientBuilder and a SiloBuilder (notice there is no cluster builder). builder.AddLogStorageBasedLogConsistencyProvider(\"LogStorage\") Grain Class Attributes Each journaled grain class must have a LogConsistencyProvider attribute to specify the log-consistency provider. Some providers additionally require a StorageProvider attribute. Eg: [StorageProvider(ProviderName = \"OrleansLocalStorage\")] [LogConsistencyProvider(ProviderName = \"LogStorage\")] public class EventSourcedBankAccountGrain : JournaledGrain<BankAccountState>, IEventSourcedBankAccountGrain { ... } So here \" OrleansLocalStorage \" is being used for storing the grain state, where was \" LogStorage \" is the in-memory storage provider for EventSourcing events. LogConsistencyProvider Attributes To specify the log-consistency provider, add a [LogConsistencyProvider(ProviderName=...)] attribute to the grain class, and give the name of the provider as configured by the Cluster Configuration. For example: [LogConsistencyProvider(ProviderName = \"CustomStorage\")] public class ChatGrain : JournaledGrain<XDocument, IChatEvent>, IChatGrain, ICustomStorage { ... } StorageProvider Attributes Some log-consistency providers (including LogStorage and StateStorage ) use a standard StorageProvider to communicate with storage. This provider is specified using a separate StorageProvider attribute, as follows: [LogConsistencyProvider(ProviderName = \"LogStorage\")] [StorageProvider(ProviderName = \"AzureBlobStorage\")] public class ChatGrain : JournaledGrain<XDocument, IChatEvent>, IChatGrain { ... } Default Providers It is possible to omit the LogConsistencyProvider and/or the StorageProvider attributes, if a default is specified in the configuration. This is done by using the special name Default for the respective provider. For example: <LogConsistencyProviders> <Provider Type=\"Orleans.EventSourcing.LogStorage.LogConsistencyProvider\" Name=\"Default\" /> </LogConsistencyProviders> <StorageProviders> <Provider Type=\"Orleans.Storage.MemoryStorage\" Name=\"Default\" /> </StorageProviders>"
  },
  "docs/grains/event_sourcing/immediate_vs_delayed_confirmation.html": {
    "href": "docs/grains/event_sourcing/immediate_vs_delayed_confirmation.html",
    "title": "Immediate vs. Delayed Confirmation | Microsoft Orleans Documentation",
    "keywords": "Immediate Confirmation For many applications, we want to ensure that events are confirmed immediately, so that the persisted version does not lag behind the current version in memory, and we do not risk losing the latest state if the grain should fail. We can guarantee this by following these rules: Confirm all RaiseEvent calls using ConfirmEvents before the grain method returns. Make sure tasks returned by RaiseConditionalEvent complete before the grain method returns. Avoid [Reentrant] or [AlwaysInterleave] attributes, so only one grain call can be processed at a time. If we follow these rules, it means that after an event is raised, no other grain code can execute until the event has been written to storage. Therefore, it is impossible to observe inconsistencies between the version in memory and the version in storage. While this is often exactly what we want, it also has some potential disadvantages. Potential Disadvantages if the connection to a remote cluster or to storage is temporarily interrupted , then the grain becomes unavailable: effectively, the grain cannot execute any code while it is stuck waiting to confirm the events, which can take an indefinite amount of time (the log-consistency protocol keeps retrying until storage connectivity is restored). when handling a lot of of updates to a single grain instance , confirming them one at a time can become very inefficient, i.e. have poor throughput. Delayed Confirmation To improve availability and throughput in the situations mentioned above, grains can choose to do one or both of the following: allow grain methods to raise events without waiting for confirmation. allow reentrancy, so the grain can keep processing new calls even if previous calls get stuck waiting for confirmation. This means it is possible for grain code to execute while some events are still in the process of being confirmed. The JournaledGrain API has some specific provisions to give developers precise control over how to deal with unconfirmed events that are currently \"in flight\". The following property can be examined to find out what events are currently unconfirmed: IEnumerable<EventType> UnconfirmedEvents { get; } Also, since the state returned by the State property does not include the effect of unconfirmed events, there is an alternative property StateType TentativeState { get; } which returns a \"tentative\" state, obtained from \"State\" by applying all the unconfirmed events. The tentative state is essentially a \"best guess\" at what will likely become the next confirmed state, after all unconfirmed events are confirmed. However, there is no guarantee that it actually will, because the grain may fail, or because the events may race against other events and lose, causing them to be canceled (if they are conditional) or appear at a later position in the sequence than anticipated (if they are unconditional). Concurrency Guarantees Note that Orleans turn-based scheduling (cooperative concurrency) guarantees always apply, even when using reentrancy or delayed confirmation. This means that even though several methods may be in progress, only one can be actively executing --- all others are stuck at an await, so there are never any true races caused by parallel threads. In particular, note that: The properties State , TentativeState , Version , and UnconfirmedEvents can change during the execution of a method. But such changes can only happen while stuck at an await. These guarantees assume that the user code stays within the recommended practice with respect to tasks and async/await (in particular, does not use thread pool tasks, or only uses them for code that does not call grain functionality and that are properly awaited)."
  },
  "docs/grains/event_sourcing/index.html": {
    "href": "docs/grains/event_sourcing/index.html",
    "title": "Event Sourcing Overview | Microsoft Orleans Documentation",
    "keywords": "Event Sourcing Event sourcing provides a flexible way to manage and persist grain state. An event-sourced grain has many potential advantages over a standard grain. For one, it can be used with many different storage provider configurations, and supports geo-replication across multiple clusters. Moreover, it cleanly separates the grain class from definitions of the grain state (represented by a grain state object) and grain updates (represented by event objects). The documentation is structured as follows: JournaledGrain Basics explains how to define an event-sourced grains by deriving from JournaledGrain , how to access the current state, and how to raise events that update the state. Replicated Instances explains how the event-sourcing mechanism handles replicated grain instances and ensures consistency. It discusses the possibility of racing events and conflicts, and how to address them. Immediate/Delayed Confirmation explains how delayed confirmation of events, and reentrancy, can improve availability and throughput. Notifications explains how to subscribe to notifications, allowing grains to react to new events. Event Sourcing Configuration explains how to configure projects, clusters, and log-consistency providers. Built-In Log-Consistency Providers explains how the three currently included log-consistency providers work. JournaledGrain Diagnostics explains how to monitor for connection errors, and get simple statistics. The behavior documented above is reasonably stable, as far as the JournaledGrain API is concerned. However, we expect to extend or change the list of log consistency providers soon, to more easily allow developers to plug in standard event storage systems."
  },
  "docs/grains/event_sourcing/journaledgrain_basics.html": {
    "href": "docs/grains/event_sourcing/journaledgrain_basics.html",
    "title": "JournaledGrain API | Microsoft Orleans Documentation",
    "keywords": "JournaledGrain Basics Journaled grains derive from JournaledGrain<StateType,EventType> , with the following type parameters: The StateType represents the state of the grain. It must be a class with a public default constructor. EventType is a common supertype for all the events that can be raised for this grain, and can be any class or interface. All state and event objects should be serializable (because the log-consistency providers may need to persist them, and/or send them in notification messages). For grains whose events are POCOs (plain old C# objects), JournaledGrain<StateType> can be used as a shorthand for JournaledGrain<StateType,Object> . Reading the Grain State To read the current grain state, and determine its version number, the JournaledGrain has properties GrainState State { get; } int Version { get; } The version number is always equal to the total number of confirmed events, and the state is the result of applying all the confirmed events to the initial state. The initial state, which has version 0 (because no events have been applied to it), is determined by the default constructor of the GrainState class. Important: The application should never directly modify the object returned by State . It is meant for reading only. Rather, when the application wants to modify the state, it must do so indirectly by raising events. Raising Events Raising events is accomplished by calling the RaiseEvent function. For example, a grain representing a chat can raise a PostedEvent to indicate that a user submitted a post: RaiseEvent(new PostedEvent() { Guid = guid, User = user, Text = text, Timestamp = DateTime.UtcNow }); Note that RaiseEvent kicks off a write to storage access, but does not wait for the write to complete. For many applications, it is important to wait until we have confirmation that the event has been persisted. In that case, we always follow up by waiting for ConfirmEvents : RaiseEvent(new DepositTransaction() { DepositAmount = amount, Description = description }); await ConfirmEvents(); Note that even if you don't explicitly call ConfirmEvents , the events will eventually be confirmed - it happens automatically in the background. State Transition Methods The runtime updates the grain state automatically whenever events are raised. There is no need for the application to explicitly update the state after raising an event. However, the application still has to provide the code that specifies how to update the state in response to an event. This can be done in two ways. (a) The GrainState class can implement one or more Apply methods on the StateType . Typically, one would create multiple overloads, and the closest match is chosen for the runtime type of the event: class GrainState { Apply(E1 @event) { // code that updates the state } Apply(E2 @event) { // code that updates the state } } (b) The grain can override the TransitionState function: protected override void TransitionState(State state, EventType @event) { // code that updates the state } The transition methods are assumed to have no side effects other than modifying the state object, and should be deterministic (otherwise, the effects are unpredictable). If the transition code throws an exception, that exception is caught and included in a warning in the Orleans log, issued by the log-consistency provider. When, exactly, the runtime calls the transition methods depends on the chosen log consistency provider and its configuration. It is best for applications not to rely on a particular timing, except when specifically guaranteed by the log consistency provider. Some providers, such as the LogStorage log-consistency provider, replay the event sequence every time the grain is loaded. Therefore, as long as the event objects can still be properly deserialized from storage, it is possible to radically modify the GrainState class and the transition methods. But for other providers, such as the StateStorage log-consistency provider, only the GrainState object is persisted, so developers must ensure that it can be deserialized correctly when read from storage. Raising Multiple Events It is possible to make multiple calls to RaiseEvent before calling ConfirmEvents: RaiseEvent(e1); RaiseEvent(e2); await ConfirmEvents(); However, this is likely to cause two successive storage accesses, and it incurs a risk that the grain fails after writing only the first event. Thus, it is usually better to raise multiple events at once, using RaiseEvents(IEnumerable<EventType> events) This guarantees that the given sequence of events is written to storage atomically. Note that since the version number always matches the length of the event sequence, raising multiple events increases the version number by more than one at a time. Retrieving the Event Sequence The following method from the base JournaledGrain class allows the application to retrieve a specified segment of the sequence of all confirmed events: Task<IReadOnlyList<EventType>> RetrieveConfirmedEvents(int fromVersion, int toVersion) However, it is not supported by all log consistency providers. If not supported, or if the specified segment of the sequence is no longer available, a NotSupportedException is thrown. To retrieve all events up to the latest confirmed version, one would call await RetrieveConfirmedEvents(0, Version); Only confirmed events can be retrieved: an exception is thrown if toVersion is larger than the current value of the property Version . Since confirmed events never change, there are no races to worry about, even in the presence of multiple instances or delayed confirmation. However, in such situations, it is possible that the value of the property Version is larger by the time the await resumes than at the time RetrieveConfirmedEvents is called, so it may be advisable to save its value in a variable. See also the section on Concurrency Guarantees."
  },
  "docs/grains/event_sourcing/journaledgrain_diagnostics.html": {
    "href": "docs/grains/event_sourcing/journaledgrain_diagnostics.html",
    "title": "JournaledGrain Diagnostics | Microsoft Orleans Documentation",
    "keywords": "JournaledGrain Diagnostics Monitoring Connection Errors By design, log consistency providers are resilient under connection errors (including both connections to storage, and connections between clusters). But just tolerating errors is not enough, as applications usually need to monitor any such issues, and bring them to the attention of an operator if they are serious. JournaledGrain subclasses can override the following methods to receive notifications when there are connection errors observed, and when those errors are resolved: protected override void OnConnectionIssue(ConnectionIssue issue) { /// handle the observed error described by issue } protected override void OnConnectionIssueResolved(ConnectionIssue issue) { /// handle the resolution of a previously reported issue } ConnectionIssue is an abstract class, with several common fields describing the issue, including how many times it has been observed since the last time connection was successful. The actual type of connection issue is defined by subclasses. Connection issues are categorized into types, such as PrimaryOperationFailed or NotificationFailed , and sometimes have extra keys (such as RemoteCluster ) that further narrow the category. If the same category of issue happens several times (for example, we keep getting a NotificationFailed that targets the same RemoteCluster ), it is reported each time by OnConnectionIssue . Once this category of issue is resolved (for example, we are finally successful with sending a notification to this RemoteCluster ), then OnConnectionIssueResolved is called once, with the same issue object that was last reported by OnConnectionIssue . Connection issues, and their resolution, for independent categories, are reported independently. Simple Statistics We currently offer a simple support for basic statistics (in the future, we will probably replace this with a more standard telemetry mechanism). Statistics collection can be enabled or disabled for a JournaledGrain by calling void EnableStatsCollection() void DisableStatsCollection() The statistics can be retrieved by calling LogConsistencyStatistics GetStats()"
  },
  "docs/grains/event_sourcing/log_consistency_providers.html": {
    "href": "docs/grains/event_sourcing/log_consistency_providers.html",
    "title": "Log-Consistency Providers | Microsoft Orleans Documentation",
    "keywords": "Built-In Log-Consistency Providers The Microsoft.Orleans.EventSourcing package includes several log-consistency providers that cover basic scenarios suitable to get started, and allow some extensibility. Orleans.EventSourcing. StateStorage .LogConsistencyProvider This provider stores grain state snapshots , using a standard storage provider that can be configured independently. The data that is kept in storage is an object that contains both the grain state (as specified by the first type parameter to JournaledGrain ) and some meta-data (the version number, and a special tag that is used to avoid duplication of events when storage accesses fail). Since the entire grain state is read/written every time we access storage, this provider is not suitable for objects whose grain state is very large. This provider does not support RetrieveConfirmedEvents : it cannot retrieve the events from storage because the events are not persisted. Orleans.EventSourcing. LogStorage .LogConsistencyProvider This provider stores the complete event sequence as a single object , using a standard storage provider that can be configured independently. The data that is kept in storage is an object that contains a List<EventType> object , and some meta-data (a special tag that is used to avoid duplication of events when storage accesses fail). This provider does support RetrieveConfirmedEvents . All events are always available and kept in memory. Since the whole event sequence is read/written every time we access storage, this provider is not suitable for use in production , unless the event sequences are guaranteed to remain pretty short. The main purpose of this provider is to illustrate the semantics of the event sourcing, and for samples/testing environments. Orleans.EventSourcing. CustomStorage .LogConsistencyProvider This provider allows the developer to plug in their own storage interface, which is then called by the conistency protocol at appropriate times. This provider does not make specific assumptions about whether what is stored are state snapshots or events - the programmer assumes control over that choice (and may store either or both). To use this provider, a grain must derive from JournaledGrain<StateType,EventType> , as before, but additionally must also implement the following interface: public interface ICustomStorageInterface<StateType, EventType> { Task<KeyValuePair<int,StateType>> ReadStateFromStorage(); Task<bool> ApplyUpdatesToStorage(IReadOnlyList<EventType> updates, int expectedversion); } The consistency provider expects these to behave a certain way. Programmers should be aware that: The first method, ReadStateFromStorage , is expected to return both the version, and the state read. If there is nothing stored yet, it should return zero for the version and a state that matches corresponds to the default constructor for StateType . ApplyUpdatesToStorage must return false if the expected version does not match the actual version (this is analogous to an e-tag check). If ApplyUpdatesToStorage fails with an exception, the consistency provider retries. This means some events could be duplicated if such an exception is thrown, but the event was actually persisted. The developer is responsible to make sure this is safe: e.g. either avoid this case by not throwing an exception, or ensure duplicated events are harmless for the application logic, or add some extra mechanism to filter duplicates. This provider does not support RetrieveConfirmedEvents . Of course, since the developer controls the storage interface anyway, they don't need to call this in the first place, but can implement their own event retrieval."
  },
  "docs/grains/event_sourcing/notifications.html": {
    "href": "docs/grains/event_sourcing/notifications.html",
    "title": "Notifications | Microsoft Orleans Documentation",
    "keywords": "Notifications It is often convenient to have the ability to react to state changes. All callbacks are subject to Orleans' turn-based guarantees; see also the section on Concurrency Guarantees. Tracking Confirmed State To be notified of any changes to the confirmed state, JournaledGrain subclasses can override this method: protected override void OnStateChanged() { // read state and/or event log and take appropriate action } OnStateChanged is called whenever the confirmed state is updated, i.e. the version number increases. This can happen when A newer version of the state was loaded from storage. An event that was raised by this instance has been successfully written to storage. A notification message was received from some other instance. Note that since all grains initially have version zero, until the initial load from storage completes, this means that OnStateChanged is called whenever the initial load completes with a version larger than zero. Tracking Tentative State To be notified of any changes to the tentative state, JournaledGrain subclasses can override this method: protected override void OnTentativeStateChanged() { // read state and/or events and take appropriate action } OnTentativeStateChanged is called whenever the tentative state changes, i.e. if the combined sequence (ConfirmedEvents + UnconfirmedEvents) changes. In particular, a callback to OnTentativeStateChanged() always happens during RaiseEvent ."
  },
  "docs/grains/event_sourcing/replicated_instances.html": {
    "href": "docs/grains/event_sourcing/replicated_instances.html",
    "title": "Replicated Grains | Microsoft Orleans Documentation",
    "keywords": "Replicated Grains Sometimes, there can be multiple instances of the same grain active, such as when operating a multi-cluster, and using the [OneInstancePerCluster] attribute. The JournaledGrain is designed to support replicated instances with minimal friction. It relies on log-consistency providers to run the necessary protocols to ensure all instances agree on the same sequence of events. In particular, it takes care of the following aspects: Consistent Versions : All versions of the grain state (except for tentative versions) are based on the same global sequence of events. In particular, if two instances see the same version number, then they see the same state. Racing Events : Multiple instances can simultaneously raise an event. The consistency provider resolves this race and ensures everyone agrees on the same sequence. Notifications/Reactivity : After an event is raised at one grain instance, the consistency provider not only updates storage, but also notifies all the other grain instances. For a general discussion of the consistency model see our TechReport and the GSP paper (Global Sequence Protocol). Conditional Events Racing events can be problematic if they have a conflict, i.e. should not both commit for some reason. For example, when withdrawing money from a bank account, two instances may independently determine that there are sufficient funds for a withdrawal, and issue a withdrawal event. But the combination of both events could overdraw. To avoid this, the JournaledGrain API supports a RaiseConditionalEvent method. bool success = await RaiseConditionalEvent(new WithdrawalEvent() { ... }); Conditional events double-check if the local version matches the version in storage. If not, it means the event sequence has grown in the meantime, which means this event has lost a race against some other event. In that case, the conditional event is not appended to the log, and RaiseConditionalEvent returns false. This is the analogue of using e-tags with conditional storage updates, and likewise provides a simple mechanism to avoid committing conflicting events. It is possible and sensible to use both conditional and unconditional events for the same grain, such as a DepositEvent and a WithdrawalEvent . Deposits need not be conditional: even if a DepositEvent loses a race, it does not have to be cancelled, but can still be appended to the global event sequence. Awaiting the task returned by RaiseConditionalEvent is sufficient to confirm the event, i.e. it is not necessary to also call ConfirmEvents . Explicit Synchronization Sometimes, it is desirable to ensure that a grain is fully caught up with the latest version. This can be enforced by calling await RefreshNow(); which both (1) confirms all unconfirmed events, and (2) loads the latest version from storage."
  },
  "docs/grains/external_tasks_and_grains.html": {
    "href": "docs/grains/external_tasks_and_grains.html",
    "title": "External Tasks and Grains | Microsoft Orleans Documentation",
    "keywords": "External Tasks and Grains By design, any sub-Tasks spawned from grain code (for example, by using await or ContinueWith or Task.Factory.StartNew ) will be dispatched on the same per-activation TaskScheduler as the parent task and therefore inherit the same single-threaded execution model as the rest of grain code. This is the main point behind single threaded execution of grain turn based concurrency. In some cases grain code might need to “break out” of the Orleans task scheduling model and “do something special”, such as explicitly pointing a Task to a different task scheduler or the .NET ThreadPool . An example of such cases is when grain code has to execute a synchronous remote blocking call (such as remote IO). Executing that blocking call in the grain context will block the grain and thus should never be made. Instead, the grain code can execute this piece of blocking code on the thread pool thread and join ( await ) the completion of that execution and proceed in the grain context. We expect that escaping from the Orleans scheduler will be a very advanced and seldom required usage scenario beyond the “normal” usage patterns. Task-based APIs await , Task.Factory.StartNew (see below), Task.ContinueWith , Task.WhenAny , Task.WhenAll , Task.Delay all respect the current task scheduler. That means that using them in the default way, without passing a different TaskScheduler, will cause them to execute in the grain context. Both Task.Run and the endMethod delegate of Task.Factory.FromAsync do not respect the current task scheduler. They both use the TaskScheduler.Default scheduler, which is the .NET thread pool task scheduler. Therefore, the code inside Task.Run and the endMethod in Task.Factory.FromAsync will always run on the .NET thread pool outside of the single-threaded execution model for Orleans grains, as detailed here . However, any code after the await Task.Run or await Task.Factory.FromAsync will run back under the scheduler at the point the task was created, which is the grain's scheduler. ConfigureAwait(false) is an explicit API to escape the current task Scheduler. It will cause the code after an awaited Task to be executed on the TaskScheduler.Default scheduler, which is the .NET thread pool, and will thus break the single-threaded execution of the grain. You should in general never use ConfigureAwait(false) directly in grain code. Methods with signature async void should not be used with grains. They are intended for graphical user interface event handlers. async void method can immediately crash the current process if they allow an exception to escape, with no way of handling the exception. This is also true for List<T>.ForEach(async element => ...) and any other method which accepts an Action<T> , since the asynchronous delegate will be coerced into an async void delegate. Task.Factory.StartNew and async delegates The usual recommendation for scheduling tasks in any C# program is to use Task.Run in favor of Task.Factory.StartNew . In fact, a quick google search on the use of Task.Factory.StartNew() will suggest that it is dangerous and that one should always favor Task.Run . But if we want to stay in the grain's single-threaded execution model for our grain then we need to use it, so how do we do it correctly then? The danger when using Task.Factory.StartNew() is that it does not natively support async delegates. This means that this is likely a bug: var notIntendedTask = Task.Factory.StartNew(SomeDelegateAsync) . notIntendedTask is not a task that completes when SomeDelegateAsync does. Instead, one should always unwrap the returned task: var task = Task.Factory.StartNew(SomeDelegateAsync).Unwrap() . Example Below is sample code that demonstrates the usage of TaskScheduler.Current , Task.Run and a special custom scheduler to escape from Orleans grain context and how to get back to it. public async Task MyGrainMethod() { // Grab the grain's task scheduler var scheduler = TaskScheduler.Current; await TaskDelay(10000); // Current task scheduler did not change, the code after await is still running // in the same task scheduler. Assert.AreEqual(scheduler, TaskScheduler.Current); Task t1 = Task.Run( () => { // This code runs on the thread pool scheduler, not on Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); Assert.AreEqual(TaskScheduler.Default, TaskScheduler.Current); }); await t1; // We are back to the Orleans task scheduler. // Since await was executed in Orleans task scheduler context, we are now back // to that context. Assert.AreEqual(orleansTS, TaskScheduler.Current); // Example of using Task.Factory.StartNew with a custom scheduler to escape from // the Orleans scheduler Task t2 = Task.Factory.StartNew(() => { // This code runs on the MyCustomSchedulerThatIWroteMyself scheduler, not on // the Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); Assert.AreEqual(MyCustomSchedulerThatIWroteMyself, TaskScheduler.Current); }, CancellationToken.None, TaskCreationOptions.None, scheduler: MyCustomSchedulerThatIWroteMyself); await t2; // We are back to Orleans task scheduler. Assert.AreEqual(orleansTS, TaskScheduler.Current); } Example - making a grain call from code that runs on a thread pool Another scenario is a piece of grain code that needs to “break out” of the grain's task scheduling model and run on a thread pool (or some other, non-grain context), but still needs to call another grain. Grain calls can be made from non-grain contexts without extra ceremony. Below is code that demonstrates how a grain call can be made from a piece of code that runs inside a grain but not in the grain context. public async Task MyGrainMethod() { // Grab the Orleans task scheduler var scheduler = TaskScheduler.Current; var fooGrain = this.GrainFactory.GetGrain<IFooGrain>(0); Task<int> t1 = Task.Run(async () => { // This code runs on the thread pool scheduler, // not on Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); int res = await fooGrain.MakeGrainCall(); // This code continues on the thread pool scheduler, // not on the Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); return res; }); int result = await t1; // We are back to the Orleans task scheduler. // Since await was executed in the Orleans task scheduler context, // we are now back to that context. Assert.AreEqual(orleansTS, TaskScheduler.Current); } Working with libraries Some external libraries that your code is using might be using ConfigureAwait(false) internally. In fact, it is a good and correct practice in .NET to use ConfigureAwait(false) when implementing general purpose libraries . This is not a problem in Orleans. As long as the code in the grain that invokes the library method is awaiting the library call with a regular await , the grain code is correct. The result will be exactly as desired – the library code will run continuations on the default scheduler (the value returned by TaskScheduler.Default , which does not guarantee that the continuations will definitely run on a ThreadPool thread as continuations are often inlined in the previous thread), while the grain code will run on the grain's scheduler. Another frequently-asked question is whether there is a need to execute library calls with Task.Run – that is, whether there is a need to explicitly offload the library code to ThreadPool (for grain code to do Task.Run(() => myLibrary.FooAsync()) ). The answer is no. There is no need to offload any code to ThreadPool except for the case of library code that is making a blocking synchronous calls. Usually, any well-written and correct .NET async library (methods that return Task and are named with an Async suffix) do not make blocking calls. Thus there is no need to offload anything to ThreadPool unless you suspect the async library is buggy or if you are deliberately using a synchronous blocking library. Deadlocks Since grains execute in a single threaded fashion, it is possible to deadlock a grain by synchronously blocking in a way that would require multiple threads to unblock. This means that code which calls any of the following methods and properties can deadlock a grain if the provided tasks have not yet completed by the time the method or property is invoked: Task.Wait() Task.Result Task.WaitAny(...) Task.WaitAll(...) task.GetAwaiter().GetResult() These methods should be avoided in any high-concurrency service because they can lead to poor performance and instability by starving the .NET ThreadPool by blocking threads which could be performing useful work and requiring the .NET ThreadPool to inject additional threads so that they can be completed. When executing grain code, these methods, as mentioned above, can cause the grain to deadlock and therefore they should also be avoided in grain code. If there is some sync-over-async work which cannot be avoided, it is best to move that work to a separate scheduler. The simplest way to do this is to use await Task.Run(() => task.Wait()) for example. Please note that it is strongly recommended to avoid sync-over-async work since, as mentioned above, it will cause your application's scalability and performance to suffer. Summary: working with Tasks in Orleans What are you trying to do? How to do it Run background work on .NET thread-pool threads. No grain code or grain calls allowed. Task.Run Run asynchronous worker task from grain code with Orleans turn-based concurrency guarantees ( see above ). Task.Factory.StartNew(WorkerAsync).Unwrap() Run synchronous worker task from grain code with Orleans turn-based concurrency guarantees. Task.Factory.StartNew(WorkerSync) Timeouts for executing work items Task.Delay + Task.WhenAny Call an asynchronous library method await the library call Use async / await The normal .NET Task-Async programming model. Supported & recommended ConfigureAwait(false) Do not use inside grain code. Allowed only inside libraries."
  },
  "docs/grains/grain_identity.html": {
    "href": "docs/grains/grain_identity.html",
    "title": "Grain Identity | Microsoft Orleans Documentation",
    "keywords": "Grain Identity In object-oriented environments, the identity of an object is hard to distinguish from a reference to it. Thus, when an object is created using new, the reference you get back represents all aspects of its identity except those that map the object to some external entity that it represents. In distributed systems, object references cannot represent instance identity, since references are typically limited to a single address space. That is certainly the case for .NET references. Furthermore, a grain must have an identity regardless of whether it is active, so that we can activate it on demand. Therefore grains have a primary key. The primary key can be a Globally Unique Identifier (GUID), a long integer, or a string. The primary key is scoped to the grain type. Therefore, the complete identity of a grain is formed from the grain's type and its key. The caller of the grain decides which scheme should be used. The options are: long GUID string GUID + string long + string Because the underlying data is the same, the schemes can be used interchangeably. When a long integer is used, a GUID is actually created and padded with zeros. Situations that require a singleton grain instance, such as a dictionary or registry, benefit from using Guid.Empty as its key. This is merely a convention, but by adhering to this convention it becomes clear at the caller site that a singleton grain is in use, as we saw in the first tutorial. Using GUIDs GUIDs are useful when there are several processes that could request a grain, such as a number of web servers in a web farm. You don't need to coordinate the allocation of keys, which could introduce a single point of failure in the system, or a system-side lock on a resource which could present a bottleneck. There is a very low chance of GUIDs colliding, so they would probably be the default choice when architecting an Orleans system. Referencing a grain by GUID in client code: var grain = grainFactory.GetGrain<IExample>(Guid.NewGuid()); Retrieving the primary key from grain code: public override Task OnActivateAsync() { Guid primaryKey = this.GetPrimaryKey(); return base.OnActivateAsync(); } Using Longs A long integer is also available, which would make sense if the grain is persisted to a relational database, where numerical indexes are preferred over GUIDs. Referencing a grain by long integer in client code: var grain = grainFactory.GetGrain<IExample>(1); Retrieving the primary key from grain code: public override Task OnActivateAsync() { long primaryKey = this.GetPrimaryKeyLong(); return base.OnActivateAsync(); } Using Strings A string is also available. Referencing a grain by String in client code: var grain = grainFactory.GetGrain<IExample>(\"myGrainKey\"); Retrieving the primary key from grain code: public override Task OnActivateAsync() { string primaryKey = this.GetPrimaryKeyString(); return base.OnActivateAsync(); } Using Compound Primary Key If you have a system that doesn't fit well with either GUIDs or longs, you can opt for a compound primary key, which allows you to use a combination of a GUID or long and a string to reference a grain. You can inherit your interface from 'IGrainWithGuidCompoundKey' or 'IGrainWithIntegerCompoundKey\" interface like this: public interface IExampleGrain : Orleans.IGrainWithIntegerCompoundKey { Task Hello(); } In client code, this adds a second argument to the GetGrain method on the grain factory: var grain = grainFactory.GetGrain<IExample>(0, \"a string!\", null); To access the compound key in the grain, we can call an overload on the GetPrimaryKey method: public class ExampleGrain : Orleans.Grain, IExampleGrain { public Task Hello() { string keyExtension; long primaryKey = this.GetPrimaryKeyLong(out keyExtension); Console.WriteLine(\"Hello from \" + keyExtension); Task.CompletedTask; } }"
  },
  "docs/grains/grain_lifecycle.html": {
    "href": "docs/grains/grain_lifecycle.html",
    "title": "Grain Lifecycle | Microsoft Orleans Documentation",
    "keywords": "Grain Lifecycle Overview Orleans grains use an observable lifecycle (See Orleans Lifecycle ) for ordered activation and deactivation. This allows grain logic, system components and application logic to be started and stopped in an ordered manner during grain activation and collection. Stages The pre-defined grain lifecycle stages are as follows. public static class GrainLifecycleStage { public const int First = int.MinValue; public const int SetupState = 1000; public const int Activate = 2000; public const int Last = int.MaxValue; } First - First stage in grain’s lifecycle SetupState – Setup grain state, prior to activation. For stateful grains, this is the stage where state is loaded from storage. Activate – Stage where OnActivateAsync and OnDeactivateAsync are called Last - Last stage in grain's lifecycle While the grain lifecycle will be used during grain activation, since grains are not always deactivated during some error cases (such as silo crashes), applications should not rely on the grain lifecycle always being executed during grain deactivations. Grain Lifecycle Participation Application logic can participate with a grain’s lifecycle in two ways: The grain can participate in its lifecycle, and/or components can access the lifecycle via the grain activation context (see IGrainActivationContext.ObservableLifecycle). A grain always participates in its own lifecycle, so application logic can be introduced by overriding the participate method. Example public override void Participate(IGrainLifecycle lifecycle) { base.Participate(lifecycle); lifecycle.Subscribe(this.GetType().FullName, GrainLifecycleStage.SetupState, OnSetupState); } In the above example, Grain<T> overrides the Participate method to tell the lifecycle to call its OnSetupState method during the SetupState stage of the lifecycle. Components created during a grain’s construction can take part in the lifecycle as well, without any special grain logic being added. Since the grain’s activation context ( IGrainActivationContext ), including the grain’s lifecycle ( IGrainActivationContext.ObservableLifecycle ), is created before the grain is created, any component injected into the grain by the container can participate in the grain’s lifecycle. Example The below component participates in the grain’s lifecycle when created using its factory function Create(..) . This logic could exist in the component’s constructor, but that risks the component being added to the lifecycle before it’s fully constructed, which may not be safe. public class MyComponent : ILifecycleParticipant<IGrainLifecycle> { public static MyComponent Create(IGrainActivationContext context) { var component = new MyComponent(); component.Participate(context.ObservableLifecycle); return component; } public void Participate(IGrainLifecycle lifecycle) { lifecycle.Subscribe<MyComponent>(GrainLifecycleStage.Activate, OnActivate); } private Task OnActivate(CancellationToken ct) { // Do stuff } } By registering the above component in the service container using its Create(..) factory function, any grain constructed with the component as a dependency will have the component taking part in its lifecycle without any special logic in the grain. Register component in container services.AddTransient<MyComponent>(sp => MyComponent.Create(sp.GetRequiredService<IGrainActivationContext>()); Grain with component as dependency public class MyGrain : Grain, IMyGrain { private readonly MyComponent component; public MyGrain(MyComponent component) { this.component = component; } }"
  },
  "docs/grains/grain_persistence/azure_storage.html": {
    "href": "docs/grains/grain_persistence/azure_storage.html",
    "title": "Azure Storage Grain Persistence | Microsoft Orleans Documentation",
    "keywords": "Azure Storage Grain Persistence The Azure Storage grain persistence provider supports both Azure Blob Storage and Azure Table Storage . Installation Install the Microsoft.Orleans.Persistence.AzureStorage package from NuGet. Configuration Azure Table Storage The Azure Table Storage provider stores state in a table row, splitting the state over multiple columns if the limits of a single column are exceeded. Each row can hold a maximum length of one megabyte, as imposed by Azure Table Storage . Configure the Azure Table Storage grain persistence provider using the ISiloBuilder.AddAzureTableGrainStorage extension methods. siloBuilder.AddAzureTableGrainStorage( name: \"profileStore\", configureOptions: options => { options.UseJson = true; options.ConnectionString = \"DefaultEndpointsProtocol=https;AccountName=data1;AccountKey=SOMETHING1\"; }); Azure Blob Storage The Azure Blob Storage provider stores state in a blob. Configure the Azure Blob Storage grain persistence provider using the ISiloBuilder.AddAzureBlobGrainStorage extension methods. siloBuilder.AddAzureBlobGrainStorage( name: \"profileStore\", configureOptions: options => { options.UseJson = true; options.ConnectionString = \"DefaultEndpointsProtocol=https;AccountName=data1;AccountKey=SOMETHING1\"; });"
  },
  "docs/grains/grain_persistence/dynamodb_storage.html": {
    "href": "docs/grains/grain_persistence/dynamodb_storage.html",
    "title": "Amazon DynamoDB Grain Persistence | Microsoft Orleans Documentation",
    "keywords": "Amazon DynamoDB Grain Persistence Installation Install the Microsoft.Orleans.Persistence.DynamoDB package from NuGet. Configuration Configure the Dynamo DB grain persistence provider using the ISiloBuilder.AddDynamoDBGrainStorage extension methods. siloBuilder.AddDynamoDBGrainStorage( name: \"profileStore\", configureOptions: options => { options.UseJson = true; options.AccessKey = /* Dynamo DB access key */; options.SecretKey = /* Dynamo DB secret key */; options.Service = /* Dynamo DB service name */; });"
  },
  "docs/grains/grain_persistence/index.html": {
    "href": "docs/grains/grain_persistence/index.html",
    "title": "Persistence | Microsoft Orleans Documentation",
    "keywords": "Persistence Grains can have multiple named persistent data objects associated with them. These state objects are loaded from storage during grain activation so that they are available during requests. Grain persistence uses an extensible plugin model so that storage providers for any database can be used. This persistence model is designed for simplicity, and is not intended to cover all data access patterns. Grains can also access databases directly, without using the grain persistence model. In the above diagram, UserGrain has a Profile state and a Cart state, each of which is stored in a separate storage system. Goals Multiple named persistent data objects per grain. Multiple configured storage providers, each of which can have different configuration and be backed by a different storage system. Storage providers can be developed and published by the community. Storage providers have complete control over how they store grain state data in persistent backing store. Corollary: Orleans is not providing a comprehensive ORM storage solution, but instead allows custom storage providers to support specific ORM requirements as and when required. Packages Orleans grain storage providers can be found on NuGet . Officially maintained packages include: Microsoft.Orleans.Persistence.AdoNet is for SQL databases and other storage systems supported by ADO.NET. For more information, see ADO.NET Grain Persistence . Microsoft.Orleans.Persistence.AzureStorage is for Azure Storage, including Azure Blob Storage, Azure Table Storage, and Azure CosmosDB, via the Azure Table Storage API. For more information, see Azure Storage Grain Persistence . Microsoft.Orleans.Persistence.DynamoDB is for Amazon DynamoDB. For more information, see Amazon DynamoDB Grain Persistence . API Grains interact with their persistent state using IPersistentState<TState> where TState is the serializable state type: public interface IPersistentState<TState> where TState : new() { TState State { get; set; } string Etag { get; } Task ClearStateAsync(); Task WriteStateAsync(); Task ReadStateAsync(); } Instances of IPersistentState<TState> are injected into the grain as constructor parameters. These parameters can be annotated with a [PersistentState(stateName, storageName)] attribute to identify the name of the state being injected and the name of the storage provider which provides it. The following example demonstrates this by injecting two named states into the UserGrain constructor: public class UserGrain : Grain, IUserGrain { private readonly IPersistentState<ProfileState> _profile; private readonly IPersistentState<CartState> _cart; public UserGrain( [PersistentState(\"profile\", \"profileStore\")] IPersistentState<ProfileState> profile, [PersistentState(\"cart\", \"cartStore\")] IPersistentState<CartState> cart, ) { _profile = profile; _cart = cart; } } Different grain types can use different configured storage providers, even if both are the same type; for example, two different Azure Table Storage provider instances, connected to different Azure Storage accounts. Reading State Grain state will automatically be read when the grain is activated, but grains are responsible for explicitly triggering the write for any changed grain state when necessary. If a grain wishes to explicitly re-read the latest state for this grain from the backing store, the grain should call the ReadStateAsync() method. This will reload the grain state from the persistent store via the storage provider, and the previous in-memory copy of the grain state will be overwritten and replaced when the ReadStateAsync() Task completes. The value of the state is accessed using the State property. For example, the following method accesses the profile state declared in the code above: public Task<string> GetNameAsync() => Task.FromResult(_profile.State.Name); There is no need to call ReadStateAsync() during normal operation; the state is loaded automatically during activation. However, ReadStateAsync() can be used to refresh state which is modified externally. See the Failure Modes section below for details of error-handling mechanisms. Writing State State can be modified via the State property. Modified state is not automatically persisted. Instead, the developer decides when to persist state by calling the WriteStateAsync() method. For example, the following method updates a property on State and persists the updated state: public async Task SetNameAsync(string name) { _profile.State.Name = name; await _profile.WriteStateAsync(); } Conceptually, the Orleans Runtime will take a deep copy of the grain state data object for its own use during any write operations. Under the covers, the runtime may use optimization rules and heuristics to avoid performing some or all of the deep copy in some circumstances, provided that the expected logical isolation semantics are preserved. See the Failure Modes section below for details of error handling mechanisms. Clearing State The ClearStateAsync() method clears the grain's state in storage. Depending on the provider, this operation may optionally delete the grain state entirely. Getting Started Before a grain can use persistence, a storage provider must be configured on the silo. First, configure storage providers, one for profile state and one for cart state: var host = new HostBuilder() .UseOrleans(siloBuilder => { // Configure Azure Table storage using the name \"profileStore\" siloBuilder.AddAzureTableGrainStorage( name: \"profileStore\", configureOptions: options => { // Use JSON for serializing the state in storage options.UseJson = true; // Configure the storage connection key options.ConnectionString = \"DefaultEndpointsProtocol=https;AccountName=data1;AccountKey=SOMETHING1\"; }) // Configure Azure Blob storage using the name \"cartStore\" .AddAzureBlobGrainStorage( name: \"cartStore\", configureOptions: options => { // Use JSON for serializing the state in storage options.UseJson = true; // Configure the storage connection key options.ConnectionString = \"DefaultEndpointsProtocol=https;AccountName=data2;AccountKey=SOMETHING2\"; }); // -- other options }) .Build(); Now that a storage provider has been configured with the name \"profileStore\" , we can access this provider from a grain. Persistent state can be added to a grain in two primary ways: By injecting IPersistentState<TState> into the grain's constructor By inheriting from Grain<TState> The recommended way to add storage to a grain is by injecting IPersistentState<TState> into the grain's constructor with an associated [PersistentState(\"stateName\", \"providerName\")] attribute. For details on Grain<TState> , see below . This is still supported, but is considered legacy. Declare a class to hold our grain's state: [Serializable] public class ProfileState { public string Name { get; set; } public Date DateOfBirth } Inject IPersistentState<ProfileState> into the grain's constructor: public class UserGrain : Grain, IUserGrain { private readonly IPersistentState<ProfileState> _profile; public UserGrain([PersistentState(\"profile\", \"profileStore\")] IPersistentState<ProfileState> profile) { _profile = profile; } } Note: the profile state will not be loaded at the time it is injected into the constructor, so accessing it is invalid at that time. The state will be loaded before OnActivateAsync is called. Now that the grain has persistent state, we can add methods to read and write the state: public class UserGrain : Grain, IUserGrain { private readonly IPersistentState<ProfileState> _profile; public UserGrain([PersistentState(\"profile\", \"profileStore\")] IPersistentState<ProfileState> profile) { _profile = profile; } public Task<string> GetNameAsync() => Task.FromResult(_profile.State.Name); public async Task SetNameAsync(string name) { _profile.State.Name = name; await _profile.WriteStateAsync(); } } Failure modes for persistence operations Failure modes for read operations Failures returned by the storage provider during the initial read of state data for that particular grain will result in failure of the activate operation for that grain; in such case, there will not be any call to that grain’s OnActivateAsync() life cycle callback method. The original request to the grain which caused the activation will be faulted back to the caller, the same way as any other failure during grain activation. Failures encountered by the storage provider when reading state data for a particular grain will result in an exception from ReadStateAsync() Task . The grain can choose to handle or ignore the Task exception, just like any other Task in Orleans. Any attempt to send a message to a grain which failed to load at silo startup time due to a missing / bad storage provider config will return the permanent error Orleans.BadProviderConfigException . Failure modes for write operations Failures encountered by the storage provider when writing state data for a particular grain will result in an exception thrown by WriteStateAsync() Task . Usually this means that the grain call exception will be thrown back to the client caller, provided the WriteStateAsync() Task is correctly chained in to the final return Task for this grain method. However, it is possible in certain advanced scenarios to write grain code to specifically handle such write errors, just like they can handle any other faulted Task . Grains that execute error-handling / recovery code must catch exceptions / faulted WriteStateAsync() Task s and not re-throw them, to signify that they have successfully handled the write error. Recommendations Use JSON serialization or another version-tolerant serialization format Code evolves over time and this often includes storage types, too. To accommodate for these changes, an appropriate serializer should be configured. For most storage providers, a UseJson option or similar is available to use JSON as a serialization format. Ensure that when evolving data contracts that already-stored data will still be loadable. Using Grain<TState> to add storage to a grain NOTE: Using Grain<T> to add storage to a grain is considered legacy functionality: grain storage should be added using IPersistentState<T> as previously described. Grain classes that inherit from Grain<T> (where T is an application-specific state data type that needs to be persisted) will have their state loaded automatically from a specified storage. Such grains are marked with a [StorageProvider] attribute that specifies a named instance of a storage provider to use for reading / writing the state data for this grain. [StorageProvider(ProviderName=\"store1\")] public class MyGrain : Grain<MyGrainState>, /*...*/ { /*...*/ } The Grain<T> base class defined the following methods for subclasses to call: protected virtual Task ReadStateAsync() { /*...*/ } protected virtual Task WriteStateAsync() { /*...*/ } protected virtual Task ClearStateAsync() { /*...*/ } The behavior of these methods corresponds to their counterparts on IPersistentState<TState> defined earlier. Creating a storage provider There are two parts to the state persistence APIs: the API exposed to the grain via IPersistentState<T> or Grain<T> , and the storage provider API, which is centered around IGrainStorage — the interface which storage providers must implement: /// <summary> /// Interface to be implemented for a storage able to read and write Orleans grain state data. /// </summary> public interface IGrainStorage { /// <summary>Read data function for this storage instance.</summary> /// <param name=\"grainType\">Type of this grain [fully qualified class name]</param> /// <param name=\"grainReference\">Grain reference object for this grain.</param> /// <param name=\"grainState\">State data object to be populated for this grain.</param> /// <returns>Completion promise for the Read operation on the specified grain.</returns> Task ReadStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); /// <summary>Write data function for this storage instance.</summary> /// <param name=\"grainType\">Type of this grain [fully qualified class name]</param> /// <param name=\"grainReference\">Grain reference object for this grain.</param> /// <param name=\"grainState\">State data object to be written for this grain.</param> /// <returns>Completion promise for the Write operation on the specified grain.</returns> Task WriteStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); /// <summary>Delete / Clear data function for this storage instance.</summary> /// <param name=\"grainType\">Type of this grain [fully qualified class name]</param> /// <param name=\"grainReference\">Grain reference object for this grain.</param> /// <param name=\"grainState\">Copy of last-known state data object for this grain.</param> /// <returns>Completion promise for the Delete operation on the specified grain.</returns> Task ClearStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); } Create a custom storage provider by implementing this interface and registering that implementation. For an example of an existing storage provider implementation, see AzureBlobGrainStorage . Storage provider semantics An opaque provider-specific Etag value ( string ) may be set by a storage provider as part of the grain state metadata populated when state was read. Some providers may choose to leave this as null if they do not use Etag s. Any attempt to perform a write operation when the storage provider detects an Etag constraint violation should cause the write Task to be faulted with transient error Orleans.InconsistentStateException and wrapping the underlying storage exception. public class InconsistentStateException : OrleansException { public InconsistentStateException( string message, string storedEtag, string currentEtag, Exception storageException) : base(message, storageException) { this.StoredEtag = storedEtag; this.CurrentEtag = currentEtag; } public InconsistentStateException(string storedEtag, string currentEtag, Exception storageException) : this(storageException.Message, storedEtag, currentEtag, storageException) { } /// <summary>The Etag value currently held in persistent storage.</summary> public string StoredEtag { get; private set; } /// <summary>The Etag value currently held in memory, and attempting to be updated.</summary> public string CurrentEtag { get; private set; } } Any other failure conditions from a storage operation must cause the returned Task to be broken with an exception indicating the underlying storage issue. In many cases, this exception may be thrown back to the caller which triggered the storage operation by calling a method on the grain. It is important to consider whether or not the caller will be able to deserialize this exception. For example, the client might not have loaded the specific persistence library containing the exception type. For this reason, it is advisable to convert exceptions into exceptions which can be propagated back to the caller. Data mapping Individual storage providers should decide how best to store grain state – blob (various formats / serialized forms) or column-per-field are obvious choices. Registering a storage provider The Orleans runtime will resolve a storage provider from the service provider ( IServiceProvider ) when a grain is created. The runtime will resolve an instance of IGrainStorage . If the storage provider is named, for example via the [PersistentState(stateName, storageName)] attribute, then a named instance of IGrainStorage will be resolved. To register a named instance of IGrainStorage , use the IServiceCollection.AddSingletonNamedService extension method following the example of the AzureTableGrainStorage provider here ."
  },
  "docs/grains/grain_persistence/relational_storage.html": {
    "href": "docs/grains/grain_persistence/relational_storage.html",
    "title": "ADO.NET Grain Persistence | Microsoft Orleans Documentation",
    "keywords": "ADO.NET Grain Persistence Relational storage backend code in Orleans is built on generic ADO.NET functionality, and is consequently database vendor agnostic. The Orleans data storage layout has been explained already in Runtime Tables. Setting up the connection strings is done as explained in Orleans Configuration Guide . To make Orleans code function with a given relational database backend, the following is required: The appropriate ADO.NET library must be loaded into the process. This should be defined as usual, e.g. via the DbProviderFactories element in the application configuration. Configure the ADO.NET invariant via the Invariant property in the options. The database needs to exist and be compatible with the code. This is done by running a vendor-specific database creation script. For more information, see ADO.NET Configuration . The ADO .NET grain storage provider allows you to store the grain state in relational databases. Currently, the following databases are supported: SQL Server MySQL/MariaDB PostgreSQL Oracle First, install the base package: Install-Package Microsoft.Orleans.Persistence.AdoNet Read the ADO.NET Configuration article for information on configuring your database, including the corresponding ADO.NET Invariant and the setup scripts. The following is an example of how to configure an ADO.NET storage provider via ISiloHostBuilder : var siloHostBuilder = new SiloHostBuilder() .AddAdoNetGrainStorage(\"OrleansStorage\", options => { options.Invariant = \"<Invariant>\"; options.ConnectionString = \"<ConnectionString>\"; options.UseJsonFormat = true; }); Essentially, you only need to set the database-vendor-specific connection string and an Invariant (see ADO.NET Configuration ) that identifies the vendor. You may also choose the format in which the data is saved, which may be either binary (default), JSON, or XML. While binary is the most compact option, it is opaque, and you will not be able to read or work with the data. JSON is the recommended option. You can set the following properties via AdoNetGrainStorageOptions : /// <summary> /// Options for AdoNetGrainStorage /// </summary> public class AdoNetGrainStorageOptions { /// <summary> /// Define the property of the connection string for AdoNet storage. /// </summary> [Redact] public string ConnectionString { get; set; } /// <summary> /// Set the stage of the silo lifecycle where storage should be initialized. Storage must be initialized prior to use. /// </summary> public int InitStage { get; set; } = DEFAULT_INIT_STAGE; /// <summary> /// Default init stage in silo lifecycle. /// </summary> public const int DEFAULT_INIT_STAGE = ServiceLifecycleStage.ApplicationServices; /// <summary> /// The default ADO.NET invariant will be used for storage if none is given. /// </summary> public const string DEFAULT_ADONET_INVARIANT = AdoNetInvariants.InvariantNameSqlServer; /// <summary> /// Define the invariant name for storage. /// </summary> public string Invariant { get; set; } = DEFAULT_ADONET_INVARIANT; /// <summary> /// Determine whether the storage string payload should be formatted in JSON. /// <remarks>If neither <see cref=\"UseJsonFormat\"/> nor <see cref=\"UseXmlFormat\"/> is set to true, then BinaryFormatSerializer will be configured to format the storage string payload.</remarks> /// </summary> public bool UseJsonFormat { get; set; } public bool UseFullAssemblyNames { get; set; } public bool IndentJson { get; set; } public TypeNameHandling? TypeNameHandling { get; set; } public Action<JsonSerializerSettings> ConfigureJsonSerializerSettings { get; set; } /// <summary> /// Determine whether storage string payload should be formatted in Xml. /// <remarks>If neither <see cref=\"UseJsonFormat\"/> nor <see cref=\"UseXmlFormat\"/> is set to true, then BinaryFormatSerializer will be configured to format storage string payload.</remarks> /// </summary> public bool UseXmlFormat { get; set; } } The ADO.NET persistence has functionality to version data and define arbitrary (de)serializers with arbitrary application rules and streaming, but currently there is no method to expose it to application code. ADO.NET Persistence Rationale The principles for ADO.NET backed persistence storage are: Keep business-critical data safe and accessible while data, the format of data, and the code evolve. Take advantage of vendor- and storage-specific functionality. In practice, this means adhering to ADO.NET implementation goals, and some added implementation logic in ADO.NET-specific storage providers that allow evolving the shape of the data in the storage. In addition to the usual storage provider capabilities, the ADO.NET provider has built-in capability to: Change storage data from one format to another (e.g. from JSON to binary) when round-tripping state. Shape the type to be saved or read from the storage in arbitrary ways. This allows the version of the state to evolve. Stream data out of the database. Both 1. and 2. can be applied based on arbitrary decision parameters, such as grain ID , grain type , payload data . This is teh case so that you can choose a serialization format, e.g. Simple Binary Encoding (SBE) and implements IStorageDeserializer and IStorageSerializer . The built-in serializers have been built using this method. The OrleansStorageDefault(De)Serializer can be used as examples of how to implement other formats. When the serializers have been implemented, they need to be added to the StorageSerializationPicker property in AdoNetGrainStorage . Here is an implementation of IStorageSerializationPicker . By default, StorageSerializationPicker will be used. An example of changing the data storage format or using serializers can be seen at RelationalStorageTests . Currently, there is no method to expose the serialization picker to the Orleans application as there is no method to access the framework-created AdoNetGrainStorage . Goals of the design 1. Allow the use of any backend that has an ADO.NET provider This should cover the broadest possible set of backends available for .NET, which is a factor in on-premises installations. Some providers are listed at ADO.NET Data Providers MSDN page , but not all are listed, such as Teradata . 2. Maintain the potential to tune queries and database structure as appropriate, even while a deployment is running In many cases, the servers and databases are hosted by a third party in contractual relation with the client. It is not an unusual situation to find a hosting environment which is virtualized, and where performance fluctuates due to unforeseen factors, such as noisy neighbors or faulty hardware. It may not be possible to alter and re-deploy either Orleans binaries (for contractual reasons) or even application binaries, but it is usually possible to tweak the database deployment parameters. Altering standard components , such as Orleans binaries, requires a lengthier procedure for optimizing in a given situation. 3. Allow you to make use of vendor- and version-specific abilities Vendors have implemented different extensions and features within their products. It is sensible to make use of these features when they are available. These are features such as native UPSERT or PipelineDB in PostgreSQL, PolyBase or natively compiled tables and stored procedures in SQL Server – and myriads of other features. 4. Make it possible to optimize hardware resources When designing an application, it is often possible to anticipate which data needs to be inserted faster than other data, and which data could more likely be put into cold storage , which is cheaper (e.g. splitting data between SSD and HDD). Additional considerations include the physical location of the data (some data could be more expensive (e.g. SSD RAID viz HDD RAID), or more secured), or some other decision basis. Related to point 3. , some databases offer special partitioning schemes, such as SQL Server Partitioned Tables and Indexes . These principles apply throughout the application life-cycle. Considering that one of the principles of Orleans itself is high availability, it should be possible to adjust the storage system without interruption to the Orleans deployment, or it should be possible to adjust the queries according to data and other application parameters. An example of dynamic changes may be seen in Brian Harry's blog post : When a table is small, it almost doesn’t matter what the query plan is. When it’s medium, an OK query plan is fine, but when it's huge (millions upon millions or billions of rows), even a slight variation in the query plan can kill you. For this reason, we hint our sensitive queries heavily. 5. No assumptions on what tools, libraries, or deployment processes are used in organizations Many organizations have familiarity with a certain set of database tools, examples being Dacpac or Red Gate . It may be that deploying a database requires either a permission or a person, such as someone in a DBA role, to do it. Usually this means also having the target database layout and a rough sketch of the queries the application will produce for use in estimating the load. There might be processes, perhaps influenced by industry standards, which mandate script-based deployment. Having the queries and database structures in an external script makes this possible. 6. Use the minimum set of interface functionality needed to load the ADO.NET libraries and functionality This is both fast, and has less surface exposed to the ADO.NET library implementation discrepancies. 7. Make the design shardable When it makes sense, for instance in a relational storage provider, make the design readily shardable. For instance, this means using no database-dependent data (e.g. IDENTITY ). Information that distinguishes row data should build on only data from the actual parameters. 8. Make the design easy to test Creating a new backend should ideally be as easy as translating one of the existing deployment scripts into the SQL dialect of the backend you are trying to target, adding a new connection string to the tests (assuming default parameters), checking to see if a given database is installed, and then runing the tests against it. 9. Taking into account the previous points, make both porting scripts for new backends and modifying already-deployed backend scripts as transparent as possible Realization of the goals The Orleans framework does not have a knowledge of deployment-specific hardware (which hardware may change during active deployment), the change of data during the deployment life-cycle, or certain vendor-specific features which are only usable in certain situations. For this reason, the interface between the database and Orleans should adhere to the minimum set of abstractions and rules to meet these goals, make it robust against misuse, and make it easy to test if needed. Runtime Tables, Cluster Management and the concrete membership protocol implementation . Also, the SQL Server implementation contains SQL Server edition-specific tuning. The interface contract between the database and Orleans is defined as follows: The general idea is that data is read and written through Orleans-specific queries. Orleans operates on column names and types when reading, and on parameter names and types when writing. The implementations must preserve input and output names and types. Orleans uses these parameters to read query results by name and type. Vendor- and deployment-specific tuning is allowed, and contributions are encouraged as long as the interface contract is maintained. The implementation across vendor-specific scripts should preserve the constraint names. This simplifies troubleshooting, by virtue of uniform naming across concrete implementations. Version – or ETag in application code – for Orleans, this represents a unique version. The type of its actual implementation is not important as long as it represents a unique version. In the implementation, Orleans code expects a signed 32-bit integer. For the sake of being explicit and removing ambiguity, Orleans expects some queries to return either TRUE as > 0 value or FALSE as = 0 value. That is, the number of affected or returned rows does not matter. If an error is raised or an exception is thrown, the query must ensure the entire transaction is rolled back, and may either return FALSE or propagate the exception. Currently, all but one query are single-row inserts or updates (note, one could replace UPDATE queries with INSERT , provided the associated SELECT queries performed the last write). Database engines support in-database programming. This is similar to the idea of loading an executable script and invoking it to execute database operations. In pseudocode it could be depicted as: const int Param1 = 1; const DateTime Param2 = DateTime.UtcNow; const string queryFromOrleansQueryTableWithSomeKey = \"SELECT column1, column2 FROM <some Orleans table> where column1 = @param1 AND column2 = @param2;\"; TExpected queryResult = SpecificQuery12InOrleans<TExpected>(query, Param1, Param2); These principles are also included in the database scripts . Some ideas on applying customized scripts Alter scripts in OrleansQuery for grain persistence with IF ELSE so that some state is saved using the default INSERT , while some grain states may use memory optimized tables . The SELECT queries need to be altered accordingly. The idea in 1. can be used to take advantage of other deployment- or vendor-specific aspects, such as splitting data between SSD or HDD , putting some data in encrypted tables, or perhaps inserting statistics data via SQL-Server-to-Hadoop, or even linked servers . The altered scripts can be tested by running the Orleans test suite, or straight in the database using, for instance, SQL Server Unit Test Project . Guidelines for adding new ADO.NET providers Add a new database setup script according to the Realization of the goals section above. Add the vendor ADO invariant name to AdoNetInvariants and ADO.NET provider-specific data to DbConstantsStore . These are (potentially) used in some query operations. e.g. to select the correct statistics insert mode (i.e. the UNION ALL with or without FROM DUAL ). Orleans has comprehensive tests for all system stores: membership, reminders and statistics. Adding tests for the new database script is done by copy-pasting existing test classes and changing the ADO invariant name. Also, derive from RelationalStorageForTesting in order to define test functionality for the ADO invariant."
  },
  "docs/grains/grain_placement.html": {
    "href": "docs/grains/grain_placement.html",
    "title": "Grain Placement | Microsoft Orleans Documentation",
    "keywords": "Grain Placement Orleans ensures that when a grain call is made there is an instance of that grain available in memory on some server in the cluster to handle the request. If the grain is not currently active in the cluster, Orleans picks one of the servers to activate the grain on. This is called grain placement. Placement is also one way that load is balanced: even placement of busy grains helps to even the workload across the cluster. The placement process in Orleans is fully configurable: developers can choose from a set of out-of-the-box placement policies such as random, prefer-local, and load-based, or custom logic can be configured. This allows for full flexibility in deciding where grains are created. For example, grains can be placed on a server close to resources which they need to operate on or close to other grains which they communicate with. By default, Orleans will pick a random compatible server. The placement strategy which Orleans uses can be configured globally or per-grain-class. In-built placement strategies Random placement A server is randomly selected from the set of compatible servers. This placement strategy is configured by adding the [RandomPlacement] attribute to a grain. Local placement If the local server is compatible, select the local server, otherwise select a random server. This placement strategy is configured by adding the [PreferLocalPlacement] attribute to a grain. Hash-based placement Hash the grain id to a non-negative integer and modulo it with the number of compatible servers. Select the corresponding server from list of compatible servers ordered by server address. Note that this is not guaranteed to remain stable as the cluster membership changes. Specifically, adding, removing, or restarting servers can alter the server selected for a given grain id. Because grains placed using this strategy are registered in the grain directory, this change in placement decision as membership changes typically does not have a noticeable effect. This placement strategy is configured by adding the [HashBasedPlacement] attribute to a grain. Activation-count-based placement The intention of this placement strategy is to place new grain activations on the least heavily loaded server based on the number of recently busy grains. It includes a mechanism in which all servers periodically publish their total activation count to all other servers. The placement director then selects a server which is predicted to have the fewest activations by examining the most recently reported activation count and a making prediction of the current activation count based upon the recent activation count made by the placement director on the current server. The director selects a number of servers at random when making this prediction, in an attempt to avoid multiple separate servers overloading the same server. By default, two servers are selected at random, but this value is configurable via ActivationCountBasedPlacementOptions . This algorithm is based on the thesis The Power of Two Choices in Randomized Load Balancing by Michael David Mitzenmacher , and is also used in NGINX for distributed load balancing, as described in the article NGINX and the \"Power of Two Choices\" Load-Balancing Algorithm . This placement strategy is configured by adding the [ActivationCountBasedPlacement] attribute to a grain. Stateless worker placement This is a special placement strategy used by stateless worker grains . This operates almost identically to PreferLocalPlacement except that each server can have multiple activations of the same grain and the grain is not registered in the grain directory since there is no need. This placement strategy is configured by adding the [StatelessWorker] attribute to a grain. Configuring the default placement strategy Orleans will use random placement unless the default is overridden. The default placement strategy can be overridden by registering an implementation of PlacementStrategy during configuration: siloBuilder.ConfigureServices(services => services.AddSingleton<PlacementStrategy, MyPlacementStrategy>()); Configuring the placement strategy for a grain The placment strategy for a grain type is configured by adding the appropriate attribute on the grain class. The relevant attributes are specified in the in-built placement strategies section. Sample custom placement strategy First define a class which implements IPlacementDirector interface, requiring a single method. In this example we assume you have a function GetSiloNumber defined which will return a silo number given the guid of the grain about to be created. public class SamplePlacementStrategyFixedSiloDirector : IPlacementDirector { public Task<SiloAddress> OnAddActivation(PlacementStrategy strategy, PlacementTarget target, IPlacementContext context) { var silos = context.GetCompatibleSilos(target).OrderBy(s => s).ToArray(); int silo = GetSiloNumber(target.GrainIdentity.PrimaryKey, silos.Length); return Task.FromResult(silos[silo]); } } You then need to define two classes to allow grain classes to be assigned to the strategy: [Serializable] public class SamplePlacementStrategy : PlacementStrategy { } [AttributeUsage(AttributeTargets.Class, AllowMultiple = false)] public sealed class SamplePlacementStrategyAttribute : PlacementAttribute { public SamplePlacementStrategyAttribute() : base(new SamplePlacementStrategy()) { } } Then just tag any grain classes you want to use this strategy with the attribute: [SamplePlacementStrategy] public class MyGrain : Grain, IMyGrain { ... } And finally register the strategy when you build the SiloHost: private static async Task<ISiloHost> StartSilo() { ISiloHostBuilder builder = new SiloHostBuilder() // normal configuration methods omitted for brevity .ConfigureServices(ConfigureServices); var host = builder.Build(); await host.StartAsync(); return host; } private static void ConfigureServices(IServiceCollection services) { services.AddSingletonNamedService<PlacementStrategy, SamplePlacementStrategy>(nameof(SamplePlacementStrategy)); services.AddSingletonKeyedService<Type, IPlacementDirector, SamplePlacementStrategyFixedSiloDirector>(typeof(SamplePlacementStrategy)); } For a second simple example showing further use of the placement context, refer to the PreferLocalPlacementDirector in the Orleans source repo"
  },
  "docs/grains/grain_versioning/backward_compatibility_guidelines.html": {
    "href": "docs/grains/grain_versioning/backward_compatibility_guidelines.html",
    "title": "Backward compatibility guidelines | Microsoft Orleans Documentation",
    "keywords": "Backward compatibility guidelines Writing backward compatible code can be hard and difficult to test. Never change the signature of existing methods Because of the way on how Orleans serializer work, you should never change the signature of existing methods. The following example is correct: [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 Task MyMethod(int arg); // New method added in V2 Task MyNewMethod(int arg, obj o); } This is not correct: [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 Task MyMethod(int arg, obj o); } NOTE : you should not do this change in your code, as it's an example of a bad practice that leads to very bad side-effects. This is an example of what can happen if you just rename the parameter names: let's say that we have the two following interface version deployed in the cluster: [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // return a - b Task<int> Substract(int a, int b); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // return y - x Task<int> Substract(int y, int x); } This methods seems identical. But if the client was called with V1, and the request is handled by a V2 activation: var grain = client.GetGrain<IMyGrain>(0); var result = await grain.Substract(5, 4); // Will return \"-1\" instead of expected \"1\" This is due to how the internal Orleans serializer works. Avoid changing existing method logic It can seems obvious, but you should be very careful when changing the body of an existing method. Unless you are fixing a bug, it is better to just add a new method if you need to modify the code. Example: // V1 public interface MyGrain : IMyGrain { // First method Task MyMethod(int arg) { SomeSubRoutine(arg); } } // V2 public interface MyGrain : IMyGrain { // Method inherited from V1 // Do not change the body Task MyMethod(int arg) { SomeSubRoutine(arg); } // New method added in V2 Task MyNewMethod(int arg) { SomeSubRoutine(arg); NewRoutineAdded(arg); } } Do not remove methods from grain interfaces Unless you are sure that they are no longer used, you should not remove methods from the grain interface. If you want to remove methods, this should be done in 2 steps: Deploy V2 grains, with V1 method marked as Obsolete [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 [Obsolete] Task MyMethod(int arg); // New method added in V2 Task MyNewMethod(int arg, obj o); } When you are sure that no V1 calls are made (effectively V1 is no longer deployed in the running cluster), deploy V3 with V1 method removed [Version(3)] public interface IMyGrain : IGrainWithIntegerKey { // New method added in V2 Task MyNewMethod(int arg, obj o); }"
  },
  "docs/grains/grain_versioning/compatible_grains.html": {
    "href": "docs/grains/grain_versioning/compatible_grains.html",
    "title": "Compatible grains | Microsoft Orleans Documentation",
    "keywords": "Compatible grains When an existing grain activation is about to process a request, the runtime will check if the version in the request and the actual version of the grain are compatible. Orleans does not infer at runtime which policy to use , The default behavior to determine if two versions are compatible is determined by GrainVersioningOptions.CompatibilityStrategy Backward compatible (default) Definition A grain interface version Vn can be backward compatible with Vm if: The name of the interface didn't change (or the overridden typecode) All public methods present in the Vm version are in the Vn version. It is important that the signatures of the methods inherited from Vm are not modified : since Orleans use an internal built-in serializer, modifying/renaming a field (even private) can make the serialization to break. Since Vn can have added methods compared to Vm, Vm is not compatible with Vn. Example If in the cluster we have two versions of a given interface, V1 and V2 and that V2 is backward compatible with V1: If the current activation is a V2 and the requested version is V1, the current activation will be able to process the request normally If the current activation is a V1 and the requested version is V2, the current activation will be deactivated and a new activation compatible with V2 will be created (see version selector strategy ). Fully compatible Definition A grain interface version Vn can be fully compatible with Vm if: Vn is backward compatible with Vm No public methods were added in the Vn version If Vn is fully compatible with Vm then Vm is also fully compatible with Vn. Example If in the cluster we have two versions of a given interface, V1 and V2 and that V2 is fully compatible with V1: If the current activation is a V2 and the requested version is V1, the current activation will be able to process the request normally If the current activation is a V1 and the requested version is V2, the current activation will also be able to process the request normally"
  },
  "docs/grains/grain_versioning/deploying_new_versions_of_grains.html": {
    "href": "docs/grains/grain_versioning/deploying_new_versions_of_grains.html",
    "title": "Deploy new version of grains | Microsoft Orleans Documentation",
    "keywords": "Deploy new version of grains Rolling upgrade In this method you deploy newer silos directly on your environment. This is the simplest method, but it can be difficult to interrupt an ongoing deployment and to rollback. Recommended configuration: DefaultCompatibilityStrategy set to BackwardCompatible DefaultVersionSelectorStrategy set to AllCompatibleVersions var silo = new SiloHostBuilder() [...] .Configure<GrainVersioningOptions>(options => { options.DefaultCompatibilityStrategy = nameof(BackwardCompatible); options.DefaultVersionSelectorStrategy = nameof(AllCompatibleVersions); }) [...] When using this configuration, \"old\" clients will be able to talk to activations on both versions of silos. Newer clients and silos will only trigger new activations on newer silos. Using a staging environment In this method you will need a second environment (Staging environment), on which you will deploy newer silos before stopping the Production environment. The Production and the Staging silos and clients will be part of the same cluster . It is important that silos from both environment can talk to each other. Recommended configuration: DefaultCompatibilityStrategy set to BackwardCompatible DefaultVersionSelectorStrategy set to MinimumVersion var silo = new SiloHostBuilder() [...] .Configure<GrainVersioningOptions>(options => { options.DefaultCompatibilityStrategy = nameof(BackwardCompatible); options.DefaultVersionSelectorStrategy = nameof(MinimumVersion); }) [...] Suggested deployment steps: \"V1\" silos and clients are deployed and are running in the Production slot. \"V2\" silos and clients begin to start in the Staging slot. They will join the same cluster as the Production slot. No \"V2\" activations will be created so far. Once the deployment in the Staging slot is finished, the developer can redirect some traffic to the V2 clients (smoke tests, targeted beta users, etc.). This will create V2 activations, but since Grains are backward compatible and all silos are in the same cluster, no duplicate activations will be created. If the validation is successful, proceed to VIP swap. If not, you can safely shutdown the Staging cluster: existing V2 activations will be destroyed and V1 activations will be created if needed. V1 activations will naturally \"migrate\" to V2 silos eventually. You can safely shutdown V1 silos. Warning Remember that stateless workers are not versioned and that streaming agents will also start in the staging environment."
  },
  "docs/grains/grain_versioning/grain_versioning.html": {
    "href": "docs/grains/grain_versioning/grain_versioning.html",
    "title": "Grain Interface Versioning | Microsoft Orleans Documentation",
    "keywords": "Grain Interface Versioning Warning This page describes how to use grain interface versioning. The versioning of Grain state is out of scope. Overview On a given cluster, silos can support different versions of a grain type. In this example the client and Silo{1,2,3} were compiled with grain interface A version 1. Silo 4 was compiled with A version 2. Limitations: No versioning on stateless worker Streaming interfaces are not versioned Enable versioning If the version attribute is not explicitly added to the grain interface, then the grains have a default version of 0. You can version grain by using the VersionAttribute on the grain interface: [Version(X)] public interface IVersionUpgradeTestGrain : IGrainWithIntegerKey {} Where X is the version number of the grain interface, which is typically monotonically increasing. Grain version compatibility and placement When a call from a versioned grain arrives in a cluster: If no activation exists, a compatible activation will be created If an activation exists: If the current one is not compatible, it will be deactivated and new compatible one will be created (see version selector strategy ) If the current one is compatible (see compatible grains ), the call will be handled normally. By default: All versioned grains are supposed to be backward-compatible only (see backward compatibility guidelines and compatible grains ). That means that a v1 grain can make calls to a v2 grain, but a v2 grain cannot call a v1. When multiple versions exist in the cluster, the new activation will be randomly placed on a compatible silo. You can change this default behavior via the option GrainVersioningOptions : var silo = new SiloHostBuilder() [...] .Configure<GrainVersioningOptions>(options => { options.DefaultCompatibilityStrategy = nameof(BackwardCompatible); options.DefaultVersionSelectorStrategy = nameof(MinimumVersion); }) [...]"
  },
  "docs/grains/grain_versioning/version_selector_strategy.html": {
    "href": "docs/grains/grain_versioning/version_selector_strategy.html",
    "title": "Version selector strategy | Microsoft Orleans Documentation",
    "keywords": "Version selector strategy When several versions of the same grain interface exist in the cluster, and a new activation has to be created, a compatible version will be chosen according to the strategy defined in GrainVersioningOptions.DefaultVersionSelectorStrategy . Orleans out of the box supports the following strategies: All compatible versions (default) Using this strategy, the version of the new activation will be chosen randomly across all compatible versions. For example if we have 2 versions of a given grain interface, V1 and V2: V2 is backward compatible with V1 In the cluster there are 2 silos that support V2, 8 support V1 The request was made from a V1 client/silo In this case, there is a 20% chance that the new activation will be a V2 and 80% chance that it will be a V1. Latest version Using this strategy, the version of the new activation will always be the latest compatible version. For example if we have 2 versions of a given grain interface, V1 and V2 (V2 is backward or fully compatible with V1) then all new activations will be V2. Minimum version Using this strategy, the version of the new activation will always be the requested or the minimum compatible version. For example if we have 2 versions of a given grain interface, V2, V3, all fully compatibles: If the request was made from a V1 client/silo, the new activation will be a V2 If the request was made from a V3 client/silo, the new activation will be a V2 too"
  },
  "docs/grains/grainservices.html": {
    "href": "docs/grains/grainservices.html",
    "title": "GrainServices | Microsoft Orleans Documentation",
    "keywords": "GrainServices A GrainService is a special grain; one that has no identity, and runs in every silo from startup to shutdown. Creating a GrainService Step 1. Create the interface. The interface of a GrainService is built using exactly the same principles you would use for building the interface of any other grain. public interface IDataService : IGrainService { Task MyMethod(); } Step 2. Create the DataService grain itself. If possible, make the GrainService reentrant for better performance. Note the necessary base constructor call. It’s good to know that you can also inject an IGrainFactory so you can make grain calls from your GrainService. A note about streams: a GrainService cannot write to Orleans streams because it doesn’t work within a grain task scheduler. If you need the GrainService to write to streams for you, then you will have to send the object to another kind of grain for writing to the stream. [Reentrant] public class DataService : GrainService, IDataService { readonly IGrainFactory GrainFactory; public DataService(IServiceProvider services, IGrainIdentity id, Silo silo, ILoggerFactory loggerFactory, IGrainFactory grainFactory) : base(id, silo, loggerFactory) { GrainFactory = grainFactory; } public override Task Init(IServiceProvider serviceProvider) { return base.Init(serviceProvider); } public override async Task Start() { await base.Start(); } public override Task Stop() { return base.Stop(); } public Task MyMethod() { } } Step 3. Create an interface for the GrainServiceClient to be used by other grains to connect to the GrainService. public interface IDataServiceClient : IGrainServiceClient<IDataService>, IDataService { } Step 4. Create the actual grain service client. It pretty much just acts as a proxy for the data service. Unfortunately, you have to manually type in all the method mappings, which are just simple one-liners. public class DataServiceClient : GrainServiceClient<IDataService>, IDataServiceClient { public DataServiceClient(IServiceProvider serviceProvider) : base(serviceProvider) { } public Task MyMethod() => GrainService.MyMethod(); } Step 5. Inject the grain service client into the other grains that need it. Note that the GrainServiceClient does not guarantee accessing the GrainService on the local silo. Your command could potentially be sent to the GrainService on any silo in the cluster. public class MyNormalGrain: Grain<NormalGrainState>, INormalGrain { readonly IDataServiceClient DataServiceClient; public MyNormalGrain(IGrainActivationContext grainActivationContext, IDataServiceClient dataServiceClient) { DataServiceClient = dataServiceClient; } } Step 6. Inject the grain service into the silo itself. You need to do this so that the silo will start the GrainService. (ISiloHostBuilder builder) => builder .ConfigureServices(services => { services.AddSingleton<IDataService, DataService>(); }); Additional Notes Note 1 There's an extension method on ISiloHostBuilder: AddGrainService<SomeGrainService>() . Type constraint is: where T : GrainService . It ends up calling this bit: orleans/src/Orleans.Runtime/Services/GrainServicesSiloBuilderExtensions.cs return services.AddSingleton<IGrainService>(sp => GrainServiceFactory(grainServiceType, sp)); Basically, the silo fetches IGrainService types from the service provider when starting: orleans/src/Orleans.Runtime/Silo/Silo.cs var grainServices = this.Services.GetServices<IGrainService>(); The Microsoft.Orleans.OrleansRuntime Nuget package should be referenced by the Grainservice project. Note 2 In order for this to work you have to register both the Service and its Client. The code looks something like this: var builder = new SiloHostBuilder() .AddGrainService<DataService>() // Register GrainService .ConfigureServices(s => { // Register Client of GrainService s.AddSingleton<IDataServiceClient, DataServiceClient>(); })"
  },
  "docs/grains/index.html": {
    "href": "docs/grains/index.html",
    "title": "Developing a Grain | Microsoft Orleans Documentation",
    "keywords": "Setup Before you write code to implement a grain class, create a new Class Library project targeting .NET Standard or .Net Core (preferred) or .NET Framework 4.6.1 or higher (if you cannot use .NET Standard or .NET Core due to dependencies). Grain interfaces and grain classes can be defined in the same Class Library project, or in two different projects for better separation of interfaces from implementation. In either case, the projects need to reference Microsoft.Orleans.Core.Abstractions and Microsoft.Orleans.CodeGenerator.MSBuild NuGet packages. For more thorough instructions, see the Project Setup section of Tutorial One – Orleans Basics . Grain Interfaces and Classes Grains interact with each other and get called from outside by invoking methods declared as part of the respective grain interfaces. A grain class implements one or more previously declared grain interfaces. All methods of a grain interface must return a Task (for void methods), a Task<T> or a ValueTask<T> (for methods returning values of type T ). The following is an excerpt from the Orleans version 1.5 Presence Service sample: //an example of a Grain Interface public interface IPlayerGrain : IGrainWithGuidKey { Task<IGameGrain> GetCurrentGame(); Task JoinGame(IGameGrain game); Task LeaveGame(IGameGrain game); } //an example of a Grain class implementing a Grain Interface public class PlayerGrain : Grain, IPlayerGrain { private IGameGrain currentGame; // Game the player is currently in. May be null. public Task<IGameGrain> GetCurrentGame() { return Task.FromResult(currentGame); } // Game grain calls this method to notify that the player has joined the game. public Task JoinGame(IGameGrain game) { currentGame = game; Console.WriteLine( \"Player {0} joined game {1}\", this.GetPrimaryKey(), game.GetPrimaryKey()); return Task.CompletedTask; } // Game grain calls this method to notify that the player has left the game. public Task LeaveGame(IGameGrain game) { currentGame = null; Console.WriteLine( \"Player {0} left game {1}\", this.GetPrimaryKey(), game.GetPrimaryKey()); return Task.CompletedTask; } } Returning Values from Grain Methods A grain method that returns a value of type T is defined in a grain interface as returning a Task<T> . For grain methods not marked with the async keyword, when the return value is available, it is usually returned via the following statement: public Task<SomeType> GrainMethod1() { ... return Task.FromResult(<variable or constant with result>); } A grain method that returns no value, effectively a void method, is defined in a grain interface as returning a Task . The returned Task indicates asynchronous execution and completion of the method. For grain methods not marked with the async keyword, when a \"void\" method completes its execution, it needs to return the special value of Task.CompletedTask : public Task GrainMethod2() { ... return Task.CompletedTask; } A grain method marked as async returns the value directly: public async Task<SomeType> GrainMethod3() { ... return <variable or constant with result>; } A \"void\" grain method marked as async that returns no value simply returns at the end of its execution: public async Task GrainMethod4() { ... return; } If a grain method receives the return value from another asynchronous method call, to a grain or not, and doesn't need to perform error handling of that call, it can simply return the Task it receives from that asynchronous call: public Task<SomeType> GrainMethod5() { ... Task<SomeType> task = CallToAnotherGrain(); return task; } Similarly, a \"void\" grain method can return a Task returned to it by another call instead of awaiting it. public Task GrainMethod6() { ... Task task = CallToAsyncAPI(); return task; } ValueTask<T> can be used instead of Task<T> Grain Reference A Grain Reference is a proxy object that implements the same grain interface as the corresponding grain class. It encapsulates the logical identity (type and unique key) of the target grain. A grain reference is used for making calls to the target grain. Each grain reference is to a single grain (a single instance of the grain class), but one can create multiple independent references to the same grain. Since a grain reference represents the logical identity of the target grain, it is independent from the physical location of the grain, and stays valid even after a complete restart of the system. Developers can use grain references like any other .NET object. It can be passed to a method, used as a method return value, etc., and even saved to persistent storage. A grain reference can be obtained by passing the identity of a grain to the GrainFactory.GetGrain<T>(key) method, where T is the grain interface and key is the unique key of the grain within the type. The following are examples of how to obtain a grain reference of the IPlayerGrain interface defined above. From inside a grain class: //construct the grain reference of a specific player IPlayerGrain player = GrainFactory.GetGrain<IPlayerGrain>(playerId); From Orleans Client code. IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); Grain Method Invocation The Orleans programming model is based on Asynchronous Programming . Using the grain reference from the previous example, here's how to perform a grain method invocation: //Invoking a grain method asynchronously Task joinGameTask = player.JoinGame(this); //The await keyword effectively makes the remainder of the method execute asynchronously at a later point (upon completion of the Task being awaited) without blocking the thread. await joinGameTask; //The next line will execute later, after joinGameTask has completed. players.Add(playerId); It is possible to join two or more Tasks ; the join operation creates a new Task that is resolved when all of its constituent Task s are completed. This is a useful pattern when a grain needs to start multiple computations and wait for all of them to complete before proceeding. For example, a front-end grain that generates a web page made of many parts might make multiple back-end calls, one for each part, and receive a Task for each result. The grain would then await the join of all of these Tasks ; when the join Task is resolved, the individual Task s have been completed, and all the data required to format the web page has been received. Example: List<Task> tasks = new List<Task>(); Message notification = CreateNewMessage(text); foreach (ISubscriber subscriber in subscribers) { tasks.Add(subscriber.Notify(notification)); } // WhenAll joins a collection of tasks, and returns a joined Task that will be resolved when all of the individual notification Tasks are resolved. Task joinedTask = Task.WhenAll(tasks); await joinedTask; // Execution of the rest of the method will continue asynchronously after joinedTask is resolve. Virtual methods A grain class can optionally override OnActivateAsync and OnDeactivateAsync virtual methods; these are invoked by the Orleans runtime upon activation and deactivation of each grain of the class. This gives the grain code a chance to perform additional initialization and cleanup operations. An exception thrown by OnActivateAsync fails the activation process. While OnActivateAsync , if overridden, is always called as part of the grain activation process, OnDeactivateAsync is not guaranteed to get called in all situations, for example, in case of a server failure or other abnormal event. Because of that, applications should not rely on OnDeactivateAsync for performing critical operations such as persistence of state changes. They should use it only for best-effort operations."
  },
  "docs/grains/interceptors.html": {
    "href": "docs/grains/interceptors.html",
    "title": "Grain Call Filters | Microsoft Orleans Documentation",
    "keywords": "Grain Call Filters Grain call filters provide a means for intercepting grain calls. Filters can execute code both before and after a grain call. Multiple filters can be installed simultaneously. Filters are asynchronous and can modify RequestContext , arguments, and the return value of the method being invoked. Filters can also inspect the MethodInfo of the method being invoked on the grain class and can be used to throw or handle exceptions. Some example usages of grain call filters are: Authorization: a filter can inspect the method being invoked and the arguments or some authorization information in the RequestContext to determine whether or not to allow the call to proceed. Logging/Telemetry: a filter can log information and capture timing data and other statistics about method invocation. Error Handling: a filter can intercept exceptions thrown by a method invocation and transform it into another exception or handle the exception as it passes through the filter. Filters come in two flavors: Incoming call filters Outgoing call filters Incoming call filters are executed when receiving a call. Outgoing call filters are executed when making a call. Incoming Call Filters Incoming grain call filters implement the IIncomingGrainCallFilter interface, which has one method: public interface IIncomingGrainCallFilter { Task Invoke(IIncomingGrainCallContext context); } The IIncomingGrainCallContext argument passed to the Invoke method has the following shape: public interface IIncomingGrainCallContext { /// <summary> /// Gets the grain being invoked. /// </summary> IAddressable Grain { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the interface method being invoked. /// </summary> MethodInfo InterfaceMethod { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the implementation method being invoked. /// </summary> MethodInfo ImplementationMethod { get; } /// <summary> /// Gets the arguments for this method invocation. /// </summary> object[] Arguments { get; } /// <summary> /// Invokes the request. /// </summary> Task Invoke(); /// <summary> /// Gets or sets the result. /// </summary> object Result { get; set; } } The IIncomingGrainCallFilter.Invoke(IIncomingGrainCallContext) method must await or return the result of IIncomingGrainCallContext.Invoke() to execute the next configured filter and eventually the grain method itself. The Result property can be modified after awaiting the Invoke() method. The ImplementationMethod property returns the MethodInfo of the implementation class. The MethodInfo of the interface method can be accessed using the InterfaceMethod property. Grain call filters are called for all method calls to a grain and this includes calls to grain extensions (implementations of IGrainExtension ) which are installed in the grain. For example, grain extensions are used to implement Streams and Cancellation Tokens. Therefore, it should be expected that the value of ImplementationMethod is not always a method in the grain class itself. Configuring Incoming Grain Call Filters Implementations of IIncomingGrainCallFilter can either be registered as silo-wide filters via Dependency Injection or they can be registered as grain-level filters via a grain implementing IIncomingGrainCallFilter directly. Silo-wide Grain Call Filters A delegate can be registered as a silo-wide grain call filters using Dependency Injection like so: siloHostBuilder.AddIncomingGrainCallFilter(async context => { // If the method being called is 'MyInterceptedMethod', then set a value // on the RequestContext which can then be read by other filters or the grain. if (string.Equals(context.InterfaceMethod.Name, nameof(IMyGrain.MyInterceptedMethod))) { RequestContext.Set(\"intercepted value\", \"this value was added by the filter\"); } await context.Invoke(); // If the grain method returned an int, set the result to double that value. if (context.Result is int resultValue) context.Result = resultValue * 2; }); Similarly, a class can be registered as a grain call filter using the AddIncomingGrainCallFilter helper method. Here is an example of a grain call filter which logs the results of every grain method: public class LoggingCallFilter : IIncomingGrainCallFilter { private readonly Logger log; public LoggingCallFilter(Factory<string, Logger> loggerFactory) { this.log = loggerFactory(nameof(LoggingCallFilter)); } public async Task Invoke(IIncomingGrainCallContext context) { try { await context.Invoke(); var msg = string.Format( \"{0}.{1}({2}) returned value {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), context.Result); this.log.Info(msg); } catch (Exception exception) { var msg = string.Format( \"{0}.{1}({2}) threw an exception: {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), exception); this.log.Info(msg); // If this exception is not re-thrown, it is considered to be // handled by this filter. throw; } } } This filter can then be registered using the AddIncomingGrainCallFilter extension method: siloHostBuilder.AddIncomingGrainCallFilter<LoggingCallFilter>(); Alternatively, the filter can be registered without the extension method: siloHostBuilder.ConfigureServices( services => services.AddSingleton<IIncomingGrainCallFilter, LoggingCallFilter>()); Per-grain Grain Call Filters A grain class can register itself as a grain call filter and filter any calls made to it by implementing IIncomingGrainCallFilter like so: public class MyFilteredGrain : Grain, IMyFilteredGrain, IIncomingGrainCallFilter { public async Task Invoke(IIncomingGrainCallContext context) { await context.Invoke(); // Change the result of the call from 7 to 38. if (string.Equals(context.InterfaceMethod.Name, nameof(this.GetFavoriteNumber))) { context.Result = 38; } } public Task<int> GetFavoriteNumber() => Task.FromResult(7); } In the above example, all calls to the GetFavoriteNumber method will return 38 instead of 7 , because the return value has been altered by the filter. Another use case for filters is in access control, as in this example: [AttributeUsage(AttributeTargets.Method)] public class AdminOnlyAttribute : Attribute { } public class MyAccessControlledGrain : Grain, IMyFilteredGrain, IIncomingGrainCallFilter { public Task Invoke(IIncomingGrainCallContext context) { // Check access conditions. var isAdminMethod = context.ImplementationMethod.GetCustomAttribute<AdminOnlyAttribute>(); if (isAdminMethod && !(bool) RequestContext.Get(\"isAdmin\")) { throw new AccessDeniedException($\"Only admins can access {context.ImplementationMethod.Name}!\"); } return context.Invoke(); } [AdminOnly] public Task<int> SpecialAdminOnlyOperation() => Task.FromResult(7); } In the above example, the SpecialAdminOnlyOperation method can only be called if \"isAdmin\" is set to true in the RequestContext . In this way, grain call filters can be used for authorization. In this example, it is the responsibility of the caller to ensure that the \"isAdmin\" value is set correctly and that authentication is performed correctly. Note that the [AdminOnly] attribute is specified on the grain class method. This is because the ImplementationMethod property returns the MethodInfo of the implementation, not the interface. The filter could also check the InterfaceMethod property. Ordering of Grain Call Filters Grain call filters follow a defined ordering: IIncomingGrainCallFilter implementations configured in the dependency injection container, in the order in which they are registered. Grain-level filter, if the grain implements IIncomingGrainCallFilter . Grain method implementation or grain extension method implementation. Each call to IIncomingGrainCallContext.Invoke() encapsulates the next defined filter so that each filter has a chance to execute code before and after the next filter in the chain and eventually the grain method itself. Outgoing Call Filters Outgoing grain call filters are similar to incoming grain call filters with the major difference being that they are invoked on the caller (client) rather than the callee (grain). Outgoing grain call filters implement the IOutgoingGrainCallFilter interface, which has one method: public interface IOutgoingGrainCallFilter { Task Invoke(IOutgoingGrainCallContext context); } The IOutgoingGrainCallContext argument passed to the Invoke method has the following shape: public interface IOutgoingGrainCallContext { /// <summary> /// Gets the grain being invoked. /// </summary> IAddressable Grain { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the interface method being invoked. /// </summary> MethodInfo InterfaceMethod { get; } /// <summary> /// Gets the arguments for this method invocation. /// </summary> object[] Arguments { get; } /// <summary> /// Invokes the request. /// </summary> Task Invoke(); /// <summary> /// Gets or sets the result. /// </summary> object Result { get; set; } } The IOutgoingGrainCallFilter.Invoke(IOutgoingGrainCallContext) method must await or return the result of IOutgoingGrainCallContext.Invoke() to execute the next configured filter and eventually the grain method itself. The Result property can be modified after awaiting the Invoke() method. The MethodInfo of the interface method being called can be accessed using the InterfaceMethod property. Outgoing grain call filters are invoked for all method calls to a grain and this includes calls to system methods made by Orleans. Configuring Outgoing Grain Call Filters Implementations of IOutgoingGrainCallFilter can either be registered on both silos and clients using Dependency Injection. A delegate can be registered as a call filter like so: builder.AddOutgoingGrainCallFilter(async context => { // If the method being called is 'MyInterceptedMethod', then set a value // on the RequestContext which can then be read by other filters or the grain. if (string.Equals(context.InterfaceMethod.Name, nameof(IMyGrain.MyInterceptedMethod))) { RequestContext.Set(\"intercepted value\", \"this value was added by the filter\"); } await context.Invoke(); // If the grain method returned an int, set the result to double that value. if (context.Result is int resultValue) context.Result = resultValue * 2; }); In the above code, builder may be either an instance of ISiloHostBuilder or IClientBuilder . Similarly, a class can be registered as an outgoing grain call filter. Here is an example of a grain call filter which logs the results of every grain method: public class LoggingCallFilter : IOutgoingGrainCallFilter { private readonly Logger log; public LoggingCallFilter(Factory<string, Logger> loggerFactory) { this.log = loggerFactory(nameof(LoggingCallFilter)); } public async Task Invoke(IOutgoingGrainCallContext context) { try { await context.Invoke(); var msg = string.Format( \"{0}.{1}({2}) returned value {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), context.Result); this.log.Info(msg); } catch (Exception exception) { var msg = string.Format( \"{0}.{1}({2}) threw an exception: {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), exception); this.log.Info(msg); // If this exception is not re-thrown, it is considered to be // handled by this filter. throw; } } } This filter can then be registered using the AddOutgoingGrainCallFilter extension method: builder.AddOutgoingGrainCallFilter<LoggingCallFilter>(); Alternatively, the filter can be registered without the extension method: builder.ConfigureServices( services => services.AddSingleton<IOutgoingGrainCallFilter, LoggingCallFilter>()); As with the delegate call filter example, builder may be an instance of either ISiloHostBuiler or IClientBuilder . Use Cases Exception Conversion When an exception which has been thrown from the server is getting deserialized on the client, you may sometimes get the following exception instead of the actual one: TypeLoadException: Could not find Whatever.dll. This happens if the assembly containing the exception is not available to the client. For example, say you are using Entity Framework in your grain implementations; then it is possible that an EntityException is thrown. The client on the other hand does not (and should not) reference EntityFramework.dll since it has no knowledge about the underlying data access layer. When the client tries to deserialize the EntityException , it will fail due to the missing DLL; as a consequence a TypeLoadException is thrown hiding the original EntityException . One may argue that this is pretty okay, since the client would never handle the EntityException ; otherwise it would have to reference EntityFramework.dll . But what if the client wants at least to log the exception? The problem is that the original error message is lost. One way to workaround this issue is to intercept server-side exceptions and replace them by plain exceptions of type Exception if the exception type is presumably unknown on the client side. However, there is one important thing we have to keep in mind: we only want to replace an exception if the caller is the grain client . We don't want to replace an exception if the caller is another grain (or the Orleans infrastructure which is making grain calls, too; e.g. on the GrainBasedReminderTable grain). On the server side this can be done with a silo-level interceptor: public class ExceptionConversionFilter : IIncomingGrainCallFilter { private static readonly HashSet<string> KnownExceptionTypeAssemblyNames = new HashSet<string> { typeof(string).Assembly.GetName().Name, \"System\", \"System.ComponentModel.Composition\", \"System.ComponentModel.DataAnnotations\", \"System.Configuration\", \"System.Core\", \"System.Data\", \"System.Data.DataSetExtensions\", \"System.Net.Http\", \"System.Numerics\", \"System.Runtime.Serialization\", \"System.Security\", \"System.Xml\", \"System.Xml.Linq\", \"MyCompany.Microservices.DataTransfer\", \"MyCompany.Microservices.Interfaces\", \"MyCompany.Microservices.ServiceLayer\" }; public async Task Invoke(IIncomingGrainCallContext context) { var isConversionEnabled = RequestContext.Get(\"IsExceptionConversionEnabled\") as bool? == true; if (!isConversionEnabled) { // If exception conversion is not enabled, execute the call without interference. await context.Invoke(); return; } RequestContext.Remove(\"IsExceptionConversionEnabled\"); try { await context.Invoke(); } catch (Exception exc) { var type = exc.GetType(); if (KnownExceptionTypeAssemblyNames.Contains(type.Assembly.GetName().Name)) { throw; } // Throw a base exception containing some exception details. throw new Exception( string.Format( \"Exception of non-public type '{0}' has been wrapped.\" + \" Original message: <<<<----{1}{2}{3}---->>>>\", type.FullName, Environment.NewLine, exc, Environment.NewLine)); } } } This filter can then be registered on the silo: siloHostBuilder.AddIncomingGrainCallFilter<ExceptionConversionFilter>(); Enable the filter for calls made by the client by adding an outgoing call filter: clientBuilder.AddOutgoingGrainCallFilter(context => { RequestContext.Set(\"IsExceptionConversionEnabled\", true); return context.Invoke(); }); This way the client tells the server that it wants to use exception conversion. Calling Grains from Interceptors It is possible to make grain calls from an interceptor by injecting IGrainFactory into the interceptor class: private readonly IGrainFactory grainFactory; public CustomCallFilter(IGrainFactory grainFactory) { this.grainFactory = grainFactory; } public async Task Invoke(IIncomingGrainCallContext context) { // Hook calls to any grain other than ICustomFilterGrain implementations. // This avoids potential infinite recursion when calling OnReceivedCall() below. if (!(context.Grain is ICustomFilterGrain)) { var filterGrain = this.grainFactory.GetGrain<ICustomFilterGrain>(context.Grain.GetPrimaryKeyLong()); // Perform some grain call here. await filterGrain.OnReceivedCall(); } // Continue invoking the call on the target grain. await context.Invoke(); }"
  },
  "docs/grains/observers.html": {
    "href": "docs/grains/observers.html",
    "title": "Observers | Microsoft Orleans Documentation",
    "keywords": "Observers There are situations in which a simple message/response pattern is not enough, and the client needs to receive asynchronous notifications. For example, a user might want to be notified when a new instant message has been published by a friend. Client observers is a mechanism that allows notifying clients asynchronously. An observer is a one-way asynchronous interface that inherits from IGrainObserver , and all its methods must be void. The grain sends a notification to the observer by invoking it like a grain interface method, except that it has no return value, and so the grain need not depend on the result. The Orleans runtime will ensure one-way delivery of the notifications. A grain that publishes such notifications should provide an API to add or remove observers. In addition, it is usually convenient to expose a method that allows an existing subscription to be cancelled. Grain developers may use a utility class such as ObserverManager<T> to simplify development of observed grain types. Unlike grains, which are automatically reactivated as-needed after failure, clients are not fault tolerant: a client which fails may never recover. For this reason, the ObserverManager<T> utility removes subscriptions after a configured duration. Clients which are active should resubscribe on a timer to keep their subscription active. To subscribe to a notification, the client must first create a local object that implements the observer interface. It then calls a method on the observer factory, CreateObjectReference() , to turn the object into a grain reference, which can then be passed to the subscription method on the notifying grain. This model can also be used by other grains to receive asynchronous notifications. Grains can also implement IGrainObserver interfaces. Unlike in the client subscription case, the subscribing grain simply implements the observer interface and passes in a reference to itself (e.g. this.AsReference<IMyGrainObserverInterface>() ). There is no need for CreateObjectReference() because grains are already addressable. Code Example Let's assume that we have a grain that periodicaly sends messages to clients. For simplicity, the message in our example will be a string. We first define the interface on the client that will receive the message. The interface will look like this public interface IChat : IGrainObserver { void ReceiveMessage(string message); } The only special thing is that the interface should inherit from IGrainObserver . Now any client that wants to observe those messages should implement a class which implements IChat . The simplest case would be something like this: public class Chat : IChat { public void ReceiveMessage(string message) { Console.WriteLine(message); } } On the server, we should next have a Grain which sends these chat messages to clients. The Grain should also have a mechanism for clients to subscribe and unsubscribe themselves for notifications. For subscriptions, the grain can use a copy of the utility class ObserverManager<T> . class HelloGrain : Grain, IHello { private readonly ObserverManager<IChat> _subsManager; public HelloGrain(ILogger<HelloGrain> logger) { _subsManager = new ObserverManager<IChat>(TimeSpan.FromMinutes(5), logger, \"subs\"); } // Clients call this to subscribe. public Task Subscribe(IChat observer) { _subsManager.Subscribe(observer, observer); return Task.CompletedTask; } //Clients use this to unsubscribe and no longer receive messages. public Task UnSubscribe(IChat observer) { _subsManager.Unsubscribe(observer, observer); return Task.CompletedTask; } } To send a message to clients, the Notify method of the ObserverManager<IChat> instance can be used. The method takes an Action<T> method or lambda expression (where T is of type IChat here). You can call any method on the interface to send it to clients. In our case we only have one method, ReceiveMessage , and our sending code on the server would look like this: public Task SendUpdateMessage(string message) { _subsManager.Notify(s => s.ReceiveMessage(message)); return Task.CompletedTask; } Now our server has a method to send messages to observer clients, two methods for subscribing/unsubscribing, and the client has implemented a class able to observe the grain messages. The last step is to create an observer reference on the client using our previously implemented Chat class, and let it receive the messages after subscribing to it. The code would look like this: //First create the grain reference var friend = _grainFactory.GetGrain<IHello>(0); Chat c = new Chat(); //Create a reference for chat, usable for subscribing to the observable grain. var obj = await _grainFactory.CreateObjectReference<IChat>(c); //Subscribe the instance to receive messages. await friend.Subscribe(obj); Now whenever our grain on the server calls the SendUpdateMessage method, all subscribed clients will receive the message. In our client code, the Chat instance in variable c will receive the message and output it to the console. Note: Objects passed to CreateObjectReference are held via a WeakReference<T> and will therefore be garbage collected if no other references exist. Users should maintain a reference for each observer which they do not want to be collected. Note: Observers are inherently unreliable, since you don't get any response back to know if the message is received and processed or simply failed due to any condition which might arise in a distributed system. Because of that, your observers should poll the grain periodically or use any other mechanism to ensure that they received all messages which they should have received. In some situations you can afford to lose some messages and you don't need any additional mechanism, but if you need to make sure that all observers are always receiving the messages and are receiving all of them, both periodic resubscriptions and polling the observer grain can help to ensure eventual processing of all messages. Execution model Implementations of IGrainObserver are registered via a call to IGrainFactory.CreateObjectReference and each call to that method creates a new reference which points to that implementation. Orleans will execute requests sent to each one of these references one-by-one, to completion. Observers are non-reentrant and therefore concurrent requests to an observer will not be interleaved by Orleans. If there are multiple observers which are receiving requests concurrently, those requests can execute in parallel. Execution of observer methods are not affected by attributes such as [AlwaysInterleave] or [Reentrant] : the execution model cannot be customized by a developer."
  },
  "docs/grains/oneway.html": {
    "href": "docs/grains/oneway.html",
    "title": "One-way requests | Microsoft Orleans Documentation",
    "keywords": "One-way requests Grains execute requests (method calls) asynchronously and so all grain interface methods must return an asynchronous type, such as Task . By awaiting the completion of a task returned from a grain call, the caller is notified that the request has completed and any exceptions or return values can are propagated back to the caller so that they can be handled. There are cases where a caller merely wants to notify a grain that some event has happened and does not need to be informed of any exeptions or receive a completion signal. For these cases, Orleans supports one-way requests . One-way requests return to the caller immediately and do not signal failure or completion. A one-way request does not even guarantee that the caller received the request. The primary benefit of a one-way request is that they save messaging costs associated with sending a response back to the caller and can therefore improve performance in some specialized cases. One-way requests are an advanced performance feature and should be used with care and only when a developer has determined that a one-way request is beneficial. It is recommended to prefer regular bi-directional requests, which signal completion and propagate errors back to callers. A request can be made one-way by marking the grain interface method with the [OneWay] attribute, like so: public interface IOneWayGrain : IGrainWithGuidKey { [OneWay] Task Notify(MyData data); } One-way requests must return either Task or ValueTask and must not return generic variants of those types ( Task<T> and ValueTask<T> )."
  },
  "docs/grains/reentrancy.html": {
    "href": "docs/grains/reentrancy.html",
    "title": "Reentrancy | Microsoft Orleans Documentation",
    "keywords": "Request scheduling Grain activations have a single-threaded execution model and, by default, process each request from beginning to completion before the next request can begin processing. In some circumstances, it may be desirable for an activation to process other requests while one request is waiting for an asynchronous operation to complete. For this and other reasons, Orleans gives the developer some control over the request interleaving behavior, as described below in the Reentrancy section. What follows is an example of non-reentrant request scheduling, which is the default behavior in Orleans. Our initial examples with focus on the following PingGrain definition: public interface IPingGrain : IGrainWithStringKey { Task Ping(); Task CallOther(IPingGrain other); } public class PingGrain : Grain, IPingGrain { private readonly ILogger<PingGrain> _logger; public PingGrain(ILogger<PingGrain> logger) => _logger = logger; public Task Ping() => Task.CompletedTask; public async Task CallOther(IPingGrain other) { _logger.LogInformation(\"1\"); await other.Ping(); _logger.LogInformation(\"2\"); } } Two grains of type PingGrain are involved in our example, A and B . A caller invokes the following call: var a = grainFactory.GetGrain(\"A\"); var b = grainFactory.GetGrain(\"B\"); await a.CallOther(b); The flow of execution is as follows: The call arrives at A , which logs \"1\" and then issues a call to B B returns immediately from Ping() back to A A logs \"2\" an returns back to the original caller While A is awaiting the call to B , it cannot process any incoming requests. Because of this, if A and B were to call each other simultaneously, they may deadlock while waiting for those calls to complete. Here is an example, based on the client issuing the following call: var a = grainFactory.GetGrain(\"A\"); var b = grainFactory.GetGrain(\"B\"); // A calls B at the same time as B calls A. // This might deadlock, depending on the non-deterministic timing of events. await Task.WhenAll(a.CallOther(b), b.CallOther(a)); Case 1: the calls do not deadlock In this example: The Ping() call from A arrives at B before the CallOther(a) call arrives at B . Therefore, B processes the Ping() call before the CallOther(a) call. Because B processes the Ping() call, A is able to return back to the caller. When B issues its Ping() call to A , A is still busy logging its message ( \"2\" ), so the call has to wait a short duration, but it is soon able to be processed. A processes the Ping() call and returns to B which returns to the original caller. Now, we will examine a less fortunate series of events: one in which the same code results in a deadlock due to slightly different timing. Case 2: the calls deadlock In this example: The CallOther calls arrive at their respective grains and are processed simultaneously. Both grains log \"1\" and proceed to await other.Ping() . Since both grains are still busy (processing the CallOther request, which has not finished yet), the Ping() requests wait After some period of time, Orleans determines that the call has timed out and each Ping() call results in an exception being thrown. This exception is not handled by the CallOther method body and so it bubbles up to the original caller. The following section describes how to prevent deadlocks by allowing multiple requests to interleave their execution with each other. Reentrancy Orleans defaults to choosing a safe execution flow: one in which the internal state of a grain is not modified concurrently by multiple requests. Concurrent modification of internal state complicates logic and puts a greater burden on the developer. This protection against those kinds of concurrency bugs has a cost which we saw above, primarily liveness : certain call patterns can lead to deadlocks. One way to avoid deadlocks is to ensure that grain calls never form a cycle. Often times, it is difficult to write code which is cycle-free and cannot deadlock. Waiting for each request to run from beginning to completion before processing the next request can also hurt performance. For example, by default, if a grain method performs some asynchronous request to a database service then the grain will pause request execution until the response from the database arrives at the grain. Each of those cases are discussed in the sections which follow. For these reasons, Orleans provides developers with options to allow some or all requests to be executed concurrently , interleaving their execution with each other. In Orleans, this is called reentrancy or interleaving . By executing requests concurrently, grains which perform asynchronous operations can process more requests in a shorter period of time. Multiple requests may be interleaved in the following cases: The grain class is marked as [Reentrant] The interface method is marked as [AlwaysInterleave] The grain's [MayInterleave(x)] predicate returns true With reentrancy, the following case becomes a valid execution and the possibility of the above deadlock is removed. Case 3: the grain or method is reentrant In this example, grains A and B are able to call each other simultaneously without any potential for request scheduling deadlocks because both grains are reentrant . The following sections provide more details on reentrancy. Reentrant grains Grain implementation classes may be marked with the [Reentrant] attribute to indicate that different requests may be freely interleaved. In other words, a reentrant activation may start executing another request while a previous request has not finished processing. Execution is still limited to a single thread, so the activation is still executing one turn at a time, and each turn is executing on behalf of only one of the activation’s requests. Reentrant grain code will never run multiple pieces of grain code in parallel (execution of grain code will always be single-threaded), but reentrant grains may see the execution of code for different requests interleaving. That is, the continuation turns from different requests may interleave. For example, with the pseudo-code below, when Foo and Bar are 2 methods of the same grain class: Task Foo() { await task1; // line 1 return Do2(); // line 2 } Task Bar() { await task2; // line 3 return Do2(); // line 4 } If this grain is marked [Reentrant] , the execution of Foo and Bar may interleave. For example, the following order of execution is possible: Line 1, line 3, line 2 and line 4. That is, the turns from different requests interleave. If the grain was not reentrant, the only possible executions would be: line 1, line 2, line 3, line 4 OR: line 3, line 4, line 1, line 2 (a new request cannot start before the previous one finished). The main tradeoff in choosing between reentrant and non-reentrant grains is the code complexity to make interleaving work correctly, and the difficulty to reason about it. In a trivial case when the grains are stateless and the logic is simple, fewer (but not too few, so that all the hardware threads are used) reentrant grains should, in general, be slightly more efficient. If the code is more complex, then a larger number of non-reentrant grains, even if slightly less efficient overall, should save you a lot of grief of figuring out non-obvious interleaving issues. In the end, the answer will depend on the specifics of the application. Interleaving methods Grain interface methods marked with [AlwaysInterleave] will be interleaved regardless of whether the grain is reentrant or not. Consider the following example: public interface ISlowpokeGrain : IGrainWithIntegerKey { Task GoSlow(); [AlwaysInterleave] Task GoFast(); } public class SlowpokeGrain : Grain, ISlowpokeGrain { public async Task GoSlow() { await Task.Delay(TimeSpan.FromSeconds(10)); } public async Task GoFast() { await Task.Delay(TimeSpan.FromSeconds(10)); } } Now consider the call flow initiated by the following client request: var slowpoke = client.GetGrain<ISlowpokeGrain>(0); // A) This will take around 20 seconds await Task.WhenAll(slowpoke.GoSlow(), slowpoke.GoSlow()); // B) This will take around 10 seconds. await Task.WhenAll(slowpoke.GoFast(), slowpoke.GoFast(), slowpoke.GoFast()); Calls to GoSlow will not be interleaved, so the execution of the two GoSlow() calls will take around 20 seconds. On the other hand, because GoFast is marked [AlwaysInterleave] , the three calls to it will be executed concurrently and will complete in approximately 10 seconds total instead of requiring at least 30 seconds to complete. Reentrancy using a predicate Grain classes can specify a predicate to determine interleaving on a call-by-call basis by inspecting the request. The [MayInterleave(string methodName)] attribute provides this functionality. The argument to the attribute is the name of a static method within the grain class which accepts an InvokeMethodRequest object and returns a bool indicating whether or not the request should be interleaved. Here is an example which allows interleaving if the request argument type has the [Interleave] attribute: [AttributeUsage(AttributeTargets.Class | AttributeTargets.Struct)] public sealed class InterleaveAttribute : Attribute { } // Specify the may-interleave predicate. [MayInterleave(nameof(ArgHasInterleaveAttribute))] public class MyGrain : Grain, IMyGrain { public static bool ArgHasInterleaveAttribute(InvokeMethodRequest req) { // Returning true indicates that this call should be interleaved with other calls. // Returning false indicates the opposite. return req.Arguments.Length == 1 && req.Arguments[0]?.GetType().GetCustomAttribute<InterleaveAttribute>() != null; } public Task Process(object payload) { // Process the object. } }"
  },
  "docs/grains/request_context.html": {
    "href": "docs/grains/request_context.html",
    "title": "Request Context | Microsoft Orleans Documentation",
    "keywords": "Request Context RequestContext is an Orleans feature that allows application metadata, such as a trace ID, to flow with requests. Application metadata may be added on the client; it will flow with Orleans requests to the receiving grain. The feature is implemented by a public static class, RequestContext, in the Orleans namespace. This class exposes two simple methods: void Set(string key, object value) is used to store a value in the request context. The value can be any Serializable type. Object Get(string key) is used to retrieve a value from the current request context. The backing storage for RequestContext is thread-static. When a thread (whether client-side or within Orleans) sends a request, the contents of the sending thread’s RequestContext is included with the Orleans message for the request; when the grain code receives the request, that metadata is accessible from the local RequestContext. If the grain code does not modify the RequestContext, then any grain it makes a request to will receive the same metadata, and so on. Application metadata also is maintained when you schedule a future computation using StartNew or ContinueWith; in both cases, the continuation will execute with the same metadata as the scheduling code had at the moment the computation was scheduled (that is, the system makes a copy of the current metadata and passes it to the continuation, so changes after the call to StartNew or ContinueWith will not be seen by the continuation). Note that application metadata does not flow back with responses; that is, code that runs as a result of a response being received, either within a ContinueWith continuation or after a call to Wait or GetValue, will still run within the current context that was set by the original request. For example, to set a trace ID in the client to a new GUID, one would simply call: RequestContext.Set(\"TraceId\", new Guid()); Within grain code (or other code that runs within Orleans on a scheduler thread), the trace ID of the original client request could be used, for instance, when writing a log: Logger.Info(\"Currently processing external request {0}\", RequestContext.Get(\"TraceId\")); While any serializable object may be sent as application metadata, it’s worth mentioning that large or complex objects may add noticeable overhead to message serialization time. For this reason, the use of simple types (strings, GUIDs, or numeric types) is recommended."
  },
  "docs/grains/stateless_worker_grains.html": {
    "href": "docs/grains/stateless_worker_grains.html",
    "title": "Stateless Worker Grains | Microsoft Orleans Documentation",
    "keywords": "Stateless Worker Grains By default, the Orleans runtime creates no more than one activation of a grain within the cluster. This is the most intuitive expression of the Virtual Actor model with each grain corresponding to an entity with a unique type/identity. However, there are also cases when an application needs to perform functional stateless operations that are not tied to a particular entity in the system. For example, if client sends requests with compressed payloads that need to be decompressed before they could be routed to the target grain for processing, such decompression/routing logic is not tied to a specific entity in the application, and can easily scale out. When the [StatelessWorker] attribute is applied to a grain class, it indicates to the Orleans runtime that grains of that class should be treated as Stateless Worker grains. Stateless Worker grains have the following properties that make their execution very different from that of normal grain classes. The Orleans runtime can and will create multiple activations of a Stateless Worker grain on different silos of the cluster. Requests made to Stateless Worker grains are always executed locally, that is on the same silo where the request originated, either made by a grain running on the silo or received by the silo's client gateway. Hence, calls to Stateless Worker grains from other grains or from client gateways never incur a remote message. The Orleans Runtime automatically creates additional activations of a Stateless Worker grain if the already existing ones are busy. The maximum number of activations of a Stateless Worker grain the runtime creates per silo is limited by default by the number of CPU cores on the machine, unless specified explicitly by the optional maxLocalWorkers argument. Because of 2 and 3, Stateless Worker grain activations are not individually addressable. Two subsequent requests to a Stateless Worker grain may be processed by different activations of it. Stateless Worker grains provide a straightforward way of creating an auto-managed pool of grain activations that automatically scales up and down based on the actual load. The runtime always scans for available Stateless Worker grain activations in the same order. Because of that, it always dispatches a requests to the first idle local activation it can find, and only gets to the last one if all previous activations are busy. If all activations are busy and the activation limit hasn't been reached, it creates one more activation at the end of the list, and dispatches the request to it. That means that when the rate of requests to a Stateless Worker grain increases, and existing activations are all currently busy, the runtime expands the pool of its activations up to the limit. Conversely, when the load drops, and it can be handled by a smaller number of activations of the Stateless Worker grain, the activations at the tail of the list will not be getting requests dispatched to them. They will become idle, and eventually deactivated by the standard activation collection process. Hence, the pool of activations will eventually shrink to match the load. The following example defines a Stateless Worker grain class MyStatelessWorkerGrain with the default maximum activation number limit. [StatelessWorker] public class MyStatelessWorkerGrain : Grain, IMyStatelessWorkerGrain { ... } Making a call to a Stateless Worker grain is the same as to any other grain. The only difference is that in most cases a single grain ID is used, 0 or Guid.Empty . Multiple grain IDs can be used when having multiple Stateless Worker grain pools, one per ID, is desirable. var worker = GrainFactory.GetGrain<IMyStatelessWorkerGrain>(0); await worker.Process(args); This one defines a Stateless Worker grain class with no more than one grain activation per silo. [StatelessWorker(1)] // max 1 activation per silo public class MyLonelyWorkerGrain : ILonelyWorkerGrain { ... } Note that [StatelessWorker] attribute does not change reentrancy of the target grain class. Just like any other grains, Stateless Worker grains are non-reentrant by default. They can be explicitly made reentrant by adding a [Reentrant] attribute to the grain class. State The \"Stateless\" part of \"Stateless Worker\" does not mean that a Stateless Worker cannot have state and is limited only to executing functional operations. Like any other grain, a Stateless Worker grain can load and keep in memory any state it needs. It's just because multiple activations of a Stateless Worker grain can be created on the same and different silos of the cluster, there is no easy mechanism to coordinate state held by different activations. There are several useful patterns that involve Stateless Worker holding state. Scaled out hot cache items For hot cache items that experience high throughput, holding each such item in a Stateless Worker grain makes it a) automatically scale out within a silo and across all silos in the cluster; and b) makes the data always locally available on the silo that received the client request via its client gateway, so that the requests can be answered without an extra network hop to another silo. Reduce style aggregation In some scenarios applications need to calculate certain metrics across all grains of a particular type in the cluster, and report the aggregates periodically. Examples are reporting number of players per game map, average duration of a VoIP call, etc. If each of the many thousands or millions of grains were to report their metrics to a single global aggregator, the aggregator would get immediately overloaded unable to process the flood of reports. The alternative approach is to turn this task into a 2 (or more) step reduce style aggregation. The first layer of aggregation is done by reporting grain sending their metrics to a Stateless Worker pre-aggregation grain. The Orleans runtime will automatically create multiple activations of the Stateless Worker grain with each silo. Since all such calls will be processed locally with no remote calls or serialization of the messages, the cost of such aggregation will be significantly less than in a remote case. Now each of the pre-aggregation Stateless Worker grain activations, independently or in coordination with other local activations, can send their aggregated reports to the global final aggregator (or to another reduction layer if necessary) without overloading it."
  },
  "docs/grains/timers_and_reminders.html": {
    "href": "docs/grains/timers_and_reminders.html",
    "title": "Timers and Reminders | Microsoft Orleans Documentation",
    "keywords": "Timers and Reminders The Orleans runtime provides two mechanisms, called timers and reminders, that enable the developer to specify periodic behavior for grains. Timers Timer Description Timers are used to create periodic grain behavior that isn't required to span multiple activations (instantiations of the grain). It is essentially identical to the standard . NET System.Threading.Timer class. In addition, timers are subject to single-threaded execution guarantees within the grain activation that it operates on. Each activation may have zero or more timers associated with it. The runtime executes each timer routine within the runtime context of the activation that it is associated with. Timer Usage To start a timer, use the Grain.RegisterTimer method, which returns an IDisposable reference: public IDisposable RegisterTimer( Func<object, Task> asyncCallback, // function invoked when the timer ticks object state, // object to pass to asyncCallback TimeSpan dueTime, // time to wait before the first timer tick TimeSpan period) // the period of the timer Cancel the timer by disposing it. A timer will cease to trigger if the grain is deactivated or when a fault occurs and its silo crashes. Important Considerations When activation collection is enabled, the execution of a timer callback does not change the activation's state from idle to in-use. This means that a timer cannot be used to postpone deactivation of otherwise idle activations. The period passed to Grain.RegisterTimer is the amount of time that passes from the moment the Task returned by asyncCallback is resolved to the moment that the next invocation of asyncCallback should occur. This not only makes it impossible for successive calls to asyncCallback to overlap, but also makes it so that the length of time asyncCallback takes to complete affects the frequency at which asyncCallback is invoked. This is an important deviation from the semantics of System.Threading.Timer . Each invocation of asyncCallback is delivered to an activation on a separate turn, and will never run concurrently with other turns on the same activation. Note however, asyncCallback invocations are not delivered as messages and are thus not subject to message interleaving semantics. This means that invocations of asyncCallback should be considered as behaving as if running on a reentrant grain with respect to other messages to that grain. Reminders Reminder Description Reminders are similar to timers, with a few important differences: Reminders are persistent and will continue to trigger in almost all situations (including partial or full cluster restarts) unless explicitly cancelled. Reminder \"definitions\" are written to storage. However, each specific occurrence, with its specific time, is not. This has the side effect that if the cluster is completely down at the time of a specific reminder tick, it will be missed and only the next tick of the reminder will happen. Reminders are associated with a grain, not any specific activation. If a grain has no activation associated with it when a reminder ticks, the grain will be created. If an activation becomes idle and is deactivated, a reminder associated with the same grain will reactivate the grain when it ticks next. Reminders are delivered by message and are subject to the same interleaving semantics as all other grain methods. Reminders should not be used for high-frequency timers- their period should be measured in minutes, hours, or days. Configuration Reminders, being persistent, rely upon storage to function. You must specify which storage backing to use before the reminder subsystem will function. This is done by configuring one of the reminder providers via UseXReminderService extension methods, where X is the name of the provider, for example, UseAzureTableReminderService . Azure Table configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var silo = new SiloHostBuilder() [...] .UseAzureTableReminderService(options => options.ConnectionString = connectionString) [...] SQL: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; const string invariant = \"YOUR_INVARIANT\"; var silo = new SiloHostBuilder() [...] .UseAdoNetReminderService(options => { options.ConnectionString = connectionString; options.Invariant = invariant; }) [...] If you just want a placeholder implementation of reminders to work without needing to set up an Azure account or SQL database, then this will give you a development-only implementation of the reminder system: var silo = new SiloHostBuilder() [...] .UseInMemoryReminderService() [...] Reminder Usage A grain that uses reminders must implement the IRemindable.ReceiveReminder method. Task IRemindable.ReceiveReminder(string reminderName, TickStatus status) { Console.WriteLine(\"Thanks for reminding me-- I almost forgot!\"); return Task.CompletedTask; } To start a reminder, use the Grain.RegisterOrUpdateReminder method, which returns an IGrainReminder object: protected Task<IGrainReminder> RegisterOrUpdateReminder(string reminderName, TimeSpan dueTime, TimeSpan period) reminderName is a string that must uniquely identify the reminder within the scope of the contextual grain. dueTime specifies a quantity of time to wait before issuing the first timer tick. period specifies the period of the timer. Since reminders survive the lifetime of any single activation, they must be explicitly cancelled (as opposed to being disposed). You cancel a reminder by calling Grain.UnregisterReminder : protected Task UnregisterReminder(IGrainReminder reminder) reminder is the handle object returned by Grain.RegisterOrUpdateReminder . Instances of IGrainReminder aren't guaranteed to be valid beyond the lifespan of an activation. If you wish to identify a reminder in a way that persists, use a string containing the reminder's name. If you only have the reminder's name and need the corresponding instance of IGrainReminder , call the Grain.GetReminder method: protected Task<IGrainReminder> GetReminder(string reminderName) Which Should I Use? We recommend that you use timers in the following circumstances: When it doesn't matter (or is desirable) that the timer ceases to function if the activation is deactivated or failures occur. The resolution of the timer is small (e.g. reasonably expressible in seconds or minutes). The timer callback can be started from Grain.OnActivateAsync or when a grain method is invoked. We recommend that you use reminders in the following circumstances: When the periodic behavior needs to survive the activation and any failures. Performing infrequent tasks (e.g. reasonably expressible in minutes, hours, or days). Combining Timers and Reminders You might consider using a combination of reminders and timers to accomplish your goal. For example, if you need a timer with a small resolution that needs to survive across activations, you can use a reminder that runs every five minutes, whose purpose is to wake up a grain that restarts a local timer that may have been lost due to a deactivation."
  },
  "docs/grains/transactions.html": {
    "href": "docs/grains/transactions.html",
    "title": "Transactions in Orleans 2.0 | Microsoft Orleans Documentation",
    "keywords": "Orleans Transactions Orleans supports distributed ACID transactions against persistent grain state. Setup Orleans transactions are opt-in. A silo must be configured to use transactions. If it is not, any calls to transactional methods on grains will receive an OrleansTransactionsDisabledException . To enable transactions on a silo, call UseTransactions() on the silo host builder. var builder = new SiloHostBuilder().UseTransactions(); Transactional State Storage To use transactions, the user needs to configure a data store. To support various data stores with transactions, the storage abstraction ITransactionalStateStorage has been introduced. This abstraction is specific to the needs of transactions, unlike generic grain storage ( IGrainStorage ). To use transaction-specific storage, the user can configure their silo using any implementation of ITransactionalStateStorage , such as Azure ( AddAzureTableTransactionalStateStorage ). Example: var builder = new SiloHostBuilder() .AddAzureTableTransactionalStateStorage(\"TransactionStore\", options => { options.ConnectionString = ”YOUR_STORAGE_CONNECTION_STRING”); }) .UseTransactions(); For development purposes, if transaction-specific storage is not available for the data store you need, an IGrainStorage implementation may be used instead. For any transactional state that does not have a store configured for it, transactions will attempt to fail over to grain storage using a bridge. Accessing transactional state via a bridge to grain storage will be less efficient and is not a pattern we intend to support long term, hence the recommendation that this only be used for development purposes. Programming Model Grain Interfaces For a grain to support transactions, transactional methods on a grain interface must be marked as being part of a transaction using the “Transaction” attribute. The attribute needs indicate how the grain call behaves in a transactional environment via the transaction options below: TransactionOption.Create - Call is transactional and will always create a new transaction context (i.e., it will start a new transaction), even if called within an existing transaction context. TransactionOption.Join - Call is transactional but can only be called within the context of an existing transaction. TransactionOption.CreateOrJoin - Call is transactional. If called within the context of a transaction, it will use that context, else it will create a new context. TransactionOption.Suppress - Call is not transactional but can be called from within a transaction. If called within the context of a transaction, the context will not be passed to the call. TransactionOption.Supported - Call is not transactional but supports transactions. If called within the context of a transaction, the context will be passed to the call. TransactionOption.NotAllowed - Call is not transactional and cannot be called from within a transaction. If called within the context of a transaction, it will throw a NotSupportedException . Calls can be marked as “Create”, meaning the call will always start its own transaction. For example, the Transfer operation in the ATM grain below will always start a new transaction which involves the two referenced accounts. public interface IATMGrain : IGrainWithIntegerKey { [Transaction(TransactionOption.Create)] Task Transfer(Guid fromAccount, Guid toAccount, uint amountToTransfer); } The transactional operations Withdraw and Deposit on the account grain are marked “Join”, indicating that they can only be called within the context of an existing transaction, which would be the case if they were called during IATMGrain.Transfer(…) . The GetBalance call is marked CreateOrJoin so it can be called from within an existing transaction, like via IATMGrain.Transfer(…) , or on its own. public interface IAccountGrain : IGrainWithGuidKey { [Transaction(TransactionOption.Join)] Task Withdraw(uint amount); [Transaction(TransactionOption.Join)] Task Deposit(uint amount); [Transaction(TransactionOption.CreateOrJoin)] Task<uint> GetBalance(); } Important Considerations Please be aware that OnActivateAsync could NOT be marked as transactional as any such call requires a proper setup before the call. It does exist only for the grain application API. This means that an attempt to read transactional state as part of these methods will raise an exception in the runtime. Grain Implementations A grain implementation needs to use an ITransactionalState facet (see Facet System) to manage grain state via ACID transactions. public interface ITransactionalState<TState> where TState : class, new() { Task<TResult> PerformRead<TResult>(Func<TState, TResult> readFunction); Task<TResult> PerformUpdate<TResult>(Func<TState, TResult> updateFunction); } All read or write access to the persisted state must be performed via synchronous functions passed to the transactional state facet. This allows the transaction system to perform or cancel these operations transactionally. To use a transactional state within a grain, one only needs to define a serializable state class to be persisted and to declare the transactional state in the grain’s constructor with a TransactionalState attribute. The latter declares the state name and (optionally) which transactional state storage to use (see Setup). [AttributeUsage(AttributeTargets.Parameter)] public class TransactionalStateAttribute : Attribute { public TransactionalStateAttribute(string stateName, string storageName = null) { … } } Example: public class AccountGrain : Grain, IAccountGrain { private readonly ITransactionalState<Balance> balance; public AccountGrain( [TransactionalState(\"balance\", \"TransactionStore\")] ITransactionalState<Balance> balance) { this.balance = balance ?? throw new ArgumentNullException(nameof(balance)); } Task IAccountGrain.Deposit(uint amount) { return this.balance.PerformUpdate(x => x.Value += amount); } Task IAccountGrain.Withdrawal(uint amount) { return this.balance.PerformUpdate(x => x.Value -= amount); } Task<uint> IAccountGrain.GetBalance() { return this.balance.PerformRead(x => x.Value); } } In the above example, the attribute TransactionalState is used to declare that the ‘balance’ constructor argument should be associated with a transactional state named “balance”. With this declaration, Orleans will inject an ITransactionalState instance with a state loaded from the transactional state storage named \"TransactionStore\" (see Setup). The state can be modified via PerformUpdate or read via PerformRead . The transaction infrastructure will ensure that any such changes performed as part of a transaction, even among multiple grains distributed over an Orleans cluster, will either all be committed or all be undone upon completion of the grain call that created the transaction ( IATMGrain.Transfer in the above examples). Calling Transactions Transactional methods on a grain interface are called like any other grain call. IATMGrain atm = client.GetGrain<IATMGrain>(0); Guid from = Guid.NewGuid(); Guid to = Guid.NewGuid(); await atm.Transfer(from, to, 100); uint fromBalance = await client.GetGrain<IAccountGrain>(from).GetBalance(); uint toBalance = await client.GetGrain<IAccountGrain>(to).GetBalance(); In the above calls, an ATM grain is used to transfer 100 units of currency from one account to another. After the transfer is complete, both accounts are queried to get their current balance. The currency transfer as well as both account queries are performed as ACID transactions. As seen in the above example, transactions can return values within a task, like other grain calls, but upon call failure they will not throw application exceptions, but rather an OrleansTransactionException or TimeoutException . If the application throws an exception during the transaction and that exception causes the transaction to fail (as opposed failing because of other system failures), the application exception will be the inner exception of the OrleansTransactionException . If a transaction exception is thrown of type OrleansTransactionAbortedException , the transaction failed and can be retried. Any other exception thrown indicates that the transaction terminated with an unknown state. Since transactions are distributed operations, a transaction in an unknown state could have succeeded, failed, or still be in progress. For this reason, it’s advisable to allow a call timeout period ( SiloMessagingOptions.ResponseTimeout ) to pass, to avoid cascading aborts, before verifying the state or retrying the operation."
  },
  "docs/host/client.html": {
    "href": "docs/host/client.html",
    "title": "Clients | Microsoft Orleans Documentation",
    "keywords": "Clients A client allows non-grain code to interact with an Orleans cluster. Clients allow application code to communicate with grains and streams hosted in a cluster. There are two ways to obtain a client, depending on where the client code is hosted: in the same process as a silo, or in a separate process. This article will discuss both options, starting with the recommended option: co-hosting the client code in the same process as the grain code. Co-hosted clients If the client code is hosted in the same process as the grain code, then the client can be directly obtained from the hosting application's dependency injection container. In this case, the client communicates directly with the silo it is attached to and can take advantage of the extra knowledge that the silo has about the cluster. This provides several benefits, including reducing network and CPU overhead as well as decreasing latency and increasing throughput and reliability. The client utilizes the silo's knowledge of the cluster topology and state and does not need to use a separate gateway. This avoids a network hop and serialization/deserialization round trip. This therefore also increases reliability, since the number of required nodes in between the client and the grain is minimized. If the grain is a stateless worker grain or otherwise happens to be activated on the silo which the client is hosted in, then no serialization or network communication needs to be performed at all and the client can reap additional performance and reliability gains. Co-hosting client and grain code also simplifies deployment and application topology by eliminating the need for two distinct application binaries to be deployed and monitored. There are also detractors to this approach, primarily that the grain code is no longer isolated from the client process. Therefore, issues in client code, such as blocking IO or lock contention causing thread starvation can affect the performance of grain code. Even without code defects like the abovementioned, noisy neighbor effects can result simply by having the client code execute on the same processor as grain code, putting additional strain on CPU cache and additional contention for local resources in general. Additionally, identifying the source of these issues is now more difficult because monitoring systems cannot distinguish what is logically client code from grain code. Despite these detractors, co-hosting client code with grain code is a popular option and the recommended approach for most applications. To elaborate, the abovementioned detractors are minimal in practice for the following reasons: Client code is often very thin , for example translating incoming HTTP requests into grain calls, and therefore the noisy neighbor effects are minimal and comparable in cost to the otherwise required gateway. In the event that a performance issue arises, the typical workflow for a developer involves tools such as CPU profilers and debuggers, which are still effective in quickly identifying the source of the issue despite having both client and grain code executing in the same process. In other words, metrics become more coarse and less able to precisely identify the source of an issue, but more detailed tools are still effective. Obtaining a client from a host If hosting using the .NET Generic Host , the client will be available in the host's dependency injection container automatically and can be injected into services such as ASP.NET controllers or IHostedService implementations. Alternatively, a client interface such as IGrainFactory or IClusterClient can be obtained from either IHost or ISiloHost : var client = host.Services.GetService<IClusterClient>(); await client.GetGrain<IMyGrain>(0).Ping(); External clients Client code can run outside of the Orleans cluster where grain code is hosted. Hence, an external client acts as a connector or conduit to the cluster and to all grains of the application. Usually, clients are used on the frontend web servers to connect to an Orleans cluster that serves as a middle tier with grains executing business logic. In a typical setup, a frontend web server: Receives a web request Performs necessary authentication and authorization validation Decides which grain(s) should process the request Uses Grain Client to make one or more method call to the grain(s) Handles successful completion or failures of the grain calls and any returned values Sends a response for the web request Initialization of Grain Client Before a grain client can be used for making calls to grains hosted in an Orleans cluster, it needs to be configured, initialized, and connected to the cluster. Configuration is provided via ClientBuilder and a number of supplemental option classes that contain a hierarchy of configuration properties for programmatically configuring a client. More information can be in the Client Configuration guide . Example of a client configuration: var client = new ClientBuilder() // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"MyOrleansService\"; }) // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) // Application parts: just reference one of the grain interfaces that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IValueGrain).Assembly)) .Build(); Lastly, we need to call Connect() method on the constructed client object to make it connect to the Orleans cluster. It's an asynchronous method that returns a Task . So we need to wait for its completion with an await or .Wait() . await client.Connect(); Making Calls to Grains Making calls to grain from a client is really no different from making such calls from within grain code . The same GetGrain<T>(key) method, where T is the target grain interface, is used in both cases to obtain grain references . The slight difference is in through what factory object we invoke GetGrain . In client code we do that through the connected client object. IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); Task t = player.JoinGame(game) await t; A call to a grain method returns a Task or a Task<T> as required by the grain interface rules . The client can use the await keyword to asynchronously await the returned Task without blocking the thread, or in some cases the Wait() method to block the current thread of execution. The major difference between making calls to grains from client code and from within another grain is the single-threaded execution model of grains. Grains are constrained to be single-threaded by the Orleans runtime, while clients may be multi-threaded. Orleans does not provide any such guarantee on the client side, and so it is up to the client to manage its own concurrency using whatever synchronization constructs are appropriate for its environment – locks, events, Tasks , etc. Receiving Notifications There are situations in which a simple request-response pattern is not enough, and the client needs to receive asynchronous notifications. For example, a user might want to be notified when a new message has been published by someone that she is following. Observers is one such mechanism that enables exposing client side objects as grain-like targets to get invoked by grains. Calls to observers do not provide any indication of success or failure, as they are sent as one-way best effort message. So it is a responsibility of the application code to build a higher level reliability mechanism on top of observers where necessary. Another mechanism that can be used for delivering asynchronous messages to clients is Streams . Streams expose indications of success or failure of delivery of individual messages, and hence enable reliable communication back to the client. Client Connectivity There are two scenarios in which a cluster client can experience connectivity issues: When the IClusterClient.Connect method is called initially. When making calls on grain references which were obtained from a connected cluster client. In the first case, the Connect method will throw an exception to indicate what went wrong. This is typically (but not necessarily) a SiloUnavailableException . If this happens, the cluster client instance is unusable and should be disposed. A retry filter function can optionally be provided to the Connect method which could, for instance, wait for a specified duration before making another attempt. If no retry filter is provided, or if the retry filter returns false , the client gives up for good. If Connect returns successfully, the cluster client is guaranteed to be usable until it is disposed. This means that even if the client experiences connection issues, it will attempt to recover indefinitely. The exact recovery behavior can be configured on a GatewayOptions object provided by the ClientBuilder , e.g.: var client = new ClientBuilder() // ... .Configure<GatewayOptions>(opts => opts.GatewayListRefreshPeriod = TimeSpan.FromMinutes(10)) // Default is 1 min. .Build(); In the second case, where a connection issue occurs during a grain call, a SiloUnavailableException will be thrown on the client side. This could be handled like so: IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); try { await player.JoinGame(game); } catch (SiloUnavailableException) { // Lost connection to the cluster... } The grain reference is not invalidated in this situation; the call could be retried on the same reference later, when a connection might have been re-established. Dependency Injection The recommended way to create an external client in a program that uses the .NET Generic Host is to inject an IClusterClient singleton instance via dependency injection, which can then be accepted as a constructor parameter in hosted services, ASP.NET controllers, etc. [!NOTE] When co-hosting an Orleans silo in the same process that will be connecting to it, it is not necessary to manually create a client; Orleans will automatically provide one and manage its lifetime appropriately. When connecting to a cluster in a different process (e.g. on a different machine), a common pattern is to create a hosted service like this: public class ClusterClientHostedService : IHostedService { public IClusterClient Client { get; } public ClusterClientHostedService(ILoggerProvider loggerProvider) { Client = new ClientBuilder() // Appropriate client configuration here, e.g.: .UseLocalhostClustering() .ConfigureLogging(builder => builder.AddProvider(loggerProvider)) .Build(); } public async Task StartAsync(CancellationToken cancellationToken) { // A retry filter could be provided here. await Client.Connect(); } public async Task StopAsync(CancellationToken cancellationToken) { await Client.Close(); Client.Dispose(); } } The service is then registered like this: public class Program { static Task Main() { return new HostBuilder() .ConfigureServices(services => { services.AddSingleton<ClusterClientHostedService>(); services.AddSingleton<IHostedService>(sp => sp.GetService<ClusterClientHostedService>()); services.AddSingleton<IClusterClient>(sp => sp.GetService<ClusterClientHostedService>().Client); services.AddSingleton<IGrainFactory>(sp => sp.GetService<ClusterClientHostedService>().Client); }) .ConfigureLogging(builder => builder.AddConsole()) .RunConsoleAsync(); } } At this point, an IClusterClient instance could be consumed anywhere that dependency injection is supported, such as in an ASP.NET controller: public class HomeController : Controller { readonly IClusterClient _client; public HomeController(IClusterClient client) => _client = client; public IActionResult Index() { var grain = _client.GetGrain<IMyGrain>(); var model = grain.GetModel(); return View(model); } } Example Here is an extended version of the example given above of a client application that connects to Orleans, finds the player account, subscribes for updates to the game session the player is part of with an observer, and prints out notifications until the program is manually terminated. namespace PlayerWatcher { class Program { /// <summary> /// Simulates a companion application that connects to the game /// that a particular player is currently part of, and subscribes /// to receive live notifications about its progress. /// </summary> static void Main(string[] args) { RunWatcher().Wait(); // Block main thread so that the process doesn't exit. // Updates arrive on thread pool threads. Console.ReadLine(); } static async Task RunWatcher() { try { var client = new ClientBuilder() // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"MyOrleansService\"; }) // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) // Application parts: just reference one of the grain interfaces that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IValueGrain).Assembly)) .Build(); // Hardcoded player ID Guid playerId = new Guid(\"{2349992C-860A-4EDA-9590-000000000006}\"); IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); IGameGrain game = null; while (game == null) { Console.WriteLine(\"Getting current game for player {0}...\", playerId); try { game = await player.GetCurrentGame(); if (game == null) // Wait until the player joins a game { await Task.Delay(5000); } } catch (Exception exc) { Console.WriteLine(\"Exception: \", exc.GetBaseException()); } } Console.WriteLine(\"Subscribing to updates for game {0}...\", game.GetPrimaryKey()); // Subscribe for updates var watcher = new GameObserver(); await game.SubscribeForGameUpdates( await client.CreateObjectReference<IGameObserver>(watcher)); Console.WriteLine(\"Subscribed successfully. Press <Enter> to stop.\"); } catch (Exception exc) { Console.WriteLine(\"Unexpected Error: {0}\", exc.GetBaseException()); } } } /// <summary> /// Observer class that implements the observer interface. Need to pass a grain reference to an instance of this class to subscribe for updates. /// </summary> class GameObserver : IGameObserver { // Receive updates public void UpdateGameScore(string score) { Console.WriteLine(\"New game score: {0}\", score); } } } }"
  },
  "docs/host/configuration_guide/activation_garbage_collection.html": {
    "href": "docs/host/configuration_guide/activation_garbage_collection.html",
    "title": "Activation Garbage Collection | Microsoft Orleans Documentation",
    "keywords": "Activation Garbage Collection As described in the Core Concepts section, a grain activation is an in-memory instance of a grain class that gets automatically created by the Orleans runtime on an as-needed basis as a temporary physical embodiment of a grain. Activation Garbage Collection (Activation GC) is the process of removal from memory of unused grain activations. It is conceptually similar to how garbage collection of memory works in .NET. However, Activation GC only takes into consideration how long a particular grain activation has been idle. Memory usage is not used as a factor. How Activation GC Works The general process of Activation GC involves Orleans runtime in a silo periodically scanning for grain activations that have not been used at all for the configured period of time (Collection Age Limit). Once a grain activation has been idle for that long, it gets deactivated. The deactivation process begins by the runtime calling the grain’s OnDeactivateAsync() method, and completes by removing references to the grain activation object from all data structures of the silo, so that the memory is reclaimed by the .NET GC. As a result, with no burden put on the application code, only recently used grain activations stay in memory while activations that aren't used anymore get automatically removed, and system resources used by them get reclaimed by the runtime. What counts as “being active” for the purpose of grain activation collection receiving a method call receiving a reminder receiving an event via streaming What does NOT count as “being active” for the purpose of grain activation collection performing a call (to another grain or to an Orleans client) timer events arbitrary IO operations or external calls not involving Orleans framework Collection Age Limit This period of time after which an idle grain activation becomes subject to Activation GC is called Collection Age Limit. The default Collection Age Limit is 2 hours, but it can be changed globally or for individual grain classes. Explicit Control of Activation Garbage Collection Delaying Activation GC A grain activation can delay its own Activation GC, by calling this.DelayDeactivation() method: protected void DelayDeactivation(TimeSpan timeSpan) This call will ensure that this activation is not deactivated for at least the specified time duration. It takes priority over Activation Garbage Collection settings specified in the config, but does not cancel them. Therefore, this call provides an additional hook to delay the deactivation beyond what is specified in the Activation Garbage Collection settings . This call can not be used to expedite Activation Garbage Collection. A positive timeSpan value means “prevent GC of this activation for that time span”. A negative timeSpan value means “cancel the previous setting of the DelayDeactivation call and make this activation behave based on the regular Activation Garbage Collection settings”. Scenarios: 1) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(20)) , it will cause this activation to not be collected for at least 20 min. 2) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(5)) , the activation will be collected after 10 min, if no extra calls were made. 3) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(5)) , and after 7 minutes there is another call on this grain, the activation will be collected after 17 min from time zero, if no extra calls were made. 4) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(20)) , and after 7 minutes there is another call on this grain, the activation will be collected after 20 min from time zero, if no extra calls were made. Note that DelayDeactivation does not 100% guarantee that the grain activation will not get deactivated before the specified period of time expires. There are certain failure cases that may cause 'premature' deactivation of grains. That means that DelayDeactivation cannot not be used as a means to 'pin' a grain activation in memory forever or to a specific silo . DelayDeactivation is merely an optimization mechanism that can help reduce the aggregate cost of a grain getting deactivated and reactivated over time, if that matters. In most cases there should be no need to use DelayDeactivation at all. Expediting Activation GC A grain activation can also instruct the runtime to deactivate it next time it becomes idle by calling this.DeactivateOnIdle() method: protected void DeactivateOnIdle() A grain activation is considered idle if it is not processing any message at the moment. If you call DeactivateOnIdle while a grain is processing a message, it will get deactivated as soon as processing of the current message is finished. If there are any requests queued for the grain, they will be forwarded to the next activation. DeactivateOnIdle take priority over any Activation Garbage Collection settings specified in the config or DelayDeactivation . Note that this setting only applies to the grain activation from which it has been called and it does not apply to other grain activation of this type. Configuration Grain garbage collection can be configured using the GrainCollectionOptions options: mySiloHostBuilder.Configure<GrainCollectionOptions>(options => { // Set the value of CollectionAge to 10 minutes for all grain options.CollectionAge = TimeSpan.FromMinutes(10); // Override the value of CollectionAge to 5 minutes for MyGrainImplementation options.ClassSpecificCollectionAge[typeof(MyGrainImplementation).FullName] = TimeSpan.FromMinutes(5); })"
  },
  "docs/host/configuration_guide/adonet_configuration.html": {
    "href": "docs/host/configuration_guide/adonet_configuration.html",
    "title": "ADO.NET Database Configuration | Microsoft Orleans Documentation",
    "keywords": "ADO.NET Database Configuration The following sections contain links to SQL scripts to configure your database as well as the corresponding ADO.NET invariant used to configure ADO.NET providers in Orleans. These scripts are intended to be customized if needed for your deployment. Before executing scripts for Clustering, Persistence, or Reminders, one needs to create main tables with the Main scripts. Main scripts Database Script NuGet Package ADO.NET Invariant SQL Server SQLServer-Main.sql System.Data.SqlClient System.Data.SqlClient MySQL / MariaDB MySQL-Main.sql MySql.Data MySql.Data.MySqlClient PostgreSQL PostgreSQL-Main.sql Npgsql Npgsql Oracle Oracle-Main.sql ODP.net Oracle.DataAccess.Client Clustering Database Script NuGet Package ADO.NET Invariant SQL Server SQLServer-Clustering.sql System.Data.SqlClient System.Data.SqlClient MySQL / MariaDB MySQL-Clustering.sql MySql.Data MySql.Data.MySqlClient PostgreSQL PostgreSQL-Clustering.sql Npgsql Npgsql Oracle Oracle-Clustering.sql ODP.net Oracle.DataAccess.Client Persistence Database Script NuGet Package ADO.NET Invariant SQL Server SQLServer-Persistence.sql System.Data.SqlClient System.Data.SqlClient MySQL / MariaDB MySQL-Persistence.sql MySql.Data MySql.Data.MySqlClient PostgreSQL PostgreSQL-Persistence.sql Npgsql Npgsql Oracle Oracle-Persistence.sql ODP.net Oracle.DataAccess.Client Reminders Database Script NuGet Package ADO.NET Invariant SQL Server SQLServer-Reminders.sql System.Data.SqlClient System.Data.SqlClient MySQL / MariaDB MySQL-Reminders.sql MySql.Data MySql.Data.MySqlClient PostgreSQL PostgreSQL-Reminders.sql Npgsql Npgsql Oracle Oracle-Reminders.sql ODP.net Oracle.DataAccess.Client"
  },
  "docs/host/configuration_guide/client_configuration.html": {
    "href": "docs/host/configuration_guide/client_configuration.html",
    "title": "Client Configuration | Microsoft Orleans Documentation",
    "keywords": "Note If you just want to start a local silo and a local client for development purpose, look at the Local Development Configuration page. Client Configuration A client for connecting to a cluster of silos and sending requests to grains is configured programmatically via a ClientBuilder and a number of supplemental option classes. Like silo options, client option classes follow the ASP.NET Options . Add the Microsoft.Orleans.Clustering.AzureStorage nuget package to the client project. There are several key aspects of client configuration: Orleans clustering information Clustering provider Application parts Example of a client configuration: using Orleans.Hosting; var client = new ClientBuilder() // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"MyOrleansService\"; }) // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) // Application parts: just reference one of the grain interfaces that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IValueGrain).Assembly)) .Build(); Let's breakdown the steps used in this sample: Orleans clustering information [...] // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"orleans-docker\"; options.ServiceId = \"AspNetSampleApp\"; }) [...] Here we set two things: the ClusterId to \"my-first-cluster\" : this is a unique ID for the Orleans cluster. All clients and silo that uses this ID will be able to directly talk to each other. Some will choose to use a different ClusterId for each deployments for example. the ServiceId to \"AspNetSampleApp\" : this is a unique ID for your application, that will be used by some provider (for example for persistence providers). This ID should be stable (not change) across deployments . Clustering provider [...] // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) [...] The client will discover all gateway available in the cluster using this provider. Several providers are available, here in this sample we use the Azure Table provider. To get more detail, look in the matching section in the Server Configuration page. Application parts [...] // Application parts: just reference one of the grain interfaces that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IValueGrain).Assembly)).WithReferences()) [...]; To get more detail, look in the matching section in the Server Configuration page."
  },
  "docs/host/configuration_guide/configuring_.NET_garbage_collection.html": {
    "href": "docs/host/configuration_guide/configuring_.NET_garbage_collection.html",
    "title": "Configuring .NET Garbage Collection | Microsoft Orleans Documentation",
    "keywords": "Configuring .NET Garbage Collection For good performance, it is important to configure .NET garbage collection for the silo process the right way. The best combination of settings we found is to set gcServer=true and gcConcurrent=true . These are easy to set via the application csproj file. See below as an example: .NET Core Note: This method is not supported with SDK style projects compiling against the full .NET Framework // .csproj <PropertyGroup> <ServerGarbageCollection>true</ServerGarbageCollection> <ConcurrentGarbageCollection>true</ConcurrentGarbageCollection> </PropertyGroup> .NET Framework Note: SDK style projects compiling against the full .NET Framework should still use this configuration style // App.config <configuration> <runtime> <gcServer enabled=\"true\"/> <gcConcurrent enabled=\"true\"/> </runtime> </configuration> However, this is not as easy to do if a silo runs as part of an Azure Worker Role, which by default is configured to use workstation GC. This blog post shows how to set the same configuration for an Azure Worker Role - https://blogs.msdn.microsoft.com/cclayton/2014/06/05/server-garbage-collection-mode-in-microsoft-azure/ Note Server garbage collection is available only on multiprocessor computers . Therefore, even if you configure the Garbage Collection either via application csproj file or via the scripts on the referred blog post, if the silo is running on a (virtual) machine with a single core, you will not get the benefits of gcServer=true ."
  },
  "docs/host/configuration_guide/configuring_ADO.NET_providers.html": {
    "href": "docs/host/configuration_guide/configuring_ADO.NET_providers.html",
    "title": "Configuring ADO.NET Providers | Microsoft Orleans Documentation",
    "keywords": "Configuring ADO.NET Providers Any reliable deployment of Orleans requires using persistent storage to keep system state, specifically Orleans cluster membership table and reminders. One of the available options is using a SQL database via the ADO.NET providers. In order to use ADO.NET for persistence, clustering or reminders, one needs to configure the ADO.NET providers as part of the silo configuration, and, in case of clustering, also as part of the client configurations. The silo configuration code should look like this: var siloHostBuilder = new SiloHostBuilder(); var invariant = \"System.Data.SqlClient\"; // for Microsoft SQL Server var connectionString = \"Data Source=(localdb)\\MSSQLLocalDB;Initial Catalog=Orleans;Integrated Security=True;Pooling=False;Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\"; //use AdoNet for clustering siloHostBuilder.UseAdoNetClustering(options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); //use AdoNet for reminder service siloHostBuilder.UseAdoNetReminderService(options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); //use AdoNet for Persistence siloHostBuilder.AddAdoNetGrainStorage(\"GrainStorageForTest\", options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); The client configuration code should look like this: var siloHostBuilder = new SiloHostBuilder(); var invariant = \"System.Data.SqlClient\"; var connectionString = \"Data Source=(localdb)\\MSSQLLocalDB;Initial Catalog=Orleans;Integrated Security=True;Pooling=False;Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\"; //use AdoNet for clustering siloHostBuilder.UseAdoNetClustering(options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); Where the ConnectionString is set to a valid AdoNet Server connection string. In order to use ADO.NET providers for persistence, reminders or clustering, there are scripts for creating database artifacts, to which all servers that will be hosting Orleans silos need to have access. Lack of access to the target database is a typical mistake we see developers making. The scripts will be copied to project directory \\OrleansAdoNetContent where each supported ADO.NET extensions has its own directory, after you install or do a nuget restore on the AdoNet extension nugets. We split AdoNet nugets into per feature nugets: Microsoft.Orleans.Clustering.AdoNet for clustering, Microsoft.Orleans.Persistence.AdoNet for persistence and Microsoft.Orleans.Reminders.AdoNet for reminders."
  },
  "docs/host/configuration_guide/index.html": {
    "href": "docs/host/configuration_guide/index.html",
    "title": "Orleans Configuration Guide | Microsoft Orleans Documentation",
    "keywords": "Orleans Configuration Guide This Configuration Guide explains the key configuration parameters and how they should be used for most typical usage scenarios. Orleans can be used in a variety of configurations that fit different usage scenarios, such as local single node deployment for development and testing, cluster of servers, multi-instance Azure worker role, etc. This guide provides instructions for the key configuration parameters that are necessary to make Orleans run in one of the target scenarios. There are also other configuration parameters that primarily help fine tune Orleans for better performance. Silos and Clients are configured programmatically via a SiloHostBuilder and ClientBuilder respectively and a number of supplemental option classes. Option classes in Orleans follow the ASP.NET Options pattern, and can be loaded via files, environment variables etc. Please refer to the Options pattern documentation for more information. If you want to configure a silo and a client for local development, look at the Local Development Configuration section. The Server Configuration and Client Configuration sections of the guide cover configuring silos and clients, respectively. The section on Typical Configurations provides a summary of a few common configurations. A list of important core options that can be configured can be found on this section . Important : Make sure you properly configure .NET Garbage Collection as detailed in Configuring .NET Garbage Collection ."
  },
  "docs/host/configuration_guide/list_of_options_classes.html": {
    "href": "docs/host/configuration_guide/list_of_options_classes.html",
    "title": "List of Options Classes | Microsoft Orleans Documentation",
    "keywords": "List of Options Classes All Options classes used to configure Orleans should be in the Orleans.Configuration namespace. Many of them have helper methods in the Orleans.Hosting namespace. Common core options for IClientBuilder and ISiloHostBuilder Option type Used for ClusterOptions Setting the ClusterId and the ServiceId NetworkingOptions Setting timeout values for sockets and opened connections SerializationProviderOptions Setting the serialization providers TypeManagementOptions Setting the refresh period of the Type Map (see Heterogeneous silos and Versioning) IClientBuilder specific options Option type Used for ClientMessagingOptions Setting the number of connections to keep open, and specify what network interface to use ClientStatisticsOption Setting various setting related to statistics output GatewayOptions Setting the refresh period of the list of available gateways StaticGatewayListProviderOptions Setting URIs a client will use to connect to cluster ISiloHostBuilder specific options Option type Used for ClusterMembershipOptions Settings for cluster membership ConsistentRingOptions Configuration options for consistent hashing algorithm, used to balance resource allocations across the cluster. EndpointOptions Setting the Silo endpoint options GrainCollectionOptions Options for grain garbage collection GrainVersioningOptions Governs grain implementation selection in heterogeneous deployments LoadSheddingOptions Settings for load shedding configuration. Must have a registered implementation of IHostEnvironmentStatistics such as through builder.UsePerfCounterEnvironmentStatistics() (Windows only) for LoadShedding to function. MultiClusterOptions Options for configuring multi-cluster support PerformanceTuningOptions Performance tuning options (networking, number of threads) ProcessExitHandlingOptions Configure silo behavior on process exit SchedulingOptions Configuring scheduler behavior SiloMessagingOptions Configuring global messaging options that are silo related. SiloOptions Setting the name of the Silo SiloStatisticsOptions Setting various setting related to statistics output TelemetryOptions Setting telemetry consumer settings"
  },
  "docs/host/configuration_guide/local_development_configuration.html": {
    "href": "docs/host/configuration_guide/local_development_configuration.html",
    "title": "Local development configuration | Microsoft Orleans Documentation",
    "keywords": "Local development configuration For a working sample application that targets Orleans 3.0 see: https://github.com/dotnet/orleans/tree/master/Samples/3.0/HelloWorld . The sample hosts the client and the silo in .NET Core console applications that work in different platforms, while the grains and interfaces target .NET Standard 2.0. For older versions of Orleans please see their respective Sample projects: https://github.com/dotnet/orleans/tree/master/Samples/ . Silo configuration For local development, please refer to the below example of how to configure a silo for that case. It configures and starts a silo listening on loopback address and 11111 and 30000 as silo and gateway ports respectively. Add the Microsoft.Orleans.Server NuGet meta-package to the project. After you get comfortable with the API, you can pick and choose which exact packages included in Microsoft.Orleans.Server you actually need, and reference them instead. PM> Install-Package Microsoft.Orleans.Server You need to configure ClusterOptions via ISiloBuilder.Configure method, specify that you want DevelopmentClustering as your clustering choice with this silo being the primary, and then configure silo endpoints. ConfigureApplicationParts call explicitly adds the assembly with grain classes to the application setup. It also adds any referenced assembly due to the WithReferences extension. After these steps are completed, the silo host gets built and the silo gets started. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for hosting a silo, as well as a .NET Core console application. Here is an example of how a local silo can be started: public class Program { public static async Task Main(string[] args) { try { var host = await StartSilo(); Console.WriteLine(\"Press Enter to terminate...\"); Console.ReadLine(); await host.StopAsync(); return; } catch (Exception ex) { Console.WriteLine(ex); return; } } private static async Task<ISiloHost> StartSilo() { var builder = new SiloHostBuilder() // Use localhost clustering for a single local silo .UseLocalhostClustering() // Configure ClusterId and ServiceId .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"MyAwesomeService\"; }) // Configure connectivity .Configure<EndpointOptions>(options => options.AdvertisedIPAddress = IPAddress.Loopback) // Configure logging with any logging framework that supports Microsoft.Extensions.Logging. // In this particular case it logs using the Microsoft.Extensions.Logging.Console package. .ConfigureLogging(logging => logging.AddConsole()); var host = builder.Build(); await host.StartAsync(); return host; } } Client configuration For local development, please refer to the below example of how to configure a client for that case. It configures a client that would connect to a loopback silo. Add the Microsoft.Orleans.Client NuGet meta-package to the project. After you get comfortable with the API, you can pick and choose which exact packages included in Microsoft.Orleans.Client you actually need, and reference them instead. PM> Install-Package Microsoft.Orleans.Client You need to configure ClientBuilder with a cluster ID that matches the one you specified for local silo and specify static clustering as your clustering choice pointing it to the gateway port of the silo ConfigureApplicationParts call explicitly adds the assembly with grain interfaces to the application setup. After these steps are completed, we can build the client and Connect() method on it to connect to the cluster. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for running a client or reuse the console application project you created for hosting a silo. Here is an example of how a client can connect to a local silo: client = new ClientBuilder() // Use localhost clustering for a single local silo .UseLocalhostClustering() // Configure ClusterId and ServiceId .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"MyAwesomeService\"; }) .ConfigureLogging(logging => logging.AddConsole()) var client = builder.Build(); await client.Connect();"
  },
  "docs/host/configuration_guide/serialization.html": {
    "href": "docs/host/configuration_guide/serialization.html",
    "title": "Serialization and Writing Custom Serializers | Microsoft Orleans Documentation",
    "keywords": "Serialization and Writing Custom Serializers Orleans has an advanced and extensible serialization framework. Orleans serializes data types passed in grain request and response messages as well as grain persistent state objects. As part of this framework, Orleans automatically generates serialization code for those data types. In addition to generating a more efficient serialization/deserialization for types that are already .NET-serializable, Orleans also tries to generate serializers for types used in grain interfaces that are not .NET-serializable. The framework also includes a set of efficient built-in serializers for frequently used types: lists, dictionaries, strings, primitives, arrays, etc. There are 2 important features of Orleans's serializer that set it apart from a lot of other third party serialization frameworks: dynamic types/arbitrary polymorphism and object identity. Dynamic types and arbitrary polymorphism - Orleans does not put any restrictions on the types that can be passed in grain calls and maintains the dynamic nature of the actual data type. That means, for example, that if the method in the grain interfaces is declared to accept IDictionary but at runtime the sender passes SortedDictionary , the receiver will indeed get SortedDictionary (although the \"static contract\"/grain interface did not specify this behaviour). Maintaining Object identity - if the same object is passed multiple types in the arguments of a grain call or is indirectly pointed more than once from the arguments, Orleans will serialize it only once. At the receiver side Orleans will restore all references correctly, so that two pointers to the same object still point to the same object after deserialization as well. Object identity is important to preserve in scenarios like the following. Imagine actor A is sending a dictionary with 100 entries to actor B, and 10 of the keys in the dictionary point to the same object, obj, on A's side. Without preserving object identity, B would receive a dictionary of 100 entries with those 10 keys pointing to 10 different clones of obj. With object identity preserved, the dictionary on B's side looks exactly like on A's side with those 10 keys pointing to a single object obj. The above two behaviours are provided by the standard .NET binary serializer and it was therefore important for us to support this standard and familiar behaviour in Orleans as well. Generated Serializers Orleans uses the following rules to decide which serializers to generate. The rules are: 1) Scan all types in all assemblies which reference the core Orleans library. 2) Out of those assemblies: generate serializers for types that are directly referenced in grain interfaces method signatures or state class signature or for any type that is marked with [Serializable] attribute. 3) In addition, a grain interface or implementation project can point to arbitrary types for serialization generation by adding a [KnownType] or [KnownAssembly] assembly level attributes to tell code generator to generate serializers for a specific types or all eligible types within an assembly. Serialization Providers Orleans supports integration with third-party serializers using a provider model. This requires an implementation of the IExternalSerializer type described in the custom serialization section of this document. Integrations for some common serializers are maintained alongside Orleans, for example: Protocol Buffers : Orleans.Serialization.ProtobufSerializer from the Microsoft.Orleans.OrleansGoogleUtils NuGet package. Bond : Orleans.Serialization.BondSerializer from the Microsoft.Orleans.Serialization.Bond NuGet package. Newtonsoft.Json AKA Json.NET : Orleans.Serialization.OrleansJsonSerializer from the core Orleans library. Custom implementation of IExternalSerializer is described in the Writing Custom Serializers section below. Configuration It is important to ensure that serialization configuration is identical on all clients and silos. If configurations are not consistent, serialization errors may occur. Serialization providers, which implement IExternalSerializer , can be specified using the SerializationProviders property of ClientConfiguration and GlobalConfiguration in code: var cfg = new ClientConfiguration(); cfg.SerializationProviders.Add(typeof(FantasticSerializer).GetTypeInfo()); var cfg = new GlobalConfiguration(); cfg.SerializationProviders.Add(typeof(FantasticSerializer).GetTypeInfo()); Alternatively, they can be specified in XML configuration under the <SerializationProviders /> property of <Messaging> : <Messaging> <SerializationProviders> <Provider type=\"GreatCompany.FantasticSerializer, GreatCompany.SerializerAssembly\"/> </SerializationProviders> </Messaging> In both cases, multiple providers can be configured. The collection is ordered, meaning that if a provider which can serialize types A and B is specified before a provider which can only serialize type B , then the latter provider will not be used. Writing Custom Serializers In addition to automatic serialization generation, application code can provide custom serialization for types it chooses. Orleans recommends using the automatic serialization generation for the majority of your application types and only write custom serializers in rare cases when you believe it is possible to get improved performance by hand-coding serializers. This note describes how to do so, and identifies some specific cases when it might be helpful. There are 3 ways in which applications can customize serialization: Add serialization methods to your type and mark them with appropriate attributes ( CopierMethod , SerializerMethod , DeserializerMethod ). This method is preferable for types that your application owns, that is, the types that you can add new methods to. Implement IExternalSerializer and register it during configuration time. This method is useful for integrating an external serialization library. Write a separate static class annotated with an [Serializer(typeof(YourType))] with the 3 serialization methods in it and the same attributes as above. This method is useful for types that the application does not own, for example, types defined in other libraries your application has no control over. Each of these methods are detailed in the sections below. Introduction Orleans serialization happens in three stages: objects are immediately deep copied to ensure isolation; before being put on the wire; objects are serialized to a message byte stream; and when delivered to the target activation, objects are recreated (deserialized) from the received byte stream. Data types that may be sent in messages -- that is, types that may be passed as method arguments or return values -- must have associated routines that perform these three steps. We refer to these routines collectively as the serializers for a data type. The copier for a type stands alone, while the serializer and deserializer are a pair that work together. You can provide just a custom copier, or just a custom serializer and a custom deserializer, or you can provide custom implementations of all three. Serializers are registered for each supported data type at silo start-up and whenever an assembly is loaded. Registration is necessary for custom serializer routines for a type to be used. Serializer selection is based on the dynamic type of the object to be copied or serialized. For this reason, there is no need to create serializers for abstract classes or interfaces, because they will never be used. When to Consider Writing a Custom Serializer It is rare that a hand-crafted serializer routine will perform meaningfully better than the generated versions. If you are tempted to do so, you should first consider the following options: If there are fields or properties within your data types that don't have to be serialized or copied, you can mark them with the NonSerialized attribute. This will cause the generated code to skip these fields when copying and serializing. Use Immutable<T> & [Immutable] where possible to avoid copying immutable data. The section on Optimizing Copying below for details. If you're avoiding using the standard generic collection types, don't. The Orleans runtime contains custom serializers for the generic collections that use the semantics of the collections to optimize copying, serializing, and deserializing. These collections also have special \"abbreviated\" representations in the serialized byte stream, resulting in even more performance advantages. For instance, a Dictionary<string, string> will be faster than a List<Tuple<string, string>> . The most common case where a custom serializer can provide a noticeable performance gain is when there is significant semantic information encoded in the data type that is not available by simply copying field values. For instance, arrays that are sparsely populated may often be more efficiently serialized by treating the array as a collection of index/value pairs, even if the application keeps the data as a fully realized array for speed of operation. A key thing to do before writing a custom serializer is to make sure that the generated serializer is really hurting your performance. Profiling will help a bit here, but even more valuable is running end-to-end stress tests of your application with varying serialization loads to gauge the system-level impact, rather than the micro-impact of serialization. For instance, building a test version that passes no parameters to or results from grain methods, simply using canned values at either end, will zoom in on the impact of serialization and copying on system performance. Method 1: Adding Serialization Methods to the Type All serializer routines should be implemented as static members of the class or struct they operate on. The names shown here are not required; registration is based on the presence of the respective attributes, not on method names. Note that serializer methods need not be public. Unless you implement all three serialization routines, you should mark your type with the Serializable attribute so that the missing methods will be generated for you. Copier Copier methods are flagged with the Orleans.CopierMethod attribute: [CopierMethod] static private object Copy(object input, ICopyContext context) { ... } Copiers are usually the simplest serializer routines to write. They take an object, guaranteed to be of the same type as the type the copier is defined in, and must return a semantically-equivalent copy of the object. If, as part of copying the object, a sub-object needs to be copied, the best way to do so is to use the SerializationManager's DeepCopyInner routine: var fooCopy = SerializationManager.DeepCopyInner(foo, context); It is important to use DeepCopyInner, instead of DeepCopy, in order to maintain the object identity context for the full copy operation. Maintaining Object Identity An important responsibility of a copy routine is to maintain object identity. The Orleans runtime provides a helper class for this. Before copying a sub-object \"by hand\" (i.e., not by calling DeepCopyInner), check to see if it has already been referenced as follows: var fooCopy = context.CheckObjectWhileCopying(foo); if (fooCopy == null) { // Actually make a copy of foo context.RecordObject(foo, fooCopy); } The last line, the call to RecordObject , is required so that possible future references to the same object as foo references will get found properly by CheckObjectWhileCopying . Note that this should only be done for class instances, not struct instances or .NET primitives (strings, Uris, enums). If you use DeepCopyInner to copy sub-objects, then object identity is handled for you. Serializer Serialization methods are flagged with the SerializerMethod attribute: [SerializerMethod] static private void Serialize(object input, ISerializationContext context, Type expected) { ... } As with copiers, the \"input\" object passed to a serializer is guaranteed to be an instance of the defining type. The \"expected\" type may be ignored; it is based on compile-time type information about the data item, and is used at a higher level to form the type prefix in the byte stream. To serialize sub-objects, use the SerializationManager 's SerializeInner routine: SerializationManager.SerializeInner(foo, context, typeof(FooType)); If there is no particular expected type for foo, then you can pass null for the expected type. The BinaryTokenStreamWriter class provides a wide variety of methods for writing data to the byte stream. An instance of the class can be obtained via the context.StreamWriter property. See the class for documentation. Deserializer Deserialization methods are flagged with the DeserializerMethod attribute: [DeserializerMethod] static private object Deserialize(Type expected, IDeserializationContext context) { ... } The \"expected\" type may be ignored; it is based on compile-time type information about the data item, and is used at a higher level to form the type prefix in the byte stream. The actual type of the object to be created will always be the type of the class in which the deserializer is defined. To deserialize sub-objects, use the SerializationManager 's DeserializeInner routine: var foo = SerializationManager.DeserializeInner(typeof(FooType), context); Or, alternatively: var foo = SerializationManager.DeserializeInner<FooType>(context); If there is no particular expected type for foo, use the non-generic DeserializeInner variant and pass null for the expected type. The BinaryTokenStreamReader class provides a wide variety of methods for reading data from the byte stream. An instance of the class can be obtained via the context.StreamReader property. See the class for documentation. Method 2: Writing a Serializer Provider In this method, you implement Orleans.Serialization.IExternalSerializer and add it to the SerializationProviders property on both ClientConfiguration on the client and GlobalConfiguration on the silos. Configuration is detailed in the Serialization Providers section above. Implementation of IExternalSerializer follows the pattern described for serialization methods from Method 1 above with the addition of an Initialize method and an IsSupportedType method which Orleans uses to determine if the serializer supports a given type. This is the interface definition: public interface IExternalSerializer { /// <summary> /// Initializes the external serializer. Called once when the serialization manager creates /// an instance of this type /// </summary> void Initialize(Logger logger); /// <summary> /// Informs the serialization manager whether this serializer supports the type for serialization. /// </summary> /// <param name=\"itemType\">The type of the item to be serialized</param> /// <returns>A value indicating whether the item can be serialized.</returns> bool IsSupportedType(Type itemType); /// <summary> /// Tries to create a copy of source. /// </summary> /// <param name=\"source\">The item to create a copy of</param> /// <param name=\"context\">The context in which the object is being copied.</param> /// <returns>The copy</returns> object DeepCopy(object source, ICopyContext context); /// <summary> /// Tries to serialize an item. /// </summary> /// <param name=\"item\">The instance of the object being serialized</param> /// <param name=\"context\">The context in which the object is being serialized.</param> /// <param name=\"expectedType\">The type that the deserializer will expect</param> void Serialize(object item, ISerializationContext context, Type expectedType); /// <summary> /// Tries to deserialize an item. /// </summary> /// <param name=\"context\">The context in which the object is being deserialized.</param> /// <param name=\"expectedType\">The type that should be deserialized</param> /// <returns>The deserialized object</returns> object Deserialize(Type expectedType, IDeserializationContext context); } Method 3: Writing a Serializer for Individual Types In this method you write a new class annotated with an attribute [SerializerAttribute(typeof(TargetType))] , where TargetType is the type which is being serialized, and implement the 3 serialization routines. The rules for how to write those routines are identical to method 1. Orleans uses the [SerializerAttribute(typeof(TargetType))] to determine that this class is a serializer for TargetType and this attribute can be specified multiple times on the same class if it's able to serialize multiple types. Below is an example for such a class: public class User { public User BestFriend { get; set; } public string NickName { get; set; } public int FavoriteNumber { get; set; } public DateTimeOffset BirthDate { get; set; } } [Orleans.CodeGeneration.SerializerAttribute(typeof(User))] internal class UserSerializer { [CopierMethod] public static object DeepCopier(object original, ICopyContext context) { var input = (User) original; var result = new User(); // Record 'result' as a copy of 'input'. Doing this immediately after construction allows for // data structures which have cyclic references or duplicate references. // For example, imagine that 'input.BestFriend' is set to 'input'. In that case, failing to record // the copy before trying to copy the 'BestFriend' field would result in infinite recursion. context.RecordCopy(original, result); // Deep-copy each of the fields. result.BestFriend = (User)context.SerializationManager.DeepCopy(input.BestFriend); result.NickName = input.NickName; // strings in .NET are immutable, so they can be shallow-copied. result.FavoriteNumber = input.FavoriteNumber; // ints are primitive value types, so they can be shallow-copied. result.BirthDate = (DateTimeOffset)context.SerializationManager.DeepCopy(input.BirthDate); return result; } [SerializerMethod] public static void Serializer(object untypedInput, ISerializationContext context, Type expected) { var input = (User) untypedInput; // Serialize each field. SerializationManager.SerializeInner(input.BestFriend, context); SerializationManager.SerializeInner(input.NickName, context); SerializationManager.SerializeInner(input.FavoriteNumber, context); SerializationManager.SerializeInner(input.BirthDate, context); } [DeserializerMethod] public static object Deserializer(Type expected, IDeserializationContext context) { var result = new User(); // Record 'result' immediately after constructing it. As with the deep copier, this // allows for cyclic references and de-duplication. context.RecordObject(result); // Deserialize each field in the order that they were serialized. result.BestFriend = SerializationManager.DeserializeInner<User>(context); result.NickName = SerializationManager.DeserializeInner<string>(context); result.FavoriteNumber = SerializationManager.DeserializeInner<int>(context); result.BirthDate = SerializationManager.DeserializeInner<DateTimeOffset>(context); return result; } } Serializing Generic Types The TargetType parameter of [Serializer(typeof(TargetType))] can be an open-generic type, for example, MyGenericType<> . In that case, the serializer class must have the same generic parameters as the target type. Orleans will create a concrete version of the serializer at runtime for every concrete MyGenericType<T> type which is serialized, for example, one for each of MyGenericType<int> and MyGenericType<string> . Hints for Writing Serializers and Deserializers Often the simplest way to write a serializer/deserializer pair is to serialize by constructing a byte array and writing the array length to the stream, followed by the array itself, and then deserialize by reversing the process. If the array is fixed-length, you can omit it from the stream. This works well when you have a data type that you can represent compactly and that doesn't have sub-objects that might be duplicated (so you don't have to worry about object identity). Another approach, which is the approach the Orleans runtime takes for collections such as dictionaries, works well for classes with significant and complex internal structure: use instance methods to access the semantic content of the object, serialize that content, and deserialize by setting the semantic contents rather than the complex internal state. In this approach, inner objects are written using SerializeInner and read using DeserializeInner. In this case, it is common to write a custom copier, as well. If you write a custom serializer, and it winds up looking like a sequence of calls to SerializeInner for each field in the class, you don't need a custom serializer for that class. Fallback Serialization Orleans supports transmission of arbitrary types at runtime and therefore the in-built code generator cannot determine the entire set of types which will be transmitted ahead of time. Additionally, certain types cannot have serializers generated for them because they are inaccessible (for example, private ) or have fields which are inaccessible (for example, readonly ). Therefore, there is a need for just-in-time serialization of types which were unexpected or could not have serializers generated ahead-of-time. The serializer responsible for these types is called the fallback serializer . Orleans ships with two fallback serializers: Orleans.Serialization.BinaryFormatterSerializer which uses .NET's BinaryFormatter ; and Orleans.Serialization.ILBasedSerializer which emits CIL instructions at runtime to create serializers which leverage Orleans' serialization framework to serialize each field. This means that if an inaccessible type MyPrivateType contains a field MyType which has a custom serializer, that custom serializer will be used to serialize it. The fallback serializer can be configured using the FallbackSerializationProvider property on both ClientConfiguration on the client and GlobalConfiguration on the silos. var cfg = new ClientConfiguration(); cfg.FallbackSerializationProvider = typeof(FantasticSerializer).GetTypeInfo(); var cfg = new GlobalConfiguration(); cfg.FallbackSerializationProvider = typeof(FantasticSerializer).GetTypeInfo(); Alternatively, the fallback serialization provider can be specified in XML configuration: <Messaging> <FallbackSerializationProvider type=\"GreatCompany.FantasticFallbackSerializer, GreatCompany.SerializerAssembly\"/> </Messaging> BinaryFormatterSerializer is the default fallback serializer. Exception Serialization Exceptions are serialized using the fallback serializer . Using the default configuration, BinaryFormatterSerializer is the fallback serializer and so the ISerializable pattern must be followed in order to ensure correct serialization of all properties in an exception type. Here is an example of an exception type with correctly implemented serialization: [Serializable] public class MyCustomException : Exception { public string MyProperty { get; } public MyCustomException(string myProperty, string message) : base(message) { this.MyProperty = myProperty; } public MyCustomException(string transactionId, string message, Exception innerException) : base(message, innerException) { this.MyProperty = transactionId; } // Note: This is the constructor called by BinaryFormatter during deserialization public MyCustomException(SerializationInfo info, StreamingContext context) : base(info, context) { this.MyProperty = info.GetString(nameof(this.MyProperty)); } // Note: This method is called by BinaryFormatter during serialization public override void GetObjectData(SerializationInfo info, StreamingContext context) { base.GetObjectData(info, context); info.AddValue(nameof(this.MyProperty), this.MyProperty); } } Optimize Copying Using Immutable Types Orleans has a feature that can be used to avoid some of the overhead associated with serializing messages containing immutable types. This section describes the feature and its application, starting with context on where it is relevant. Serialization in Orleans When a grain method is invoked, the Orleans runtime makes a deep copy of the method arguments and forms the request out of the copies. This protects against the calling code modifying the argument objects before the data is passed to the called grain. If the called grain is on a different silo, then the copies are eventually serialized into a byte stream and sent over the network to the target silo, where they are deserialized back into objects. If the called grain is on the same silo, then the copies are handed directly to the called method. Return values are handled the same way: first copied, then possibly serialized and deserialized. Note that all 3 processes, copying, serializing, and deserializing, respect object identity. In other words, if you pass a list that has the same object in it twice, on the receiving side you'll get a list with the same object in it twice, rather than with two objects with the same values in them. Optimizing Copying In many cases, the deep copying is unnecessary. For instance, a possible scenario is a web front-end that receives a byte array from its client and passes that request, including the byte array, on to a grain for processing. The front-end process doesn't do anything with the array once it has passed it on to the grain; in particular, it doesn't reuse the array to receive a future request. Inside the grain, the byte array is parsed to fetch the input data, but not modified. The grain returns another byte array that it has created to get passed back to the web client; it discards the array as soon as it returns it. The web front-end passes the result byte array back to its client, without modification. In such a scenario, there is no need to copy either the request or response byte arrays. Unfortunately, the Orleans runtime can't figure this out by itself, since it can't tell whether or not the arrays are modified later on by the web front-end or by the grain. In the best of all possible worlds, we'd have some sort of .NET mechanism for indicating that a value is no longer modified; lacking that, we've added Orleans-specific mechanisms for this: the Immutable<T> wrapper class and the [Immutable] attribute. Using Immutable<T> The Orleans.Concurrency.Immutable<T> wrapper class is used to indicate that a value may be considered immutable; that is, the underlying value will not be modified, so no copying is required for safe sharing. Note that using Immutable<T> implies that neither the provider of the value nor the recipient of the value will modify it in the future; it is not a one-sided commitment, but rather a mutual dual-side commitment. Using Immutable<T> is simple: in your grain interface, instead of passing T , pass Immutable<T> . For instance, in the above described scenario, the grain method that was: Task<byte[]> ProcessRequest(byte[] request); Becomes: Task<Immutable<byte[]>> ProcessRequest(Immutable<byte[]> request); To create an Immutable<T> , simply use the constructor: Immutable<byte[]> immutable = new Immutable<byte[]>(buffer); To get the value inside the immutable, use the .Value property: byte[] buffer = immutable.Value; Using [Immutable] For user-defined types, the [Orleans.Concurrency.Immutable] attribute can be added to the type. This instructs Orleans' serializer to avoid copying instances of this type. The following code snippet demonstrates using [Immutable] to denote an immutable type. This type will not be copied during transmission. [Immutable] public class MyImmutableType { public MyImmutableType(int value) { this.MyValue = value; } public int MyValue { get; } } Immutability in Orleans For Orleans' purposes, immutability is a rather strict statement: the contents of the data item will not be modified in any way that could change the item's semantic meaning, or that would interfere with another thread simultaneously accessing the item. The safest way to ensure this is to simply not modify the item at all: bitwise immutability, rather than logical immutability. In some cases it is safe to relax this to logical immutability, but care must be taken to ensure that the mutating code is properly thread-safe; because dealing with multithreading is complex, and uncommon in an Orleans context, we strongly recommend against this approach and recommend sticking to bitwise immutability. Serialization Best Practices Serialization serves two primary purposes in Orleans: As a wire format for transmitting data between grains and clients at runtime. As a storage format for persisting long-lived data for later retrieval. The serializers generated by Orleans are suitable for the first purpose due to their flexibility, performance, and versatility. They are not as suitable for the second purpose, since they are not explicitly version-tolerant. It is recommended that users configure a version-tolerant serializer such as Protocol Buffers for persistent data. Protocol Buffers is supported via Orleans.Serialization.ProtobufSerializer from the Microsoft.Orleans.OrleansGoogleUtils NuGet package. The best-practices for the particular serializer of choice should be used in order to ensure version-tolerance. Third-party serializers can be configured using the SerializationProviders configuration property as described above."
  },
  "docs/host/configuration_guide/server_configuration.html": {
    "href": "docs/host/configuration_guide/server_configuration.html",
    "title": "Server Configuration | Microsoft Orleans Documentation",
    "keywords": "Note If you want to start a local silo and a local client for development purposes, look at the Local Development Configuration page Server Configuration A silo is configured programmatically via SiloHostBuilder and a number of supplemental option classes. Option classes in Orleans follow the ASP.NET Options pattern, and can be loaded via files, environment variables, etc. There are several key aspects of silo configuration: Orleans clustering information Clustering provider Endpoints to use for silo-to-silo and client-to-silo communications Application parts This is an example of a silo configuration that defines cluster information, uses Azure clustering, and configures the application parts: var silo = new SiloHostBuilder() // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"AspNetSampleApp\"; }) // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) // Endpoints .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) // Application parts: just reference one of the grain implementations that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(ValueGrain).Assembly).WithReferences()) // Now create the silo! .Build(); Let's breakdown the steps used in this sample: Orleans clustering information [...] // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"AspNetSampleApp\"; }) [...] Here we do two things: Set the ClusterId to \"my-first-cluster\" : this is a unique ID for the Orleans cluster. All clients and silos that use this ID will be able to talk directly to each other. You can choose to use a different ClusterId for different deployments, though. Set the ServiceId to \"AspNetSampleApp\" : this is a unique ID for your application that will be used by some providers, such as persistence providers. This ID should remain stable and not change across deployments . Clustering provider [...] // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) [...] Usually, a service built on Orleans is deployed on a cluster of nodes, either on dedicated hardware or in Azure. For development and basic testing, Orleans can be deployed in a single node configuration. When deployed to a cluster of nodes, Orleans internally implements a set of protocols to discover and maintain membership of Orleans silos in the cluster, including detection of node failures and automatic reconfiguration. For reliable management of cluster membership, Orleans uses Azure Table, SQL Server, or Apache ZooKeeper for synchronization of nodes. In this sample, we are using Azure Table as the membership provider. Endpoints var silo = new SiloHostBuilder() [...] // Endpoints .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) [...] An Orleans silo has two typical types of endpoint configuration: Silo-to-silo endpoints, used for communication between silos in the same cluster Client-to-silo endpoints (or gateway), used for communication between clients and silos in the same cluster In the sample, we are using the helper method .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) which sets the port used for silo-to-silo communication to 11111 and and the port for the gateway to 30000 . This method will detect which interface to listen to. This method should be sufficient in most cases, but you can customize it further if you need to. Here is an example of how to use an external IP address with some port-forwarding: [...] .Configure<EndpointOptions>(options => { // Port to use for Silo-to-Silo options.SiloPort = 11111; // Port to use for the gateway options.GatewayPort = 30000; // IP Address to advertise in the cluster options.AdvertisedIPAddress = IPAddress.Parse(\"172.16.0.42\"); // The socket used for silo-to-silo will bind to this endpoint options.GatewayListeningEndpoint = new IPEndPoint(IPAddress.Any, 40000); // The socket used by the gateway will bind to this endpoint options.SiloListeningEndpoint = new IPEndPoint(IPAddress.Any, 50000); }) [...] Internally, the silo will listen on 0.0.0.0:40000 and 0.0.0.0:50000 , but the value published in the membership provider will be 172.16.0.42:11111 and 172.16.0.42:30000 . Application parts [...] // Application parts: just reference one of the grain implementations that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(ValueGrain).Assembly).WithReferences()) [...]; Although this step is not technically required (if not configured, Orleans will scan all assemblies in the current folder), developers are encouraged to configure this. This step will help Orleans to load user assemblies and types. These assemblies are referred to as Application Parts. All Grains, Grain Interfaces, and Serializers are discovered using Application Parts. Application Parts are configured using IApplicationPartsManager , which can be accessed using the ConfigureApplicationParts extension method on IClientBuilder and ISiloHostBuilder . The ConfigureApplicationParts method accepts a delegate, Action<IApplicationPartManager> . The following extension methods on IApplicationPartManager support common uses: AddApplicationPart(assembly) a single assembly can be added using this extension method. AddFromAppDomain() adds all assemblies currently loaded in the AppDomain . AddFromApplicationBaseDirectory() loads and adds all assemblies in the current base path (see AppDomain.BaseDirectory ). Assemblies added by the above methods can be supplemented using the following extension methods on their return type, IApplicationPartManagerWithAssemblies : WithReferences() adds all referenced assemblies from the added parts. This immediately loads any transitively referenced assemblies. Assembly loading errors are ignored. WithCodeGeneration() generates support code for the added parts and adds it to the part manager. Note that this requires the Microsoft.Orleans.OrleansCodeGenerator package to be installed and is commonly referred to as runtime code generation. Type discovery requires that the provided Application Parts include specific attributes. Adding the build-time code generation package ( Microsoft.Orleans.CodeGenerator.MSBuild or Microsoft.Orleans.OrleansCodeGenerator.Build ) to each project containing Grains, Grain Interfaces, or Serializers is the recommended approach for ensuring that these attributes are present. Build-time code generation only supports C#. For F#, Visual Basic, and other .NET languages, code can be generated during configuration time via the WithCodeGeneration() method described above. More info regarding code generation could be found in the corresponding section ."
  },
  "docs/host/configuration_guide/shutting_down_orleans.html": {
    "href": "docs/host/configuration_guide/shutting_down_orleans.html",
    "title": "Shutting down Orleans | Microsoft Orleans Documentation",
    "keywords": "This document explains how to gracefully shutdown an Orleans silo before application exit, first as a Console app, and then as a Docker container app. Graceful shutdown - Console app The following code shows how to gracefully shutdown an Orleans silo console app in response to the user pressing Ctrl+C, which generates the Console.CancelkeyPress event. Normally when that event handler returns, the application will exit immediately, causing a catastrophic Orleans silo crash and loss of in-memory state. But in the sample code below, we set a.Cancel = true; to prevent the application closing before the Orleans silo has completed its graceful shutdown. using Microsoft.Extensions.Logging; using Orleans.Configuration; using Orleans.Hosting; using System; using System.Net; using System.Threading; using System.Threading.Tasks; namespace MySiloHost { class Program { static readonly ManualResetEvent _siloStopped = new ManualResetEvent(false); static ISiloHost silo; static bool siloStopping = false; static readonly object syncLock = new object(); static void Main(string[] args) { SetupApplicationShutdown(); silo = CreateSilo(); silo.StartAsync().Wait(); /// Wait for the silo to completely shutdown before exiting. _siloStopped.WaitOne(); } static void SetupApplicationShutdown() { /// Capture the user pressing Ctrl+C Console.CancelKeyPress += (s, a) => { /// Prevent the application from crashing ungracefully. a.Cancel = true; /// Don't allow the following code to repeat if the user presses Ctrl+C repeatedly. lock (syncLock) { if (!siloStopping) { siloStopping = true; Task.Run(StopSilo).Ignore(); } } /// Event handler execution exits immediately, leaving the silo shutdown running on a background thread, /// but the app doesn't crash because a.Cancel has been set = true }; } static ISiloHost CreateSilo() { return new SiloHostBuilder() .Configure(options => options.ClusterId = \"MyTestCluster\") .UseDevelopmentClustering(options => options.PrimarySiloEndpoint = new IPEndPoint(IPAddress.Loopback, 11111)) .ConfigureLogging(b => b.SetMinimumLevel(LogLevel.Debug).AddConsole()) .Build(); } static async Task StopSilo() { await silo.StopAsync(); _siloStopped.Set(); } } } Of course, there are many other ways of achieving the same goal. Below is shown a way, popular online, and misleading, that DOES NOT work properly. It does not work because it sets up a race condition between two methods trying to exit first: the Console.CancelKeyPress event handler method, and the static void Main(string[] args) method. When the event handler method finishes first, which happens at least half the time, the application will hang instead of exiting smoothly. class Program { static readonly ManualResetEvent _siloStopped = new ManualResetEvent(false); static ISiloHost silo; static bool siloStopping = false; static readonly object syncLock = new object(); static void Main(string[] args) { Console.CancelKeyPress += (s, a) => { Task.Run(StopSilo); /// Wait for the silo to completely shutdown before exiting. _siloStopped.WaitOne(); /// Now race to finish ... who will finish first? /// If I finish first, the application will hang! :( }; silo = CreateSilo(); silo.StartAsync().Wait(); /// Wait for the silo to completely shutdown before exiting. _siloStopped.WaitOne(); /// Now race to finish ... who will finish first? } static async Task StopSilo() { await silo.StopAsync(); _siloStopped.Set(); } } Graceful shutdown - Docker app To be completed."
  },
  "docs/host/configuration_guide/startup_tasks.html": {
    "href": "docs/host/configuration_guide/startup_tasks.html",
    "title": "Startup Tasks | Microsoft Orleans Documentation",
    "keywords": "Startup Tasks In many cases, some task needs to be performed automatically as soon as a silo becomes available. Startup Tasks provide this functionality. Some use cases include, but are not limited to: Starting background timers to perform periodic housekeeping tasks Pre-loading some cache grains with data downloaded from external backing storage Any exceptions that are thrown from a startup task during startup will be reported in the silo log and will stop the silo. This fail-fast approach is the standard way that Orleans handles silo start-up issues, and is intended to allow any problems with silo configuration and/or bootstrap logic to be easily detected during testing phases rather than being silently ignored and causing unexpected problems later in the silo lifecycle. Configuring Startup Tasks Startup tasks can be configured using the ISiloHostBuilder either by registering a delegate to be invoked during startup or by registering a implementation of IStartupTask . Example: Registering a delegate siloHostBuilder.AddStartupTask( async (IServiceProvider services, CancellationToken cancellation) => { // Use the service provider to get the grain factory. var grainFactory = services.GetRequiredService<IGrainFactory>(); // Get a reference to a grain and call a method on it. var grain = grainFactory.GetGrain<IMyGrain>(0); await grain.Initialize(); }); Example: Registering an IStartupTask implementation First we must define an implementation of IStartupTask : public class CallGrainStartupTask : IStartupTask { private readonly IGrainFactory grainFactory; public CallGrainStartupTask(IGrainFactory grainFactory) { this.grainFactory = grainFactory; } public async Task Execute(CancellationToken cancellationToken) { var grain = this.grainFactory.GetGrain<IMyGrain>(0); await grain.Initialize(); } } Then that implementation must be registered with the ISiloHostBuilder : siloHostBuilder.AddStartupTask<CallGrainStartupTask>();"
  },
  "docs/host/configuration_guide/typical_configurations.html": {
    "href": "docs/host/configuration_guide/typical_configurations.html",
    "title": "Typical Configurations | Microsoft Orleans Documentation",
    "keywords": "Typical Configurations Below are examples of typical configurations that can be used for development and production deployments. Local Development See Local Development Configuration Reliable Production Deployment Using Azure For a reliable production deployment using Azure, you need to use the Azure Table option for cluster membership. This configuration is typical of deployments to either on-premise servers, containers, or Azure virtual machine instances. The format of the DataConnection string is \"DefaultEndpointsProtocol=https;AccountName=<Azure storage account>;AccountKey=<Azure table storage account key>\" Silo configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var silo = new SiloHostBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAzureStorageClustering(options => options.ConnectionString = connectionString) .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Client configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var client = new ClientBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAzureStorageClustering(options => options.ConnectionString = connectionString) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Reliable Production Deployment Using SQL Server For a reliable production deployment using SQL server, a SQL server connection string needs to be supplied. Silo configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var silo = new SiloHostBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAdoNetClustering(options => { options.ConnectionString = connectionString; options.Invariant = \"System.Data.SqlClient\"; }) .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Client configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var client = new ClientBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAdoNetClustering(options => { options.ConnectionString = connectionString; options.Invariant = \"System.Data.SqlClient\"; }) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Unreliable Deployment on a Cluster of Dedicated Servers For testing on a cluster of dedicated servers when reliability isn’t a concern you can leverage MembershipTableGrain and avoid dependency on Azure Table. You just need to designate one of the nodes as a Primary. On the silos: var primarySiloEndpoint = new IPEndpoint(PRIMARY_SILO_IP_ADDRESS, 11111); var silo = new SiloHostBuilder() .UseDevelopmentClustering(primarySiloEndpoint) .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) .ConfigureLogging(logging => logging.AddConsole()) .Build(); On the clients: var gateways = new IPEndPoint[] { new IPEndPoint(PRIMARY_SILO_IP_ADDRESS, 30000), new IPEndPoint(OTHER_SILO__IP_ADDRESS_1, 30000), [...] new IPEndPoint(OTHER_SILO__IP_ADDRESS_N, 30000), }; var client = new ClientBuilder() .UseStaticClustering(gateways) .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .ConfigureLogging(logging => logging.AddConsole()) .Build();"
  },
  "docs/host/grain_directory.html": {
    "href": "docs/host/grain_directory.html",
    "title": "Grain Directory | Microsoft Orleans Documentation",
    "keywords": "Grain Directory What is the Grain Directory? Grains have stable logical identities and may get activated (instantiated) and deactivated many times over the life of the application, but at most one activation of grain exist at any point in time. Each time a grain gets activated, it may be placed on a different silo in the cluster. When a grain gets activated in the cluster, it gets registered in the global registry, Grain Directory. This ensures that subsequent invocations of that grain will be delivered to that activation of the grain, and that no other activations (instances) of that grain will be created. Grain Directory is responsible for keeping a mapping between a grain identity and where (which silo) its current activation is at. By default, Orleans uses a built-in distributed in-memory directory. This directory is eventually consistent and partitioned across all silos in the cluster in a form of a Distributed Hash Table. Starting with 3.2.0, Orleans also supports pluggable implementations of Grain Directory. Two such plugins are included in the 3.2.0 release: an Azure Table implementation: Microsoft.Orleans.GrainDirectory.AzureStorage (beta) a Redis Store implementation: Microsoft.Orleans.GrainDirectory.Redis (beta) You can configure which Grain Directory implementation to use on a per-grain type basis, and you can even inject your own implementation. Which Grain Directory should you use? We recommend to always start with the default one (built-in in-memory distributed directory). Even though it is eventually consistent and allows for occasional duplicate activation when cluster is unstable, the built-in directory is self-sufficient with no external dependencies, does not requires any configuration, and has been used in production the whole time. When you have some experience with Orleans and have a use case for Grain Directory a with stronger single-activation guarantee and/or want to minimize the number of grain that get deactivated when a silo in the cluster shuts down, consider using a storage-based implementation of Grain Directory, such as the Redis implementation. Try using it for one or a few grain types first, starting with those that are long-lived and have a significant amount of state or an expensive initialization process. Configuration Default Grain Directory configuration You don't have do to anything; the in-memory grain directory will be automatically used and partitioned across the cluster. Non-default Grain Directory configuration You need to specify name of the directory plugin to use via an attribute on the grain class and inject the directory plugin with that name during the silo configuration. Grain configuration Specifying the Grain Directory plugin name with the GrainDirectory attribute: [GrainDirectory(GrainDirectoryName = \"my-grain-directory\")] public class MyGrain : Grain, IMyGrain { [...] } Silo Configuration Here we configure the Redis Grain Directory implementation: siloBuilder.AddRedisGrainDirectory( \"my-grain-directory\", options => options.ConfigurationOptions = redisConfiguration); The Azure Grain Directory is configured like this: siloBuilder.AddAzureTableGrainDirectory( \"my-grain-directory\", options => options.ConnectionString = = azureConnectionString); You can configure multiple directories with different names to use for different grain classes: siloBuilder .AddRedisGrainDirectory( \"redis-directory-1\", options => options.ConfigurationOptions = redisConfiguration1) .AddRedisGrainDirectory( \"redis-directory-2\", options => options.ConfigurationOptions = redisConfiguration2) .AddAzureTableGrainDirectory( \"azure-directory\", options => options.ConnectionString = = azureConnectionString);"
  },
  "docs/host/heterogeneous_silos.html": {
    "href": "docs/host/heterogeneous_silos.html",
    "title": "Heterogeneous silos | Microsoft Orleans Documentation",
    "keywords": "Heterogeneous silos Overview On a given cluster, silos can support a different set of grain types: In this example the cluster supports grains of type A , B , C , D , E : Grain types A and B can be placed on Silo 1 and 2. Grain type C can be placed on Silo 1, 2 or 3. Grain type D can be only placed on Silo 3 Grain Type E can be only placed on Silo 4. All silos should reference interfaces of all grain types of the cluster, but grain classes should only be referenced by the silos that will host them. The client does not know which silo supports a given Grain Type. A given Grain Type implementation must be the same on each silo that supports it. The following scenario is NOT valid: On Silo 1 and 2: public class C: Grain, IMyGrainInterface { public Task SomeMethod() { … } } On Silo 3 public class C: Grain, IMyGrainInterface, IMyOtherGrainInterface { public Task SomeMethod() { … } public Task SomeOtherMethod() { … } } Configuration No configuration is needed, you can deploy different binaries on each silo in your cluster. However, if necessary, you can change the interval that silos and clients check for changes in types supported with the property TypeMapRefreshInterval from TypeManagementOptions For testing purposes, you can use the property ExcludedGrainTypes in GrainClassOptions , which is a list names of the types you want to exclude on the silos. Limitations Connected clients will not be notified if the set of supported Grain Types changed. In the previous example: If Silo 4 leaves the cluster, the client will still try to make calls to grain of type E . It will fail at runtime with an OrleansException . If the client was connected to the cluster before Silo 4 joined it, the client will not be able to make calls to grain of type E . It will fail with an ArgumentException Stateless grains are not supported: all silos in the cluster must support the same set of stateless grains. ImplicitStreamSubscription are not supported and thus only \"Explicit Subscriptions\" can be used in Orleans Streams."
  },
  "docs/host/monitoring/client_error_code_monitoring.html": {
    "href": "docs/host/monitoring/client_error_code_monitoring.html",
    "title": "Client Error Code Monitoring | Microsoft Orleans Documentation",
    "keywords": "Client Error Code Monitoring Group Log Type Log Code Values Threshold Description Azure Problems Warning or Error 100800 - 100899 Any Error or Warning Transient problems reading or writing to Azure table store will be logged as Warning. Transient read errors will automatically be retried. A final Error log message means there is a real problem connecting to Azure table storage. Gateway connectivity problems Warning or Error 100901 - 100904, 100912, 100913, 100921, 100923, 100158, 100161, 100178, , 101313 Any Error or Warning Problems connecting to gateways. No active gateways in the Azure table. Connection to active gateway lost. Grain call timeouts Warning 100157 Multiple Warnings logged in short space of time Grain-call timeout problems are generally caused by temporary network connectivity issues or silo restart / reboot problems. System should recover after a short time (depending on Liveness config settings) at which point Timeouts should clear. Ideally, monitoring for just the bulk log code 600157 variety of these warnings should be sufficient. Network Socket Problems Warning or Error 101000 to 101999, 100307, 100015, 100016 Any Error or Warning Socket disconnects are logged as Warning messages. Problems opening sockets or during message transmission are logged as Errors. Bulk log message compaction Any 500000 or higher Message summary based on bulk message threshold settings If multiple logs of the same log code occur within a designated time interval (the default is >5 within 1 minute) then additional log messages with that log code are suppressed and output as a \"bulk\" entry with log code equal to the original log code + 500000. So for example, multiple 100157 entries will show in the logs as 5 x 100157 + 1 x 600157 log entry per minute."
  },
  "docs/host/monitoring/index.html": {
    "href": "docs/host/monitoring/index.html",
    "title": "Runtime Monitoring | Microsoft Orleans Documentation",
    "keywords": "Orleans Logs Orleans leverages Microsoft.Extensions.Logging for all silo and client logs. Runtime Monitoring Orleans outputs its runtime statistics and metrics through the ITelemetryConsumer interface. Application can register one or more telemetry consumers with for their silos and clients, to receives statistics and metrics that Orleans runtime periotically publishes. These can be consumers for popular telemetry analytics solutions or custom ones for any other destination and purpose. Three telemetry consumer are currently included in the Orleans codebase. They are released as separate NuGet packages: Microsoft.Orleans.OrleansTelemetryConsumers.AI for publishing to Application Insights . Microsoft.Orleans.OrleansTelemetryConsumers.Counters for publishing to Windows performance counters. The Orleans runtime continually updates a number of them. CounterControl.exe tool, included in the Microsoft.Orleans.CounterControl NuGet package, helps register necessary performance counter categories. It has to run with elevated privileges. The performance counters can be monitored using any of the standard monitoring tools. Microsoft.Orleans.OrleansTelemetryConsumers.NewRelic , for publishing to New Relic . To configure your silo and client to use telemetry consumers, silo configuration code looks like this: var siloHostBuilder = new SiloHostBuilder(); //configure the silo with AITelemetryConsumer siloHostBuilder.AddApplicationInsightsTelemetryConsumer(\"INSTRUMENTATION_KEY\"); Client configuration code look like this: var clientBuilder = new ClientBuilder(); //configure the clientBuilder with AITelemetryConsumer clientBuilder.AddApplicationInsightsTelemetryConsumer(\"INSTRUMENTATION_KEY\"); To use a custom defined TelemetryConfiguration (which may have TelemetryProcessors, TelemetrySinks, etc.), silo configuration code looks like this: var siloHostBuilder = new SiloHostBuilder(); var telemetryConfiguration = TelemetryConfiguration.CreateDefault(); //configure the silo with AITelemetryConsumer siloHostBuilder.AddApplicationInsightsTelemetryConsumer(telemetryConfiguration); Client configuration code look like this: var clientBuilder = new ClientBuilder(); var telemetryConfiguration = TelemetryConfiguration.CreateDefault(); //configure the clientBuilder with AITelemetryConsumer clientBuilder.AddApplicationInsightsTelemetryConsumer(telemetryConfiguration);"
  },
  "docs/host/monitoring/silo_error_code_monitoring.html": {
    "href": "docs/host/monitoring/silo_error_code_monitoring.html",
    "title": "Silo Error Code Monitoring | Microsoft Orleans Documentation",
    "keywords": "Silo Error Code Monitoring Group Log Type Log Code Values Threshold Description Azure Problems Warning or Error 100800 - 100899 Any Error or Warning Transient problems reading or writing to Azure table store will be logged as Warning. Transient read errors will automatically be retried. A final Error log message means there is a real problem connecting to Azure table storage. Membership Connectivity Problems Warning or Error 100600 - 100699 Any Error or Warning Warning logs are an early indication of network connectivity problems and/or silo restart / migration. Ping timeouts and silo-dead votes will show up as Warning messages. Silo detecting it was voted dead will show as Error message. Grain call timeouts Warning 100157 Multiple Warnings logged in short space of time Grain-call timeout problems are generally caused by temporary network connectivity issues or silo restart / reboot problems. The system should recover after a short time (depending on Liveness config settings) at which point Timeouts should clear. Ideally, monitoring for just the bulk log code 600157 variety of these warnings should be sufficient. Silo Restart / Migration Warning 100601 or 100602 Any Warning Warning printed when silo detects it was restarted on same machine {100602) or migrated to different machine (100601) Network Socket Problems Warning or Error 101000 to 101999, 100307,100015, 100016 Any Error or Warning Socket disconnects are logged as Warning messages. Problems opening sockets or during message transmission are logged as Errors. Grain problems Warning or Error 101534 Any Error or Warning Detection of “stuck” requests for non-reentrant grains . The error code is reported every time a request takes longer than 5x request timeout time to execute."
  },
  "docs/host/powershell_client.html": {
    "href": "docs/host/powershell_client.html",
    "title": "PowerShell Client Module | Microsoft Orleans Documentation",
    "keywords": "PowerShell Client Module The Orleans PowerShell Client Module is a set of PowerShell Cmdlets that wraps GrainClient in a set of convenient commands making possible to interact with not just ManagementGrain but any IGrain just as a regular Orleans application can by using Powershell scripts. These Cmdlets enable a series of scenarios from start maintenance tasks, tests, monitoring or any other kind of automation by leveraging Powershell scripts. Here is how to use it: Installing the module From Source You can build from source the OrleansPSUtils project and just import it with: PS> Import-Module .\\projectOutputDir\\Orleans.psd1 Althought you can do that, there is a much easier and interesting way for doing that by installing it from PowerShell Gallery . From PowerShell Gallery Powershell modules today are easily shared just as Nuget packages but instead of nuget.org, they are hosted on PowerShell Gallery . To install it on a specific folder just run: PS> Save-Module -Name OrleansPSUtils -Path <path> To install it on your PowerShell modules path ( the recommended way ), just run: PS> Install-Module -Name OrleansPSUtils If you plan to use this module on an Azure Automation , just click on the button bellow: Using the module Regardless of the way you decide to install it, the first thing you need to do in order to actually use it is import the module on the current PowerShell session so the Cmdlets get available by running this: PS> Import-Module OrleansPSUtils Note : In case of building from source, you must import it as suggested on the Install section by using the path to the .psd1 instead of using the module name since it will not be on the $env:PSModulePath PowerShell runtime variable. Again, it is highly recommended that you install from PowerShell Gallery instead. After the module is imported (which means it is loaded on PowerShell session), you will have the following Cmdlets available: Start-GrainClient Stop-GrainClient Get-Grain Start-GrainClient This module is a wrapper around GrainClient.Initialize() and its overloads. Usage : Start-GrainClient The same as call GrainClient.Initialize() which will look for the known Orleans Client configuration file names Start-GrainClient [-ConfigFilePath] <string> [[-Timeout] <timespan>] Will use the provided file path as in GrainClient.Initialize(filePath) Start-GrainClient [-ConfigFile] <FileInfo> [[-Timeout] <timespan>] Use an instance of the System.FileInfo class representing the config file just as GrainClient.Initialize(fileInfo) Start-GrainClient [-Config] <ClientConfiguration> [[-Timeout] <timespan>] Use an instance of a Orleans.Runtime.Configuration.ClientConfiguration like in GrainClient.Initialize(config) Start-GrainClient [-GatewayAddress] <IPEndPoint> [[-OverrideConfig] <bool>] [[-Timeout] <timespan>] Takes a Orleans Cluster Gateway Address Endpoint Note : The Timeout parameter is optional and if it is informed and greater than System.TimeSpan.Zero , it will call Orleans.GrainClient.SetResponseTimeout(Timeout) internally. Stop-GrainClient Takes no parameters and when called, if the GrainClient is initialized will gracefuly uninitialize. Get-Grain Wrapper around GrainClient.GrainFactory.GetGrain<T>() and its overloads. The mandatory parameter is -GrainType and the -XXXKey for the current Grain key types supported by Orleans ( string , Guid , long ) and also the -KeyExtension that can be used on Grains with compound keys. This Cmdlet return a grain reference of the type passed by as parameter on -GrainType . Example: A simple example on calling MyInterfacesNamespace.IMyGrain.SayHeloTo grain method: PS> Import-Module OrleansPSUtils PS> $configFilePath = Resolve-Path(\".\\ClientConfig.xml\").Path PS> Start-GrainClient -ConfigFilePath $configFilePath PS> Add-Type -Path .\\MyGrainInterfaceAssembly.dll PS> $grainInterfaceType = [MyInterfacesNamespace.IMyGrain] PS> $grainId = [System.Guid]::Parse(\"A4CF7B5D-9606-446D-ACE9-C900AC6BA3AD\") PS> $grain = Get-Grain -GrainType $grainInterfaceType -GuidKey $grainId PS> $message = $grain.SayHelloTo(\"Gutemberg\").Result PS> Write-Output $message Hello Gutemberg! PS> Stop-GrainClient We plan to update this page as we introduce more Cmdlets like use Observers, Streams and other Orleans core features more natively on Powershell. We hope that this help people as a starting point for automation. As always, this is a work-in-progress and we love contributions! :) Please note that the intent is not to reimplement the whole client on PowerShell but instead, give IT and DevOps teams a way to interact with the Grains without need to implement a .Net application."
  },
  "docs/host/silo_lifecycle.html": {
    "href": "docs/host/silo_lifecycle.html",
    "title": "Silo Lifecycle | Microsoft Orleans Documentation",
    "keywords": "Silo Lifecycle Overview Orleans silo uses an observable lifecycle (See Orleans Lifecycle ) for ordered startup and shutdown of Orleans systems as well as application layer components. Stages Orleans Silo and Cluster Client use a common set of service lifecycle stages. public static class ServiceLifecycleStage { public const int First = int.MinValue; public const int RuntimeInitialize = 2000; public const int RuntimeServices = 4000; public const int RuntimeStorageServices = 6000; public const int RuntimeGrainServices = 8000; public const int ApplicationServices = 10000; public const int BecomeActive = Active-1; public const int Active = 20000; public const int Last = int.MaxValue; } First - First stage in service's lifecycle RuntimeInitialize - Initialize runtime environment. Silo initializes threading. RuntimeServices - Start runtime services. Silo initializes networking and various agents. RuntimeStorageServices - Initialize runtime storage. RuntimeGrainServices - Start runtime services for grains. This includes grain type management, membership service, and grain directory. ApplicationServices – Application layer services. BecomeActive – Silo joins the cluster. Active – Silo is active in the cluster and ready to accept workload. Last - Last stage in service's lifecycle Logging Due to the inversion of control, where participants join the lifecycle rather than the lifecycle having some centralized set of initialization steps, it’s not always clear from the code what the startup/shutdown order is. To help address this, logging has been added prior to silo startup to report what components are participating at each stage. These logs are recorded at Information log level on the Orleans.Runtime.SiloLifecycleSubject logger. For instance: Information, Orleans.Runtime.SiloLifecycleSubject, “Stage 2000: Orleans.Statistics.PerfCounterEnvironmentStatistics, Orleans.Runtime.InsideRuntimeClient, Orleans.Runtime.Silo” Information, Orleans.Runtime.SiloLifecycleSubject, “Stage 4000: Orleans.Runtime.Silo” Information, Orleans.Runtime.SiloLifecycleSubject, “Stage 10000: Orleans.Runtime.Versions.GrainVersionStore, Orleans.Storage.AzureTableGrainStorage-Default, Orleans.Storage.AzureTableGrainStorage-PubSubStore” Additionally, timing and error information are similarly logged for each component by stage. For instance: Information, Orleans.Runtime.SiloLifecycleSubject, “Lifecycle observer Orleans.Runtime.InsideRuntimeClient started in stage 2000 which took 33 Milliseconds.” Information, Orleans.Runtime.SiloLifecycleSubject, “Lifecycle observer Orleans.Statistics.PerfCounterEnvironmentStatistics started in stage 2000 which took 17 Milliseconds.” Silo Lifecycle Participation Application logic can take part in the silo’s lifecycle by registering a participating service in the silo’s service container. The service must be registered as an ILifecycleParticipant . public interface ISiloLifecycle : ILifecycleObservable { } public interface ILifecycleParticipant<TLifecycleObservable> where TLifecycleObservable : ILifecycleObservable { void Participate(TLifecycleObservable lifecycle); } Upon silo start, all participants ( ILifecycleParticipant<ISiloLifecycle> ) in the container will be given an opportunity to participate by calling their Participate(..) behavior. Once all have had the opportunity to participate, the silo’s observable lifecycle will start all stages in order. Example With the introduction of the silo lifecycle, bootstrap providers, which used to allow application developers to inject logic at the provider initialization phase, are no longer necessary, since application logic can now be injected at any stage of silo startup. Nonetheless, we added a ‘startup task’ façade to aid the transition for developers who had been using bootstrap providers. As an example of how components can be developed which take part in the silo’s lifecycle, we’ll look at the startup task façade. The startup task needs only to inherit from ILifecycleParticipant<ISiloLifecycle> and subscribe the application logic to the silo lifecycle at the specified stage. class StartupTask : ILifecycleParticipant<ISiloLifecycle> { private readonly IServiceProvider serviceProvider; private readonly Func<IServiceProvider, CancellationToken, Task> startupTask; private readonly int stage; public StartupTask( IServiceProvider serviceProvider, Func<IServiceProvider, CancellationToken, Task> startupTask, int stage) { this.serviceProvider = serviceProvider; this.startupTask = startupTask; this.stage = stage; } public void Participate(ISiloLifecycle lifecycle) { lifecycle.Subscribe<StartupTask>( this.stage, cancellation => this.startupTask(this.serviceProvider, cancellation)); } } From the above implementation, we can see that in the StartupTask’s Participate(..) call it subscribes to the silo lifecycle at the configured stage, passing the application callback rather than its own initialization logic. Components that need to be initialized at a given stage would provide their own callback, but the pattern is the same. Now that we have a StartupTask which will ensure that the application’s hook is called at the configured stage, we need to ensure that the StartupTask participates in the silo lifecycle. For this we need only register it in the container. We do this with an extension function on the SiloHost builder. public static ISiloHostBuilder AddStartupTask( this ISiloHostBuilder builder, Func<IServiceProvider, CancellationToken, Task> startupTask, int stage = ServiceLifecycleStage.Active) { builder.ConfigureServices(services => services.AddTransient<ILifecycleParticipant<ISiloLifecycle>>(sp => new StartupTask( sp, startupTask, stage))); return builder; } By registering the StartupTask in the silo’s service container as the marker interface ILifecycleParticipant<ISiloLifecycle> , this signals to the silo that this component needs to take part in the silo lifecycle."
  },
  "docs/implementation/cluster_management.html": {
    "href": "docs/implementation/cluster_management.html",
    "title": "Cluster Management in Orleans | Microsoft Orleans Documentation",
    "keywords": "Cluster Management in Orleans Orleans provides cluster management via a built-in membership protocol, which we sometimes refer to as Silo Membership . The goal of this protocol is for all silos (Orleans servers) to agree on the set of currently alive silos, detect failed silos, and allow new silos to join the cluster. The protocol relies on an external service to provide an abstraction of MembershipTable . MembershipTable is a flat No-SQL like durable table that we use for 2 purposes. First, it is used as a rendezvous point for silos to find each other and Orleans clients to find silos. Second, it is used to store the current membership view (list of alive silos) and helps coordinate the agreement on the membership view. We currently have 6 implementations of the MembershipTable : based on Azure Table Storage , SQL server, Apache ZooKeeper , Consul IO , AWS DynamoDB , and in-memory emulation for development. In addition to the MembershipTable each silo participates in fully distributed peer-to-peer membership protocol that detects failed silos and reaches agreement on a set alive silos. We start by describing the internal implementation of the Orleans's membership protocol below and later on describe the implementation of the MembershipTable . The Basic Membership Protocol: Upon startup every silo writes itself into a well-known MembershipTable (passed via config). A combination of silo identity ( ip:port:epoch ) and service deployment id are used as unique keys in the table. Epoch is just time in ticks when this silo started, and as such ip:port:epoch is guaranteed to be unique in a given Orleans deployment. Silos monitor each other directly, via application pings (\"are you alive\" heartbeats ). Pings are sent as direct messages from silo to silo, over the same TCP sockets that silos communicate. That way, pings fully correlate with actual networking problems and server health. Every silo pings X other silos. A silo picks whom to ping by calculating consistent hashes on other silos' identity, forming a virtual ring of all identities and picking X successor silos on the ring (this is a well-known distributed technique called consistent hashing and is widely used in many distributed hash tables, like Chord DHT ). If a silo S does not get Y ping replies from a monitored servers P, it suspects it by writing its timestamped suspicion into P’s row in the MembershipTable . If P has more than Z suspicions within K seconds, then S writes that P is dead into P’s row, and broadcasts a request for all silos to re-read the membership table (which they’ll do anyway periodically). In more details: 5.1 Suspicion is written to the MembershipTable , in a special column in the row corresponding to P. When S suspects P it writes: “at time TTT S suspected P”. 5.2 One suspicion is not enough to declare P as dead. You need Z suspicions from different silos in a configurable time window T, typically 3 minutes, to declare P as dead. The suspicion is written using optimistic concurrency control provided by the MembershipTable . 5.3 The suspecting silo S reads P's row. 5.4 If S is the last suspector (there have already been Z-1 suspectors within time period T, as written in the suspicion column), S decides to declare P as Dead. In this case, S adds itself to list of suspectors and also writes in P's Status column that P is Dead. 5.5 Otherwise, if S is not the last suspector, S just adds itself to the suspectors column. 5.6 In either case the write back uses the version number or etag that was read, so the updates to this row are serialized. In case the write has failed due to version/etag mismatch, S retries (read again, and try to write, unless P was already marked dead). 5.7 At a high level this sequence of \"read, local modify, write back\" is a transaction. However, we are not using storage transactions to do that. “Transaction” code executes locally on a server and we use optimistic concurrency provided by the MembershipTable to ensure isolation and atomicity. Every silo periodically reads the entire membership table for its deployment. That way silos learn about new silos joining and about other silos being declared dead. Configuration : we provide a default configuration, which was hand tuned during our production usage in Azure. Currently the default is: every silo is monitored by 3 other silos, 2 suspicions are enough to declare a silo dead, suspicions only from last 3 minutes (otherwise they are outdated). Pings are send every 10 seconds and you needs to miss 3 pings to suspect a silo. Enforcing Perfect Failure detection – it is theoretically possible that a silo will be declared dead if it lost communication with other silos, while the silo process itself is still running. To solve this problem once the silo is declared dead in the table it is considered dead by everyone, even if it is in fact not dead (just partitioned temporarily or heartbeat messages got lost). Everyone stops communicating with it and once it learns that it is dead (by reading its own new status from the table) it commits suicide and shuts down its process. As a result, there must be an infrastructure in place to restart the silo as a new process (a new epoch number is generated upon start). When it's hosted in Azure, that happens automatically. When it isn't, another infrastructure is required. For example, a Windows Service configured to auto restart on failure. Optimization to reduce the frequency of periodical table reads and speed up all silos learning about new joining silos and dead silos . Every time any silo writes anything successfully to the table (suspicion, new join, …) it also broadcasts to all other silos – “go and reread the table now”. The silo does NOT tell others what it wrote in the table (since this information could already be outdated/wrong), it just tells them to re-read the table. That way we learn very quickly about membership changes without the need to wait for the full periodic read cycle. We still need the periodic read, in case the “re-read the table” message gets lost. Properties of the Basic Membership Protocol and FAQ: Can handle any number of failures – our algorithm can handle any number of failures (that is, f<=n), including full cluster restart. This is in contrast with “traditional” Paxos based solutions, which require quorum, which is usually a majority. We have seen in production situations when more than half of the silos were down. Our system stayed functional, while Paxos based membership would not be able to make progress. Traffic to the table is very light - The actual pings go directly between servers and not to the table. This would generate a lot of traffic plus would be less accurate from the failure detection perspective - if a silo could not reach the table, it would miss to write its I am alive heartbeat and others would kill him. Tunable accuracy vs. completeness – both perfect and accurate failure detection is not possible in general . One usually wants an ability to tradeoff accuracy (don’t want to declare a silo that is really alive as dead) with completeness (want to declare dead a silo that is indeed dead as soon as possible). The configurable #votes to declare dead and #missed pings allows to trade those two. Scale - the basic protocol can handle thousands and probably even tens of thousands of servers. This is in contrast with traditional Paxos based solutions, such as group communication protocols, which are known not to scale beyond tens. Diagnostics - the table is also very convenient for diagnostics and troubleshooting. System administrator can instantaneously find in the table the current list of alive silos, as well as see the history of all killed silos and suspicions. This is especially useful when diagnosing problems. Why do we need reliable persistent storage for implementation of the MembershipTable ? - we use persistent storage (Azure table, SQL server, AWS DynamoDB, Apache ZooKeeper or Consul IO KV) for the MembershipTable for 2 purposes. First, it is used as a rendezvous point for silos to find each other and Orleans clients to find silos. Second, we use the reliable storage to help us coordinate the agreement on the membership view. While we perform failure detection directly in a peer to peer fashion between the silos, we store the membership view in a reliable storage and use the concurrency control mechanism provided by this storage to reach agreement of who is alive and who is dead. That way, in a sense, our protocol outsources the hard problem of distributed consensus to the cloud. In that we fully utilize the power of the underlying cloud platform, using it truly as \"Platform as a Service\". What happens if the table is not accessible for some time? (storage service is down, unavailable, or there are communication problems with it) – our protocol will NOT declare silos as dead by mistake in such a case. Currently operational silos will keep working without any problems. However, we won't be able to declare a silo dead (if we detected some silo is dead via missed pings we won’t be able to write this fact to the table) and also won't be able to allow new silos to join. So completeness will suffer, but accuracy will not - partitioning from the table will never cause us to declare silo as dead by mistake. Also, in case of a partial network partition (if some silos can access the table and some not), it could happen that we will declare a dead silo as dead, but it will take some time until all other silos learn about it. So detection could be delayed, but we will never wrongly kill someone due to table un-availability. Direct IAmAlive writes into the table for diagnostics only - in addition to heartbeats that are sent between the silos, each silo also periodically updates an \"I Am Alive\" column in his row in the table. This \"I Am Alive\" column is only used for manual troubleshooting and diagnostics and is not used by the membership protocol itself. It is usually written at much lower frequency (once every 5 minutes) and serves as a very useful tool for system administrators to check the liveness of the cluster or easily find out when the silo was last alive. Extension to totally order membership views: The basic membership protocol described above was later extended to support totally ordered membership views. We will briefly describe the reasons for this extension and how it is implemented. The extension does not change anything in the above design, just adds an additional property that all membership configurations are globally totally ordered. Why it is useful to totally order membership views? This allows serializing the joining of new silos to the cluster. That way, when a new silo joins the cluster it can validate two-way connectivity to every other silo that has already started. If some of the already joined silos do not answer it (potentially indicating a network connectivity problem with the new silo), the new silo is not allowed to join. This ensures that at least when a silo starts, there is a full connectivity between all silos in the cluster (this is implemented). Higher level protocols in the silo, such as distributed grain directory, can utilize the fact that membership views are ordered and use this information to perform smarter duplicate activations resolution. In particular, when directory finds out that 2 activations were created when membership was in flux, it may decide to deactivate the older activation that was created based on the now-outdated membership information (this is currently not implemented). Extended Membership Protocol: For implementation of this feature we utilize the support for transactions over multiple rows that is provided by the MembershipTable .. We add a membership-version row to the table that tracks table changes. When silo S wants to write suspicion or death declaration for silo P: 3.1 S reads the latest table content. If P is already dead, do nothing. Otherwise, 3.2 In the same transaction, write the changes to P's row as well as increment the version number and write it back to the table. 3.3 Both writes are conditioned with eTags. 3.4 If transaction aborts due to eTag mismatch on either P's row or on the version row, attempt again. All writes to the table modify and increment the version row. That way all writes to the table are serialized (via serializing the updates to the version row) and since silos only increment the version number, the writes are also totally ordered in increasing order. Scalability of the Extended Membership Protocol: In the extended version of the protocol all writes are serialized via one row. This can potentially hurt the scalability of the cluster managemenet protocol, since it increases the risk of conflicts between concurrent table writes. To partially mitigate this problem silos retry all their writes to the table by using exponential backoff. We have observed the extended protocols to work smoothly in production environment in Azure with up to 200 silos. However, we do think the protocol might have problems to scale beyond a thousand silos. In such large setups the updates to version row may be easily disabled, essentially maintaining the rest of the cluster managemenet protocol and giving up on the total ordering property. Please also note that we refer here to the scalability of the cluster management protocol, not the rest of Orleans. We believe that other parts of the Orleans runtime (messaging, distributed directory, grain hosting, client to gateway connectivity) are scalable way beyond hundreds of silos. Membership Table: As already mentioned, MembershipTable is used as a rendezvous point for silos to find each other and Orleans clients to find silos and also helps coordinate the agreement on the membership view. We currently have 6 implementation of the MembershipTable : based on Azure Table, SQL server, Apache ZooKeeper, Consul IO, AWS DynamoDB, and in-memory emulation for development. The interface for MembershipTable is defined in IMembershipTable . Azure Table Storage - in this implementation we use Azure deployment ID as partition key and the silo identity ( ip:port:epoch ) as row key. Together they guarantee a unique key per silo. For concurrency control we use optimistic concurrency control based on Azure Table ETags . Every time we read from the table we store the etag for every read row and use that eTag when we try to write back. etags are automatically assigned and checked by Azure Table service on every write. For multi-row transactions we utilize the support for batch transactions provided by Azure table , which guarantees serializale transactions over rows with the same partition key. SQL Server - in this implementation the configured deployment ID is used to distinguish between deployments and which silos belong to which deployments. The silo identity is defined as a combination of deploymentID, ip, port, epoch in appropriate tables and columns. The relational backend uses optimistic concurrency control and transactions, similar to the procedure of using ETags on Azure Table implementation. The relational implementation expects the database engine to generate the ETag used. In case of SQL Server, on SQL Server 2000 the generated ETag is one acquired from a call to NEWID() . On SQL Server 2005 and later ROWVERSION is used. Orleans reads and writes relational ETags as opaque VARBINARY(16) tags and stores them in memory as base64 encoded strings. Orleans supports multi-row inserts using UNION ALL (for Oracle including DUAL), which is currently used to insert statistics data. The exact implementation and rationale for SQL Server can be seen at CreateOrleansTables_SqlServer.sql . Apache ZooKeeper - in this implementation we use the configured deployment ID as a root node and the silo identity ( ip:port@epoch ) as its child node. Together they guarantee a unique path per silo. For concurrency control we use optimistic concurrency control based on the node version . Every time we read from the deployment root node we store the version for every read child silo node and use that version when we try to write back. Each time a node's data changes, the version number increases atomically by the ZooKeeper service. For multi-row transactions we utilize the multi method , which guarantees serializale transactions over silo nodes with the same parent deployment ID node. Consul IO - we used Consul's Key/Value store to impelement the membershop table. Refer to Consul-Deployment for more details. AWS DynamoDB - In this implementation we use the cluster Deployment ID as the Partition Key and Silo Identity ( ip-port-generation ) as the RangeKey making the record unity. The optimistic concurrency is made by the ETag attribute by making conditional writes on DynamoDB. The implementation logic is quite similar to Azure Table Storage. We only implemented the basic membership protocol (and not the extended protocol). In-memory emulation for development setup. We use a special system grain, called MembershipTableGrain , for that implementation. This grain lives on a designated primary silo, which is only used for a development setup . In any real production usage primary silo is not required . Configuration: Membership protocol is configured via the Liveness element in the Globals section in OrleansConfiguration.xml file. The default values were tuned in years of production usage in Azure and we believe they represent good default settings. There is no need in general to change them. Sample config element: <Liveness ProbeTimeout = \"5s\" TableRefreshTimeout =\"10s DeathVoteExpirationTimeout =\"80s\" NumMissedProbesLimit = \"3\" NumProbedSilos=\"3\" NumVotesForDeathDeclaration=\"2\" /> There are 4 types of liveness implemented. The type of the liveness protocol is configured via the SystemStoreType attribute of the SystemStore element in the Globals section in OrleansConfiguration.xml file. MembershipTableGrain - membership table is stored in a grain on primary silo. This is a development setup only . AzureTable - membership table is stored in Azure table. SqlServer - membership table is stored in a relational database. ZooKeeper - membership table is stored in a ZooKeeper ensemble . Consul - configured as Custom system store with MembershipTableAssembly = \"OrleansConsulUtils\" . Refer to Consul-Deployment for more details. DynamoDB - configured as a Custom system store with MembershipTableAssembly = \"OrleansAWSUtils\" . For all liveness types the common configuration variables are defined in Globals.Liveness element: ProbeTimeout - The number of seconds to probe other silos for their liveness or for the silo to send \"I am alive\" heartbeat messages about itself. Default is 10 seconds. TableRefreshTimeout - The number of seconds to fetch updates from the membership table. Default is 60 seconds. DeathVoteExpirationTimeout - Expiration time in seconds for death vote in the membership table. Default is 120 seconds NumMissedProbesLimit - The number of missed \"I am alive\" heartbeat messages from a silo or number of un-replied probes that lead to suspecting this silo as dead. Default is 3. NumProbedSilos - The number of silos each silo probes for liveness. Default is 3. NumVotesForDeathDeclaration - The number of non-expired votes that are needed to declare some silo as dead (should be at most NumMissedProbesLimit). Default is 2. UseLivenessGossip - Whether to use the gossip optimization to speed up spreading liveness information. Default is true. IAmAliveTablePublishTimeout - The number of seconds to periodically write in the membership table that this silo is alive. Used only for diagnostics. Default is 5 minutes. NumMissedTableIAmAliveLimit - The number of missed \"I am alive\" updates in the table from a silo that causes warning to be logged. Does not impact the liveness protocol. Default is 2. MaxJoinAttemptTime - The number of seconds to attempt to join a cluster of silos before giving up. Default is 5 minutes. ExpectedClusterSize - The expected size of a cluster. Need not be very accurate, can be an overestimate. Used to tune the exponential backoff algorithm of retries to write to Azure table. Default is 20. Design Rationale: A natural question that might be asked is why not to rely completely on Apache ZooKeeper for the cluster membership implementation, potentially by using it's out of the box support for group membership with ephemeral nodes ? Why did we bother implementing our own membership protocol? There were primarily three reasons: 1) Deployment/Hosting in the Cloud - Zookeeper is not a hosted service (at least at the time of this writing July 2015 and definitely when we first implemented this protocol in the summer of 2011 there was no version of Zookeeper running as a hosted service by any major cloud provider). It means that in the Cloud environment Orleans customers would have to deploy/run/manage their own instance of a ZK cluster. This is just yet another unnecessary burden, that we did not want to force on our customers. By using Azure Table we rely on a hosted, managed service which makes our customers lives much simpler. Basically, in the Cloud, use Cloud as a Platform, not as an Infrastructure. On the other hand, when running on premises and managing your own servers, relying on ZK as an implementation of the MembershipTable is a viable option. 2) Direct failure detection - when using ZK's group membership with ephemeral nodes the failure detection is performed between the Orleans servers (ZK clients) and ZK servers. This may not necessarily correlate with the actual network problems between Orleans servers. Our desire was that the failure detection would accurately reflect the intra-cluster state of the communication. Specifically, in our design, if an Orleans silo cannot communicate with the MembershipTable it is not considered dead and can keep working. As opposite to that, have we used ZK group membership with ephemeral nodes a disconnection from a ZK server may cause an Orleans silo (ZK client) to be declared dead, while it may actually be alive and fully functional. 3) Portability and flexibility - as part of Orleans's philosophy, we do not want to force a strong dependence on any particular technology, but rather have a flexible design where different components can be easily switched with different implementations. This is exactly the purpuse that MembershipTable abstraction serves. Acknowledgements: We would to acknowledge the contribution of Alex Kogan to the design and implementation of the first version of this protocol. This work was done as part of summer internship in Microsoft Research in the Summer of 2011. The implementation of ZooKeeper based MembershipTable was done by Shay Hazor , the implementation of SQL MembershipTable was done by Veikko Eeva , the implementation of AWS DynamoDB MembershipTable was done by Gutemberg Ribeiro and the implementation of Consul based MembershipTable was done by Paul North ."
  },
  "docs/implementation/index.html": {
    "href": "docs/implementation/index.html",
    "title": "Implementation Details | Microsoft Orleans Documentation",
    "keywords": "Implementation Details Overview Orleans Lifecycle Some Orleans behaviors are sufficiently complex that they need ordered startup and shutdown. To address this, a general component lifecycle pattern has been introduced. Messaging Delivery Guarantees Orleans messaging delivery guarantees are at-most-once , by default. Optionally, if configured to do retries upon timeout, Orleans provides at-least-once delivery instead. Scheduler Orleans Scheduler is a component within the Orleans runtime responsible for executing application code and parts of the runtime code to ensure the single threaded execution semantics. Cluster Management Orleans provides cluster management via a built-in membership protocol, which we sometimes refer to as Silo Membership. The goal of this protocol is for all silos (Orleans servers) to agree on the set of currently alive silos, detect failed silos, and allow new silos to join the cluster. Streams Implementation This section provides a high level overview of Orleans Stream implementation. It describes concepts and details that are not visible on the application level. Load Balancing Load balancing, in a broad sense, is one of the pillars of the Orleans runtime. Unit Testing This section shows how to unit test your grains to make sure they behave correctly."
  },
  "docs/implementation/load_balancing.html": {
    "href": "docs/implementation/load_balancing.html",
    "title": "Load Balancing | Microsoft Orleans Documentation",
    "keywords": "Load Balancing Load balancing, in a broad sense, is one of the pillars of the Orleans runtime . Orleans runtime tries to make everything balanced, since balancing allows to maximize resource usage and avoid hotspots, which leads to better performance, as well as helps with elasticity. Load balancing in Orleans applies in multiple places. Below is a non-exhaustive list of places where the runtime performs balancing: Default actor placement strategy is random - new activations are placed randomly across silos. That results in a balanced placement and prevents hotspots for most scenarios. A more advanced ActivationCountPlacement tries to equalize the number of activations on all silos, which results in a more even distribution of activations across silos. This is especially important for elasticity. Grain Directory service is built on top of a Distributed Hash Table, which inherently is balanced. The directory service maps grains to activations, each silo owns part of the global mapping table, and this table is globally partitioned in a balanced way across all silos. We use consistent hashing with virtual buckets for that. Clients connect to all gateways and spread their requests across them, in a balanced way. Reminder service is a distributed partitioned runtime service. The assignment of which silo is responsible to serve which reminder is balanced across all silos via consistent hashing, just like in grain directory. Performance critical components within a silo are partitioned, and the work across them is locally balanced . That way the silo runtime can fully utilize all available CPU cores and not create in-silo bottlenecks. This applies to all local resources: allocation of work to threads, sockets, dispatch responsibilities, queues, etc. StreamQueueBalance balances the responsibility of pulling events from persistence queues across silos in the cluster. Also notice that balancing, in a broad sense, does not necessarily mean loss of locality . One can be balanced and still maintain a good locality. For example, when balancing means sharding/partitioning, you can partition responsibility for a certain logical task, while still maintaining locality within each partition. That applies both for local and distributed balancing. Refer to this presentation on Balancing Techniques in Orleans for more details."
  },
  "docs/implementation/messaging_delivery_guarantees.html": {
    "href": "docs/implementation/messaging_delivery_guarantees.html",
    "title": "Messaging Delivery Guarantees | Microsoft Orleans Documentation",
    "keywords": "Messaging Delivery Guarantees Orleans messaging delivery guarantees are at-most-once , by default. Optionally, if configured to do retries upon timeout, Orleans provides at-least-once deliv­ery instead. In more detail: Every message in Orleans has automatic timeout (the exact timeout can be configured). If the reply does not arrive on time, the return Task is broken with timeout exception. Orleans can be configured to do automatic retries upon timeout. By default it does NOT do automatic retries. Application code of course can also choose to do retries upon timeout. If the Orleans system is configured not to do automatic retries (default setting) and the application is not resending – Orleans provides at-most-once message delivery . A message will either be delivered once or not at all. It will never be delivered twice. In the system with retries (either by the runtime or by the application) the message may arrive multiple times. Orleans currently does nothing to durably store which messages already arrived and suppress the second delivery. (We believe this would be pretty costly.) So in a system with retries Orleans does NOT guarantee at most once delivery. If you keep retrying potentially indefinitely , the message will eventually arrive , thus providing at-least-once delivery guarantee. Notice that “will eventually arrive” is something that the runtime needs to guarantee. It does not come for free just by itself even if you keep retrying. Orleans provides eventual delivery since grains never go into any permanent failure state and a failed grain will eventually be re-activated on another silo. So to summarize : in the system without retries Orleans guarantees at-most-once message delivery. In the system with infinite retries Orleans guarantees at-least-once (and does NOT guarantee at-most-once). Note : In the Orleans technical report we accidentally only mentioned the 2nd option with automatic retries. We forgot to mention that by default with no retries, Orleans provides at-most-once delivery."
  },
  "docs/implementation/orleans_lifecycle.html": {
    "href": "docs/implementation/orleans_lifecycle.html",
    "title": "Orleans Lifecycle | Microsoft Orleans Documentation",
    "keywords": "Orleans Lifecycle Overview Some Orleans behaviors are sufficiently complex that they need ordered startup and shutdown. Some components with such behaviors include grains, silos, and clients. To address this, a general component lifecycle pattern has been introduced. This pattern consists of an observable lifecycle, which is responsible for signaling on stages of a component’s startup and shutdown, and lifecycle observers which are responsible for performing startup or shutdown operations at specific stages. See also Grain Lifecycle and Silo Lifecycle . Observable Lifecycle Components that need ordered startup and shutdown can use an observable lifecycle which allows other components to observe the LiveCycle and receive notification when a stage is reached during startup or shutdown. public interface ILifecycleObservable { IDisposable Subscribe(string observerName, int stage, ILifecycleObserver observer); } The subscribe call registers an observer for notification when a stage is reached while starting or stopping. The observer name is for reporting purposes. The stage indicated at which point in the startup/shutdown sequence the observer will be notified. Each stage of lifecycle is observable. All observers will be notified when the stage is reached when starting and stopping. Stages are started in ascending order and stopped in descending order. The observer can unsubscribe by disposing of the returned disposable. Lifecycle Observer Components which need to take part in another component’s lifecycle need provide hooks for their startup and shutdown behaviors and subscribe to a specific stage of an observable lifecycle. public interface ILifecycleObserver { Task OnStart(CancellationToken ct); Task OnStop(CancellationToken ct); } OnStart/OnStop will be called when the stage subscribed to is reached during startup/shutdown. Utilities For convenience, helper functions have been created for common lifecycle usage patterns. Extensions Extension functions exist for subscribing to observable lifecycle which do not require that the subscribing component implement ILifecycleObserver. Instead, these allow components to pass in lambdas or members function to be called at the subscribed stages. IDisposable Subscribe(this ILifecycleObservable observable, string observerName, int stage, Func<CancellationToken, Task> onStart, Func<CancellationToken, Task> onStop); IDisposable Subscribe(this ILifecycleObservable observable, string observerName, int stage, Func<CancellationToken, Task> onStart); Similar extension functions allow generic type arguments to be used in place of the observer name. IDisposable Subscribe<TObserver>(this ILifecycleObservable observable, int stage, Func<CancellationToken, Task> onStart, Func<CancellationToken, Task> onStop); IDisposable Subscribe<TObserver>(this ILifecycleObservable observable, int stage, Func<CancellationToken, Task> onStart); Lifecycle Participation Some extensibility points need a way of recognizing what components are interested in participating in a lifecycle. A lifecycle participant marker interface has been introduced for this purpose. More about how this is used will be covered when exploring silo and grain lifecycles. public interface ILifecycleParticipant<TLifecycleObservable> where TLifecycleObservable : ILifecycleObservable { void Participate(TLifecycleObservable lifecycle); } Example From our lifecycle tests, below is an example of a component that takes part in an observable lifecycle at multiple stages of the lifecycle. enum TestStages { Down, Initialize, Configure, Run, } class MultiStageObserver : ILifecycleParticipant<ILifecycleObservable> { public Dictionary<TestStages,bool> Started { get; } = new Dictionary<TestStages, bool>(); public Dictionary<TestStages, bool> Stopped { get; } = new Dictionary<TestStages, bool>(); private Task OnStartStage(TestStages stage) { this.Started[stage] = true; return Task.CompletedTask; } private Task OnStopStage(TestStages stage) { this.Stopped[stage] = true; return Task.CompletedTask; } public void Participate(ILifecycleObservable lifecycle) { lifecycle.Subscribe<MultiStageObserver>((int)TestStages.Down, ct => OnStartStage(TestStages.Down), ct => OnStopStage(TestStages.Down)); lifecycle.Subscribe<MultiStageObserver>((int)TestStages.Initialize, ct => OnStartStage(TestStages.Initialize), ct => OnStopStage(TestStages.Initialize)); lifecycle.Subscribe<MultiStageObserver>((int)TestStages.Configure, ct => OnStartStage(TestStages.Configure), ct => OnStopStage(TestStages.Configure)); lifecycle.Subscribe<MultiStageObserver>((int)TestStages.Run, ct => OnStartStage(TestStages.Run), ct => OnStopStage(TestStages.Run)); } }"
  },
  "docs/implementation/scheduler.html": {
    "href": "docs/implementation/scheduler.html",
    "title": "Scheduling | Microsoft Orleans Documentation",
    "keywords": "Scheduling There are two forms of scheduling in Orleans which are relevant to grains: Request scheduling, the scheduling of incoming grain calls for execution according to scheduling rules discussed in Reentrancy Task scheduling, the scheduling of synchronous blocks of code to be executed in a single-threaded manner All grain code is executed on the grain's task scheduler, which means that requests are also executed on the grain's task scheduler. Even if the request scheduling rules allow multiple requests to execute concurrently , they will not execute in parallel because the grain's task scheduler always executes tasks one-by-one and hence never executes multiple tasks in parallel. Task scheduling To better understand scheduling, consider the following grain, MyGrain , which has a method called DelayExecution() which logs a message, waits some time, then logs another message before returning. public interface IMyGrain : IGrain { public Task DelayExecution(); } public class MyGrain : Grain, IMyGrain { private readonly ILogger<MyGrain> _logger; public MyGrain(ILogger<MyGrain> logger) => _logger = logger; public async Task DelayExecution() { _logger.LogInformation(\"Executing first task\"); await Task.Delay(1000); _logger.LogInformation(\"Executing second task\"); } } When this method is executed, the method body will be executed in two parts: The first _logger.LogInformation(...) call and the call to Task.Delay(1000) The second _logger.LogInformation(...) call The second task will not be scheduled on the grain's task scheduler until the Task.Delay(1000) call completes, at which point it will schedule the continuation of the grain method. Here is a graphical representation of how a request is scheduled and executed as two tasks: Note that the above description is not specific to Orleans and is instead how task scheduling in .NET works: asynchronous methods in C# are converted into an asynchronous state machine by the compiler and execution progresses through the asynchronous state machine in discrete steps. Each step is scheduled on the current TaskScheduler (accessed via TaskScheduler.Current , defaulting to TaskScheduler.Default ) or the current SynchronizationContext . If a TaskScheduler is being used, each step in the method is represented by a Task instance which is passed to that TaskScheduler . Therefore, a Task in .NET can represent two conceptual things: An asynchronous operation which can be waited on. The execution of the DelayExecution() method above is represented by a Task which can be awaited. A synchronous block of work. Each stage within the DelayExecution() method above is represented by a Task . When TaskScheduler.Default is in use, continuations are scheduled directly onto the .NET ThreadPool and are not wrapped in a Task object. The wrapping of continuations in Task instances occurs transparently and therefore developers rarely need to be aware of these implementation details. Task scheduling in Orleans Each grain activation has its own TaskScheduler instance which is responsible for enforcing the single threaded execution model of grains. Internally, this TaskScheduler is implemented via ActivationTaskScheduler and WorkItemGroup . WorkItemGroup keeps enqueued tasks in a Queue<Task> internally and implements IThreadPoolWorkItem . In order to execute each currently enqueued Task , WorkItemGroup schedules itself on the .NET ThreadPool . When the .NET ThreadPool invokes the WorkItemGroup 's IThreadPoolWorkItem.Execute() method, the WorkItemGroup executes the enqueued Task instances one-by-one. Each grain has a scheduler which executes by scheduling itself on the .NET ThreadPool : Each scheduler contains a queue of tasks: The .NET ThreadPool executes each work item enqueued to it. This includes grain schedulers as well as other work items, such as work items scheduled via Task.Run(...) : Note that a grain's scheduler can only execute on one thread at a time, but it does not always execute on the same thread. The .NET ThreadPool is free to use a different thread each time the grain's scheduler is executed. The grain's scheduler is responsible for making sure that it only executes on one thread at a time and this is how the single threaded execution model of grains is implemented."
  },
  "docs/implementation/streams_implementation/azure_queue_streams.html": {
    "href": "docs/implementation/streams_implementation/azure_queue_streams.html",
    "title": "Azure Queue Streams Implementation Details | Microsoft Orleans Documentation",
    "keywords": "Orleans Azure Queue Streams Implementation Details Each stream provider (Azure Queues, EventHub, SMS, SQS, ...) has it's own queue specific details and configuration. This section provides some details about the usage, configuration and implementation of Orleans Azure Queue Streams . This section is not comprehensive, and more details are available in the streaming tests, which contain most of the configuration options, specifically AQClientStreamTests , AQSubscriptionMultiplicityTests , and the extension functions for IAzureQueueStreamConfigurator and ISiloPersistentStreamConfigurator . Overview Orleans Azure Queue requires the package Microsoft.Orleans.Streaming.AzureStorage . The package contains - in addition to the implementation - also some extension methods that make the configuration at silo startup easier. The minimal configuration requires at least to specify the connection string, as example: hostBuilder .AddAzureQueueStreams(\"AzureQueueProvider\", configurator => { configurator.ConfigureAzureQueue( ob => ob.Configure(options => { options.ConnectionString = \"xxx\"; options.QueueNames = new List<string> { \"yourprefix-azurequeueprovider-0\" }; })); configurator.ConfigureCacheSize(1024); configurator.ConfigurePullingAgent(ob => ob.Configure(options => { options.GetQueueMsgsTimerPeriod = TimeSpan.FromMilliseconds(200); })); }) // a PubSubStore could be needed, as example Azure Table Storage .AddAzureTableGrainStorage(\"PubSubStore\", options => { options.ConnectionString = \"xxx\"; }) The pulling agents will pull repeatedly until there are no more messages on a queue, then delay for a configurable period before continuing to pull. This process occurs for each queue . Internally the pulling agents place messages in a cache (one cache per queue) for delivery to consumers, but will stop reading if the cache fills up. Messages are removed from the cache once consumers process the messages, so the read rate should roughly be throttled by the processing rate of the consumers. By default it uses 8 queues (see AzureQueueOptions ) and 8 related pulling agents, a delay of 100ms (see StreamPullingAgentOptions.GetQueueMsgsTimerPeriod ) and a cache size ( IQueueCache ) of 4096 messages (see SimpleQueueCacheOptions.CacheSize ). Configuration The default configuration should fit a production environment, but for special needs it's possible to configure the default behaviour. As example, in a development machine it's possible to reduce the number of the pulling agents to using just one queue. This can help to reduce CPU usage and resource pressure. hostBuilder .AddAzureQueueStreams<AzureQueueDataAdapterV2>(\"AzureQueueProvider\", optionsBuilder => optionsBuilder.Configure(options => { options.ConnectionString = \"xxx\"; options.QueueNames = new List<string> { \"yourprefix-azurequeueprovider-0\" }; })) Tuning In a production system can emerge the need of tuning over the default configuration. When tuning there are some factors that should be considered, and it's service specific. First, most of the settings are per queue, so for a large number of streams, the load on each queue can be reduced by configuring more queues. Since streams process messages in order per stream, the gating factor will be the number of events being sent on a single stream. A reasonable balance of cache time ( StreamPullingAgentOptions.GetQueueMsgsTimerPeriod ) vs visibility time ( AzureQueueOptions.MessageVisibilityTimeout ) is that the visibility should be configured to double the time messages are expected to be in the cache. Example Assuming a system with this characteristics: 100 streams, 10 queues, Each stream processing 60 messages per minute, Each message takes around 30ms to process, 1 minute worth of messages in cache (cache time). So we can calculate some parameters of the system: Streams/queue: Even balancing of streams across queues would be an ideal 10 streams/queue (100 streams / 10 queues). But since streams won't always be evenly balanced over the queues, doubling (or even tripling) the ideal is safer than expecting ideal distribution. Hence 20 streams/queue (10 streams/queue x 2 as safety factor) is probably reasonable. Messages/minute: This means each queue will be expected to process up to 1200 messages/minute (60 messages x 20 streams). Then we can determine the visibility time to use: Visibility time: The cache time (1 minute) is configured to hold 1 minute of messages (so 1200 messages, as we calculated messages/minute above). We assumed that each message takes 30 ms to process, then we can expect messages to spend up to 36 seconds in the cache (0.030 sec x 1200 msg = 36 sec), so the visibility time - doubled for safety - would need be over 72 seconds (36 sec of time in cache x 2). Accordingly, if we define a bigger cache, that would require a longer visibility time. Final considerations in a real world system: Since order is only per stream, and a queue consume many streams, it's likely that messages will be processed across multiple streams in parallel (as example: we have a grain for stream, which can run in parallel). This means we'll burn through the cache in far less time, but we planned for the worse case: it will give the system room to continue to function well even under intermittent delays and transient errors. So we can configure Azure Queue Streams using: hostBuilder .AddAzureQueueStreams(\"AzureQueueProvider\", configurator => { configurator.ConfigureAzureQueue( ob => ob.Configure(options => { options.ConnectionString = \"xxx\"; options.QueueNames = new List<string> { \"yourprefix-azurequeueprovider-1\", [...] \"yourprefix-azurequeueprovider-10\", }; options.MessageVisibilityTimeout = TimeSpan.FromSeconds(72); })); configurator.ConfigureCacheSize(1200); })"
  },
  "docs/implementation/streams_implementation/index.html": {
    "href": "docs/implementation/streams_implementation/index.html",
    "title": "Streams Implementation Details | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Implementation Details This section provides a high level overview of Orleans Stream implementation. It describes concepts and details that are not visible on the application level. If you only plan to use streams, you do not have to read this section. Terminology : We refer by the word \"queue\" to any durable storage technology that can ingest stream events and allows either to pull events or provides a push-based mechanism to consume events. Usually, to provide scalability, those technologies provide sharded/partitioned queues. For example, Azure Queues allow to create multiple queues, Event Hubs have multiple hubs, Kafka topics, ... Persistent Streams All Orleans Persistent Stream Providers share a common implementation PersistentStreamProvider . This generic stream provider needs be configured with a technology specific IQueueAdapterFactory . For instance, for testing purposes we have queue adapters that generate their own test data rather than reading the data from a queue. The code below shows how we configure a persistent stream provider to use our custom (generator) queue adapter. It does this by configuring the persistent stream provider with a factory function used to create the adapter. hostBuilder.AddPersistentStreams(StreamProviderName, GeneratorAdapterFactory.Create); When a stream producer generates a new stream item and calls stream.OnNext() , the Orleans Streaming Runtime invokes the appropriate method on the IQueueAdapter of that stream provider which enqueues the item directly onto the appropriate queue. Pulling Agents At the heart of the Persistent Stream Provider are the pulling agents. Pulling agents pull events from a set of durable queues and deliver them to the application code in grains that consumes them. One can think of the pulling agents as a distributed \"micro-service\" -- a partitioned, highly available, and elastic distributed component. The pulling agents run inside the same silos that host application grains and are fully managed by the Orleans Streaming Runtime. StreamQueueMapper and StreamQueueBalancer Pulling agents are parameterized with IStreamQueueMapper and IStreamQueueBalancer . IStreamQueueMapper provides a list of all queues and is also responsible for mapping streams to queues. That way, the producer side of the Persistent Stream Provider knows into which queue to enqueue the message. IStreamQueueBalancer expresses the way queues are balanced across Orleans silos and agents. The goal is to assign queues to agents in a balanced way, to prevent bottlenecks and support elasticity. When a new silo is added to the Orleans cluster, queues are automatically rebalanced across the old and new silos. StreamQueueBalancer allows customizing that process. Orleans has a number of built-in StreamQueueBalancers, to support different balancing scenarios (large and small number of queues) and different environments (Azure, on prem, static). Using the test generator example from above, the code below shows how one could configure the queue mapper and queue balancer. hostBuilder .AddPersistentStreams(StreamProviderName, GeneratorAdapterFactory.Create, providerConfigurator=>providerConfigurator .Configure<HashRingStreamQueueMapperOptions>(ob=>ob.Configure( options=>{ options.TotalQueueCount = 8; })) .UseDynamicClusterConfigDeploymentBalancer() ); The above code configures the GeneratorAdapter to use a queue mapper with 8 queues, and balances the queues across the cluster using the DynamicClusterConfigDeploymentBalancer . Pulling Protocol Every silo runs a set of pulling agents, every agent is pulling from one queue. Pulling agents themselves are implemented by an internal runtime component, called SystemTarget . SystemTargets are essentially runtime grains, are subject to single threaded concurrency, can use regular grain messaging, and are as lightweight as grains. In contrast to grains, SystemTargets are not virtual: they are explicitly created (by the runtime) and are not location transparent. By implementing pulling agents as SystemTargets, the Orleans Streaming Runtime can rely on built-in Orleans features and can scale to a very large number of queues, since creating a new pulling agent is as cheap as creating a new grain. Every pulling agent runs a periodic timer that pulls from the queue (by invoking IQueueAdapterReceiver ) GetQueueMessagesAsync() method. The returned messages are put in the internal per-agent data structure called IQueueCache . Every message is inspected to find out its destination stream. The agent uses the Pub Sub to find out the list of stream consumers that subscribed to this stream. Once the consumer list is retrieved, the agent stores it locally (in its pub-sub cache) so it does not need to consult with Pub Sub on every message. The agent also subscribes to the pub-sub to receive notification of any new consumers that subscribe to that stream. This handshake between the agent and the pub-sub guarantees strong streaming subscription semantics : once the consumer has subscribed to the stream it will see all events that were generated after it has subscribed . In addition, using StreamSequenceToken allows it to subscribe in the past. Queue Cache IQueueCache is an internal per-agent data structure that allows to decoupling dequeuing new events from the queue and delivering them to consumers. It also allows to decoupling delivery to different streams and to different consumers. Imagine a situation where one stream has 3 stream consumers and one of them is slow. If care is not taken, it is possible that this slow consumer will impact the agent's progress, slowing the consumption of other consumers of that stream, and even slowing the dequeuing and delivery of events for other streams. To prevent that and allow maximum parallelism in the agent, we use IQueueCache . IQueueCache buffers stream events and provides a way for the agent to deliver events to each consumer at its own pace. The per-consumer delivery is implemented by the internal component called IQueueCacheCursor , which tracks per-consumer progress. That way, each consumer receives events at its own pace: fast consumers receive events as quickly as they are dequeued from the queue, while slow consumers receive them later on. Once the message is delivered to all consumers, it can be deleted from the cache. Backpressure Backpressure in the Orleans Streaming Runtime applies in two places: bringing stream events from the queue to the agent and delivering the events from the agent to stream consumers . The latter is provided by the built-in Orleans message delivery mechanism. Every stream event is delivered from the agent to consumers via the standard Orleans grain messaging, one at a time. That is, the agents sends one event (or a limited size batch of events) to each individual stream consumer and awaits this call. The next event will not start being delivered until the Task for the previous event was resolved or broken. That way we naturally limit the per-consumer delivery rate to one message at a time. With regard to bringing stream events from the queue to the agent, Orleans Streaming provides a new special Backpressure mechanism. Since the agent decouples dequeuing of events from the queue and delivering them to consumers, it is possible that a single slow consumer will fall behind so much that the IQueueCache will fill up. To prevent IQueueCache from growing indefinitely, we limit its size (the size limit is configurable). However, the agent never throws away undelivered events. Instead, when the cache starts to fill up, the agents slow the rate of dequeuing events from the queue. That way, we can \"ride out\" the slow delivery periods by adjusting the rate at which we consume from the queue (\"backpressure\") and get back into fast consumption rate later on. To detect the \"slow delivery\" valleys the IQueueCache uses an internal data structure of cache buckets that tracks the progress of delivery of events to individual stream consumers. This results in a very responsive and self-adjusting system."
  },
  "docs/implementation/testing.html": {
    "href": "docs/implementation/testing.html",
    "title": "Unit Testing | Microsoft Orleans Documentation",
    "keywords": "Unit Testing This tutorial shows how to unit test your grains to make sure they behave correctly. There are two main ways to unit test your grains, and the method you choose will depend on the type of functionality you are testing. The Microsoft.Orleans.TestingHost NuGet package can be used to create test silos for your grains, or you can use a mocking framework like Moq to mock parts of the Orleans runtime that your grain interacts with. Using TestCluster The Microsoft.Orleans.TestingHost NuGet package contains TestCluster which can be used to create an in-memory cluster, comprised of two silos by default, which can be used to test grains. using System; using System.Threading.Tasks; using Orleans; using Orleans.TestingHost; using Xunit; namespace Tests { public class HelloGrainTests { [Fact] public async Task SaysHelloCorrectly() { var builder = new TestClusterBuilder(); var cluster = builder.Build(); cluster.Deploy(); var hello = cluster.GrainFactory.GetGrain<IHelloGrain>(Guid.NewGuid()); var greeting = await hello.SayHello(); cluster.StopAllSilos(); Assert.Equal(\"Hello, World\", greeting); } } } Due to the overhead of starting an in-memory cluster you may wish to create a TestCluster and reuse it among multiple test cases. For example this can be done using xUnit's class or collection fixtures (see https://xunit.github.io/docs/shared-context.html for more details). In order to share a TestCluster between multiple test cases, first create a fixture type: public class ClusterFixture : IDisposable { public ClusterFixture() { var builder = new TestClusterBuilder(); var cluster = builder.Build(); this.Cluster.Deploy(); } public void Dispose() { this.Cluster.StopAllSilos(); } public TestCluster Cluster { get; private set; } } Next create a collection fixture: [CollectionDefinition(ClusterCollection.Name)] public class ClusterCollection : ICollectionFixture<ClusterFixture> { public const string Name = \"ClusterCollection\"; } You can now reuse a TestCluster in your test cases: using System; using System.Threading.Tasks; using Orleans; using Xunit; namespace Tests { [Collection(ClusterCollection.Name)] public class HelloGrainTests { private readonly TestCluster _cluster; public HelloGrainTests(ClusterFixture fixture) { _cluster = fixture.Cluster; } [Fact] public async Task SaysHelloCorrectly() { var hello = _cluster.GrainFactory.GetGrain<IHelloGrain>(Guid.NewGuid()); var greeting = await hello.SayHell(); Assert.Equal(\"Hello, World\", greeting); } } } xUnit will call the Dispose method of the ClusterFixture type when all tests have been completed and the in-memory cluster silos will be stopped. TestCluster also has a constructor which accepts TestClusterOptions that can be used to configure the silos in the cluster. If you are using Dependency Injection in your Silo to make services available to Grains, you can use this pattern as well: public class ClusterFixture : IDisposable { public ClusterFixture() { var builder = new TestClusterBuilder(); builder.AddSiloBuilderConfigurator<TestSiloConfigurations>(); this.Cluster = builder.Build(); this.Cluster.Deploy(); } public void Dispose() { this.Cluster.StopAllSilos(); } public TestCluster Cluster { get; private set; } } public class TestSiloConfigurations : ISiloConfigurator { public void Configure(ISiloBuilder siloBuilder) { siloBuilder.ConfigureServices(services => { services.AddSingleton<T, Impl>(...); }); } } Using Mocks Orleans also makes it possible to mock many parts of system, and for many of scenarios this is the easiest way to unit test grains. This approach does have limitations (e.g. around scheduling reentrancy and serialization), and may require that grains include code used only by your unit tests. The Orleans TestKit provides an alternative approach which side-steps many of these limitations. For example, let us imagine that the grain we are testing interacts with other grains. In order to be able to mock those other grains we also need to mock the GrainFactory member of the grain under test. By default GrainFactory is a normal protected property, but most mocking frameworks require properties to be public and virtual to be able to mock them. So the first thing we need to do is make GrainFactory both public and virtual property: public new virtual IGrainFactory GrainFactory { get { return base.GrainFactory; } } Now we can create our grain outside of the Orleans runtime and use mocking to control the behaviour of GrainFactory : using System; using System.Threading.Tasks; using Orleans; using Xunit; using Moq; namespace Tests { public class WorkerGrainTests { [Fact] public async Task RecordsMessageInJournal() { var data = \"Hello, World\"; var journal = new Mock<IJournalGrain>(); var worker = new Mock<WorkerGrain>(); worker .Setup(x => x.GrainFactory.GetGrain<IJournalGrain>(It.IsAny<Guid>())) .Returns(journal.Object); await worker.DoWork(data) journal.Verify(x => x.Record(data), Times.Once()); } } } Here we create our grain under test, WorkerGrain , using Moq which means we can then override the behaviour of the GrainFactory so that it returns a mocked IJournalGrain . We can then verify that our WorkerGrain interacts with the IJournalGrain as we expect."
  },
  "docs/index.html": {
    "href": "docs/index.html",
    "title": "Introduction | Microsoft Orleans Documentation",
    "keywords": "Orleans is a cross-platform framework for building robust, scalable distributed applications Orleans builds on the developer productivity of .NET and brings it to the world of distributed applications, such as cloud services. Orleans scales from a single on-premises server to globally distributed, highly-available applications in the cloud. Orleans takes familiar concepts like objects, interfaces, async/await, and try/catch and extends them to multi-server environments. As such, it helps developers experienced with single-server applications transition to building resilient, scalable cloud services and other distributed applications. For this reason, Orleans has often been referred to as \"Distributed .NET\". It was created by Microsoft Research and introduced the Virtual Actor Model as a novel approach to building a new generation of distributed systems for the Cloud era. The core contribution of Orleans is its programming model which tames the complexity inherent to highly-parallel distributed systems without restricting capabilities or imposing onerous constraints on the developer. Grains The fundamental building block in any Orleans application is a grain . Grains are entities comprising user-defined identity, behavior, and state. Grain identities are user-defined keys which make Grains always available for invocation. Grains can be invoked by other grains or by external clients such as Web frontends, via strongly-typed communication interfaces (contracts). Each grain is an instance of a class which implements one or more of these interfaces. Grains can have volatile and/or persistent state that can be stored in any storage system. As such, grains implicitly partition application state, enabling automatic scalability and simplifying recovery from failures. Grain state is kept in memory while the grain is active, leading to lower latency and less load on data stores. Instantiation of grains is automatically performed on demand by the Orleans runtime. Grains which are not used for a while are automatically removed from memory to free up resources. This is possible because of their stable identity, which allows invoking grains whether they are already loaded into memory or not. This also allows for transparent recovery from failure because the caller does not need to know on which server a grain is instantiated on at any point in time. Grains have a managed lifecycle, with the Orleans runtime responsible for activating/deactivating, and placing/locating grains as needed. This allows the developer to write code as if all grains were always in-memory. Taken together, the stable identity, statefulness, and managed lifecycle of Grains are core factors that make systems built on Orleans scalable, performant, & reliable without forcing developers to write complex distributed systems code. Example: Internet of Things Cloud Backend Consider a cloud backend for an Internet of Things system. This application needs to process incoming device data, filter, aggregate, and process this information, and enable sending commands to devices. In Orleans, it is natural to model each device with a grain which becomes a digital twin of the physical device it corresponds to. These grains keep the latest device data in memory, so that they can be quickly queried and processed without the need to communicate with the physical device directly. By observing streams of time-series data from the device, the grain can detect changes in conditions, such as measurements exceeding a threshold, and trigger an action. A simple thermostat could be modeled as follows: public interface IThermostat : IGrainWithStringKey { Task<List<Command>> OnUpdate(ThermostatStatus update); } Events arriving from the thermostat from a Web frontend can be sent to its grain by invoking the OnUpdate method which optionally returns a command back to the device. var thermostat = client.GetGrain<IThermostat>(id); return await thermostat.OnUpdate(update); The same thermostat grain can implement a separate interface for control systems to interact with: public interface IThermostatControl : IGrainWithStringKey { Task<ThermostatStatus> GetStatus(); Task UpdateConfiguration(ThermostatConfiguration config); } These two interfaces ( IThermostat and IThermostatControl ) are implemented by a single implementation class: public class ThermostatGrain : Grain, IThermostat, IThermostatControl { private ThermostatStatus _status; private List<Command> _commands; public Task<List<Command>> OnUpdate(ThermostatStatus status) { _status = status; var result = _commands; _commands = new List<Command>(); return Task.FromResult(result); } public Task<ThermostatStatus> GetStatus() => Task.FromResult(_status); public Task UpdateConfiguration(ThermostatConfiguration config) { _commands.Add(new ConfigUpdateCommand(config)); return Task.CompletedTask; } } The grain class above does not persist its state. More thorough example demonstrating state persistence is available in the documentation . Orleans Runtime The Orleans runtime is what implements the programming model for applications.The main component of the runtime is the silo , which is responsible for hosting grains. Typically, a group of silos run as a cluster for scalability and fault-tolerance. When run as a cluster, silos coordinate with each other to distribute work, detect and recover from failures. The runtime enables grains hosted in the cluster to communicate with each other as if they are within a single process. In addition to the core programming model, the silo provides grains with a set of runtime services, such as timers, reminders (persistent timers), persistence, transactions, streams, and more. See the features section below for more detail. Web frontends and other external clients call grains in the cluster using the client library which automatically manages network communication. Clients can also be co-hosted in the same process with silos for simplicity. Orleans is compatible with .NET Standard 2.0 and above, running on Windows, Linux, and macOS, in full .NET Framework or .NET Core. Features Persistence Orleans provides a simple persistence model which ensures that state is available to a grain before requests are processed and that consistency is maintained. Grains can have multiple named persistent data objects, for example, one called \"profile\" for a user's profile and one called \"inventory\" for their inventory. This state can be stored in any storage system. For example, profile data may be stored in one database and inventory in another. While a grain is running, this state is kept in memory so that read requests can be served without accessing storage. When the grain updates its state, a state.WriteStateAsync() call ensures that the backing store is updated for durability and consistency. For more information, see the Grain Persistence documentation. Distributed ACID Transactions In addition to the simple persistence model described above, grains can have transactional state . Multiple grains can participate in ACID transactions together regardless of where their state is ultimately stored. Transactions in Orleans are distributed and decentralized (there is no central transaction manager or transaction coordinator) and have serializable isolation . For more information on transactions in Orleans, see the documentation and the Microsoft Research technical report . Streams Streams help developers to process series of data items in near-real time. Streams in Orleans are managed : streams do not need to be created or registered before a grain or client publishes to a stream or subscribes to a stream. This allows for greater decoupling of stream producers and consumers from each other and from the infrastructure. Stream processing is reliable: grains can store checkpoints (cursors) and reset to a stored checkpoint during activation or at any point afterwards. Streams supports batch delivery of messages to consumers to improve efficiency and recovery performance. Streams are backed by queueing services such as Azure Event Hubs, Amazon Kinesis, and others. An arbitrary number of streams can be multiplexed onto a smaller number of queues and the responsibility for processing these queues is balanced evenly across the cluster. Timers & Reminders Reminders are a durable scheduling mechanism for grains. They can be used to ensure that some action is completed at a future point even if the grain is not currently activated at that time. Timers are the non-durable counterpart to reminders and can be used for high-frequency events which do not require reliability. For more information, see the Timers and Reminders documentation. Flexible Grain Placement When a grain is activated in Orleans, the runtime decides which server (silo) to activate that grain on. This is called grain placement. The placement process in Orleans is fully configurable: developers can choose from a set of out-of-the-box placement policies such as random, prefer-local, and load-based, or custom logic can be configured. This allows for full flexibility in deciding where grains are created. For example, grains can be placed on a server close to resources which they need to operate on or other grains which they communicate with. For more information see the Grain Placement documentation. Grain Versioning & Heterogeneous Clusters Application code evolves over time and upgrading live, production systems in a manner which safely accounts for these changes can be challenging, particularly in stateful systems. Grain interfaces in Orleans can be optionally versioned. The cluster maintains a mapping of which grain implementations are available on which silos in the cluster and the versions of those implementations. This version information is used by the runtime in conjunction with placement strategies to make placement decisions when routing calls to grains. In addition to safe update of versioned grains, this also enables heterogeneous clusters, where different silos have different sets of grain implementations available. For more information, see the Grain Versioning documentation. Elastic Scalability & Fault Tolerance Orleans is designed to scale elastically. When a silo joins a cluster it is able to accept new activations and when a silo leaves the cluster (either because of scale down or a machine failure) the grains which were activated on that silo will be re-activated on remaining silos as needed. An Orleans cluster can be scaled down to a single silo. The same properties which enable elastic scalability also enable fault tolerance: the cluster automatically detects and quickly recovers from failures. Run Anywhere Orleans runs anywhere that .NET Core or .NET Framework are supported. This includes hosting on Linux, Windows, and macOS and deploying to Kubernetes, virtual or physical machines, on premises or in the cloud, and PaaS services such as Azure Cloud Services. Stateless Workers Stateless workers are specially marked grains which do not have any associated state and can be activated on multiple silos simultaneously. This enables increased parallelism for stateless functions. For more information, see the Stateless Worker Grains documentation. Grain Call Filters Logic which is common to many grains can be expressed as Grain Call Filters . Orleans supports filters for both incoming and outgoing calls. Some common use-cases of filters are: authorization, logging and telemetry, and error handling. Request Context Metadata and other information can be passed along a series of requests using request context . Request context can be used for holding distributed tracing information or any other user-defined values. Getting Started Please see the getting started tutorial . Building On Windows, run the build.cmd script to build the NuGet packages locally, then reference the required NuGet packages from /Artifacts/Release/* . You can run Test.cmd to run all BVT tests, and TestAll.cmd to also run Functional tests. On Linux and macOS, run the build.sh script or dotnet build ./OrleansCrossPlatform.sln to build Orleans. Official Builds The latest stable, production-quality release is located here . Nightly builds are published to https://orleans.pkgs.visualstudio.com/orleans-public/_packaging/orleans-builds/nuget/v3/index.json . These builds pass all functional tests, but are not thoroughly tested as the stable builds or pre-release builds published to NuGet. Using the nightly build packages in your project To use nightly builds in your project, add the MyGet feed using either of the following methods: Changing the .csproj file to include this section: <RestoreSources> $(RestoreSources); https://orleans.pkgs.visualstudio.com/orleans-public/_packaging/orleans-builds/nuget/v3/index.json; </RestoreSources> or Creating a NuGet.config file in the solution directory with the following contents: <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <packageSources> <clear /> <add key=\"orleans-ci\" value=\"https://orleans.pkgs.visualstudio.com/orleans-public/_packaging/orleans-builds/nuget/v3/index.json\" /> <add key=\"nuget\" value=\"https://api.nuget.org/v3/index.json\" /> </packageSources> </configuration> Community Ask questions by opening an issue on GitHub or on Stack Overflow Chat on Gitter Orleans Blog Follow the @msftorleans Twitter account for Orleans announcements. OrleansContrib - GitHub organization for community add-ons to Orleans Various community projects, including Monitoring, Design Patterns, Storage Providers, etc. Guidelines for developers wanting to contribute code changes to Orleans . You are also encouraged to report bugs or start a technical discussion by starting a new thread on GitHub. License This project is licensed under the MIT license . Quick Links Microsoft Research project home Technical Report: Distributed Virtual Actors for Programmability and Scalability Orleans Documentation Origin of Orleans Orleans was created at Microsoft Research and designed for use in the cloud . Since 2011, it has been used extensively in the cloud and on premises by several Microsoft product groups, most notably by game studios, such as 343 Industries and The Coalition as a platform for cloud services behind Halo 4 and 5, and Gears of War 4, as well as by a number of other companies. Orleans was open-sourced in January 2015, and attracted many developers that formed one of the most vibrant open source communities in the .NET ecosystem . In an active collaboration between the developer community and the Orleans team at Microsoft, features are added and improved on a daily basis. Microsoft Research continues to partner with the Orleans team to bring new major features, such as geo-distribution , indexing , and distributed transactions , that are pushing the state of the art. Orleans has become the framework of choice for building distributed systems and cloud services for many .NET developers."
  },
  "docs/migration/codegen.html": {
    "href": "docs/migration/codegen.html",
    "title": "Code Generation in Orleans 2.0 | Microsoft Orleans Documentation",
    "keywords": "Code Generation in Orleans 2.0 Code generation has been improved in Orleans 2.0, improving startup times and providing a more deterministic, debuggable experience. As with earlier versions, Orleans provides both build-time and run-time code generation. During Build - This is the recommended option and only supports C# projects. In this mode, code generation will run every time your project is compiled. A build task is injected into your project's build pipeline and the code is generated in the project's intermediate output directory. To activate this mode, add one of the packages Microsoft.Orleans.CodeGenerator.MSBuild or Microsoft.Orleans.OrleansCodeGenerator.Build to all projects which contain Grains, Grain interfaces, serializers, or types which require serializers. Differences between the packages and additional codegen information could be found in the corresponding Code Generation section. Additional diagnostics can be emitted at build-time by specifying value for OrleansCodeGenLogLevel in the target project's csproj file. For example, <OrleansCodeGenLogLevel>Trace</OrleansCodeGenLogLevel> . During Configuration - This is the only supported option for F#, Visual Basic, and other non-C# projects. This mode generates code during the configuration phase. To access this, see the Configuration documentation. Both modes generate the same code, however run-time code generation can only generate code for publicly accessible types."
  },
  "docs/migration/index.html": {
    "href": "docs/migration/index.html",
    "title": "Migration | Microsoft Orleans Documentation",
    "keywords": "Orleans 2.0 2.0 is a major release of Orleans with the main goal of making it .NET Standard 2.0 compatible and cross-platform (via .NET Core). As part of that effort, several modernizations of Orleans APIs were made to make it more aligned with how technologies like ASP.NET are configured and hosted today. Because it is compatible with .NET Standard 2.0, Orleans 2.0 can be used by applications targeting .NET Core or full .NET Framework. The emphasis of testing by the Core team for this release is on full .NET Framework to ensure that existing applications can easily migrate from 1.5 to 2.0, and with full backward compatibility. The most significant changes in 3.0 are as follows: Completely moved to programmatic configuration leveraging Dependency Injection with a fluid builder pattern API. The old API based on configuration objects and XML files is preserved for backward compatibility, but will not move forward and will get deprecated in the future. See more details in the Configuration section. Explicit programmatic specification of application assemblies that replaces automatic scanning of folders by the Orleans runtime upon silo or client initialization. Orleans will still automatically find relevant types, such as grain interfaces and classes, serializers, etc. in the specified assemblies, but it will no longer try to load every assembly it can find in the folder. An optional helper method for loading all assemblies in the folder is provided for backward compatibility: IApplicationPartManager.AddFromApplicationBaseDirectory() . See Configuration and Migration sections for more details. Overhaul of code generation. While mostly invisible for the developer, code generation became much more robust in handling serialization of various possible types. Special handling is required for F# assemblies. See the Code generation section for more details. Created a Microsoft.Orleans.Core.Abstractions NuGet package and moved/refactored several types into it. Grain code would most likely need to reference only these abstractions, whereas the silo host and client will reference more of the Orleans packages. We plan to update this package less frequently. Add support for Scoped services. This means that each grain activation gets its own scoped service provider, and Orleans registers a contextual IGrainActivationContext object that can be injected into a Transient or Scoped service to get access to activation specific information and grain activation lifecycle events. This is similar to how ASP.NET Core 2.0 creates a scoped context for each Request, but in the case of Orleans, it applies to the entire lifetime of a grain activation. See Service Lifetimes and Registration Options in the ASP.NET Core documentation for more information about service lifetimes. Migrated the logging infrastructure to use Microsoft.Extensions.Logging (same abstractions as ASP.NET Core 2.0). 2.0 includes a beta version of support for ACID distributed cross-grain transactions. The functionality will be ready for prototyping and development, and will graduate for production use sometime after the 2.0 release. See Transactions for more details."
  },
  "docs/migration/migration-1.5.html": {
    "href": "docs/migration/migration-1.5.html",
    "title": "Migration from Orleans 1.5 to 2.0 | Microsoft Orleans Documentation",
    "keywords": "Migration from Orleans 1.5 to 2.0 The bulk of the Orleans APIs stayed unchanged in 2.0 or implementation of those APIs were left in legacy classes for backward compatibility. At the same time, the newly introduced APIs provide some new capabilities or better ways of accomplishing those tasks. There are also more subtle differences when it comes to .NET SDK tooling and Visual Studio support that helps to be aware of. This document provides guidance for migrating application code from to Orleans 2.0. Visual Studio and Tooling requirements Orleans 2.0.0 is built on top of .NET Standard 2.0. Because of that, you need to upgrade development tools to ensure yourself a pleasant developing experience. We recommend to use Visual Studio 2017 or above to develop Orleans 2.0.0 applications. Based on our experience, version 15.5.2 and above works best. .NET Standard 2.0.0 is compatible with .NET 4.6.1 and above, .NET Core 2.0, and a list of other frameworks. Orleans 2.0.0 inherited that compatibility. For more information on .NET Standard compatibility with other framework, please refer to .NET Standard documentation : If you are developing a .NET Core or .NET application using Orleans, you will need to follow certain steps to set up your environment, such as installing .NET Core SDK. For more information, please refer to their documentation . Available options for configuration code Hosting Configuring and Starting a Silo (using the new SiloBuilder API and legacy ClusterConfiguration object) There's a number of new option classes in Orleans 2.0 that provide a new way for configuring a silo. To ease migration to the new API, there is a optional backward compatibility package, Microsoft.Orleans.Runtime.Legacy , that provides a bridge from the old 1.x configuration API to the new one. If you add Microsoft.Orleans.Runtime.Legacy package, a silo can still be configured programmatically via the legacy ClusterConfiguration object that can then be passed to SiloHostBuilder to build and start a silo. You still need to specify grain class assemblies via the ConfigureApplicationParts call. Here is an example of how a local silo can be configured in the legacy way: public class Program { public static async Task Main(string[] args) { try { var host = await StartSilo(); Console.WriteLine(\"Press Enter to terminate...\"); Console.ReadLine(); await host.StopAsync(); return 0; } catch (Exception ex) { Console.WriteLine(ex); return 1; } } private static async Task<ISiloHost> StartSilo() { // define the cluster configuration (temporarily required in the beta version, // will not be required by the final release) var config = ClusterConfiguration.LocalhostPrimarySilo(); // add providers to the legacy configuration object. config.AddMemoryStorageProvider(); var builder = new SiloHostBuilder() .UseConfiguration(config) // Add assemblies to scan for grains and serializers. // For more info read the Application Parts section .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(HelloGrain).Assembly) .WithReferences()) // Configure logging with any logging framework that supports Microsoft.Extensions.Logging. // In this particular case it logs using the Microsoft.Extensions.Logging.Console package. .ConfigureLogging(logging => logging.AddConsole()); var host = builder.Build(); await host.StartAsync(); return host; } } Configuring and Connecting a Client (using the new ClientBuilder API and legacy ClientConfiguration object) There's a number of new option classes in Orleans 2.0 that provide a new way for configuring a client. To ease migration to the new API, there is a optional backward compatibility package, Microsoft.Orleans.Core.Legacy , that provides a bridge from the old 1.x configuration API to the new one. If you added Microsoft.Orleans.Core.Legacy package, a client can still be configured programmatically via the legacy ClientConfiguration object that can then be passed to ClientBuilder to build and connect the client. You still need to specify grain interface assemblies via the ConfigureApplicationParts call. Here is an example of how a client can connect to a local silo, using legacy configuration: // define the client configuration (temporarily required in the beta version, // will not be required by the final release) var config = ClientConfiguration.LocalhostSilo(); var builder = new ClientBuilder() .UseConfiguration(config) // Add assemblies to scan for grains interfaces and serializers. // For more info read the Application Parts section .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IHello).Assembly)) .ConfigureLogging(logging => logging.AddConsole()) var client = builder.Build(); await client.Connect(); Logging Orleans 2.0 uses the same logging abstractions as ASP.NET Core 2.0. You can find replacement for most Orleans logging feature in ASP.NET Core logging. Orleans specific logging feature, such as ILogConsumer and message bulking, is still maintained in Microsoft.Orleans.Logging.Legacy package, so that you still have the option to use them. But how to configure your logging with Orleans changed in 2.0. Let me walk you through the process of migration. In 1.5, logging configuration is done through ClientConfiguration and NodeConfiguration . You can configure DefaultTraceLevel , TraceFileName , TraceFilePattern , TraceLevelOverrides , TraceToConsole , BulkMessageLimit , LogConsumers , etc through it. In 2.0, logging configuration is consistent with ASP.NET Core 2.0 logging, which means most of the configuration is done through Microsoft.Extensions.Logging.ILoggingBuilder . To configure DefaultTraceLevel and TraceLevelOverrides , you need to apply log filtering to ILoggingBuilder . For example, to set trace level to 'Debug' on orleans runtime, you can use sample below, siloBuilder.AddLogging(builder=>builder.AddFilter(\"Orleans\", LogLevel.Debug)); You can configure log level for you application code in the same way. If you want to set a default minimum trace level to be Debug, use sample below siloBuilder.AddLogging(builder=>builder.SetMinimumLevel(LogLevel.Debug); For more information on log filtering, please see their docs on https://docs.microsoft.com/en-us/aspnet/core/fundamentals/logging ; To configure TraceToConsole to be true , you need to reference Microsoft.Extensions.Logging.Console package and then use AddConsole() extension method on ILoggingBuilder . The same with TraceFileName and TraceFilePattern , if you want to log messages to a file, you need to use AddFile(\"file name\") method on ILoggingBuilder . If you still want to use Message Bulking feature, You need to configure it through ILoggingBuilder as well. Message bulking feature lives in Microsoft.Orleans.Logging.Legacy package. So you need to add dependency on that package first. And then configure it through ILoggingBuilder . Below is an example on how to configure it with ISiloHostBuilder siloBuiler.AddLogging(builder => builder.AddMessageBulkingLoggerProvider(new FileLoggerProvider(\"mylog.log\"))); This method would apply message bulking feature to the FileLoggerProvider , with default bulking config. Since we are going to eventually deprecate and remove LogConsumer feature support in the future, we highly encourage you to migrate off this feature as soon as possible. There's couple approaches you can take to migrate off. One option is to maintain your own ILoggerProvider , which creates ILogger who logs to all your existing log consumers. This is very similar to what we are doing in Microsoft.Orleans.Logging.Legacy package. You can take a look at LegacyOrleansLoggerProvider and borrow logic from it. Another option is replace your ILogConsumer with existing implementation of ILoggerProvider on nuget which provides identical or similar functionality, or implement your own ILoggerProvider which fits your specfic logging requirement. And configure those ILoggerProvider s with ILoggingBuilder . But if you cannot migrate off log consumer in the short term, you can still use it. The support for ILogConsumer lives in Microsoft.Orleans.Logging.Legacy package. So you need to add dependency on that package first, and then configure Log consumers through extension method AddLegacyOrleansLogging on ILoggingBuilder . There's native AddLogging method on IServiceCollection provided by ASP.NET for you to configure ILoggingBuilder . We also wrap that method under extension method on ISiloHostBuilder and IClientBuilder . So you can call AddLogging method on silo builder and client builder as well to configure ILoggingBuilder . below is an example: var severityOverrides = new OrleansLoggerSeverityOverrides(); severityOverrides.LoggerSeverityOverrides.Add(typeof(MyType).FullName, Severity.Warning); siloBuilder.AddLogging(builder => builder.AddLegacyOrleansLogging(new List<ILogConsumer>() { new LegacyFileLogConsumer($\"{this.GetType().Name}.log\") }, severityOverrides)); You can use this feature if you invested in custom implementation of ILogConsumer and cannot convert them to implementation of ILoggerProvider in the short term. Logger GetLogger(string loggerName) method on Grain base class and IProviderRuntime , and Logger Log { get; } method on IStorageProvider are still maintained as a deprecated feature in 2.0. You can still use it in your process of migrating off orleans legacy logging. But we recommend you to migrate off them as soon as possible. Provider Configuration In Orleans 2.0, configuration of the included providers has been standardized to obtain Service ID and Cluster ID from the ClusterOptions configured for the silo or client. Service ID is a stable identifier of the service or application that the cluster represents. Service ID does not change between deployments and upgrades of clusters that implement the service over time. Unlike Service ID, Cluster ID stays the same only through the lifecycle of a cluster of silos. If a running cluster gets shut down, and a new cluster for the same service gets deployed, the new cluster will have a new and unique Cluster ID, but will maintain the Service ID of the old cluster. Service ID is often used as part of a key for persisting data that needs to have continuity throughout the life of the service. Examples are grain state, reminders, and queues of persistent streams. On the other hand, data within a cluster membership table only makes sense within the scope of its cluster, and hence is normally keyed off Cluster ID. Prior to 2.0, behavior of Orleans providers was sometimes inconsistent with regards to using Service ID and Cluster ID (that was also previously called Deployment ID). Because of this unifications and the overall change of provider configuration API, data written to storage by some providers may change location or key. An example of a provider that is sensitive to this change is Azure Queue stream provider. If you are migrating an existing service from 1.x to 2.0, and need to maintain backward compatibility with regards to location or keys of data persisted by the providers you are using in the service, please verify that the data will be where your service or provider expects it to be. If your service happen to depend on the incorrect usage of Service ID and Cluster ID by a 1.x provider, you can override ClusterOptions for that specific provider by calling ISiloHostBuilder.AddProviderClusterOptions() or IClientBuilder.AddProviderClusterOptions() and force it to read/write data from/to the 1.x location in storage"
  },
  "docs/migration/migration-azure-2.0.html": {
    "href": "docs/migration/migration-azure-2.0.html",
    "title": "Migration from Orleans 1.5 to 2.0 when using Azure | Microsoft Orleans Documentation",
    "keywords": "Migration from Orleans 1.5 to 2.0 when using Azure In Orleans 2.0, the configuration of silos and clients has changed. In Orleans 1.5 we used to have a monolith object that handled all the configuration pieces Providers were added to that configuration object, too. In Orleans 2.0, the configuration process is organizes around SiloHostBuilder , similar to how it is done in ASP.NET Core with the WebHostBuilder . In Orleans 1.5, the configuration for Azure looked like this: var config = AzureSilo.DefaultConfiguration(); config.AddMemoryStorageProvider(); config.AddAzureTableStorageProvider(\"AzureStore\", RoleEnvironment.GetConfigurationSettingValue(\"DataConnectionString\")); The AzureSilo class exposes a static method named DefaultConfiguration() that was used for loading configuration XML file. This way of configuring a silo is deprecated but still supported via the legacy support package . In Orleans 2.0, configuration is completely programmatic. The new configuration API looks like this: //Load the different settings from the services configuration var proxyPort = RoleEnvironment.CurrentRoleInstance.InstanceEndpoints[\"OrleansProxyEndpoint\"].IPEndpoint.Port; var siloEndpoint = RoleEnvironment.CurrentRoleInstance.InstanceEndpoints[\"OrleansSiloEndpoint\"].IPEndpoint; var connectionString = RoleEnvironment.GetConfigurationSettingValue(\"DataConnectionString\"); var deploymentId = RoleEnvironment.DeploymentId; var builder = new SiloHostBuilder() //Set service ID and cluster ID .Configure<ClusterOptions>(options => { options.ClusterId = deploymentId; options.ServiceIs = \"my-app\"; }) // Set silo name .Configure<SiloOptions>(options => options.SiloName = this.Name) //Then, we can configure the different endpoints .ConfigureEndpoints(siloEndpoint.Address, siloEndpoint.Port, proxyPort) //Then, we set the connection string for the storage .UseAzureStorageClustering(options => options.ConnectionString = connectionString) //If reminders are needed, add the service, the connection string is required .UseAzureTableReminderService(connectionString) //If Queues are needed, add the service, set the name and the Adapter, the one shown here //is the one provided with Orleans, but it can be a custom one .AddAzureQueueStreams<AzureQueueDataAdapterV2>(\"StreamProvider\", configurator => configurator.Configure(configure => { configure.ConnectionString = connectionString; })) //If Grain Storage is needed, add the service and set the name .AddAzureTableGrainStorage(\"AzureTableStore\"); AzureSilo to ISiloHost In Orleans 1.5, the AzureSilo class was the recommended way to host a silo in an Azure Worker Role. This is still supported via the Microsoft.Orleans.Hosting.AzureCloudServices NuGet package . public class WorkerRole : RoleEntryPoint { AzureSilo silo; public override bool OnStart() { // Do other silo initialization – for example: Azure diagnostics, etc return base.OnStart(); } public override void OnStop() { silo.Stop(); base.OnStop(); } public override void Run() { var config = AzureSilo.DefaultConfiguration(); config.AddMemoryStorageProvider(); config.AddAzureTableStorageProvider(\"AzureStore\", RoleEnvironment.GetConfigurationSettingValue(\"DataConnectionString\")); // Configure storage providers silo = new AzureSilo(); bool ok = silo.Start(config); silo.Run(); // Call will block until silo is shutdown } } Orleans 2.0 provides a more flexible and modular API for configuring and hosting a silo via SiloHostBuilder and ISiloHost . public class WorkerRole : RoleEntryPoint { private ISiloHost host; private ISiloHostBuilder builder; private readonly CancellationTokenSource cancellationTokenSource = new CancellationTokenSource(); private readonly ManualResetEvent runCompleteEvent = new ManualResetEvent(false); public override void Run() { try { this.RunAsync(this.cancellationTokenSource.Token).Wait(); runCompleteEvent.WaitOne(); } finally { this.runCompleteEvent.Set(); } } public override bool OnStart() { //builder is the SiloHostBuilder from the first section // Build silo host, so that any errors will restart the role instance this.host = this.builder.Build(); return base.OnStart(); } public override void OnStop() { this.cancellationTokenSource.Cancel(); this.runCompleteEvent.WaitOne(); this.host.StopAsync().Wait(); base.OnStop(); } private Task RunAsync(CancellationToken cancellationToken) { return this.host.StartAsync(cancellationToken); } }"
  },
  "docs/resources/best_practices.html": {
    "href": "docs/resources/best_practices.html",
    "title": "Best Practices | Microsoft Orleans Documentation",
    "keywords": "Best Practices Orleans was built with the goal to greatly simplify building of distributed scalable applications, especially for the cloud. Orleans invented the Virtual Actor Model as an evolution of the Actor Model optimized for the cloud scenarios. Grains (virtual actors) are the base building blocks of an Orleans-based application. They encapsulate state and behavior of application entities and maintain their lifecycle. The programming model of Orleans and the characteristics of its runtime fit some types of applications better than others. This document is intended to capture some of the tried and proven application patterns that work well in Orleans. Orleans should be considered when: Significant number (hundreds, millions, billions, and even trillions) of loosely coupled entities. To put the number in perspective, Orleans can easily create a grain for every person on Earth in a small cluster, so long as a subset of that total number is active at any point in time. Examples: user profiles, purchase orders, application/game sessions, stocks Entities are small enough to be single-threaded Example: Determine if stock should be purchased based on current price Workload is interactive Example: request-response, start/monitor/complete More than one server is expected or may be required Orleans runs on a cluster which is expanded by adding servers to expand the cluster Global coordination is not needed or on a smaller scale between a few entities at a time Scalability and performance of execution is achieved by parallelizing and distributed a large number of mostly independent tasks with no single point of synchronization. Orleans is not the best fit when: Memory must be shared between entities Each grain maintains its own states and should not be shared. A small number of large entities that may be multithreaded A microservice may be a better option when supporting complex logic in a single service Global coordination and/or consistency is needed Such global coordination would severely limit performance of an Orleans-based application. Orleans was built to easily scale to a global scale without the need of in-depth manual coordination. Operations that run for a long time Batch jobs, Single Instruction Multiple Data (SIMD) tasks This depends on the need of the application and may be a fit for Orleans Grains Overview : Grains resemble objects. However, they are distributed, virtual, and asynchronous. They are loosely coupled, isolated, and primarily independent Each grain is encapsulated which also maintains its own state independently of other grains Grains fail independently Avoid chatty communication between grains Direct memory use is significantly less expensive than message passing Highly chatty grains may be better combined as a single grain Complexity/Size of arguments and serialization need to be considered Deserializing twice may be more expensive than resending a binary message Avoid bottleneck grains Single coordinator/Registry/Monitor Do staged aggregation if required Asynchronicity : No thread blocking: All items must be Async (Task Asynchronous Programming (TAP)) await is the best syntax to use when composing async operations Common Scenarios: Return a concrete value: return Task.FromResult(value); Return a Task of the same type: return foo.Bar(); Await a Task and continue execution: var x = await bar.Foo(); var y = DoSomething(x); return y; Fan-out: var tasks = new List<Task>(); foreach(var grain in grains) { tasks.Add(grain.Foo()) } await Task.WhenAll(tasks); DoMoreWork(); Implementation of Grains : Never perform a thread-blocking operation within a grain. All operations other than local computations must be explicitly asynchronous. Examples: Synchronously waiting for an IO operation or a web service call, locking, running an excessive loop that is waiting for a condition, etc. When to use a [StatelessWorker] Functional operations such as: decryption, decompression, and before forwarding for processing When only local grains are required in multiple activations Example: Performs well with staged aggregation within local silo first Grains are non-reentrant by default Deadlock can occur due to call cycles Examples: The grain calls itself Grains A calls B while C is also calling A (A->B->C->A) Grain A calls Grain B as Grain B is calling Grain A (A->B->A) Timeouts are used to automatically break deadlocks Attribute [Reentrant] can be used to allow the grain class reentrant Reentrant is still single-threaded however, it may interleave (divide processing/memory between tasks) Handling interleaving increases risk by being error prone Inheritance Grain classes inherit from the Grain base class. Grain intrerfaces (one or more) can be added to each grain. Disambiguation may be needed to implement the same interface in multiple grain classes Generics are supported Grain State Persistence Orleans’ grain state persistence APIs are designed to be easy-to-use and provide extensible storage functionality. Tutorial: Needs to be created Overview : Orleans.IGrainState is extended by a .NET interface which contains fields that should be included in the grain’s persisted state. Grains are persisted by using IPersistentState<TState> is extended by the grain class that adds a strongly typed State property into the grain’s base class. The initial State.ReadStateAsync() automatically occurs prior to ActiveAsync() has been called for a grain. When the grain’s state object’s data is changed, then the grain should call State.WriteStateAsync() Typically, grains call State.WriteStateAsync() at the end of grain method to return the Write promise. The Storage provider could try to batch Writes that may increase efficiency, but behavioral contract and configurations are orthogonal (independent) to the storage API used by the grain. A timer is an alternative method to write updates periodically. The timer allows the application to determine the amount of “eventual consistency”/statelessness allowed. Timing (immediate/none/minutes) can also be controlled as to when to update. PersistetState classes, like other grain classes, can only be associated with one storage provider. [StorageProvider(ProviderName=”name”)] attribute associates the grain class with a particular provider <StorageProvider> will need to be added to the Silo config file which should also include the corresponding “name” from [StorageProvider(ProviderName=”name”)] A composite storage provider can be used with SharedStorageProvider Storage Providers Built-in Storage Providers Orleans.Storage houses all of the built-in storage providers. The namespace is: OrleansProviders.dll MemoryStorage (Data stored in memory without durable persistence) is used only for debugging and unit testing. AzureTableStorage Configure the Azure storage account information with an optional DeleteStateOnClear (hard or soft deletions) Orleans serializer efficiently stores JSON data in one Azure table cell Data size limit == max size of the Azure column which is 64kb of binary data Community contributed code that extends the use of multiple table columns which increases the overall maximum size to 1mb. Storage Provider Debugging Tips TraceOverride Verbose3 will log much more information about storage operations. Update silo config file LogPrefix=”Storage” for all providers, or specific type using “Storage.Memory” / ”Storage.Azure” / “Storage.Shard” How to deal with Storage Operation Failures Grains and storage providers can await storage operations and retry failures as needed Unhandled failures will propagate back to the caller and will be seen by the client as a broken promise Other than the initial read, there is not a concept that automatically destroys activations if a storage operation fails Retrying a failing storage is not a default feature for built-in storage providers Grain Persistence Tips Grain Size Optimal throughput is achieved by using multiple smaller grains rather than a few larger grains. However, the best practice of choosing a grain size and type is base on the application domain model . Example: Users, Orders, etc. External Changing Data Grain are able to re-read the current state data from storage by using State.ReadStateAsyc() A timer can also be used to re-read data from storage periodically as well The functional requirements could be based on a suitable “staleness” of the information Example: Content Cache Grain Adding and Removing Fields The storage provider will determine the effects of adding and removing additional fields from its persisted state. Azure table does not support schemas and should automatically adjust to the additional fields. Writing Custom Providers Storage providers are simple to write which is also a significant extension element for Orleans Tutorial: need tutorial The API GrainState API contract drives the storage API contract (Write, Clear, ReadStateAsync()) The storage behavior is typically configurable (Batch writing, Hard or Soft Deletions, etc.) and defined by the storage provider Cluster Management Orleans automatically manages clusters Failed nodes --that is that can fail and join at any moment-- are automatically handled by Orleans The same silo instance table that is created for the clustering protocol can also be used for diagnostics. The table keeps a history of all of the silos in the cluster. There are also configuration options of an aggressive or a more lenient failure detection Failures can happen at any time and are a normal occurrence In the event a silo fails, the grains that were activated on the failed silo will automatically be reactived later on other silos within the cluster. Grains have an ability to timeout. A retry solution such as Polly can assist with retries. Orleans provides a message delivery guaruntee where each message is delivered at-most-once. It is a responsibility of the caller to retry any failed calls if needed. Common practice is to retry from end-to-end from the client/front end Deployment and Production Management Scaling out and in Monitor the Service-Level Agreement (SLA) Add or Remove instances Orleans automatically rebalances and takes advantage of the new hardware. However, activated grains are not rebalanced when a new silo is added to the cluster. Logging and Testing Logging, Tracing, and Monitoring Inject logging Dependency injection public HelloGrain(ILogger<HelloGrain> logger) {this.logger = logger;} Microsoft.Extensions.Logging is utilized for functional and flexible logging Testing Microsoft.Orleans.TestingHost NuGet package contains TestCluster which can be used to create an in-memory cluster, comprised of two silos by default, which can be used to test grains. Additional information can be found here Troubleshooting Use Azure table-based membership for development and testing Works with Azure Storage Emulator for local troubleshooting OrleansSiloInstances table displays the state of the cluster Use unique deployment Ids (partition keys) in order to keep it simple Silo isn’t starting Check OrleansSiloInstances to determine if the silo registered there. Make sure that firewall is open for TCP ports: 11111 and 30000 Check the logs, including the extra log that contains startup errors Frontend (Client) cannot connect to the silo cluster The client must be hosted in the same service as the silos Check OrleansSiloInstances to make sure the silos (gateways) are registered Check the client log to make sure that the gateways match the ones listed in the OrleansSiloInstances’ table Check the client log to validate that the client was able to connect to one or more of the gateways"
  },
  "docs/resources/contributing.html": {
    "href": "docs/resources/contributing.html",
    "title": "Contributing to Orleans | Microsoft Orleans Documentation",
    "keywords": "Contributing to Orleans Some notes and guidelines for developers who want to contribute to Orleans. Contributing To This Project Here are some pointers for anyone looking for mini-features and work items that would make a positive contribution to Orleans. These are just a few ideas, so if you think of something else that would be useful, then spin up a discussion thread on GitHub to discuss the proposal, and go for it! Orleans GitHub Repository Pull requests are always welcome! Intern and Student Projects Some suggestions for possible intern / student projects. Documentation Guidelines A style guide for writing documentation for this site. Code Contributions This project uses the same contribution process as the other DotNet projects on GitHub. DotNet Project Contribution Guidelines Guidelines and workflow for contributing to DotNet projects on GitHub. DotNet CLA Contribution License Agreement for DotNet projects on GitHub. .NET Framework Design Guidelines Some basic API design rules, coding standards, and style guide for .NET Framework APIs. Coding Standards and Conventions We try not to be too OCD about coding style wars, but in case of disputes we do fall back to the core principles in the two \".NET Coding Standards\" books used by the other DotNet OSS projects on GitHub: C# Coding Style Guide .NET Framework Design Guidelines There are lots of other useful documents on the .NET CoreCLR and .NET Core Framework documentation sites which are worth reading, although most experienced C# developers will probably have picked up many of those best-practices by osmosis, particularly around performance and memory management. Source Code Organization Orleans has not religiously followed a \"One Class Per File\" rule, but instead we have tried to use pragmatic judgment to maximize the change of \"code understand-ability\" for developers on the team. If lots of small-ish classes share a \"common theme\" and/or are always dealt with together, then it is OK to place those into one source code file in most cases. See for example the various \"log consumer\" classes were originally placed in single source file, as they represented a single unit of code comprehension. As a corollary, it is much easier to find the source code for a class if it is in a file with the same name as the class [similar to Java file naming rules], so there is a tension and value judgment here between code find-ability and minimizing / constraining the number of projects in a solution and files within a project [which both have direct impact on the Visual Studio \"Opening\" and \"Building\" times for large projects]. Code search tools in VS and ReSharper definitely help here. Dependencies and Inter-Project References One topic that we are very strict about is around dependency references between components and sub-systems. Component / Project References References between projects in a solution must always use \" Project References \" rather than \" DLL References \" to ensure that component build relationships are known to the build tools. Right : <ProjectReference Include=\"..\\Orleans\\Orleans.csproj\"> <Project>{BC1BD60C-E7D8-4452-A21C-290AEC8E2E74}</Project> <Name>Orleans</Name> </ProjectReference> Wrong : <Reference Include=\"Orleans\" > <HintPath>..\\Orleans\\bin\\Debug\\Orleans.dll</HintPath> </Reference> In order to help ensure we keep inter-project references clean, then on the build servers [and local Build.cmd script] we deliberately use side-by-side input .\\src and output .\\Binaries directories rather than the more normal in-place build directory structure (eg. [PROJ]\\bin\\Release ) used by VS on local dev machines. Unified Component Versions We use the same unified versions of external component throughout the Orleans code base, and so should never need to add bindingRedirect entries in App.config files. Also, in general it should almost never be necessary to have Private=True elements in Orleans project files, except to override a conflict with a Windows / VS \"system\" component. Some package management tools can occasionally get confused when making version changes, and sometimes think that we are using multiple versions of the same assembly within a solution, which of course we never do. We long for the day when package management tools for .NET can make version changes transactionally! Until then, it is occasionally necessary to \"fix\" the misguided actions of some .NET package management tools by hand-editing the .csproj files (they are just XML text files) back to sanity and/or using the \"Discard Edited Line\" functions that most good Git tools such as Atlassian SourceTree provide. Using \"sort\" references and unified component versions avoids creating brittle links between Orleans run-time and/or external components, and has proved highly effective in the last several years at reducing stress levels for the Orleans Team during important deployment milestones. :)"
  },
  "docs/resources/documentation_guidelines.html": {
    "href": "docs/resources/documentation_guidelines.html",
    "title": "Documentation Guidelines | Microsoft Orleans Documentation",
    "keywords": "Documentation Guidelines The Orleans documentation is built in Markdown . We use a few simple conventions to ensure a homogeneous style throughout the full set of documents. These standards are being introduced. If you have issues with these guidelines then raise an issue or a Pull Request. If you find documentation that fails to meet the guidelines, then make a fix and submit a pull request. Also if you are using windows 10 you can go to the store and find free MarkDown editors like this Structure Language The documentation will follow US-English spelling. Desktop tools like http://markdownpad.com and Visual Studio Code have spell checking features. Paragraph structure Each sentence should be written on a single line, and only one sentence per line. This makes merging changes easier and helps identify verbose language. Paragraphs in Markdown are just one or more lines of consecutive text followed by one or more blank lines. Headings Headings should be used to structure a document. Avoid using other emphasis features like ALLCAPS, Italics or bold to identify a new topic. Using a header is not only more consistent, but also allows linking to the header. Footers At the end of a page, it is helpful to link to the next logical page in the documentation. If the page is the last in a sub-section, then linking back to the index page is useful. Styles Code formatting Blocks of example code should be formatted with the triple back tick format followed by the language. [StorageProvider(ProviderName=\"store1\")] public class MyGrain<IMyGrainState> { ... } Which will render as [StorageProvider(ProviderName=\"store1\")] public class MyGrain<IMyGrainState> ... { ... } Inline code should be marked with a single backtick (`). This include references to: type names e.g. Task<T> variable names e.g. game namespaces e.g. Orleans.Storage.AzureTableStorage If showing text that is an output (e.g. text file content or console output) you can either use the triple back tick without specifying a language or you can indent the content. For example: 1 said: Welcome to my team! 0 said: Thanks! 1 said: Thanks! 0 said: Thanks! File names and paths When referencing a filename, directory/folder or URI then use standard italics to format. This can be done by surrounding the string with either with a single asterisk ( * ) or a single underscore ( _ ) Examples: OrleansRuntimeInterfaces.dll C:\\Binaries ../src/Grain.cs Tables Markdown supports tabular data . Tables could be used to structure data so that is is easily consumable for the reader. Suffix Unit ms millisecond(s) s second(s) m minute(s) Links When referencing another concept, provide a link to that concept. Forward and backward references within a page can be linked via the header. e.g. link back to Structure Links to other documents can either link to the page or to a sub-section/header within the page. External links should be exposed as the full link. e.g. https://github.com/dotnet/roslyn Contribution The Orleans documentation is managed as Markdown files in a Git repository hosted on GitHub in the gh-pages branch . See the GitHub Pages documentation on how to use the gh-pages branch convention for \"Project site\" documents."
  },
  "docs/resources/frequently_asked_questions.html": {
    "href": "docs/resources/frequently_asked_questions.html",
    "title": "Frequently Asked Questions | Microsoft Orleans Documentation",
    "keywords": "Frequently Asked Questions Availability Can I freely use Orleans in my project? Absolutely. The source code has been released under the MIT license . NuGet packages are published on nuget.org . Is Orleans production ready? I heard it's a research project. Orleans, indeed, initially started as a research project within Microsoft Research. It later grew into a product and has been used in production within Microsoft since 2011, and by other companies after it was publicly released in 2015. Orleans is definitely production ready, and powers many highly available systems and cloud services. Does Microsoft support Orleans? Source code of Orleans has been released under an MIT license on GitHub . Microsoft continues to invest in Orleans and accepts community contributions to the codebase. Positioning Is Orleans a server product? How do I run Orleans? Orleans is a framework, a set of libraries, that helps you build an application. Orleans-based applications can be run in various hosting environments, in the Cloud or on on-premises clusters or even on a single machine. It is the responsibility of application developer to build, deploy, and run an Orleans-based application in their target hosting environment. Where can I run Orleans? Orleans can run in any environment where .NET application can run. Prior to Orleans 2.0, it required full .NET Framework. Starting with 2.0, Orleans conforms to .NET Standard 2.0, and hence can run on .NET Core in Windows and non-Windows environments that support .NET Core. Is Orleans built for Azure? No. We believe that you should be able to run Orleans anywhere you need, the way you need. Orleans is very flexible, and has a number of optional providers that help host it in cloud environment, such as Azure, AWS or GCP, or on on-premises clusters, with a choice of technologies to support Orleans' clustering protocol. What is the difference between Orleans and other actor languages and frameworks, such as Erlang or Akka? While based on the same base principles of the Actor Model, Orleans took a step forward, and introduced a notion of Virtual Actors that greatly simplifies developer's experience and is much more suitable for cloud services and high-scale systems. Design How big or how small should a grain be in my application? The grain isolation model makes them very good at representing independent isolated contexts of state and computation. In most cases, grains naturally map to such application entities as users, sessions, accounts. Those entities are generally isolated from each other, can be accessed and updated independently, and expose a well defined set of supported operations. This works well with the intuitive \"one entity - one grain\" modeling. An application entity may be too big to be efficiently represented by a single grain if it encapsulates too much state, and as a result has to handle a high rate of requests to it. Even though a single grain can generally handle up to a few thousand trivial calls per second, the rule of thumb is to be wary of individual grain receiving hundreds of requests per second. That may be a sign of the grain being too large, and decomposing it into a set of smaller grains may lead to a more stable and balanced system. An application entity may be too small to be a grain if that would cause constant interaction of other grains with it, and as a result, cause too much of a messaging overhead. In such cases, it may make more sense to make those closely interacting entities part of a single grain, so that they would invoke each other directly. How should you avoid grain hot spots? The throughput of a grain is limited by a single thread that its activation can execute on. Therefore, it is advisable to avoid designs where a single grain receives a disproportionate share of requests or is involved in processing requests to other grains. There are various patterns that help prevent overloading of a single grain even when logically it is a central point of communication. For example, if a grain is an aggregator of some counters or statistics that are reported by a large number of grains on a regular basis, one proven approach is to add a controlled number of intermediate aggregator grains and assign each of the reporting grains (using a modulo on a key or a hash) to an intermediate aggregator, so that the load is more or less evenly distributed across all intermediate aggregator grains that in their turn periodically report partial aggregates to the central aggregator grain. How To How do I tear down a grain? In general there is no need for application logic to force deactivation of a grain, as the Orleans runtime automatically detects and deactivates idle activations of a grain to reclaim system resources. Letting Orleans do that is more efficient because it batches deactivation operations instead of executing them one by one. In the rare cases when you think you do need to expedite deactivation of a grain, the grain can do that by calling the base.DeactivateOnIdle() method. Can I tell Orleans where to activate a grain? It is possible to do so using restrictive placement strategies, but we generally consider this a rather advanced pattern that requires careful consideration. By doing what the question suggests, the application would take on the burden of resource management without necessarily having enough information about the global state of the system to do so well. This is especially counter-productive in cases of silo restarts, which in cloud environments may happen on a regular basis for OS patching. Thus, specific placement may have a negative impact on your application's scalability as well as resilience to system failure. That being said, for the rare cases where the application indeed knows where a particular grain should be activated, for example, if it has a knowledge of the locality of grain's persistent state, in 1.5.0 we introduced custom placement policies and directors. How do you version grains or add new grain classes and interfaces? You can add silos with new grain classes or new versions of existing grain classes to a running cluster. Can I Connect to Orleans silos from the public Internet? Orleans is designed to be hosted as the back-end part of a service, and you are expected to create a front-end tier to which external clients will connect. It can be an HTTP based Web API project, a socket server, a SignalR server or anything else fits the needs of the application. You can connect to Orleans from the Internet if you expose TCP endpoints of silos to it, but it is not a good practice from the security point of view. What happens if a silo fails before my grain call returns a response for my call? In case of a silo failure in the middle of a grain call, you'll receive an exception that you can catch in your code and retry or do something else to handle the error according to your application logic. The grain that failed with the silo will get automatically re-instantiated upon a next call to it. The Orleans runtime does not eagerly recreate grains from a failed silo because many of them may not be needed immediately or at all. Instead, the runtime recreates such grains individually and only when a new request arrives for a particular grain. For each grain it picks one of the available silos as a new host. The benefit of this approach is that the recovery process is performed only for grains that are actually being used and it is spread in time and across all available silos, which improves the responsiveness of the system and the speed of recovery. Note also that there is a delay between the time when a silo fails and when the Orleans cluster detects the failure. The delay is a configurable tradeoff between the speed of detection and the probability of false positives. During this transition period all calls to the grain will fail, but after the detection of the failure the grain will be created, upon a new call to it, on another silo, so it will be eventually available. What happens if a grain call takes too long to execute? Since Orleans uses a cooperative multi-tasking model, it will not preempt the execution of a grain automatically but Orleans generates warnings for long executing grain calls so you can detect them. Cooperative multi-tasking has a much better throughput compared to preemptive multi-tasking. Keep in mind that grain calls should not execute any long running tasks like IO operations synchronously and should not block on other tasks to complete. All waiting should be done asynchronously using the await keyword or other asynchronous waiting mechanisms. Grains should return as soon as possible to let other grains execute for maximum throughput."
  },
  "docs/resources/index.html": {
    "href": "docs/resources/index.html",
    "title": "Resources | Microsoft Orleans Documentation",
    "keywords": "Resources Contributing Some notes and guidelines for developers who want to contribute to Orleans. Documentation Guidelines The Orleans documentation is built in Markdown. We use a few simple conventions to ensure a homogeneous style throughout the full set of documents. Links Links to articles by members of the Orleans team and others. Presentations A collection of PowerPoint presentations about topics including Orleans Best Practices, Balancing Techniques, and Streaming."
  },
  "docs/resources/links.html": {
    "href": "docs/resources/links.html",
    "title": "Links | Microsoft Orleans Documentation",
    "keywords": "Links By Orleans team Orleans Architecture: Principles and Approach I Episode 142: Microsoft Research project Orleans simplify development of scalable cloud services Orleans: Thinking Big and Small Available Now: Preview of Project “Orleans” – Cloud Services at Scale Orleans: Distributed Virtual Actors for Programmability and Scalability By others Introducing Orleans Microsoft Orleans v2.0 - A comprehensive guide for beginners and experts alike (PowerPoint) A First Look at Project Orleans A Second Look at Project Orleans Project Orleans: An Introduction Introduction To Project Orleans Introduction to Orleans Project Orleans: Different Than Erlang, Designed for a Broad Group of Developers Two Reasons You May Want to Use Microsoft’s Project Orleans Hatay Tuna & Christian Martinez - Applied Actor Model with Orleans Actor Programming with Orleans: What’s Different? Orleans – a “cloud native” runtime built for #azure Project Orleans - Actor Model framework A look at Microsoft Orleans through Erlang-tinted glasses Using Codename “Orleans” in Enterprise Applications Beyond the introduction Grains, Grains and more Grains Fine-graining your Orleans Grains inside the IoT universe Monitorable Grains Aggregating Results in Orleans Creating RESTful Services using Orleans Tackle Distribution, High Throughput and Low-Latency with Orleans – A “cloud native” Runtime Built for #Azure Saving state only once in a while in #ProjectOrleans Using Orleans for building scalable cloud applications Orleans in an IoT universe Orleans Preview & Halo 4 Using Project “Orleans” in Halo Orleans & Thinking Outside the Box John Azariah & Mahesh Krishnan - Immutability, State and Scale - Functional, Distributed Applications in Azure last edited: 5 June 2018"
  },
  "docs/resources/nuget_packages.html": {
    "href": "docs/resources/nuget_packages.html",
    "title": "Orleans NuGet Packages | Microsoft Orleans Documentation",
    "keywords": "Orleans NuGet packages Key Packages There are 5 key NuGet packages you will need to use in most scenarios: Microsoft Orleans Core Abstractions PM> Install-Package Microsoft.Orleans.Core.Abstractions Contains Orleans.Core.Abstractions.dll, which defines Orleans public types that are needed for developing application code (grain interfaces and classes). This package is needs to be directly or indirectly referenced by any Orleans project. Add it to your projects that define grain interfaces and classes. Microsoft Orleans Build-time Code Generation Microsoft.Orleans.OrleansCodeGenerator.Build . PM> Install-Package Microsoft.Orleans.OrleansCodeGenerator.Build Appeared in Orleans 1.2.0. Build time support for grain interfaces and implementation projects. Add it to your grain interfaces and implementation projects to enable code generation of grain references and serializers. Microsoft.Orleans.CodeGenerator.MSBuild . PM> Install-Package Microsoft.Orleans.CodeGenerator.MSBuild Appeared as part of Orleans 2.1.0 . An alternative to the Microsoft.Orleans.OrleansCodeGenerator.Build package. Leverages Roslyn for code analysis to avoid loading application binaries and improves support for incremental builds, which should result in shorter build times. Microsoft Orleans Server Libraries PM> Install-Package Microsoft.Orleans.Server A meta-package for easily building and starting a silo. Includes the following packages: Microsoft.Orleans.Core.Abstractions Microsoft.Orleans.Core Microsoft.Orleans.OrleansRuntime Microsoft.Orleans.OrleansProviders Microsoft Orleans Client Libraries PM> Install-Package Microsoft.Orleans.Client A meta-package for easily building and starting an Orleans client (frontend). Includes the following packages: Microsoft.Orleans.Core.Abstractions Microsoft.Orleans.Core Microsoft.Orleans.OrleansProviders Microsoft Orleans Core Library PM> Install-Package Microsoft.Orleans.Core Contains implementation for most Orleans public types used by application code and Orleans clients (frontends). Reference it for building libraries and client applications that use Orleans types but don't deal with hosting or silos. Included in Microsoft.Orleans.Client and Microsoft.Orleans.Server meta-packages, and is referenced, directly or indirectly, by most other packages. Hosting Microsoft Orleans Runtime PM> Install-Package Microsoft.Orleans.OrleansRuntime Library for configuring and starting a silo. Reference it in your silo host project. Included in Microsoft.Orleans.Server meta-package. Microsoft Orleans Runtime Abstractions PM> Install-Package Microsoft.Orleans.Runtime.Abstractions Contains interfaces and abstractions for types implemented in Microsoft.Orleans.OrleansRuntime. Microsoft Orleans Hosting on Azure Cloud Services PM> Install-Package Microsoft.Orleans.Hosting.AzureCloudServices Contains helper classes for hosting silos and Orleans clients as Azure Cloud Services (Worker Roles and Web Roles). Microsoft Orleans Service Fabric Hosting Support PM> Install-Package Microsoft.Orleans.Hosting.ServiceFabric Contains helper classes for hosting silos as a stateless Service Fabric service. Clustering Providers The below packages include plugins for persisting cluster membership data in various storage technologies. Microsoft Orleans clustering provider for Azure Table Storages PM> Install-Package Microsoft.Orleans.Clustering.AzureStorage Includes the plugin for using Azure Tables for storing cluster membership data. Microsoft Orleans clustering provider for ADO.NET Providers PM> Install-Package Microsoft.Orleans.Clustering.AdoNet Includes the plugin for using ADO.NET for storing cluster membership data in one of the supported databases. Microsoft Orleans Consul Utilities PM> Install-Package Microsoft.Orleans.OrleansConsulUtils Includes the plugin for using Consul for storing cluster membership data. Microsoft Orleans ZooKeeper Utilities PM> Install-Package Microsoft.Orleans.OrleansZooKeeperUtils Includes the plugin for using ZooKeeper for storing cluster membership data. Microsoft Orleans clustering provider for AWS DynamoDB PM> Install-Package Microsoft.Orleans.Clustering.DynamoDB Includes the plugin for using AWS DynamoDB for storing cluster membership data. Reminder Providers The below packages include plugins for persisting reminders in various storage technologies. Microsoft Orleans Reminders Azure Table Storage PM> Install-Package Microsoft.Orleans.Reminders.AzureStorage Includes the plugin for using Azure Tables for storing reminders. Microsoft Orleans Reminders ADO.NET Providers PM> Install-Package Microsoft.Orleans.Reminders.AdoNet Includes the plugin for using ADO.NET for storing reminders in one of the supported databases. Microsoft Orleans reminders provider for AWS DynamoDB PM> Install-Package Microsoft.Orleans.Reminders.DynamoDB Includes the plugin for using AWS DynamoDB for storing reminders. Grain Storage Providers The below packages include plugins for persisting grain state in various storage technologies. Microsoft Orleans Persistence Azure Storage PM> Install-Package Microsoft.Orleans.Persistence.AzureStorage Includes the plugins for using Azure Tables or Azure Blobs for storing grain state. Microsoft Orleans Persistence ADO.NET Providers PM> Install-Package Microsoft.Orleans.Persistence.AdoNet Includes the plugin for using ADO.NET for storing grain state in one of the supported databases. Microsoft Orleans Persistence DynamoDB PM> Install-Package Microsoft.Orleans.Persistence.DynamoDB Includes the plugin for using AWS DynamoDB for storing grain state. Stream Providers The below packages include plugins for delivering streaming events. Microsoft Orleans ServiceBus Utilities PM> Install-Package Microsoft.Orleans.OrleansServiceBus Includes the stream provider for Azure Event Hubs. Microsoft Orleans Streaming Azure Storage PM> Install-Package Microsoft.Orleans.Streaming.AzureStorage Includes the stream provider for Azure Queues. Microsoft Orleans Streaming AWS SQS PM> Install-Package Microsoft.Orleans.Streaming.SQS Includes the stream provider for AWS SQS service. Microsoft Orleans Google Cloud Platform Utilities PM> Install-Package Microsoft.Orleans.OrleansGCPUtils Includes the stream provider for GCP PubSub service. Additional Packages Microsoft Orleans Code Generation PM> Install-Package Microsoft.Orleans.OrleansCodeGenerator Includes the run time code generator. Microsoft Orleans Event-Sourcing PM> Install-Package Microsoft.Orleans.EventSourcing Contains a set of base types for creating grain classes with event-sourced state. Development and Testing Microsoft Orleans Providers PM> Install-Package Microsoft.Orleans.OrleansProviders Contains a set of persistence and stream providers that keep data in memory. Intended for testing. In general, not recommended for production use, unless data loss is care of a silo failure is acceptable. Microsoft Orleans Testing Host Library PM> Install-Package Microsoft.Orleans.TestingHost Includes the library for hosting silos and clients in a testing project. Serializers Microsoft Orleans Bond Serializer PM> Install-Package Microsoft.Orleans.Serialization.Bond Includes support for Bond serializer . Microsoft Orleans Google Utilities PM> Install-Package Microsoft.Orleans.OrleansGoogleUtils Includes Google Protocol Buffers serializer. Microsoft Orleans protobuf-net Serializer PM> Install-Package Microsoft.Orleans.ProtobufNet Includes protobuf-net version of Protocol Buffers serializer. Telemetry Microsoft Orleans Telemetry Consumer - Performance Counters PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.Counters Windows Performance Counters implementation of Orleans Telemetry API. Microsoft Orleans Telemetry Consumer - Azure Application Insights PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.AI Includes the telemetry consumer for Azure Application Insights. Microsoft Orleans Telemetry Consumer - NewRelic PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.NewRelic Includes the telemetry consumer for NewRelic. Tools Microsoft Orleans Performance Counter Tool PM> Install-Package Microsoft.Orleans.CounterControl Includes OrleansCounterControl.exe, which registers Windows performance counter categories for Orleans statistics and for deployed grain classes. Requires elevation. Can be executed in Azure as part of a role startup task. Transactions Microsoft Orleans Transactions support PM> Install-Package Microsoft.Orleans.Transactions Includes support for cross-grain transactions (beta). Microsoft Orleans Transactions on Azure PM> Install-Package Microsoft.Orleans.Transactions.AzureStorage Includes a plugin for persisting transaction log in Azure Table (beta)."
  },
  "docs/resources/orleans_architecture_principles_and_approach_I.html": {
    "href": "docs/resources/orleans_architecture_principles_and_approach_I.html",
    "title": "Orleans Architecture - Principles and Approach I | Microsoft Orleans Documentation",
    "keywords": "Now that Orleans is (finally) available as open source, it's important to be clear about the goals and principles that has motivated the design decisions behind Orleans so that new changes either fit within that framework or explicitly and intentionally revise those goals and principles. About the time I joined the Orleans project, we agreed that the goal was to produce a framework that would allow mainstream developers to easily build scalable distributed (cloud) applications. To break this down a bit: The target audience shouldn't exclude programmers who haven't done distributed systems development . We want to enable all developers, whether cloud experts or cloud beginners, to focus on their application logic and features -- which is to say, what actually provides business value -- rather than on generic distributed systems issues. The goal is to allow them to build cloud applications easily . Easily means that they shouldn't have to think about distribution any more than is absolutely required. Easily also means that Orleans should present as familiar a façade to the developer as possible; in a .NET context, that means C# objects and interfaces. Those applications should be \"scalable by default\" . Since our target users aren't necessarily distributed systems experts, we want to provide them a framework that will lead them to build scalable applications without explicitly thinking about it. This means that the framework has to make a lot of decisions for them in order to guarantee an acceptable degree of scalability, even if that means that the scalability isn't optimal for every application. We supplemented this goal with a set of architectural principles: We're focused on the 80% case . There are certainly applications that Orleans isn't appropriate for; that's OK. There are applications that Orleans is a reasonable fit for, but where you can get somewhat better performance by a bunch of hand-tuning that Orleans doesn't allow; that's OK too. The 80% that Orleans fits well and performs well enough on covers a lot of interesting applications, and we'd rather do a great job on 80% than a lousy job on 99%. Scalability is paramount . We'll trade off raw performance if that gets us better scaling. Availability is paramount . A cloud application should be like a utility: always there when you want it. Detect and fix problems , don't assume you can 100% prevent them. At cloud scale, bad things happen often, and even impossible bad things happen, just less often. This has led us to what is often termed \"recovery-oriented computing\", rather than trying to be fault-tolerant; our experience has shown that fault tolerance is fragile and often illusory. Even mathematically proven protocols are no protection against random bit flips in memory or disk controllers that fail while reporting success -- both real examples I've seen in production in my career. The above has led us to certain practices: API-first design : if we don't know how we're going to expose a feature to the developer, then we don't build it. Of course, the best way is for a feature have no developer exposure at all... Make it easy to do the right thing : keep things as simple as possible (but no simpler), don't provide a hammer if a screwdriver is the right tool. As one of our early adopters put it, we try to help our customers \"fall into the pit of success\". If there is a standard pattern that will work well for 80% of the applications out there, then don't worry about enabling every possible alternative. Orleans' embrace of asynchrony is a good example of this. Make it easy for developers to extend the framework without breaking it . Custom serialization and persistence providers are a couple of examples of this. Some sort of custom task scheduling extension would be an anti-example. Follow the principle of least surprise : as much as possible, things should be as familiar, but everything should behave the way it looks. The next post will start applying these principles to the current Orleans design and walk through the motivations for some specific decisions we made. Thanks for reading! Alan Geller Alan Geller, http://research.microsoft.com/en-us/people/ageller/ , works on quantum computing at Microsoft Research. He was one of the primary architects of Orleans from 2008 until 2012. Earlier, he was the platform architect for Amazon Web Services from 2004 to 2008, and before that built a wide variety of large-scale production distributed systems in telecommunications and financial services."
  },
  "docs/resources/orleans_thinking_big_and_small.html": {
    "href": "docs/resources/orleans_thinking_big_and_small.html",
    "title": "Orleans - Thinking Big and Small | Microsoft Orleans Documentation",
    "keywords": "TL;DR: You don’t need hundreds of servers to benefit from Orleans. A handful is enough. As we just announced availability of the Project Orleans as a public preview ( Available Now: Preview of Project “Orleans” – Cloud Services at Scale ), some of the initial questions and discussions at //build/ were around what type of services the Orleans programming model is suitable for. I heard statements that Orleans is for super-high scale systems. While technically correct, they felt incomplete to me, and compelled me to write this post. Applicability Spectrum One extreme of the Orleans applicability spectrum is a single machine application. Some people see isolation of actors and safe concurrency as big enough benefits that they are worth the price of message passing. That’s not the use case we optimized for while building Orleans, but it’s a legitimate usage pattern, just not very interesting in the cloud context. At the other end of the spectrum we find massive deployments that span thousands of servers. We tested Orleans on deployments of hundreds of servers, and I’m sure it will run fine on thousands, even if that will require some configuration tweaks. However, I’m personally rather skeptical about how many products actually need a single cloud service spanning thousands of servers as opposed to running multiple related services interacting with each other where each service instance is deployed on tens or hundreds of servers. Distributed system – same problems regardless of the size The moment a system moves from a single server to multiple servers, developers face very much the same set of challenges, regardless of its size -- whether it's a 3-5, 30-50 or 300-500 server system. They now have to deal with distribution of their computations, coordination between them, scalability, fault tolerance and reconfigurations, diagnostics, etc. They are building a distributed system now, which is never easy. And building a stateful distributed system is even harder. Orleans was designed to help with building such systems by providing an easy to use set of abstractions that greatly simplifies developers’ lives and helps them avoid common distributed systems pitfalls. The distributed runtime was built to perform most of the heavy lifting. Developers can equally benefit from these features of Orleans when building services of different sizes because the problems Orleans solves for them are really the same. The abstraction of grains simplifies reasoning about your system while encouraging fine-grain partitioning of state for scalability. The virtual actor feature helps with resource management and fault tolerance. Automatic propagation of exceptions minimizes error handling code without losing failures. The distributed runtime takes care of server failures, messaging, routing, single-threaded execution, and other system level guarantees. You don’t need hundreds of servers to start reaping the developer productivity gains. Elasticity Predicting load for your future system is hard and often simply impossible. Every startup dreams of getting slashdotted one day, which is a blessing for the business and a curse for the system. Or your CMO may like your BI data so much that she suddenly wants to have it in 5 second aggregates instead of 30 minutes. Building for high load that may never materialize is expensive. The Orleans model helps solve the elasticity problem by encouraging designing your system in a scalable way, so that you can start with a small deployment and stay small or scale out big if needed without changing your application code. Bottom Line You should be able to benefit from Orleans the moment you go from a single-server setup to a distributed system, whether it’s 2 or 3 servers or thousands of them. You can even start building your single-server solution with Orleans if you believe you may need one day scale it out or make fault tolerant. The beauty here is that your code won’t need to change. Just add more servers and your grains will spread across them. -Sergey Bykov"
  },
  "docs/resources/presentations/index.html": {
    "href": "docs/resources/presentations/index.html",
    "title": "Orleans Presentations | Microsoft Orleans Documentation",
    "keywords": "Orleans Best Practices A collection of tips and trick to help design, build, and run an Orleans-based application. Orleans Presentation from the 28th International Symposium on Distributed Computing (DISC 2014) Orleans Presentation from the 15th International Workshop on High Performance Transaction Systems (HPTS 2013) Balancing Techniques in Orleans Uniform API is 42 - Virtual Meetup #3 Orleans at FreeBay - Virtual Meetup #4 Orleans Streaming - Virtual Meetup #5 - May 2015 Geo Distributed Orleans - Virtual Meetup #6 - October 2015 Orleankka Functional API for Orleans - Virtual Meetup #7 Orleans Roadmap - Virtual Meetup #8 - January 2016 Orleans Networking discussion- Virtual Meetup #8.5 - February 2016 Orleans on Service Fabric - Virtual Meetup #9 Part 1 - February 2016 Orleans with YAMS - Virtual Meetup #9 Part 2 - February 2016 Walk In Distributed Systems Park With Orleans Orleans at Microsoft by Reuben Bond - August 2020 (video)"
  },
  "docs/resources/student_projects.html": {
    "href": "docs/resources/student_projects.html",
    "title": "Student Projects | Microsoft Orleans Documentation",
    "keywords": "Student Projects We suggest 2 types of projects for students: The first type includes exploratory, open-ended, research-oriented projects with the goal of enabling new capabilities in Orleans. These projects would usually have broad scope and would be suitable for M.S. or Ph.D. student or advanced undergraduate students in their last year of studies. The end goal of these projects would be to contribute ideas and design to Orleans. We do not necessarily expect the code produced in these projects to be directly contributed to this repository, however this would be nice. The second type includes ideas for student education . These are either ideas for interesting applications that can be built on top of Orleans or some new capabilities for Orleans. These projects are suitable to be given in advanced undergraduate or graduate courses, where students learn about Cloud Computing and modern distributed technologies and want to gain real-world hands-on experience in building Cloud applications. We do not expect the code produced in these projects to be contributed directly to this repository. Research projects: Auto-scale. In this project students can start by exploring the existing auto-scaling mechanisms for controlling resource allocation in Windows Azure ( Autoscaling Application Block ). The next step involves exploring various statistics and resource consumption metrics collected by Orleans, and using them as an input for Azure Autoscaling. An advanced stage of this project may involve improving the internal Orleans mechanisms for reacting to elasticity changes, for example by implementing live actor migration to reduce the time taken to utilize new resources. Auto-generated front-ends for Orleans-based cloud services . This project seamlessly extends the Orleans actor model into the HTTP world. The ramp-up part of the project includes dynamically generating HTTP endpoints for actors based on their .NET interfaces and metadata. The main part involves automatically generating front-ends to support web sockets and bi-directional streaming of data, which requires complex code generation with optimizations for high performance. It also requires attention to fault tolerance, to maintain high availability of streaming sessions across server reboots and client reconnects and migration -- a significant research challenge. Storage provider for Entity Framework . This project involves enabling Orleans objects to store their state in a database and to subsequently query it. This might include adding support for Orleans object persistence on SQL Azure Database using Entity Framework (EF), which is Microsoft's open-source object-relational mapper for .NET, and exposing that data via LINQ queries. The implementation can be evaluated and tuned using standard database benchmarks and/or custom Orleans' applications. Distributed system benchmark . Define a list of benchmarks suitable for distributed systems like Orleans. The benchmark applications may be analogous in spirit to the TPC database benchmark or UCB \"Parallel Dwarfs\" implemented here and may be used to characterize the performance and scalability of distributed frameworks. Consider developing a new benchmark targeted for Orleans, for example, to compare the performance of storage providers. Declarative dataflow language over streams . Define and build a Trident-Storm like declarative language over Orleans streams. Develop an optimizer that configures the stream processing to minimize overall cost. Programming model for client devices . Extend Orleans to client devices, such as sensors, phones, tablets, and desktops. Enable grain logic to execute on the client. Potentially support tier splitting, that is, dynamically deciding which parts of the code execute on the device and which is offloaded to the cloud. Queries over grain/actor classes, secondary indices . Build a distributed, scalable, and reliable grain index. This includes formally defining the query model and implementing the distributed index. The index itself can be implemented as Orleans grains and/or stored in a database. Large scale simulations . Orleans is a great fit for building large scale simulations. Explore the usage of Orleans for different simulations, for example, protein interactions, network simulations, simulated annealing, etc. Course projects: Internet Of Things applications . For example, the application could enable sensors/devices to report their state to the cloud, where each device is represented in the cloud by an Orleans actor. Users can connect to the actor that represents their device via a web browser and check its status or control it. This project involves mastering a number of modern cloud technologies, including Windows Azure , Orleans, WebApi or ASP.NET, SignalR for streaming commands back from the cloud to the device, and writing a sensor/device/phone app. Twitter-like large scalable chat service in the cloud based on Orleans . Each user could be represented by an Orleans Actor, which contains its list of followers. Faceboook-like social app based on Orleans . Each user could be represented by an Orleans Actor, which includes a list of friends and wall on which friends can write. Simple storage provider . Add a storage provider for a storage system, such as a key-value store or database system. A simple one could use the Orleans serializer , as in the existing Azure Table storage provider . A more sophisticated one would map state variables of an Orleans class to fine-grained structures of the storage system. A complex one is the Entity Framework storage provider mentioned above under Research Projects . Compare the performance of different storage providers for different types and sizes of actor state. Comparison with other distributed application frameworks . Take a sample application written for another application framework, such as Google App Engine or Akka , and translate it into Orleans. Summarize the relative strengths and weaknesses of each framework by comparing the apps. Concluded Research projects: Below are a number of examples of previous successful research projects. Distributed log analysis, correlation and debugging . Debugging large-scale distributed systems is a challenging task due to enormous amounts of data and complex dynamic interactions between the distributed components, running on different processes and different machines. The goal of this project was to analyze prior art on this topic, propose a solution, and then implement prototype tools for collecting, correlating and analyzing application error log file data across a multi-machine distributed application runtime environment. This involved exploring the problem space from a variety of perspectives, including: a. Approaches to efficient logging, collection and analysis of failure information from various log-capture mechanisms in a distributed Orleans runtime environment. b. Possible applications of machine learning to find log patterns that signal serious production issues, and then detecting these patterns in near real time as a production monitoring utility. c. Ways to help individual developers perform real-time debugging of run-time issues with their applications. This project was performed successfully and result in a published paper PAD: Performance Anomaly Detection in Multi-Server Distributed Systems and a proof of concept implementation of a distributed log analysis tool. Horton - Distributed Graph Database . Horton was a research project with a goal to build a system to store, manage and query large-scale distributed graphs. It was implemented entirely as an Orleans application. The project resulted in a number of publications and a number of very successful student projects."
  },
  "docs/streaming/index.html": {
    "href": "docs/streaming/index.html",
    "title": "Orleans Streams | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Orleans v.1.0.0 added support for streaming extensions to the programing model. Streaming extensions provide a set of abstractions and APIs that make thinking about and working with streams simpler and more robust. Streaming extensions allow developers to write reactive applications that operate on a sequence of events in a structured way. The extensibility model of stream providers makes the programming model compatible with and portable across a wide range of existing queuing technologies, such as Event Hubs , ServiceBus , Azure Queues , and Apache Kafka . There is no need to write special code or run dedicated processes to interact with such queues. Why should I care? If you already know all about Stream Processing and are familiar with technologies like Event Hubs , Kafka , Azure Stream Analytics , Apache Storm , Apache Spark Streaming , and Reactive Extensions (Rx) in .NET , you may be asking why should you care. Why do we need yet another Stream Processing System and how Actors are related to Streams? \"Why Orleans Streams?\" is meant to answer that question. Programming Model There are a number of principles behind Orleans Streams Programming Model: Orleans streams are virtual . That is, a stream always exists. It is not explicitly created or destroyed, and it can never fail. Streams are identified by stream IDs, which are just logical names comprised of GUIDs and strings. Orleans Streams allow you to decouple generation of data from its processing, both in time and space . That means that the stream producer and the stream consumer may be on different servers or in different time zones, and will withstand failures. Orleans streams are lightweight and dynamic . Orleans Streaming Runtime is designed to handle a large number of streams that come and go at a high rate. Orleans stream bindings are dynamic . Orleans Streaming Runtime is designed to handle cases where grains connect to and disconnect from streams at a high rate. Orleans Streaming Runtime transparently manages the lifecycle of stream consumption . After an application subscribes to a stream, it will then receive the stream's events, even in the presence of failures. Orleans streams work uniformly across grains and Orleans clients . Programming APIs Applications interact with streams via APIs that are very similar to the well-known Reactive Extensions (Rx) in .NET , by using Orleans.Streams.IAsyncStream<T> that implements Orleans.Streams.IAsyncObserver<T> and Orleans.Streams.IAsyncObservable<T> interfaces. In a typical example below, a device generates some data, which is sent as an HTTP request to the service running in the Cloud. The Orleans client running in the front-end server receives this HTTP call and publishes the data into a matching device stream: public async Task OnHttpCall(DeviceEvent deviceEvent) { // Post data directly into the device's stream. IStreamProvider streamProvider = GrainClient.GetStreamProvider(\"MyStreamProvider\"); IAsyncStream<DeviceEventData> deviceStream = streamProvider.GetStream<DeviceEventData>(deviceEvent.DeviceId, \"MyNamespace\"); await deviceStream.OnNextAsync(deviceEvent.Data); } In another example below, a chat user (implemented as Orleans Grain) joins a chat room, gets a handle to a stream of chat messages generated by all others users in this room, and subscribes to it. Notice that the chat user does not need to know about the chat room grain itself (there might not be such a grain in our system) or about other users in that group that produce messages. Needless to say, to publish to the chat stream, users don't need to know who is currently subscribed to the stream. This demonstrates how chat users can be completely decoupled in time and space. public class ChatUser: Grain { public async Task JoinChat(Guid chatGroupId) { IStreamProvider streamProvider = base.GetStreamProvider(\"MyStreamProvider\"); IAsyncStream<string> chatStream = streamProvider.GetStream<string>(chatGroupId, \"MyNamespace\"); await chatStream.SubscribeAsync(async (message, token) => Console.WriteLine(message)) } } Quick Start Sample The Quick Start Sample is a good quick overview of the overall workflow of using streams in the application. After reading it, you should read the Streams Programming APIs to get a deeper understanding of the concepts. Streams Programming APIs A Streams Programming APIs provides a detailed description of the programming APIs. Stream Providers Streams can come via physical channels of various shapes and forms and can have different semantics. Orleans Streaming is designed to support this diversity via the concept of Stream Providers , which is an extensibility point in the system. Orleans currently has implementations of two stream providers: TCP based Simple Message Stream Provider and Azure Queue based Azure Queue Stream Provider . More details on Stream Providers can be found at Stream Providers . Stream Semantics Stream Subscription Semantics : Orleans Streams guarantee Sequential Consistency for Stream Subscription operations. Specifically, when a consumer subscribes to a stream, once the Task representing the subscription operation was successfuly resolved, the consumer will see all events that were generated after it has subscribed. In addition, Rewindable streams allow you to subscribe from an arbitrary point in time in the past by using StreamSequenceToken (more details can be found here ). Individual Stream Events Delivery Guarantees : Individual event delivery guarantees depend on individual stream providers. Some provide only best-effort at-most-once delivery (such as Simple Message Streams (SMS)), while others provide at-least-once delivery (such as Azure Queue Streams). It is even possible to build a stream provider that will guarantee exactly-once delivery (we don't have such a provider yet, but it is possible to build one). Events Delivery Order : Event order also depends on a particular stream provider. In SMS streams, the producer explicitly controls the order of events seen by the consumer by controlling the way it publishes them. Azure Queue streams do not guarantee FIFO order, since the underlying Azure Queues do not guarantee order in failure cases. Applications can also control their own stream delivery ordering by using StreamSequenceToken . Streams Implementation The Orleans Streams Implementation provides a high-level overview of the internal implementation. Code Samples More examples of how to use streaming APIs within a grain can be found here . We plan to create more samples in the future. More Material Orleans Virtual Meetup about Streams Orleans Streaming Presentation from Virtual Meetup"
  },
  "docs/streaming/stream_providers.html": {
    "href": "docs/streaming/stream_providers.html",
    "title": "Orleans Stream Providers | Microsoft Orleans Documentation",
    "keywords": "Stream Providers Streams can come in different shapes and forms. Some streams may deliver events over direct TCP links, while others deliver events via durable queues. Different stream types may use different batching strategies, different caching algorithms, or different back pressure procedures. To avoid constraining streaming applications to only a subset of those behavioral choices, Stream Providers are extensibility points to Orleans Streaming Runtime that allow users to implement any type of stream. This extensibility point is similar in spirit to Orleans Storage Providers . Orleans currently ships with many stream providers, including : Simple Message Stream Provider and Azure Queue Stream Provider . Simple Message Stream Provider Simple Message Stream Provider, also known as the SMS provider, delivers events over TCP by utilizing regular Orleans grain messaging. Since events in SMS are delivered over unreliable TCP links, SMS does not guarantee reliable event delivery and does not automatically resend failed messages for SMS streams. By default the producer's call to stream.OnNextAsync returns a Task that represents the processing status of the stream consumer, which tells the producer whether the consumer successfully received and processed the event. If this Task fails, the producer can decide to send the same event again, thus achieving reliability on the application level. Although stream message delivery is best effort, SMS streams themselves are reliable. That is, the subscriber-to-producer binding performed by Pub-Sub is fully reliable. Azure Queue (AQ) Stream Provider Azure Queue (AQ) Stream Provider delivers events over Azure Queues. On the producer side, AQ Stream Provider enqueues events directly into Azure Queue. On the consumer side, AQ Stream Provider manages a set of pulling agents that pull events from a set of Azure Queues and deliver them to application code that consumes them. One can think of the pulling agents as a distributed \"micro-service\" -- a partitioned, highly available, and elastic distributed component. The pulling agents run inside the same silos that host application grains. Thus, there is no need to run separate Azure worker roles to pull from the queues. The existence of pulling agents, their management, backpressure, balancing the queues between them, and handing off queues from a failed agent to another agent are fully managed by Orleans Streaming Runtime and are transparent to application code that uses streams. Queue Adapters Different stream providers that deliver events over durable queues exhibit similar behavior and are subject to a similar implementation. Therefore, we provide a generic extensible PersistentStreamProvider that allows developers to plug in different types of queues without writing a completely new stream provider from scratch. PersistentStreamProvider uses an IQueueAdapter component, which abstracts specific queue implementation details and provides means to enqueue and dequeue events. All the rest is handled by the logic inside the PersistentStreamProvider . Azure Queue Provider mentioned above is also implemented this way: it is an instance of PersistentStreamProvider that uses an AzureQueueAdapter . Next Orleans Streams Implementation Details"
  },
  "docs/streaming/streams_programming_APIs.html": {
    "href": "docs/streaming/streams_programming_APIs.html",
    "title": "Orleans Streams Programming APIs | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Programming APIs Applications interact with streams via APIs that are very similar to the well known Reactive Extensions (Rx) in .NET . The main difference is that Orleans stream extensions are asynchronous , to make processing more efficient in Orleans' distributed and scalable compute fabric. Async Stream An application starts by using a stream provider to get a handle to a stream. You can read more about stream providers here , but for now you can think of it as stream factory that allows implementers to customize streams behavior and semantics: IStreamProvider streamProvider = base.GetStreamProvider(\"SimpleStreamProvider\"); IAsyncStream<T> stream = streamProvider.GetStream<T>(Guid, \"MyStreamNamespace\"); An application can get a reference to the stream provider either by calling the GetStreamProvider method on the Grain class when inside a grain, or by calling the GrainClient.GetStreamProvider() method when on the client. Orleans.Streams.IAsyncStream<T> is a logical, strongly-typed handle to a virtual stream . It is similar in spirit to Orleans Grain Reference. Calls to GetStreamProvider and GetStream are purely local. The arguments to GetStream are a GUID and an additional string that we call a stream namespace (which can be null). Together the GUID and the namespace string comprise the stream identity (similar in sprit to the arguments to GrainFactory.GetGrain ). The combination of GUID and namespace string provide extra flexibility in determining stream identities. Just like grain 7 may exist within the Grain type PlayerGrain and a different grain 7 may exist within the grain type ChatRoomGrain , Stream 123 may exist with the stream namespace PlayerEventsStream and a different stream 123 may exist within the stream namespace ChatRoomMessagesStream . Producing and Consuming IAsyncStream<T> implements both Orleans.Streams.IAsyncObserver<T> and Orleans.Streams.IAsyncObservable<T> interfaces. That way an application can use the stream either to produce new events into the stream by using Orleans.Streams.IAsyncObserver<T> or to subscribe to and consume events from a stream by using Orleans.Streams.IAsyncObservable<T> . public interface IAsyncObserver<in T> { Task OnNextAsync(T item, StreamSequenceToken token = null); Task OnCompletedAsync(); Task OnErrorAsync(Exception ex); } public interface IAsyncObservable<T> { Task<StreamSubscriptionHandle<T>> SubscribeAsync(IAsyncObserver<T> observer); } To produce events into the stream, an application just calls await stream.OnNextAsync<T>(event) To subscribe to a stream, an application calls StreamSubscriptionHandle<T> subscriptionHandle = await stream.SubscribeAsync(IAsyncObserver) The argument to SubscribeAsync can either be an object that implements the IAsyncObserver interface or a combination of lambda functions to process incoming events. More options for SubscribeAsync are available via AsyncObservableExtensions class. SubscribeAsync returns a StreamSubscriptionHandle<T> , which is an opaque handle that can be used to unsubscribe from the stream (similar in spirit to an asynchronous version of IDisposable ). await subscriptionHandle.UnsubscribeAsync() It is important to note that the subscription is for a grain, not for an activation . Once the grain code is subscribed to the stream, this subscription surpasses the life of this activation and stays durable forever, until the grain code (potentially in a different activation) explicitly unsubscribes. This is the heart of a virtual stream abstraction : not only do all streams always exist, logically, but also a stream subscription is durable and lives beyond a particular physical activation that created the subscription. Multiplicity An Orleans stream may have multiple producers and multiple consumers. A message published by a producer will be delivered to all consumers that were subscribed to the stream before the message was published. In addition, the consumer can subscribe to the same stream multiple times. Each time it subscribes it gets back a unique StreamSubscriptionHandle<T> . If a grain (or client) is subscribed X times to the same stream, it will receive the same event X times, once for each subscription. The consumer can also unsubscribe from an individual subscription. It can find all its current subscriptions by calling: IList<StreamSubscriptionHandle<T>> allMyHandles = await IAsyncStream<T>.GetAllSubscriptionHandles() Recovering From Failures If the producer of a stream dies (or its grain is deactivated), there is nothing it needs to do. The next time this grain wants to produce more events it can get the stream handle again and produce new events in the same way. Consumer logic is a little bit more involved. As we said before, once a consumer grain is subscribed to a stream, this subscription is valid until the grain explicitly unsubscribes. If the consumer of the stream dies (or its grain is deactivated) and a new event is generated on the stream, the consumer grain will be automatically re-activated (just like any regular Orleans grain is automatically activated when a message is sent to it). The only thing that the grain code needs to do now is to provide an IAsyncObserver<T> to process the data. The consumer basically needs to re-attach processing logic as part of the OnActivateAsync method. To do that it can call: StreamSubscriptionHandle<int> newHandle = await subscriptionHandle.ResumeAsync(IAsyncObserver) The consumer uses the previous handle it got when it first subscribed in order to \"resume processing\". Notice that ResumeAsync merely updates an existing subscription with the new instance of IAsyncObserver logic and does not change the fact that this consumer is already subscribed to this stream. How does the consumer get an old subscriptionHandle? There are 2 options. The consumer may have persisted the handle it was given back from the original SubscribeAsync operation and can use it now. Alternatively, if the consumer does not have the handle, it can ask the IAsyncStream<T> for all its active subscription handles, by calling: IList<StreamSubscriptionHandle<T>> allMyHandles = await IAsyncStream<T>.GetAllSubscriptionHandles() The consumer can now resume all of them, or unsubscribe from some if it wishes to. COMMENT: If the consumer grain implements the IAsyncObserver interface directly ( public class MyGrain<T> : Grain, IAsyncObserver<T> ), it should in theory not be required to re-attach the IAsyncObserver and thus will not need to call ResumeAsync . The streaming runtime should be able to automatically figure out that the grain already implements IAsyncObserver and will just invoke those IAsyncObserver methods. However, the streaming runtime currently does not support this and the grain code still needs to explicitly call ResumeAsync , even if the grain implements IAsyncObserver directly. Supporting this is on our TODO list. Explicit and Implicit Subscriptions By default, a stream consumer has to explicitly subscribe to the stream. This subscription would usually be triggered by some external message that the grain (or client) receives that instructs it to subscribe. For example, in a chat service when a user joins a chat room his grain receives a JoinChatGroup message with the chat name, which will cause the user grain to subscribe to this chat stream. In addition, Orleans Streams also support \"Implicit Subscriptions\" . In this model the grain does not explicitly subscribe to the stream. This grain is subscribed automatically, implicitly, just based on its grain identity and an ImplicitStreamSubscription attribute. Implicit subscriptions' main value is allowing the stream activity to trigger the grain activation (hence triggering the subscription) automatically. For example, using SMS streams, if one grain wanted to produce a stream and another grain process this stream, the producer would need to know the identity of the consumer grain and make a grain call to it telling it to subscribe to the stream. Only after that can it start sending events. Instead, using implicit subscriptions, the producer can just start producing events to a stream, and the consumer grain will automatically be activated and subscribe to the stream. In that case, the producer doesn't care at all who is reading the events Grain implementation class of type MyGrainType can declare an attribute [ImplicitStreamSubscription(\"MyStreamNamespace\")] . This tells the streaming runtime that when an event is generated on a stream whose identity is GUID XXX and \"MyStreamNamespace\" namespace, it should be delivered to the grain whose identity is XXX of type MyGrainType . That is, the runtime maps stream <XXX, MyStreamNamespace> to consumer grain <XXX, MyGrainType> . The presence of ImplicitStreamSubscription causes the streaming runtime to automatically subscribe this grain to a stream and deliver the stream events to it. However, the grain code still needs to tell the runtime how it wants events to be processed. Essentially, it needs to attach the IAsyncObserver . Therefore, when the grain is activated, the grain code inside OnActivateAsync needs to call: IStreamProvider streamProvider = base.GetStreamProvider(\"SimpleStreamProvider\"); IAsyncStream<T> stream = streamProvider.GetStream<T>(this.GetPrimaryKey(), \"MyStreamNamespace\"); StreamSubscriptionHandle<T> subscription = await stream.SubscribeAsync(IAsyncObserver<T>); Writing Subscription Logic Below are the guidelines on how to write the subscription logic for various cases: explicit and implicit subscriptions, rewindable and non-rewindable streams. The main difference between explicit and implicit subscriptions is that for implicit the grain always has exactly one implicit subscription for every stream namespace; there is no way to create multiple subscriptions (there is no subscription multiplicity), there is no way to unsubscribe, and the grain logic always only needs to attach the processing logic. That also means that for implicit subscriptions there is never a need to Resume a subscription. On the other hand, for explicit subscriptions, one needs to Resume the subscription, otherwise if the grain subscribes again it will result in the grain being subscribed multiple times. Implicit Subscriptions: For implicit subscriptions the grain needs to subscribe to attach the processing logic. This should be done in the grain's OnActivateAsync method. The grain should simply execute await stream.SubscribeAsync(OnNext ...) in its OnActivateAsync method. That will cause this particular activation to attach the OnNext function to process that stream. The grain can optionally specify the StreamSequenceToken as an argument to SubscribeAsync , which will cause this implicit subscription to start consuming from that token. There is never a need for implicit subscription to call ResumeAsync . public async override Task OnActivateAsync() { var streamProvider = GetStreamProvider(PROVIDER_NAME); var stream = streamProvider.GetStream<string>(this.GetPrimaryKey(), \"MyStreamNamespace\"); await stream.SubscribeAsync(OnNextAsync) } Explicit Subscriptions: For explicit subscriptions, a grain must call SubscribeAsync to subscribe to the stream. This creates a subscription, as well as attaches the processing logic. The explicit subscription will exist until the grain unsubscribes, so if a grain gets deactivated and reactivated, the grain is still explicitly subscribed, but no processing logic will be attached. In this case the grain needs to re-attach the processing logic. To do that, in its OnActivateAsync , the grain first needs to find out what subscriptions it has, by calling stream.GetAllSubscriptionHandles() . The grain must execute ResumeAsync on each handle it wishes to continue processing or UnsubscribeAsync on any handles it is done with. The grain can also optionally specify the StreamSequenceToken as an argument to the ResumeAsync calls, which will cause this explicit subscription to start consuming from that token. public async override Task OnActivateAsync() { var streamProvider = GetStreamProvider(PROVIDER_NAME); var stream = streamProvider.GetStream<string>(this.GetPrimaryKey(), \"MyStreamNamespace\"); var subscriptionHandles = await stream.GetAllSubscriptionHandles(); if (!subscriptionHandles.IsNullOrEmpty()) subscriptionHandles.ForEach(async x => await x.ResumeAsync(OnNextAsync)); } Stream Order and Sequence Tokens The order of event delivery between an individual producer and an individual consumer depends on the stream provider. With SMS the producer explicitly controls the order of events seen by the consumer by controlling the way the producer publishes them. By default (if the FireAndForget option for SMS provider is set to false) and if the producer awaits every OnNextAsync call, the events arrive in FIFO order. In SMS it is up to the producer to decide how to handle delivery failures that will be indicated by a broken Task returned by the OnNextAsync call. Azure Queue streams do not guarantee FIFO order, since the underlying Azure Queues do not guarantee order in failure cases. (They do guarantee FIFO order in failure-free executions.) When a producer produces the event into Azure Queue, if the enqueue operation fails, it is up to the producer to attempt another enqueue and later on deal with potential duplicate messages. On the delivery side, the Orleans Streaming runtime dequeues the event from the queue and attempts to deliver it for processing to consumers. The Orleans Streaming runtime deletes the event from the queue only upon successful processing. If the delivery or processing fails, the event is not deleted from the queue and will automatically re-appear in the queue later. The Streaming runtime will try to deliver it again, thus potentially breaking the FIFO order. The above behavior matches the normal semantics of Azure Queues. Application Defined Order : To deal with the above ordering issues, an application can optionally specify its own ordering. This is achieved via a StreamSequenceToken , which is an opaque IComparable object that can be used to order events. A producer can pass an optional StreamSequenceToken to the OnNext call. This StreamSequenceToken will be passed all the way to the consumer and will be delivered together with the event. That way, an application can reason and reconstruct its order independently of the streaming runtime. Rewindable Streams Some streams only allow an application to subscribe to them starting at the latest point in time, while other streams allow \"going back in time\". The latter capability is dependent on the underlying queuing technology and the particular stream provider. For example, Azure Queues only allow consuming the latest enqueued events, while EventHub allows replaying events from an arbitrary point in time (up to some expiration time). Streams that support going back in time are called Rewindable Streams . The consumer of a rewindable stream can pass a StreamSequenceToken to the SubscribeAsync call. The runtime will deliver events to it starting from that StreamSequenceToken . A null token means the consumer wants to receive events starting from the latest. The ability to rewind a stream is very useful in recovery scenarios. For example, consider a grain that subscribes to a stream and periodically checkpoints its state together with the latest sequence token. When recovering from a failure, the grain can re-subscribe to the same stream from the latest checkpointed sequence token, thereby recovering without losing any events that were generated since the last checkpoint. Event Hubs provider is rewindable. You can find its code here . SMS and Azure Queue providers are not rewindable. Stateless Automatically Scaled-Out Processing By default Orleans Streaming is targeted to support a large number of relatively small streams, each processed by one or more stateful grains. Collectively, the processing of all the streams together is sharded among a large number of regular (stateful) grains. The application code controls this sharding by assigning stream ids and grain ids and by explicitly subscribing. The goal is sharded stateful processing . However, there is also an interesting scenario of automatically scaled-out stateless processing . In this scenario an application has a small number of streams (or even one large stream) and the goal is stateless processing. An example is a global stream of events, where the processing involves decoding each event and potentially forwarding it to other streams for further stateful processing. The stateless scaled-out stream processing can be supported in Orleans via StatelessWorker grains. Current Status of Stateless Automatically Scaled-Out Processing: This is not yet implemented. An attempt to subscribe to a stream from a StatelessWorker grain will result in undefined behavior. We are considering to support this option . Grains and Orleans Clients Orleans streams work uniformly across grains and Orleans clients . That is, exactly the same APIs can be used inside a grain and in an Orleans client to produce and consume events. This greatly simplifies the application logic, making special client-side APIs, such as Grain Observers, redundant. Fully Managed and Reliable Streaming Pub-Sub To track stream subscriptions, Orleans uses a runtime component called Streaming Pub-Sub which serves as a rendezvous point for stream consumers and stream producers. Pub Sub tracks all stream subscriptions, persists them, and matches stream consumers with stream producers. Applications can choose where and how the Pub-Sub data is stored. The Pub-Sub component itself is implemented as grains (called PubSubRendezvousGrain ), which use Orleans Declarative Persistence. PubSubRendezvousGrain uses the storage provider named PubSubStore . As with any grain, you can designate an implementation for a storage provider. For Streaming Pub-Sub you can change the implementation of the PubSubStore at silo construction time using the silo host builder: The following configures Pub-Sub to store its state in Azure tables. hostBuilder.AddAzureTableGrainStorage(\"PubSubStore\", options=>{ options.ConnectionString = \"Secret\"; }); That way Pub-Sub data will be durably stored in Azure Table. For initial development you can use memory storage as well. In addition to Pub-Sub, the Orleans Streaming Runtime delivers events from producers to consumers, manages all runtime resources allocated to actively used streams, and transparently garbage collects runtime resources from unused streams. Configuration In order to use streams you need to enable stream providers via the silo host or cluster client builders. You can read more about stream providers here . Sample stream provider setup: hostBuilder.AddSimpleMessageStreamProvider(\"SMSProvider\") .AddAzureQueueStreams<AzureQueueDataAdapterV2>(\"AzureQueueProvider\", optionsBuilder => optionsBuilder.Configure( options=>{ options.ConnectionString = \"Secret\"; })) .AddAzureTableGrainStorage(\"PubSubStore\", options=>{ options.ConnectionString = \"Secret\"; }); Next Orleans Stream Providers"
  },
  "docs/streaming/streams_quick_start.html": {
    "href": "docs/streaming/streams_quick_start.html",
    "title": "Orleans Streams Quick Start | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Quick Start This guide will show you a quick way to set up and use Orleans Streams. To learn more about the details of the streaming features, read other parts of this documentation. Required Configurations In this guide we'll use a Simple Message based Stream which uses grain messaging to send stream data to subscribers. We will use the in-memory storage provider to store lists of subscriptions, so it is not a wise choice for real production applications. On the silo, where hostBuilder is an ISiloHostBuilder hostBuilder.AddSimpleMessageStreamProvider(\"SMSProvider\") .AddMemoryGrainStorage(\"PubSubStore\"); On the cluster client, where clientBuilder is an IClientBuilder clientBuilder.AddSimpleMessageStreamProvider(\"SMSProvider\"); NOTE By default, messages that are passed over the Simple Message Stream are considered immutable, and may be passed by reference to other grains. To turn off this behavior, you must config the SMS provider to turn off OptimizeForImmutableData siloBuilder .AddSimpleMessageStreamProvider(\"SMSProvider\", (options) => options.OptimizeForImmutableData = false); Now we can create streams, send data using them as producers and also receive data as subscribers. Producing Events Producing events for streams is relatively easy. You should first get access to the stream provider which you defined in the config above ( SMSProvider ) and then choose a stream and push data to it. //Pick a GUID for a chat room grain and chat room stream var guid = some guid identifying the chat room //Get one of the providers which we defined in our config var streamProvider = GetStreamProvider(\"SMSProvider\"); //Get the reference to a stream var stream = streamProvider.GetStream<int>(guid, \"RANDOMDATA\"); As you can see, our stream has a GUID and a namespace. This will make it easy to identify unique streams. For example, the namespace for a chat room can be \"Rooms\" and the GUID can be the owning RoomGrain's GUID. Here we use the GUID of some known chat room. Using the OnNext method of the stream we can push data to it. Let's do it inside a timer, using random numbers. You could use any other data type for the stream as well. RegisterTimer(s => { return stream.OnNextAsync(new System.Random().Next()); }, null, TimeSpan.FromMilliseconds(1000), TimeSpan.FromMilliseconds(1000)); Subscribing and receiving streaming data For receiving data, we can use implicit/explicit subscriptions, which are fully described in other pages of the manual. Here we use implicit subscriptions, which are easier. When a grain type wants to implicitly subscribe to a stream, it uses the attribute ImplicitStreamSubscription (namespace)] . For our case we'll define a ReceiverGrain like this: [ImplicitStreamSubscription(\"RANDOMDATA\")] public class ReceiverGrain : Grain, IRandomReceiver Whenever data is pushed to the streams of the namespace RANDOMDATA, as we have in the timer, a grain of type ReceiverGrain with the same GUID of the stream will receive the message. Even if no activations of the grain currently exist, the runtime will automatically create a new one and send the message to it. In order for this to work, we need to complete the subscription process by setting our OnNext method for receiving data. To do so, our ReceiverGrain should call something like this in its OnActivateAsync //Create a GUID based on our GUID as a grain var guid = this.GetPrimaryKey(); //Get one of the providers which we defined in config var streamProvider = GetStreamProvider(\"SMSProvider\"); //Get the reference to a stream var stream = streamProvider.GetStream<int>(guid, \"RANDOMDATA\"); //Set our OnNext method to the lambda which simply prints the data. This doesn't make new subscriptions, because we are using implicit subscriptions via [ImplicitStreamSubscription]. await stream.SubscribeAsync<int>(async (data, token) => Console.WriteLine(data)); We are all set! Now the only requirement is that something trigger our producer grain's creation, and then it will register the timer and start sending random ints to all interested parties. Again, this guide skips lots of details and is only good for showing the big picture. Read other parts of this manual and other resources on RX to gain a good understanding of what is available and how. Reactive programming can be a very powerful approach to solve many problems. You could for example use LINQ in the subscriber to filter numbers and do all sorts of interesting stuff. Next Orleans Streams Programming APIs"
  },
  "docs/streaming/streams_why.html": {
    "href": "docs/streaming/streams_why.html",
    "title": "Why Orleans Streams? | Microsoft Orleans Documentation",
    "keywords": "Why Orleans Streams? There are already a wide range of technologies that allow you to build stream processing systems. Those include systems to durably store stream data (e.g., Event Hubs and Kafka ) and systems to express compute operations over stream data (e.g., Azure Stream Analytics , Apache Storm , and Apache Spark Streaming ). Those are great systems that allow you to build efficient data stream processing pipelines. Limitations of Existing Systems However, those systems are not suitable for fine-grained free-form compute over stream data . The Streaming Compute systems mentioned above all allow you to specify a unified data-flow graph of operations that are applied in the same way to all stream items . This is a powerful model when data is uniform and you want to express the same set of transformation, filtering, or aggregation operations over this data. But there are other use cases where you need to express fundamentally different operations over different data items. And in some of them as part of this processing you occasionally need to make an external call, such as invoke some arbitrary REST API. The unified data-flow stream processing engines either do not support those scenarios, support them in a limited and constrained way, or are inefficient in supporting them. This is because they are inherently optimized for a large volume of similar items, and usually limited in terms of expressiveness, processing . Orleans Streams target those other scenarios. Motivation It all started with requests from Orleans users to support returning a sequence of items from a grain method call. As you can imagine, that was only the tip of the iceberg. They actually needed much more than that. A typical scenario for Orleans Streams is when you have per user streams and you want to perform different processing for each user , within the context of an individual user. We may have millions of users but some of them are interested in weather and can subscribe to weather alerts for a particular location, while some are interested in sports events; somebody else is tracking status of a particular flight. Processing those events requires different logic, but you don't want to run two independent instances of stream processing. Some users are interested in only a particular stock and only if a certain external condition applies, a condition that may not necessarily be part of the stream data (and thus needs to be checked dynamically at runtime as part of processing). Users change their interests all the time, hence their subscriptions to specific streams of events come and go dynamically, thus the streaming topology changes dynamically and rapidly . On top of that, the processing logic per user evolves and changes dynamically as well, based on user state and external events . External events may modify the processing logic for a particular user. For example, in a game cheating detection system, when a new way to cheat is discovered the processing logic needs to be updated with the new rule to detect this new violation. This needs to be done of course without disrupting the ongoing processing pipeline . Bulk data-flow stream processing engines were not built to support such scenarios. It goes almost without saying that such a system has to run on a number of network-connected machines, not on a single node. Hence, the processing logic has to be distributed in a scalable and elastic manner across a cluster of servers. New Requirements We identified 4 basic requirements for our Stream Processing system that will allow it to target the above scenarios. Flexible stream processing logic Support for highly dynamic topologies Fine-grained stream granularity Distribution Flexible stream processing logic We want the system to support different ways of expressing the stream processing logic. The existing systems we mentioned above require the developer to write a declarative data-flow computation graph, usually by following a functional programming style. This limits the expressiveness and flexibility of the processing logic. Orleans streams are indifferent to the way processing logic is expressed. It can be expressed as a data-flow (e.g., by using Reactive Extensions (Rx) in .NET ); as a functional program; as a declarative query; or in a general imperative logic. The logic can be stateful or stateless, may or may not have side effects, and can trigger external actions. All power goes to the developer. Support for dynamic topologies We want the system to allow for dynamically evolving topologies. The existing systems we mentioned above are usually limited to only static topologies that are fixed at deployment time and cannot evolve at runtime. In the following example of a dataflow expression everything is nice and simple until you need to change it. Stream.GroupBy(x=> x.key).Extract(x=>x.field).Select(x=>x+2).AverageWindow(x, 5sec).Where(x=>x > 0.8) * Change the threshold condition in the Where filter, add an additional Select statement or add another branch in the data-flow graph and produce a new output stream. In existing systems this is not possible without tearing down the entire topology and restarting the data-flow from scratch. Practically, those systems will checkpoint the existing computation and will be able to restart from the latest checkpoint. Still, such a restart is disruptive and costly to an online service that produces results in real time. Such a restart becomes especially impractical when we are talking about a large number of such expressions being executed with similar but different (per-user, per-device, etc.) parameters and that continually change. We want the system to allow for evolving the stream processing graph at runtime, by adding new links or nodes to the computation graph, or by changing the processing logic within the computation nodes. Fine grained stream granularity In the existing systems, the smallest unit of abstraction is usually the whole flow (topology). However, many of our target scenarios require an individual node/link in the topology to be a logical entity by itself. That way each entity can be potentially managed independently. For example, in the big stream topology comprising multiple links, different links can have different characteristics and can be implemented over different physical transports. Some links can go over TCP sockets, while others over reliable queues. Different links can have different delivery guarantees. Different nodes can have different checkpointing strategies, and their processing logic can be expressed in different models or even different languages. Such flexibility is usually not possible in existing systems. The unit of abstraction and flexibility argument is similar to a comparison of SoA (Service Oriented Architectures) vs. Actors. Actor systems allow more flexibility, since each actor is essentially an independently managed ''tiny service''. Similarly, we want the stream system to allow for such fine grained control. Distribution And of course, our system should have all the properties of a \"good distributed system\" . That includes: Scalability - supports large number of streams and compute elements. Elasticity - allows to add/remove resources to grow/shrink based on load. Reliability - be resilient to failures Efficiency - use the underlying resources efficiently Responsiveness - enable near real time scenarios. These were the requirements we had in mind for building Orleans Streaming . Clarificaton : Orleans currently does not directly support writing declarative dataflow expressions like in the example above. The current Orleans Streaming APIs are more low level building blocks, as described here . Providing declarative dataflow expressions is our future goal. Next Orleans Streams Programming APIs"
  },
  "docs/tutorials_and_samples/Adventure.html": {
    "href": "docs/tutorials_and_samples/Adventure.html",
    "title": "Adventure | Microsoft Orleans Documentation",
    "keywords": "Adventure A simple multiplayer text adventure game inspired by old-fashioned, text-based adventure games. Instructions Open OrleansAdventure.sln in Visual Studio. Found here. Start the 'AdventureSetup' project. Once AdventureSetup is running, start the 'AdventureClient' project. You will then be prompted to enter your name on the command line. Enter it and begin the game. Overview The AdventureSetup program reads a game description (\"map\") from AdventureConfig.txt. It sets up a series of \"rooms\" e.g. forest, beach, caves, a clearing etc . These locations are connected to other rooms to model the places and layout of the game. The sample configuration describes only a handful of locations. Rooms can contain \"things\" such as keys, swords etc. The AdventureClient program sets up your player and provides a simple text based user interface to allow you to play the game. You can move around rooms and interact with things using a simple command language, saying things such as \"go north\" or \"take brass key\". Why Orleans? Orleans allows the game to be described via very simple C# code while allowing it to scale to a massive multiplayer game. For this motivation to be meaningful, the labyrinth of rooms needs to be very large and need to support a large number of simultaneous players. One value of Orleans is that the service can be designed for growth, the overhead of running it at a small scale is not significant, and you can remain confident that it will scale if the need arises. How is it modeled? Player and Rooms are modeled as grains. These grains allow us to distribute the game with each grain modelling state and functionality. Things such as keys are modeled as plain old objects - they are really just simple immutable data structures that move around rooms and among players; they don't need to be grains. Possible improvements Make the map much, much, bigger Make the brass key unlock something Allow players to message each other Make eating food and drinking water possible and meaningful"
  },
  "docs/tutorials_and_samples/custom_grain_storage.html": {
    "href": "docs/tutorials_and_samples/custom_grain_storage.html",
    "title": "Custom Grain Storage | Microsoft Orleans Documentation",
    "keywords": "Custom Grain Storage Writing a Custom Grain Storage In the tutorial on declarative actor storage, we looked at allowing grains to store their state in an Azure table using one of the built-in storage providers. While Azure is a great place to squirrel away your data, there are many alternatives. In fact, there are so many that there was no way to support them all. Instead, Orleans is designed to let you easily add support for your own form of storage by writing a grain storage. In this tutorial, we'll walk through how to write a simple file-based grain storage. A file system is not the best place to store grains states as it is local, there can be issues with file locks and the last update date is not sufficient to prevent inconsistency. But it's an easy example to help us illustrate the implementation of a Grain Storage . Getting Started An Orleans grain storage is a class that implements IGrainStorage which is included in Microsoft.Orleans.Core NuGet package . We also inherit from ILifecycleParticipant<ISiloLifecycle> which will allow us to subscribe to a particular event in the lifecycle of the silo. We start by creating a class named FileGrainStorage . using Orleans; using System; using Orleans.Storage; using Orleans.Runtime; using System.Threading.Tasks; namespace GrainStorage { public class FileGrainStorage : IGrainStorage, ILifecycleParticipant<ISiloLifecycle> { private readonly string _storageName; private readonly FileGrainStorageOptions _options; private readonly ClusterOptions _clusterOptions; private readonly IGrainFactory _grainFactory; private readonly ITypeResolver _typeResolver; private JsonSerializerSettings _jsonSettings; public FileGrainStorage(string storageName, FileGrainStorageOptions options, IOptions<ClusterOptions> clusterOptions, IGrainFactory grainFactory, ITypeResolver typeResolver) { _storageName = storageName; _options = options; _clusterOptions = clusterOptions.Value; _grainFactory = grainFactory; _typeResolver = typeResolver; } public Task ClearStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { throw new NotImplementedException(); } public Task ReadStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { throw new NotImplementedException(); } public Task WriteStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { throw new NotImplementedException(); } public void Participate(ISiloLifecycle lifecycle) { throw new NotImplementedException(); } } } Prior starting the implementation, we create an option class containing the root directory where the grains states files will be stored under. For that we will create an options file FileGrainStorageOptions : public class FileGrainStorageOptions { public string RootDirectory { get; set; } } The create a constructor containing two fields, storageName to specify which grains should write using this storage [StorageProvider(ProviderName = \"File\")] and directory which would be the directory where the grain states will be saved. IGrainFactory , ITypeResolver will be used in the next section where we will initilize the storage. We also take two options as argument, our own FileGrainStorageOptions and the ClusterOptions . Those will be needed for the implementation of the storage functionalities. We also need JsonSerializerSettings as we are serializing and deserializing in Json format. Json is an implementation detail, it is up to the developer to decide what serialization/deserialization protocol would fit the application. Another common format is binary format. Initializing the storage To initialize the storage, we register an Init function on the ApplicationServices lifecycle. public void Participate(ISiloLifecycle lifecycle) { lifecycle.Subscribe(OptionFormattingUtilities.Name<FileGrainStorage>(_storageName), ServiceLifecycleStage.ApplicationServices, Init); } The Init function is used to set the _jsonSettings which will be used to configure the Json serializer. At the same time we create the folder to store the grains states if it does not exist yet. private Task Init(CancellationToken ct) { // Settings could be made configurable from Options. _jsonSettings = OrleansJsonSerializer.UpdateSerializerSettings(OrleansJsonSerializer.GetDefaultSerializerSettings(_typeResolver, _grainFactory), false, false, null); var directory = new System.IO.DirectoryInfo(_rootDirectory); if (!directory.Exists) directory.Create(); return Task.CompletedTask; } We also provide a common function to construct the filename ensuring uniqueness per service, grain Id and grain type. private string GetKeyString(string grainType, GrainReference grainReference) { return $\"{_clusterOptions.ServiceId}.{grainReference.ToKeyString()}.{grainType}\"; } Reading State To read a grain state, we get the filename using the function we previously defined and combine it to the root directory coming from the options. public async Task ReadStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { var fName = GetKeyString(grainType, grainReference); var path = Path.Combine(_options.RootDirectory, fName); var fileInfo = new FileInfo(path); if (!fileInfo.Exists) { grainState.State = Activator.CreateInstance(grainState.State.GetType()); return; } using (var stream = fileInfo.OpenText()) { var storedData = await stream.ReadToEndAsync(); grainState.State = JsonConvert.DeserializeObject(storedData, _jsonSettings); } grainState.ETag = fileInfo.LastWriteTimeUtc.ToString(); } We use the fileInfo.LastWriteTimeUtc as a ETag which will be used by other functions for inconsistency checks to prevent data loss. Note that for the deserialization, we use the _jsonSettings which was set on the Init function. This is important to be able to serialize/deserialize properly the state. Writing State Writing the state is similar to reading the state. public async Task WriteStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { var storedData = JsonConvert.SerializeObject(grainState.State, _jsonSettings); var fName = GetKeyString(grainType, grainReference); var path = Path.Combine(_options.RootDirectory, fName); var fileInfo = new FileInfo(path); if (fileInfo.Exists && fileInfo.LastWriteTimeUtc.ToString() != grainState.ETag) { throw new InconsistentStateException($\"Version conflict (WriteState): ServiceId={_clusterOptions.ServiceId} ProviderName={_storageName} GrainType={grainType} GrainReference={grainReference.ToKeyString()}.\"); } using (var stream = new StreamWriter(fileInfo.Open(FileMode.Create, FileAccess.Write))) { await stream.WriteAsync(storedData); } fileInfo.Refresh(); grainState.ETag = fileInfo.LastWriteTimeUtc.ToString(); } Similarly as reading, we use _jsonSettings to write the state. The current ETag is used to check against the last updated time in UTC of the file. If the date is different, it means that another activation of the same grain changed the state concurrently. In this situation, we throw an InconsistentStateException which will result in the current activation being killed to prevent overwritting the state previously saved by the other activated grain. Clearing State Clearing the state would be deleting the file if the file exists. public Task ClearStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { var fName = GetKeyString(grainType, grainReference); var path = Path.Combine(_options.RootDirectory, fName); var fileInfo = new FileInfo(path); if (fileInfo.Exists) { if (fileInfo.LastWriteTimeUtc.ToString() != grainState.ETag) { throw new InconsistentStateException($\"Version conflict (ClearState): ServiceId={_clusterOptions.ServiceId} ProviderName={_storageName} GrainType={grainType} GrainReference={grainReference.ToKeyString()}.\"); } grainState.ETag = null; grainState.State = Activator.CreateInstance(grainState.State.GetType()); fileInfo.Delete(); } return Task.CompletedTask; } For the same reason as WriteState , we check for inconsistency before proceeding to delete the file and reset the ETag, we check if the current ETag is the same as the last write time UTC. Putting it Together After that we will create a factory which will allow us to scope the options setting to the provider name and at the same time create an instance of the FileGrainStorage to ease the registration to the service collection. public static class FileGrainStorageFactory { internal static IGrainStorage Create(IServiceProvider services, string name) { IOptionsSnapshot<FileGrainStorageOptions> optionsSnapshot = services.GetRequiredService<IOptionsSnapshot<FileGrainStorageOptions>>(); return ActivatorUtilities.CreateInstance<FileGrainStorage>(services, name, optionsSnapshot.Get(name), services.GetProviderClusterOptions(name)); } } Lastly to register the grain storage, we create an extension on the ISiloHostBuilder which internally register the grain storage as a named service using .AddSingletonNamedService(...) , an extension provided by Orleans.Core . public static class FileSiloBuilderExtensions { public static ISiloHostBuilder AddFileGrainStorage(this ISiloHostBuilder builder, string providerName, Action<FileGrainStorageOptions> options) { return builder.ConfigureServices(services => services.AddFileGrainStorage(providerName, options)); } public static IServiceCollection AddFileGrainStorage(this IServiceCollection services, string providerName, Action<FileGrainStorageOptions> options) { services.AddOptions<FileGrainStorageOptions>(providerName).Configure(options); return services .AddSingletonNamedService(providerName, FileGrainStorageFactory.Create) .AddSingletonNamedService(providerName, (s, n) => (ILifecycleParticipant<ISiloLifecycle>)s.GetRequiredServiceByName<IGrainStorage>(n)); } } Our FileGrainStorage implements two interfaces, IGrainStorage and ILifecycleParticipant<ISiloLifecycle> therefore we need to register two named services for each interfaces: return services .AddSingletonNamedService(providerName, FileGrainStorageFactory.Create) .AddSingletonNamedService(providerName, (s, n) => (ILifecycleParticipant<ISiloLifecycle>)s.GetRequiredServiceByName<IGrainStorage>(n)); This enables us to add the file storage using the extension on the ISiloHostBuilder : var silo = new SiloHostBuilder() .UseLocalhostClustering() .AddFileGrainStorage(\"File\", opts => { opts.RootDirectory = \"C:/TestFiles\"; }) .Build(); Now we will be able to decorate our grains with the provider [StorageProvider(ProviderName = \"File\")] and it will store in the grain state in the root directory set in the options."
  },
  "docs/tutorials_and_samples/Hello-World.html": {
    "href": "docs/tutorials_and_samples/Hello-World.html",
    "title": "Hello World | Microsoft Orleans Documentation",
    "keywords": "Hello World Run the Hello World sample One way to run this sample is to download a local copy of HelloWorld from the Samples/2.0/HelloWorld/ folder . Open two Command Prompt windows and navigate to the HelloWorld folder in each one. Build the project. Start the silo in one window with the command: dotnet run --project src\\SiloHost After the silo is running, start the client in the other window with this: dotnet run --project src\\OrleansClient The silo and client windows will display greetings to each other. How Orleans says Hello In this sample, a client connects with a grain, sends it a greeting and receives a greeting back. The client then prints that greeting and that's that. Simple enough in theory, but since there's distribution involved, there's a bit more to it. There are four projects involved -- one for declaring the grain interfaces, one for the grain implementations, and one for the client, one for the silo host There's one grain interface, in IHello.cs: public interface IHello : Orleans.IGrainWithIntegerKey { Task<string> SayHello(string greeting); } This is simple enough, and we can see that all replies must be represented as a Task or Task in communication interfaces. The implementation, found in HelloGrain.cs, is similarly trivial: public class HelloGrain : Orleans.Grain, HelloWorldInterfaces.IHello { Task<string> HelloWorldInterfaces.IHello.SayHello(string greeting) { return Task.FromResult($\"You said: '{greeting}', I say: Hello!\"); } } The class inherits from the base class Grain , and implements the communication interface defined earlier. Since there is nothing that the grain needs to wait on, the method is not declared async and instead returns its value using Task.FromResult() . The client, which orchestrates the grain code and is found in OrleansClient project, looks like this: //configure the client with proper cluster options, logging and clustering client = new ClientBuilder() .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"HelloWorldApp\"; }) .ConfigureLogging(logging => logging.AddConsole()) .Build(); //connect the client to the cluster, in this case, which only contains one silo await client.Connect(); ... // example of calling grains from the initialized client var friend = client.GetGrain<IHello>(0); var response = await friend.SayHello(\"Good morning, my friend!\"); Console.WriteLine(\"\\n\\n{0}\\n\\n\", response); The silo host, which configures and starts the silo, in SiloHost project looks like this: //define the cluster configuration var builder = new SiloHostBuilder() //configure the cluster with local host clustering .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"HelloWorldApp\"; }) .Configure<EndpointOptions>(options => options.AdvertisedIPAddress = IPAddress.Loopback) .ConfigureLogging(logging => logging.AddConsole()); //build the silo var host = builder.Build(); //start the silo await host.StartAsync();"
  },
  "docs/tutorials_and_samples/index.html": {
    "href": "docs/tutorials_and_samples/index.html",
    "title": "Samples | Microsoft Orleans Documentation",
    "keywords": "Samples Hello, World! A Hello, World! application which demonstrates how to create and use your first grains. Demonstrates How to get started with Orleans How to define and implement grain interface How to get a reference to a grain and call a grain Adventure Before there were graphical user interfaces, before the era of game consoles and massive-multiplayer games, there were VT100 terminals and there was Colossal Cave Adventure , Zork , and Microsoft Adventure . Possibly lame by today's standards, back then it was a magical world of monsters, chirping birds, and things you could pick up. It's the inspiration for this sample. Demonstrates How to structure an application (in this case, a game) using grains How to connect an external client to an Orleans cluster ( ClientBuilder ) Chirper A social network pub/sub system, with short text messages being sent between users. Publishers send out short \"Chirp\" messages (not to be confused with \"Tweets\" , for a variety of legal reasons) to any other users that are following them. Demonstrates How to build a simplified social media / social network application using Orleans How to store state within a grain using grain persistence ( IPersistentState<T> ) Grains which implement multiple grain interfaces Reentrant grains, which allow for multiple grain calls to be executed concurrently, in a single-threaded, interleaving fashion Using a grain observer ( IGrainObserver ) to receive push notifications from grains ## GPS Tracker A service for tracking GPS-equipped IoT devices on a map. Device locations are updated in near-real-time using SignalR and hence this sample demonstrates one approach to integrating Orleans with SignalR. The device updates originate from a device gateway , which is implemented using a separate process which connects to the main service and simulates a number of devices moving in a pseudorandom fashion around an area of San Francisco. Demonstrates How to use Orleans to build an Internet of Things application How Orleans can be co-hosted and integrated with ASP.NET Core SignalR How to broadcast real-time updates from a grain to a set of clients using Orleans and SignalR HanBaoBao An English-Mandarin dictionary Web application demonstrating deployment to Kubernetes, fan-out grain calls, and request throttling. Demonstrates How to build a realistic application using Orleans How to deploy an Orleans-based application to Kubernetes How to integrate Orleans with ASP.NET Core and a Single-page Application JavaScript framework ( Vue.js ) How to implement leaky-bucket request throttling How to load and query data from a database How to cache results lazily and temporarily How to fan-out requests to many grains and collect the results Presence Service A gaming presence service, similar to one of the Orleans-based services built for Halo . A presence service tracks players and game sessions in near-real-time. Demonstrates A simplified version of a real-world use of Orleans Using a grain observer ( IGrainObserver ) to receive push notifications from grains Tic Tac Toe A Web-based Tic-tac-toe game using ASP.NET MVC, JavaScript, and Orleans. Demonstrates How to build an online game using Orleans How to build a basic game lobby system How to access Orleans grains from an ASP.NET Core MVC application Voting A Web application for voting on a set of choices. This sample demonstrates deployment to Kubernetes. The application uses .NET Generic Host to co-host ASP.NET Core and Orleans as well as the Orleans Dashboard together in the same process. Demonstrates How to deploy an Orleans-based application to Kubernetes How to configure the Orleans Dashboard Chat Room A terminal-based chat application built using Orleans Streams . Demonstrates How to build a chat application using Orleans How to use Orleans Streams Bank Account Simulates bank accounts, using ACID transactions to transfer random amounts between a set of accounts. Demonstrates How to use Orleans Transactions to safely perform operations involving multiple stateful grains with ACID guarantees and serializable isolation. Blazor Server and Blazor WebAssembly These two Blazor samples are based on the Blazor introductory tutorials , adapted for use with Orleans. The Blazor WebAssembly sample uses the Blazor WebAssembly hosting model . The Blazor Server sample uses the Blazor Server hosting model . They include an interactive counter, a TODO list, and a Weather service. Demonstrates How to integrate ASP.NET Core Blazor Server with Orleans How to integrate ASP.NET Core Blazor WebAssembly (WASM) with Orleans Stocks A stock price application which fetches prices from a remote service using an HTTP call and caches prices temporarily in a grain. A BackgroundService periodically polls for updates stock prices from various StockGrain grains which correspond to a set of stock symbols. Demonstrates How to use Orleans from within a BackgroundService . How to use timers within a grain How to make external service calls using .NET's HttpClient and cache the results within a grain. Transport Layer Security A Hello, World! application configured to use mutual Transport Layer Security to secure network communication between every server. Demonstrates How to configure mutual-TLS (mTLS) authentication for Orleans Visual Basic Hello World A Hello, World! application using Visual Basic. Demonstrates How to develop Orleans-based applications using Visual Basic F# Hello World A Hello, World! application using F#. Demonstrates How to develop Orleans-based applications using F# Streaming: Pub/Sub Streams over Azure Event Hubs An application using Orleans Streams with Azure Event Hubs as the provider and implicit subscribers. Demonstrates How to use Orleans Streams How to use the [ImplicitStreamSubscription(namespace)] attribute to implicitly subscribe a grain to the stream with the corresponding id How to configure Orleans Streams for use with Azure Event Hubs Streaming: Custom Data Adapter An application using Orleans Streams with a non-Orleans publisher pushing to a stream which a grain consumes via a custom data adapter which tells Orleans how to interpret stream messages. Demonstrates How to use Orleans Streams How to use the [ImplicitStreamSubscription(namespace)] attribute to implicitly subscribe a grain to the stream with the corresponding id How to configure Orleans Streams for use with Azure Event Hubs How to consume stream messages published by non-Orleans publishers by providing a custom EventHubDataAdapter implementation (a custom data adapter)"
  },
  "docs/tutorials_and_samples/overview_helloworld.html": {
    "href": "docs/tutorials_and_samples/overview_helloworld.html",
    "title": "Tutorial 1 Hello World | Microsoft Orleans Documentation",
    "keywords": "Overview: Hello World This overview ties into the Hello World sample application available here . The main concepts of Orleans involve a silo, a client, and one or more grains. Creating an Orleans app involves configuring the silo, configuring the client, and writing the grains. Configuring the silo Silos are configured programmatically via SiloHostBuilder and a number of supplemental option classes. A list of all of the options can be found here. [...] private static async Task<ISiloHost> StartSilo() { // define the cluster configuration var builder = new SiloHostBuilder() .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"HelloWorldApp\"; }) .Configure<EndpointOptions>(options => options.AdvertisedIPAddress = IPAddress.Loopback) .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(HelloGrain).Assembly).WithReferences()) .ConfigureLogging(logging => logging.AddConsole()); var host = builder.Build(); await host.StartAsync(); return host; } Option Used for .UseLocalhostClustering() Configures the client to connect to a silo on the localhost. ClusterOptions ClusterId is the name for the Orleans cluster must be the same for silo and client so they can talk to each other. ServiceId is the ID used for the application and it must not change across deployments EndpointOptions This tells the silo where to listen. For this example, we are using a loopback . ConfigureApplicationParts Adds the grain class and interface assembly as application parts to your orleans application. After loading the configurations, the SiloHost is built and then started asynchronously. Configuring the client Similar to the silo, the client is configured via ClientBuilder and a similar collection of option classes. private static async Task<IClusterClient> StartClientWithRetries() { attempt = 0; IClusterClient client; client = new ClientBuilder() .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"HelloWorldApp\"; }) .ConfigureLogging(logging => logging.AddConsole()) .Build(); await client.Connect(RetryFilter); Console.WriteLine(\"Client successfully connect to silo host\"); return client; } Option Used for .UseLocalhostClustering() Same as for SiloHost ClusterOptions Same as for SiloHost A more in-depth guide to configuring your client can be found in the Client Configuration section of the Configuration Guide. Writing a grain Grains are the key primitives of the Orleans programming model. Grains are the building blocks of an Orleans application, they are atomic units of isolation, distribution, and persistence. Grains are objects that represent application entities. Just like in the classic Object Oriented Programming, a grain encapsulates state of an entity and encodes its behavior in the code logic. Grains can hold references to each other and interact by invoking each other’s methods exposed via interfaces. You can read more about them in the Core Concepts section of the Orleans documentation. This is the main body of code for the Hello World grain: [...] namespace HelloWorld.Grains { public class HelloGrain : Orleans.Grain, IHello { Task<string> IHello.SayHello(string greeting) { logger.LogInformation($\"SayHello message received: greeting = '{greeting}'\"); return Task.FromResult($\"You said: '{greeting}', I say: Hello!\"); } } } A grain class implements one or more grain interfaces, as you can read here, in the Grains section. [...] namespace HelloWorld.Interfaces { public interface IHello : Orleans.IGrainWithIntegerKey { Task<string> SayHello(string greeting); } } How the parts work together This programming model is built as part of our core concept of distributed Object Oriented Programming. SiloHost is started first. Then, the OrleansClient program is started. The Main method of OrleansClient calls the method that starts the client, StartClientWithRetries(). The client is passed to the DoClientWork() method. private static async Task DoClientWork(IClusterClient client) { // example of calling grains from the initialized client var friend = client.GetGrain<IHello>(0); var response = await friend.SayHello(\"Good morning, my friend!\"); Console.WriteLine(\"\\n\\n{0}\\n\\n\", response); } At this point, OrleansClient creates a reference to the IHello grain and calls its SayHello() method through its interface, IHello. This call activates the grain in the silo. OrleansClient sends a greeting to the activated grain. The grain returns the greeting as a response to OrleansClient, which OrleansClient displays on the console. Running the sample app To run the sample app, refer to the Readme."
  },
  "docs/tutorials_and_samples/testing.html": {
    "href": "docs/tutorials_and_samples/testing.html",
    "title": "Unit Testing | Microsoft Orleans Documentation",
    "keywords": "Unit Testing This tutorial shows how to unit test your grains to make sure they behave correctly. There are two main ways to unit test your grains, and the method you choose will depend on the type of functionality you are testing. The Microsoft.Orleans.TestingHost NuGet package can be used to create test silos for your grains, or you can use a mocking framework like Moq to mock parts of the Orleans runtime that your grain interacts with. Using TestCluster The Microsoft.Orleans.TestingHost NuGet package contains TestCluster which can be used to create an in-memory cluster, comprised of two silos by default, which can be used to test grains. using System; using System.Threading.Tasks; using Orleans; using Orleans.TestingHost; using Xunit; namespace Tests { public class HelloGrainTests { [Fact] public async Task SaysHelloCorrectly() { var builder = new TestClusterBuilder(); var cluster = builder.Build(); cluster.Deploy(); var hello = cluster.GrainFactory.GetGrain<IHelloGrain>(Guid.NewGuid()); var greeting = await hello.SayHello(); cluster.StopAllSilos(); Assert.Equal(\"Hello, World\", greeting); } } } Due to the overhead of starting an in-memory cluster you may wish to create a TestCluster and reuse it among multiple test cases. For example this can be done using xUnit's class or collection fixtures (see https://xunit.github.io/docs/shared-context.html for more details). In order to share a TestCluster between multiple test cases, first create a fixture type: public class ClusterFixture : IDisposable { public ClusterFixture() { var builder = new TestClusterBuilder(); var cluster = builder.Build(); this.Cluster.Deploy(); } public void Dispose() { this.Cluster.StopAllSilos(); } public TestCluster Cluster { get; private set; } } Next create a collection fixture: [CollectionDefinition(ClusterCollection.Name)] public class ClusterCollection : ICollectionFixture<ClusterFixture> { public const string Name = \"ClusterCollection\"; } You can now reuse a TestCluster in your test cases: using System; using System.Threading.Tasks; using Orleans; using Xunit; namespace Tests { [Collection(ClusterCollection.Name)] public class HelloGrainTests { private readonly TestCluster _cluster; public HelloGrainTests(ClusterFixture fixture) { _cluster = fixture.Cluster; } [Fact] public async Task SaysHelloCorrectly() { var hello = _cluster.GrainFactory.GetGrain<IHelloGrain>(Guid.NewGuid()); var greeting = await hello.SayHello(); Assert.Equal(\"Hello, World\", greeting); } } } xUnit will call the Dispose method of the ClusterFixture type when all tests have been completed and the in-memory cluster silos will be stopped. TestCluster also has a constructor which accepts TestClusterOptions that can be used to configure the silos in the cluster. If you are using Dependency Injection in your Silo to make services available to Grains, you can use this pattern as well: public class ClusterFixture : IDisposable { public ClusterFixture() { var builder = new TestClusterBuilder(); builder.AddSiloBuilderConfigurator<TestSiloConfigurations>(); this.Cluster = builder.Build(); this.Cluster.Deploy(); } public void Dispose() { this.Cluster.StopAllSilos(); } public TestCluster Cluster { get; private set; } } public class TestSiloConfigurations : ISiloConfigurator { public void Configure(ISiloBuilder siloBuilder) { siloBuilder.ConfigureServices(services => { services.AddSingleton<T, Impl>(...); }); } } Using Mocks Orleans also makes it possible to mock many parts of system, and for many of scenarios this is the easiest way to unit test grains. This approach does have limitations (e.g. around scheduling reentrancy and serialization), and may require that grains include code used only by your unit tests. The Orleans TestKit provides an alternative approach which side-steps many of these limitations. For example, let us imagine that the grain we are testing interacts with other grains. In order to be able to mock those other grains we also need to mock the GrainFactory member of the grain under test. By default GrainFactory is a normal protected property, but most mocking frameworks require properties to be public and virtual to be able to mock them. So the first thing we need to do is make GrainFactory both public and virtual property: public new virtual IGrainFactory GrainFactory { get { return base.GrainFactory; } } Now we can create our grain outside of the Orleans runtime and use mocking to control the behaviour of GrainFactory : using System; using System.Threading.Tasks; using Orleans; using Xunit; using Moq; namespace Tests { public class WorkerGrainTests { [Fact] public async Task RecordsMessageInJournal() { var data = \"Hello, World\"; var journal = new Mock<IJournalGrain>(); var worker = new Mock<WorkerGrain>(); worker .Setup(x => x.GrainFactory.GetGrain<IJournalGrain>(It.IsAny<Guid>())) .Returns(journal.Object); await worker.DoWork(data) journal.Verify(x => x.Record(data), Times.Once()); } } } Here we create our grain under test, WorkerGrain , using Moq which means we can then override the behaviour of the GrainFactory so that it returns a mocked IJournalGrain . We can then verify that our WorkerGrain interacts with the IJournalGrain as we expect."
  },
  "docs/tutorials_and_samples/tutorial_1.html": {
    "href": "docs/tutorials_and_samples/tutorial_1.html",
    "title": "Tutorial One | Microsoft Orleans Documentation",
    "keywords": "Tutorial One - Creating a Minimal Orleans Application This tutorial provides step by step instructions for creating a basic functioning Orleans application. It is designed to be self-contained and minimalistic, with the following traits: It relies only on NuGet packages It has been tested in Visual Studio 2017 using Orleans 2.2.0 It has no reliance on external storage Keep in mind that this is only a tutorial and lacks appropriate error handling and other goodies that would be useful for a production environment. However, it should help the readers get a real hands-on with regards to the structure of Orleans and allow them to focus their continued learning on the parts most relevant to them. Project Setup For this tutorial we’re going to create 4 projects: a library to contain the grain interfaces a library to contain the grain classes a console application to host our Silo a console application to host our Client After following this tutorial, the complete Solution should look like this: Create the structure in Visual Studio Note: You can use the default project types in c# for each of these projects. You will replace the default code with the code given for each project, below. You will also probably need to add using statements. Start by creating a Console App (.NET Core) project in a new solution. Call the project part Silo and name the solution OrleansHelloWorld . Add another Console App (.NET Core) project and name it Client . Add a Class Library (.NET Standard) and name it GrainInterfaces . Add another Class Library (.NET Standard) and name it Grains . Delete default source files Delete Class1.cs from Grains Delete Class1.cs from GrainInterfaces Add References Grains references GrainInterfaces . Silo references GrainInterfaces and Grains . Client references GrainInterfaces . Add Orleans NuGet Packages Project Nuget Package Silo Microsoft.Orleans.Server Silo Microsoft.Extensions.Logging.Console Client Microsoft.Extensions.Logging.Console Client Microsoft.Orleans.Client Grain Interfaces Microsoft.Orleans.Core.Abstractions Grain Interfaces Microsoft.Orleans.CodeGenerator.MSBuild Grains Microsoft.Orleans.CodeGenerator.MSBuild Grains Microsoft.Orleans.Core.Abstractions Grains Microsoft.Extensions.Logging.Abstractions Microsoft.Orleans.Server and Microsoft.Orleans.Client are meta-packages that bring dependency that you will most likely need on the Silo and Client side. Microsoft.Orleans.Core.Abstractions is needed everywhere. It included in both Microsoft.Orleans.Server and Microsoft.Orleans.Client . Microsoft.Orleans.CodeGenerator.MSBuild automatically generates code that is needed to make calls to grains across machine boundaries. So it is needed in both GrainInterfaces and Grains projects. Define a Grain Interface In the GrainInterfaces project, add a IHello.cs code file and define the following IHello interface in it: using System.Threading.Tasks; namespace OrleansBasics { public interface IHello : Orleans.IGrainWithIntegerKey { Task<string> SayHello(string greeting); } } Define a Grain Class In the Grains project, add a HelloGrain.cs code file and define the following class in it: using Microsoft.Extensions.Logging; using System.Threading.Tasks; namespace OrleansBasics { public class HelloGrain : Orleans.Grain, IHello { private readonly ILogger logger; public HelloGrain(ILogger<HelloGrain> logger) { this.logger = logger; } Task<string> IHello.SayHello(string greeting) { logger.LogInformation($\"\\n SayHello message received: greeting = '{greeting}'\"); return Task.FromResult($\"\\n Client said: '{greeting}', so HelloGrain says: Hello!\"); } } } Create the Silo – Program.cs At this step, we add code to initialize a server that will host and run our grains - a silo. We will use the development clustering provider here, so that we can run everything locally, without a dependency on external storage systems. You can find more information about that in the Local Development Configuration page of the Orleans documentation. We will run a cluster with a single silo in it. Add the following code to Program.cs of the Silo project: using System; using System.Threading.Tasks; using Microsoft.Extensions.Logging; using Orleans; using Orleans.Configuration; using Orleans.Hosting; namespace OrleansBasics { public class Program { public static int Main(string[] args) { return RunMainAsync().Result; } private static async Task<int> RunMainAsync() { try { var host = await StartSilo(); Console.WriteLine(\"\\n\\n Press Enter to terminate...\\n\\n\"); Console.ReadLine(); await host.StopAsync(); return 0; } catch (Exception ex) { Console.WriteLine(ex); return 1; } } private static async Task<ISiloHost> StartSilo() { // define the cluster configuration var builder = new SiloHostBuilder() .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"OrleansBasics\"; }) .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(HelloGrain).Assembly).WithReferences()) .ConfigureLogging(logging => logging.AddConsole()); var host = builder.Build(); await host.StartAsync(); return host; } } } Create the Client – Program.cs Finally, we need to configure a client for communicating with our grains, connect it to the the cluster (with a single silo in it), and invoke the grain. Note that the clustering configuration must match the one we used for the silo. There is more information about the client in the Clusters and Clients section of the Orleans documentation. using Microsoft.Extensions.Logging; using Orleans; using Orleans.Configuration; using System; using System.Threading.Tasks; namespace OrleansBasics { public class Program { static int Main(string[] args) { return RunMainAsync().Result; } private static async Task<int> RunMainAsync() { try { using (var client = await ConnectClient()) { await DoClientWork(client); Console.ReadKey(); } return 0; } catch (Exception e) { Console.WriteLine($\"\\nException while trying to run client: {e.Message}\"); Console.WriteLine(\"Make sure the silo the client is trying to connect to is running.\"); Console.WriteLine(\"\\nPress any key to exit.\"); Console.ReadKey(); return 1; } } private static async Task<IClusterClient> ConnectClient() { IClusterClient client; client = new ClientBuilder() .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"OrleansBasics\"; }) .ConfigureLogging(logging => logging.AddConsole()) .Build(); await client.Connect(); Console.WriteLine(\"Client successfully connected to silo host \\n\"); return client; } private static async Task DoClientWork(IClusterClient client) { // example of calling grains from the initialized client var friend = client.GetGrain<IHello>(0); var response = await friend.SayHello(\"Good morning, HelloGrain!\"); Console.WriteLine($\"\\n\\n{response}\\n\\n\"); } } } Run the application Build the solution and run the Silo. After you get the confirmation message that the Silo is running (\"Press enter to terminate...\"), run the Client. Success looks like this: Further Reading List of Orleans Packages Orleans Configuration Guide Orleans Best Practices"
  },
  "docs/whats_new_in_orleans.html": {
    "href": "docs/whats_new_in_orleans.html",
    "title": "What's new in Orleans | Microsoft Orleans Documentation",
    "keywords": "What's new in Orleans? v2.3.2 May 9th 2019 Three bug fixes. v2.3.1 April 26th 2019 A few improvements, a bug fix, and batch stream API added back. v2.3.0 March 20th 2019 Major improvements Support for the ASP.NET Core hosting API (Microsoft.Extensions.Hosting). Thanks to @galvesribeiro! Replacement of the custom implementation of named options with Microsoft.Extensions.Options. EventHub stream provider got upgrade to EvenHub 2.2.1 and is also compatible with 3.0.0. Old dead entries in the cluster membership table now get automatically cleaned up, which is helpful for hosting environments that use new IP endpoints for restarted silos. Hosted client that enables efficient hosting of frontend code within the silo process is now enabled by default. Support for IHostEnvironmentStatistics on Linux, which enables CPU and memory metrics as well as load shedding. Thanks to @martinothamar! v2.3.0-rc2 March 13th 2019 Refactored stream batch behaviors to support batch consumption. (#5425) is the only change. While technically it is breaking due to the changes to the batch streaming API, it shouldn't break any working application code because the batching functionality wasn't fully wired previously. No breaking change in the wire protocol or persistence. This release is backward-compatible with 2.x releases. v2.3.0-rc1 March 5th 2019 Major improvements Support for the ASP.NET Core hosting API (Microsoft.Extensions.Hosting). Replacement of the custom implementation of named options with Microsoft.Extensions.Options. EventHub stream provider got upgrade to EvenHub 2.2.1 and is also compatible with 3.0.0. Old dead entries in the cluster membership table now get automatically cleaned up, which is helpful for hosting environments that use new IP endpoints for restarted silos. Hosted client that enables efficient hosting of frontend code within the silo process is now enabled by default. v1.5.7 February 28th 2019 Two fixes backported from v2.x Non-breaking bug fixes Fixes for Multi-Cluster Support (#3974) Add GSI cache maintenance and tests (#5184) v2.2.0 December 13th 2018 This release is primarily about bringing support for ACID cross-grain transactions to production-ready quality. This release includes no breaking changes and is backward compatible with 2.0.* releases, which allows for in-place upgrade of a running cluster. v2.1.0 September 28th 2018 Major changes New scheduler ( #3792 ) Hosted Client ( #3362 ) Distributed Transaction Manager ( #3820 , #4502 , #4538 , #4566 , #4568 , #4591 , #4599 , #4613 , #4609 , #4616 , #4608 , #4628 , #4638 , #4685 , #4714 , #4739 , #4768 , #4799 , #4781 , #4810 , #4820 , #4838 , #4831 , #4871 , #4887 ) New Code Generator ( #4934 , #5010 , #5011 ) Support for Transfer of Coordination in transactions ( #4860 , #4894 , #4949 , #5026 , #5024 ) v1.5.6 September 27th 2018 Improvements and bug fixes since 1.5.5. Non-breaking improvements Make MaxSockets in SocketManager configurable #5033 . v2.1.0-rc2 September 21st 2018 Major changes New Code Generator ( #4934 , #5010 , #5011 ). v2.1.0-rc1 September 14th 2018 Major changes Transactions (beta2) ( #4851 , #4923 , #4951 , #4950 , #4953 ) Support for Transfer of Coordination in transaction ( #4860 , #4894 , #4949 ) v1.5.5 September 7th 2018 Improvements and bug fixes since 1.5.4. Non-breaking bug fixes Fix programmatic subscribe bugs ( #4943 - #3843 ) Propagate message serialization errors to callers ( #4944 - #4907 ) Breaking bug fixes Add StreamSubscriptionHandleFactory to subscribe on behalf feature ( #4943 - #3843 ). While technically a breaking change, it only impacts users of the programmatic subscriptions feature that tried to use it with SMS stream by fixing that scenario (along with #3843 ). v2.0.4 August 7th 2018 Non-breaking bug fixes Use netcoreapp2.0 for msbuild target dll if using dotnet core msbuild but targeting full .net ( #4895 ) v2.1.0 August 28th 2018 Major changes New scheduler ( #3792 ) Hosted Client ( #3362 ) Distributed Transaction Manager (beta)( #3820 , #4502 , #4538 , #4566 , #4568 , #4591 , #4599 , #4613 , #4609 , #4616 , #4608 , #4628 , #4638 , #4685 , #4714 , #4739 , #4768 , #4799 , #4781 , #4810 , #4820 , #4838 , #4831 , #4871 , #4887 ) v2.0.4 August 7th 2018 Improvements and bug fixes since 2.0.3. Non-breaking bug fixes Workaround for CoreFx/#30781 when running on .NET Core ( #4736 ) Fix for .NET Core 2.1 build-time code generation ( #4673 ) v1.5.4 June 13th 2018 v2.0.3 May 14th 2018 This is a first patch release with a partial build -- only 9 NuGet packages got updated: Microsoft.Orleans.OrleansRuntime Microsoft.Orleans.OrleansServiceBus Microsoft.Orleans.Runtime.Legacy Microsoft.Orleans.OrleansCodeGenerator.Build Microsoft.Orleans.Core.Legacy Microsoft.Orleans.Transactions Microsoft.Orleans.OrleansCodeGenerator Microsoft.Orleans.Core Microsoft.Orleans.TestingHost The rest of the packages stayed unchanged at 2.0.0, except for the Microsoft.Orleans.ServiceFabric meta-package which is at 2.0.2. v2.0.0 March 28th 2018 Major changes (since 2.0.0-rc2) All included providers obtain ServiceId and ClusterId from the global ClusterOptions and do not have those properties on their own options classes (#4235, #4277, 4290) Use string for ServiceId instead of Guid (#4262) v2.0.0-rc2 March 12th 2018 Major changes (since 2.0.0-rc1) A new \"facade\" API for easier configuration of various aspects of stream providers: Persistent stream configurators v2.0.0-rc1 February 27th 2018 Major changes (since 2.0.0-beta3) New provider lifecycle model to replace the old one Builder pattern and options-based configuration of components and extension v2.0.0-beta3 December 21st 2017 Community Virtual Meetup #15 Orleans 2.0 with the core team December 13th 2017 Presentation v2.0.0-beta2 December 12th 2017 v1.5.3 December 8th 2017 v2.0.0-beta1 October 26th 2017 Major new features Most packages are now targeting .NET Standard 2.0 (which mean they can be used from either .NET Framework or .NET Core 2.0) and on non-Windows platforms. v1.5.2 October 17th 2017 v1.5.1 August 28th 2017 v1.5.0 July 6th 2017 Major new features Non-static grain client via ClientBuilder enables connecting to multiple Orleans cluster from the same app domain and connecting to other clusters from within a silo. Support for versioning of grain interfaces for non-downtime upgrades. Support for custom grain placement strategies and directors. Support for hash-based grain placement. v1.4.2 June 9th 2017 v1.4.1 March 27th 2017 Community Virtual Meetup #14 Orleans FSM with John Azariah March 22nd 2017 v1.4.0 February 21st 2017 Major new features Revamped JournaledGrain for event sourcing with support for geo-distributed log-based consistency providers. Abstraction of Grain Services with fixed-placed per-silo application components with their workload partitioned via cluster consistency ring. Support for heterogeneous silos with non-uniform distribution of available grain classes. Cluster membership provider for Service Fabric. Community Virtual Meetup #13 Upgrading Orleans Applications with Sergey Bykov and team February 8th 2017 Presentation v1.4.0-beta February 1st 2017 Major new features Revamped JournaledGrain for event sourcing with support for geo-distributed log-based consistency providers. Abstraction of Grain Services with fixed-placed per-silo application components with their workload partitioned via cluster consistency ring. Support for heterogeneous silos with non-uniform distribution of available grain classes. Cluster membership provider for Service Fabric. Community Virtual Meetup #12 Deploying Orleans with Jakub Konecki December 8th 2016 Presentation v1.3.1 November 15th 2016 Community Virtual Meetup #11 A monitoring and visualisation show with Richard Astbury , Dan Vanderboom and Roger Creyke October 13th 2016 v1.3.0 October 11th 2016 v1.2.4 October 5th 2016 v1.3.0-beta2 September 27th 2016 Notable new features Support for geo-distributed multi-cluster deployments #1108 #1109 #1800 Added new Amazon AWS basic Orleans providers #2006 Support distributed cancellation tokens in grain methods #1599 Community Virtual Meetup #10 The roadmap to Orleans 2.0 with the core team August 25th 2016 v1.2.3 July 11th 2016 v1.2.2 June 15th 2016 v1.2.1 May 19th 2016 v1.2.0 May 4th 2016 v1.2.0-beta April 18th 2016 Major improvements Added an EventHub stream provider based on the same code that is used in Halo 5. Increased throughput by between 5% and 26% depending on the scenario. Migrated all but 30 functional tests to GitHub. Grain state doesn't have to extend GrainState anymore (marked as [Obsolete] ) and can be a simple POCO class. Added support for per-grain-class and global server-side interceptors. Added support for using Consul 0.6.0 as a Membership Provider. Support C# 6. Switched to xUnit for testing as a step towards CoreCLR compatibility. v1.1.3 March 9th 2016 Community Virtual Meetup #9 Nehme Bilal and Reuben Bond talk about deploying Orleans with YAMS and Service Fabric Fabruary 26st 2016 Community Virtual Meetup #8.5 Networking discussion hosted by Jason Bragg February 11th 2016 Community Virtual Meetup #8 Orleans core team present the roadmap January 21st 2016 v1.1.2 January 20th 2016 v1.1.1 January 11th 2016 Community Virtual Meetup #7 Christmas Special - Yevhen Bobrov on Orleankka December 17th 2015 v1.1.0 December 14nd 2015 Community Virtual Meetup #6 MSR PhDs on Geo Distributed Orleansp October 23rd 2015 v1.0.10 September 22nd 2015 v1.0.9 July 15th 2015 v1.0.8 May 26th 2015 Community Virtual Meetup #5 Gabriel Kliot on the new Orleans Streaming API May 22nd 2015 v1.0.7 May 15th 2015 Community Virtual Meetup #4 Reuben Bond on using Orleans at FreeBay April 15th 2015 v1.0.5 March 30th 2015 Community Virtual Meetup #3 Yevhen Bobrov on a Uniform API for Orleans March 6th 2015 Community Virtual Meetup #2 Orleans team live Q&A and roadmap January 12th 2015 Orleans Open Source v1.0 Update (January 2015) Community Virtual Meetup #1 Jakub Konecki on Event Sourced Grains December 18th 2014"
  },
  "index.html": {
    "href": "index.html",
    "title": "Orleans is a cross-platform framework for building robust, scalable distributed applications | Microsoft Orleans Documentation",
    "keywords": "Orleans is a cross-platform framework for building robust, scalable distributed applications Orleans builds on the developer productivity of .NET and brings it to the world of distributed applications, such as cloud services. Orleans scales from a single on-premises server to globally distributed, highly-available applications in the cloud. Orleans takes familiar concepts like objects, interfaces, async/await, and try/catch and extends them to multi-server environments. As such, it helps developers experienced with single-server applications transition to building resilient, scalable cloud services and other distributed applications. For this reason, Orleans has often been referred to as \"Distributed .NET\". It was created by Microsoft Research and introduced the Virtual Actor Model as a novel approach to building a new generation of distributed systems for the Cloud era. The core contribution of Orleans is its programming model which tames the complexity inherent to highly-parallel distributed systems without restricting capabilities or imposing onerous constraints on the developer. Documentation is located here Chinese translation of the documentation can be found here here"
  }
}