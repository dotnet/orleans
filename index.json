{
  "Documentation/deployment/cluster_management.html": {
    "href": "Documentation/deployment/cluster_management.html",
    "title": "Cluster Management in Orleans | Microsoft Orleans Documentation",
    "keywords": "Cluster Management in Orleans Orleans provides cluster management via a built-in membership protocol, which we sometimes refer to as Silo Membership . The goal of this protocol is for all silos (Orleans servers) to agree on the set of currently alive silos, detect failed silos, and allow new silos to join the cluster. The protocol relies on an external service to provide an abstraction of MembershipTable . MembershipTable is a flat No-SQL like durable table that we use for 2 purposes. First, it is used as a rendezvous point for silos to find each other and Orleans clients to find silos. Second, it is used to store the current membership view (list of alive silos) and helps coordinate the agreement on the membership view. We currently have 6 implementations of the MembershipTable : based on Azure Table Storage , SQL server, Apache ZooKeeper , Consul IO , AWS DynamoDB , and in-memory emulation for development. In addition to the MembershipTable each silo participates in fully distributed peer-to-peer membership protocol that detects failed silos and reaches agreement on a set alive silos. We start by describing the internal implementation of the Orleans's membership protocol below and later on describe the implementation of the MembershipTable . The Basic Membership Protocol: Upon startup every silo writes itself into a well-known MembershipTable (passed via config). A combination of silo identity ( ip:port:epoch ) and service deployment id are used as unique keys in the table. Epoch is just time in ticks when this silo started, and as such ip:port:epoch is guaranteed to be unique in a given Orleans deployment. Silos monitor each other directly, via application pings (\"are you alive\" heartbeats ). Pings are sent as direct messages from silo to silo, over the same TCP sockets that silos communicate. That way, pings fully correlate with actual networking problems and server health. Every silo pings X other silos. A silo picks whom to ping by calculating consistent hashes on other silos' identity, forming a virtual ring of all identities and picking X successor silos on the ring (this is a well-known distributed technique called consistent hashing and is widely used in many distributed hash tables, like Chord DHT ). If a silo S does not get Y ping replies from a monitored servers P, it suspects it by writing its timestamped suspicion into P’s row in the MembershipTable . If P has more than Z suspicions within K seconds, then S writes that P is dead into P’s row, and broadcasts a request for all silos to re-read the membership table (which they’ll do anyway periodically). In more details: 5.1 Suspicion is written to the MembershipTable , in a special column in the row corresponding to P. When S suspects P it writes: “at time TTT S suspected P”. 5.2 One suspicion is not enough to declare P as dead. You need Z suspicions from different silos in a configurable time window T, typically 3 minutes, to declare P as dead. The suspicion is written using optimistic concurrency control provided by the MembershipTable . 5.3 The suspecting silo S reads P's row. 5.4 If S is the last suspector (there have already been Z-1 suspectors within time period T, as written in the suspicion column), S decides to declare P as Dead. In this case, S adds itself to list of suspectors and also writes in P's Status column that P is Dead. 5.5 Otherwise, if S is not the last suspector, S just adds itself to the suspectors column. 5.6 In either case the write back uses the version number or etag that was read, so the updates to this row are serialized. In case the write has failed due to version/etag mismatch, S retries (read again, and try to write, unless P was already marked dead). 5.7 At a high level this sequence of \"read, local modify, write back\" is a transaction. However, we are not using storage transactions to do that. “Transaction” code executes locally on a server and we use optimistic concurrency provided by the MembershipTable to ensure isolation and atomicity. Every silo periodically reads the entire membership table for its deployment. That way silos learn about new silos joining and about other silos being declared dead. Configuration : we provide a default configuration, which was hand tuned during our production usage in Azure. Currently the default is: every silo is monitored by 3 other silos, 2 suspicions are enough to declare a silo dead, suspicions only from last 3 minutes (otherwise they are outdated). Pings are send every 10 seconds and you needs to miss 3 pings to suspect a silo. Enforcing Perfect Failure detection – it is theoretically possible that a silo will be declared dead if it lost communication with other silos, while the silo process itself is still running. To solve this problem once the silo is declared dead in the table it is considered dead by everyone, even if it is in fact not dead (just partitioned temporarily or heartbeat messages got lost). Everyone stops communicating with it and once it learns that it is dead (by reading its own new status from the table) it commits suicide and shuts down its process. As a result, there must be an infrastructure in place to restart the silo as a new process (a new epoch number is generated upon start). When it's hosted in Azure, that happens automatically. When it isn't, another infrastructure is required. For example, a Windows Service configured to auto restart on failure. Optimization to reduce the frequency of periodical table reads and speed up all silos learning about new joining silos and dead silos . Every time any silo writes anything successfully to the table (suspicion, new join, …) it also broadcasts to all other silos – “go and reread the table now”. The silo does NOT tell others what it wrote in the table (since this information could already be outdated/wrong), it just tells them to re-read the table. That way we learn very quickly about membership changes without the need to wait for the full periodic read cycle. We still need the periodic read, in case the “re-read the table” message gets lost. Properties of the Basic Membership Protocol and FAQ: Can handle any number of failures – our algorithm can handle any number of failures (that is, f<=n), including full cluster restart. This is in contrast with “traditional” Paxos based solutions, which require quorum, which is usually a majority. We have seen in production situations when more than half of the silos were down. Our system stayed functional, while Paxos based membership would not be able to make progress. Traffic to the table is very light - The actual pings go directly between servers and not to the table. This would generate a lot of traffic plus would be less accurate from the failure detection perspective - if a silo could not reach the table, it would miss to write its I am alive heartbeat and others would kill him. Tunable accuracy vs. completeness – both perfect and accurate failure detection is not possible in general . One usually wants an ability to tradeoff accuracy (don’t want to declare a silo that is really alive as dead) with completeness (want to declare dead a silo that is indeed dead as soon as possible). The configurable #votes to declare dead and #missed pings allows to trade those two. Scale - the basic protocol can handle thousands and probably even tens of thousands of servers. This is in contrast with traditional Paxos based solutions, such as group communication protocols, which are known not to scale beyond tens. Diagnostics - the table is also very convenient for diagnostics and troubleshooting. System administrator can instantaneously find in the table the current list of alive silos, as well as see the history of all killed silos and suspicions. This is especially useful when diagnosing problems. Why do we need reliable persistent storage for implementation of the MembershipTable ? - we use persistent storage (Azure table, SQL server, AWS DynamoDB, Apache ZooKeeper or Consul IO KV) for the MembershipTable for 2 purposes. First, it is used as a rendezvous point for silos to find each other and Orleans clients to find silos. Second, we use the reliable storage to help us coordinate the agreement on the membership view. While we perform failure detection directly in a peer to peer fashion between the silos, we store the membership view in a reliable storage and use the concurrency control mechanism provided by this storage to reach agreement of who is alive and who is dead. That way, in a sense, our protocol outsources the hard problem of distributed consensus to the cloud. In that we fully utilize the power of the underlying cloud platform, using it truly as \"Platform as a Service\". What happens if the table is not accessible for some time? (storage service is down, unavailable, or there are communication problems with it) – our protocol will NOT declare silos as dead by mistake in such a case. Currently operational silos will keep working without any problems. However, we won't be able to declare a silo dead (if we detected some silo is dead via missed pings we won’t be able to write this fact to the table) and also won't be able to allow new silos to join. So completeness will suffer, but accuracy will not - partitioning from the table will never cause us to declare silo as dead by mistake. Also, in case of a partial network partition (if some silos can access the table and some not), it could happen that we will declare a dead silo as dead, but it will take some time until all other silos learn about it. So detection could be delayed, but we will never wrongly kill someone due to table un-availability. Direct IAmAlive writes into the table for diagnostics only - in addition to heartbeats that are sent between the silos, each silo also periodically updates an \"I Am Alive\" column in his row in the table. This \"I Am Alive\" column is only used for manual troubleshooting and diagnostics and is not used by the membership protocol itself. It is usually written at much lower frequency (once every 5 minutes) and serves as a very useful tool for system administrators to check the liveness of the cluster or easily find out when the silo was last alive. Extension to totally order membership views: The basic membership protocol described above was later extended to support totally ordered membership views. We will briefly describe the reasons for this extension and how it is implemented. The extension does not change anything in the above design, just adds an additional property that all membership configurations are globally totally ordered. Why it is useful to totally order membership views? This allows serializing the joining of new silos to the cluster. That way, when a new silo joins the cluster it can validate two-way connectivity to every other silo that has already started. If some of the already joined silos do not answer it (potentially indicating a network connectivity problem with the new silo), the new silo is not allowed to join. This ensures that at least when a silo starts, there is a full connectivity between all silos in the cluster (this is implemented). Higher level protocols in the silo, such as distributed grain directory, can utilize the fact that membership views are ordered and use this information to perform smarter duplicate activations resolution. In particular, when directory finds out that 2 activations were created when membership was in flux, it may decide to deactivate the older activation that was created based on the now-outdated membership information (this is currently not implemented). Extended Membership Protocol: For implementation of this feature we utilize the support for transactions over multiple rows that is provided by the MembershipTable .. We add a membership-version row to the table that tracks table changes. When silo S wants to write suspicion or death declaration for silo P: 3.1 S reads the latest table content. If P is already dead, do nothing. Otherwise, 3.2 In the same transaction, write the changes to P's row as well as increment the version number and write it back to the table. 3.3 Both writes are conditioned with eTags. 3.4 If transaction aborts due to eTag mismatch on either P's row or on the version row, attempt again. All writes to the table modify and increment the version row. That way all writes to the table are serialized (via serializing the updates to the version row) and since silos only increment the version number, the writes are also totally ordered in increasing order. Scalability of the Extended Membership Protocol: In the extended version of the protocol all writes are serialized via one row. This can potentially hurt the scalability of the cluster managemenet protocol, since it increases the risk of conflicts between concurrent table writes. To partially mitigate this problem silos retry all their writes to the table by using exponential backoff. We have observed the extended protocols to work smoothly in production environment in Azure with up to 200 silos. However, we do think the protocol might have problems to scale beyond a thousand silos. In such large setups the updates to version row may be easily disabled, essentially maintaining the rest of the cluster managemenet protocol and giving up on the total ordering property. Please also note that we refer here to the scalability of the cluster management protocol, not the rest of Orleans. We believe that other parts of the Orleans runtime (messaging, distributed directory, grain hosting, client to gateway connectivity) are scalable way beyond hundreds of silos. Membership Table: As already mentioned, MembershipTable is used as a rendezvous point for silos to find each other and Orleans clients to find silos and also helps coordinate the agreement on the membership view. We currently have 6 implementation of the MembershipTable : based on Azure Table, SQL server, Apache ZooKeeper, Consul IO, AWS DynamoDB, and in-memory emulation for development. The interface for MembershipTable is defined in IMembershipTable . Azure Table Storage - in this implementation we use Azure deployment ID as partition key and the silo identity ( ip:port:epoch ) as row key. Together they guarantee a unique key per silo. For concurrency control we use optimistic concurrency control based on Azure Table ETags . Every time we read from the table we store the etag for every read row and use that eTag when we try to write back. etags are automatically assigned and checked by Azure Table service on every write. For multi-row transactions we utilize the support for batch transactions provided by Azure table , which guarantees serializale transactions over rows with the same partition key. SQL Server - in this implementation the configured deployment ID is used to distinguish between deployments and which silos belong to which deployments. The silo identity is defined as a combination of deploymentID, ip, port, epoch in appropriate tables and columns. The relational backend uses optimistic concurrency control and transactions, similar to the procedure of using ETags on Azure Table implementation. The relational implementation expects the database engine to generate the ETag used. In case of SQL Server, on SQL Server 2000 the generated ETag is one acquired from a call to NEWID() . On SQL Server 2005 and later ROWVERSION is used. Orleans reads and writes relational ETags as opaque VARBINARY(16) tags and stores them in memory as base64 encoded strings. Orleans supports multi-row inserts using UNION ALL (for Oracle including DUAL), which is currently used to insert statistics data. The exact implementation and rationale for SQL Server can be seen at CreateOrleansTables_SqlServer.sql . Apache ZooKeeper - in this implementation we use the configured deployment ID as a root node and the silo identity ( ip:port@epoch ) as its child node. Together they guarantee a unique path per silo. For concurrency control we use optimistic concurrency control based on the node version . Every time we read from the deployment root node we store the version for every read child silo node and use that version when we try to write back. Each time a node's data changes, the version number increases atomically by the ZooKeeper service. For multi-row transactions we utilize the multi method , which guarantees serializale transactions over silo nodes with the same parent deployment ID node. Consul IO - we used Consul's Key/Value store to impelement the membershop table. Refer to Consul-Deployment for more details. AWS DynamoDB - In this implementation we use the cluster Deployment ID as the Partition Key and Silo Identity ( ip-port-generation ) as the RangeKey making the record unity. The optimistic concurrency is made by the ETag attribute by making conditional writes on DynamoDB. The implementation logic is quite similar to Azure Table Storage. We only implemented the basic membership protocol (and not the extended protocol). In-memory emulation for development setup. We use a special system grain, called MembershipTableGrain , for that implementation. This grain lives on a designated primary silo, which is only used for a development setup . In any real production usage primary silo is not required . Configuration: Membership protocol is configured via the Liveness element in the Globals section in OrleansConfiguration.xml file. The default values were tuned in years of production usage in Azure and we believe they represent good default settings. There is no need in general to change them. Sample config element: <Liveness ProbeTimeout = \"5s\" TableRefreshTimeout =\"10s DeathVoteExpirationTimeout =\"80s\" NumMissedProbesLimit = \"3\" NumProbedSilos=\"3\" NumVotesForDeathDeclaration=\"2\" /> There are 4 types of liveness implemented. The type of the liveness protocol is configured via the SystemStoreType attribute of the SystemStore element in the Globals section in OrleansConfiguration.xml file. MembershipTableGrain - membership table is stored in a grain on primary silo. This is a development setup only . AzureTable - membership table is stored in Azure table. SqlServer - membership table is stored in a relational database. ZooKeeper - membership table is stored in a ZooKeeper ensemble . Consul - configured as Custom system store with MembershipTableAssembly = \"OrleansConsulUtils\" . Refer to Consul-Deployment for more details. DynamoDB - configured as a Custom system store with MembershipTableAssembly = \"OrleansAWSUtils\" . For all liveness types the common configuration variables are defined in Globals.Liveness element: ProbeTimeout - The number of seconds to probe other silos for their liveness or for the silo to send \"I am alive\" heartbeat messages about itself. Default is 10 seconds. TableRefreshTimeout - The number of seconds to fetch updates from the membership table. Default is 60 seconds. DeathVoteExpirationTimeout - Expiration time in seconds for death vote in the membership table. Default is 120 seconds NumMissedProbesLimi t - The number of missed \"I am alive\" heartbeat messages from a silo or number of un-replied probes that lead to suspecting this silo as dead. Default is 3. NumProbedSilos - The number of silos each silo probes for liveness. Default is 3. NumVotesForDeathDeclaration - The number of non-expired votes that are needed to declare some silo as dead (should be at most NumMissedProbesLimit). Default is 2. UseLivenessGossip - Whether to use the gossip optimization to speed up spreading liveness information. Default is true. IAmAliveTablePublishTimeout - The number of seconds to periodically write in the membership table that this silo is alive. Used only for diagnostics. Default is 5 minutes. NumMissedTableIAmAliveLimit - The number of missed \"I am alive\" updates in the table from a silo that causes warning to be logged. Does not impact the liveness protocol. Default is 2. MaxJoinAttemptTime - The number of seconds to attempt to join a cluster of silos before giving up. Default is 5 minutes. ExpectedClusterSize - The expected size of a cluster. Need not be very accurate, can be an overestimate. Used to tune the exponential backoff algorithm of retries to write to Azure table. Default is 20. Design Rationale: A natural question that might be asked is why not to rely completely on Apache ZooKeeper for the cluster membership implementation, potentially by using it's out of the box support for group membership with ephemeral nodes ? Why did we bother implementing our own membership protocol? There were primarily three reasons: 1) Deployment/Hosting in the Cloud - Zookeeper is not a hosted service (at least at the time of this writing July 2015 and definitely when we first implemented this protocol in the summer of 2011 there was no version of Zookeeper running as a hosted service by any major cloud provider). It means that in the Cloud environment Orleans customers would have to deploy/run/manage their own instance of a ZK cluster. This is just yet another unnecessary burden, that we did not want to force on our customers. By using Azure Table we rely on a hosted, managed service which makes our customers lives much simpler. Basically, in the Cloud, use Cloud as a Platform, not as an Infrastructure. On the other hand, when running on premises and managing your own servers, relying on ZK as an implementation of the MembershipTable is a viable option. 2) Direct failure detection - when using ZK's group membership with ephemeral nodes the failure detection is performed between the Orleans servers (ZK clients) and ZK servers. This may not necessarily correlate with the actual network problems between Orleans servers. Our desire was that the failure detection would accurately reflect the intra-cluster state of the communication. Specifically, in our design, if an Orleans silo cannot communicate with the MembershipTable it is not considered dead and can keep working. As opposite to that, have we used ZK group membership with ephemeral nodes a disconnection from a ZK server may cause an Orleans silo (ZK client) to be declared dead, while it may actually be alive and fully functional. 3) Portability and flexibility - as part of Orleans's philosophy, we do not want to force a strong dependence on any particular technology, but rather have a flexible design where different components can be easily switched with different implementations. This is exactly the purpuse that MembershipTable abstraction serves. Acknowledgements: We would to acknowledge the contribution of Alex Kogan to the design and implementation of the first version of this protocol. This work was done as part of summer internship in Microsoft Research in the Summer of 2011. The implementation of ZooKeeper based MembershipTable was done by Shay Hazor , the implementation of SQL MembershipTable was done by Veikko Eeva , the implementation of AWS DynamoDB MembershipTable was done by Gutemberg Ribeiro and the implementation of Consul based MembershipTable was done by Paul North ."
  },
  "Documentation/deployment/azure_web_apps_with_azure_cloud_services.html": {
    "href": "Documentation/deployment/azure_web_apps_with_azure_cloud_services.html",
    "title": "Using Azure Web Apps with Azure Cloud Services | Microsoft Orleans Documentation",
    "keywords": "Using Azure Web Apps with Azure Cloud Services If you would like to connect to an Azure Cloud Services Silo from an Azure Web App rather than a Web Role hosted within the same cloud service you can. For this to work securely you will need to assign both the Azure Web App and the Worker Role hosting the Silo to an Azure Virtual Network . First we'll setup the Azure Web App, you can follow this guide which will create the virtual network and assign it to the Azure Web App. Now we can assign the cloud service to the virtual network by modifying the ServiceConfiguration file. <NetworkConfiguration> <VirtualNetworkSite name=\"virtual-network-name\" /> <AddressAssignments> <InstanceAddress roleName=\"role-name\"> <Subnets> <Subnet name=\"subnet-name\" /> </Subnets> </InstanceAddress> </AddressAssignments> </NetworkConfiguration> Also make sure the Silo endpoints are configured. <Endpoints> <InternalEndpoint name=\"OrleansSiloEndpoint\" protocol=\"tcp\" port=\"11111\" /> <InternalEndpoint name=\"OrleansProxyEndpoint\" protocol=\"tcp\" port=\"30000\" /> </Endpoints> You can now connect from the Web App to the rest of the cluster. Potential Issues If the Web App is having difficulty connecting to the Silo: Make sure you have at least two roles , or two instances of one role in your Azure Cloud Service, or the InternalEndpoint firewall rules may not be generated. Check that both the Web App and the Silo are using the same ClusterId and ServiceId . Make sure the network security group is set up to allow internal virtual network connections. If you haven't got one you can create and assign one easily using the following PowerShell : New-AzureNetworkSecurityGroup -Name \"Default\" -Location \"North Europe\" Get-AzureNetworkSecurityGroup -Name \"Default\" | Set-AzureNetworkSecurityGroupToSubnet -VirtualNetworkName \"virtual-network-name\" -SubnetName \"subnet-name\""
  },
  "Community/Who-Is-Using-Orleans.html": {
    "href": "Community/Who-Is-Using-Orleans.html",
    "title": "Who Is Using Orleans? | Microsoft Orleans Documentation",
    "keywords": "Who Is Using Orleans? Orleans has been used extensively by several Microsoft projects and product groups, most notably by 343 Industries as a platform for all of Halo 4 and Halo 5 cloud services. There are various other internal projects at Microsoft which are using Orleans, but we are not able to talk publicly about many of those yet. There are many more companies and projects which are also using Orleans, and this page provides a partial list of some that we know about.... Feel free to send us a pull request on GitHub to add your company / project to this list. Companies Companies currently using Orleans in production: Gassumo Microsoft Skype , Azure , others Microsoft Studios 343 Studios ( Halo ), Age of Empires , BigPark , Black Tusk , others Microsoft Research NašeÚkoly.CZ Trustev Mailcloud Limited Gigya Honeywell Mesh Systems MESHVista Smart Cloud IoT Platform leverages Orleans for back-end services monitoring device state and business logic Applicita Limited A number of client projects where extreme scale and performance is required Drawboard Cloud collaboration and synchronisation platform YouScan Social media monitoring & analytics provider. Orleans is used for stateful stream processing at scale, reliable execution of long running jobs and as a main application server. Visa PagoLivre Mobile and Social Payment platform invertirOnline.com Argentinian-based electronic brokerage firm Lebara Nomnio Nomnio IoT Platform and industry projects where reliability and performance is required Real Artists Ship 2.0 Fast, native, comprehensive issue tracking for GitHub Manufacturing Resources International MRI designs, engineers, and fabricates BoldVu® LCD displays used in out of home advertising networks. Orleans powers our IOT infrastructure to help monitor and maintain our displays Projects and Applications Projects, websites and applications powered by Orleans, or provide extensions to Orleans. Claw (Clash Of Animal Warriors) is a real-time multiplayer mobile game which uses Orleans for its MatchMaker software which should handle many players at the same time and respond to them as fast as possible. Halo 4 - 343 Industries Microsoft BigPark Studio Orleans-Contrib Community contribution projects, including Orleans Monitoring, Design Patterns, Storage Provider, etc. Pegasus Mission More Info here and here Sync.Today 2015 .NET Business Processes Automation Platform. More info here Microdot A microservices framework by Gigya, for writing Orleans based microservices"
  },
  "1.5/Tutorials/My-First-Orleans-Application.html": {
    "href": "1.5/Tutorials/My-First-Orleans-Application.html",
    "title": "My First Orleans Application | Microsoft Orleans Documentation",
    "keywords": "My First Orleans Application In this tutorial, we will walk through the steps to get the simplest possible Orleans application up and running, the all-too-familiar \"Hello World!\". We're using VS 2017, but it works equally well with VS 2012, VS 2013 and VS 2015. Before we start, there are three Orleans concepts that you will run into in this tutorial: that of a grain, a communication interface, and a silo. Grains Grains form the core of the Orleans programming model - they are distributed virtual actors. Grains are .NET classes that derive from a particular base class. It is easy to think about actors as objects that get dynamically instantiated on different servers and can invoke each other. They are distributed because interactions with grains may happen across process and computer boundaries, virtual because a particular grain may not be loaded in memory when another component sends it a message. If not present, the grain will be activated on-demand. Communication interfaces Communication interfaces describe how to communicate with grains. They are .NET interfaces extending a particular base interface. Silos Silos are containers of grains, potentially millions of grains in a single silo. Typically, you will run one silo per machine, but it sometimes make sense to run more than one on a single machine, when testing, for example. Getting Started Before getting started, make sure the Microsoft Orleans Tools for Visual Studio is installed. The plugin can be downloaded from: https://marketplace.visualstudio.com/items?itemName=sbykov.MicrosoftOrleansToolsforVisualStudio After starting Visual Studio, go to create a new project. Under \"Visual C#,\" you should see the following: Choose the \"Orleans Dev/Test Host\" project type, create a directory for the solution, and create the project: At this point go ahead and compile your project to download the packages. The project is just a console application populated with code that helps you host a silo in an environment that is \"developer friendly,\" i.e. where everything runs in a single process. The main code does three things: it creates a silo, initializes the Orleans client runtime, and waits for user input before terminating: static void Main(string[] args) { // First, configure and start a local silo var siloConfig = ClusterConfiguration.LocalhostPrimarySilo(); var silo = new SiloHost(\"TestSilo\", siloConfig); silo.InitializeOrleansSilo(); silo.StartOrleansSilo(); Console.WriteLine(\"Silo started.\"); // Then configure and connect a client. var clientConfig = ClientConfiguration.LocalhostSilo(); var client = new ClientBuilder().UseConfiguration(clientConfig).Build(); client.Connect().Wait(); Console.WriteLine(\"Client connected.\"); // // This is the place for your test code. // Console.WriteLine(\"\\nPress Enter to terminate...\"); Console.ReadLine(); // Shut down client.Close(); silo.ShutdownOrleansSilo(); } Adding Some Grains At this point, we have everything we need except some actual Orleans-based code. Next we will create two more projects, one to hold the communication interface, and one to hold our grain. Separating the two is a best practice since the interface project is shared between the client and server-side, while the grains are implementation code and should be private to the server side. In addition to the Dev/Test host, there are two more Orleans projects, and we should create one of each in our solution: Once you have them in your solution, make sure to add a reference to the grain interface project from each of the other projects: the host, which will contain our client code, and the grain collection project. Add a reference for the grain collection project to the host project, so that it is automatically (re-)built and copied when starting the debugger. Open the IGrain1.cs file and add a method SayHello() to it. We should have something like this: public interface IGrain1 : IGrainWithIntegerKey { Task<string> SayHello(); } One of the important things is choosing a Key type for your grains, in this example we are using the Integer Key type. There are also Guids, strings and various compound keys that may meet your needs. Additionally, Orleans relies on TPL tasks in the interface method's return type -- an essential means to achieving scalability in the lightweight Orleans programming model is to use asynchronous I/O everywhere, and Orleans forces you to do so. Use Task or Task<T> as the return type of all methods of communication interfaces. Next, we turn our attention to the grain implementation, which is found in Grain1.cs . The first thing to do is make sure that the interface it implements is the right one: it should be MyGrainInterfaces1.IGrain1 , unless you renamed the project and/or the interface in the previous step. Then, we ask VS to generate the method stub for the one interface method we defined earlier: public Task<string> SayHello() { throw new NotImplementedException(); } We're finally ready to add the much-anticipated \"Hello World!\" code. Just return the string as the contents of a Task: public Task<string> SayHello() { return Task.FromResult(\"Hello World!\"); } OK, we're nearly done. All we need is a bit of client code. This will go in the Program.cs file in the Host project. In place of the comment following the call to GrainClient.Initialize() , add these two lines: var friend = client.GetGrain<MyGrainInterfaces1.IGrain1>(0); Console.WriteLine(\"\\n\\n{0}\\n\\n\", friend.SayHello().Result); That's it! Hit F5, let the silo initialization code take its time. This will take a few seconds, maybe as much as ten, and there will be a lot of log messages printed. At the very end, you should see the printout of the greeting. These are the essential steps to create and run Orleans-based code: define communication interfaces, implement them using grain classes, and write some client code to communicate with the grains in order to test them. In a realistic production environment, the grain code would be deployed in a silo hosted by Windows Azure or Windows Server and the client would most likely be a Web site or service using Orleans for the backend logic. However, that is just about making different configuration choices - the code in the simplified environment is the same as in the production environment. Next Next we'll see how we can run a minimal Orleans application. Minimal Orleans Application"
  },
  "1.5/Tutorials/Minimal-Orleans-Application.html": {
    "href": "1.5/Tutorials/Minimal-Orleans-Application.html",
    "title": "Minimal Orleans Application | Microsoft Orleans Documentation",
    "keywords": "Minimal Orleans Application This tutorial provides step by step instructions for creating a basic functioning Orleans application. It is designed to be self-contained and minimalistic, with the following traits. It does not need the SDK or Extension to be installed, and relies on Nuget packages only. Has been tested in both Visual Studio 2013 and 2015 using Orleans 1.2.0. Has no reliance on SQL or Azure Keep in mind that this is only a tutorial and lacks appropriate error handling and other goodies that would be useful for a production environment. However, it should help the readers get a real hands-on with regards to different facets of Orleans and allow them to focus their continued learning on the parts most relevant to them. You can find the final source code in Samples\\Tutorial.Minimal folder ( see latest version online ). Project Setup For this tutorial we’re going to need to create 3 projects. A Library that contains the interfaces (Communication interfaces), a library that contains the implementation (called Grains), and a simple console application that will Host our Silo. For further understanding of this terminology please see the document Getting Started with Orleans . The Solution will eventually look like this. (Missing files will be added in the sections below) Within Visual Studio Create a blank solution called OrleansTest Create a New Console Application called Host Create a New class library called GrainInterfaces Create a New class library called GrainCollection We just use the default project types in c#. Delete the Extras Delete Class1.cs from GrainCollection Delete Class1.cs from GrainInterfaces Add the following References GrainCollection references GrainInterfaces Host references GrainInterfaces Host references GrainCollection Adding Orleans Orleans is available via Nuget. The primary goodness is in Microsoft.Orleans.Core but we will be including packages that provide additional functionality. Specifically, we will be using Template packages, which provide autocode generation for our grains and interfaces, and the Runtime which is used for hosting. With Nuget Add Microsoft.Orleans.OrleansCodeGenerator.Build to GrainInterfaces Add Microsoft.Orleans.OrleansCodeGenerator.Build to GrainCollection Add Microsoft.Orleans.OrleansRuntime to Host Creating our Grain Interface In GrainInterfaces create an interface IHello.cs public interface IHello : Orleans.IGrainWithIntegerKey { Task<string> SayHello(string msg); } Creating our Implementation In GrainCollection create a class HelloGrain.cs class HelloGrain : Orleans.Grain, IHello { public Task<string> SayHello(string msg) { return Task.FromResult(string.Format(\"You said {0}, I say: Hello!\", msg)); } } Host The host requires the most amount of attention to get Orleans up and running. Throughout future tutorials, much of this will change, or go away (Orleans comes with a nice precanned SiloHost and the extension provides a template that simplifies this). However this small implementation should demonstrate the basics of getting started. Host – App.Config Change App.config to enable the recommended server garbage collection <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <runtime> <gcServer enabled=\"true\"/> <gcConcurrent enabled=\"true\"/> </runtime> </configuration> Host – OrleansConfiguration.xml Within the Host project, add an XML file named OrleansConfiguration.xml. This will be used for cluster configuration. Make sure to set the Copy to Output directory file property to Copy if newer : <?xml version=\"1.0\" encoding=\"utf-8\"?> <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <SeedNode Address=\"localhost\" Port=\"11111\" /> </Globals> <Defaults> <Networking Address=\"localhost\" Port=\"11111\" /> <ProxyingGateway Address=\"localhost\" Port=\"30000\" /> </Defaults> </OrleansConfiguration> It is possible to configure this within the code, but it is fairly difficult to do so. Host – Program.cs Program.cs is our lengthiest code block. We attempt to accomplish a number of objectives here Initialize Orleans in its own AppDomain Run a trivial task (DoSomeClientWork) Wait for the user to press enter Shutdown gracefully The Orleans samples come with a very nice class called HostWrapper, which abstracts some of the boiler plate within this example and is worth exploring for a more robust implementation. We're going to do this by hand in this tutorial. using Orleans.Runtime.Host; using Orleans; using System.Net; using System; class Program { static SiloHost siloHost; static void Main(string[] args) { // Orleans should run in its own AppDomain, we set it up like this AppDomain hostDomain = AppDomain.CreateDomain(\"OrleansHost\", null, new AppDomainSetup() { AppDomainInitializer = InitSilo }); DoSomeClientWork(); Console.WriteLine(\"Orleans Silo is running.\\nPress Enter to terminate...\"); Console.ReadLine(); // We do a clean shutdown in the other AppDomain hostDomain.DoCallBack(ShutdownSilo); } static void DoSomeClientWork() { // Orleans comes with a rich XML and programmatic configuration. Here we're just going to set up with basic programmatic config var config = Orleans.Runtime.Configuration.ClientConfiguration.LocalhostSilo(30000); GrainClient.Initialize(config); var friend = GrainClient.GrainFactory.GetGrain<IHello>(0); var result = friend.SayHello(\"Goodbye\").Result; Console.WriteLine(result); } static void InitSilo(string[] args) { siloHost = new SiloHost(System.Net.Dns.GetHostName()); // The Cluster config is quirky and weird to configure in code, so we're going to use a config file siloHost.ConfigFileName = \"OrleansConfiguration.xml\"; siloHost.InitializeOrleansSilo(); var startedok = siloHost.StartOrleansSilo(); if (!startedok) throw new SystemException(String.Format(\"Failed to start Orleans silo '{0}' as a {1} node\", siloHost.Name, siloHost.Type)); } static void ShutdownSilo() { if (siloHost != null) { siloHost.Dispose(); GC.SuppressFinalize(siloHost); siloHost = null; } } } Running the application At this point we should be able to run the Host project. A console should appear with a large amount of logging text, and at the end it should look like this Within the appropriate bin directory (Debug/Release) there will be a number of log files showing this information as well. The amount and method of logging is configurable. Troubleshooting System.SystemException: 'Failed to start Orleans silo 'YOUR-HOST-NAME' as a Secondary node': Problem: The silo is trying to start but does not find a the specified file to get the configuration. Solution: Set the property \"Copy to Output Directory\" to \"Copy if newer\", to set it, right click on the configuration file, then click on properties. ``` Further Reading List of Orleans Packages Orleans Configuration Guide Orleans Best Practices Running in a Stand Alone Silo Azure Web Sample"
  },
  "1.5/Tutorials/Declarative-Persistence.html": {
    "href": "1.5/Tutorials/Declarative-Persistence.html",
    "title": "Declarative Persistence | Microsoft Orleans Documentation",
    "keywords": "Declarative Persistence In the second tutorial, we saw how grain state survived the client being shut down, which opens up for a lot of cache-like scenarios, where Orleans is relied upon as a kind of 'cache with behavior,' an object-oriented cache, if you will. That is already very valuable and goes a long way toward achieving server-side scalability with a simple, familiar, programming model and the built-in single-threaded execution guarantees. However, it is sometimes the case that some of the state you are accumulating belongs in some form of permanent storage, so that it can survive a silo shutdown, or a grain migrating from one silo to another for load-balancing or a complete restart/shutdown of the service. What we have seen so far will not support such situations. Fortunately, Orleans offers a simple declarative model for identifying the state that needs to be stored in a permanent location, while leaving the decision when to save and restore state under programmatic control. You are not required to use the declarative persistence mechanism and can still access storage directly from your grain code, but it’s a nice way to save you some boilerplate code and build applications that are portable across various storage services. Getting Started We'll continue to build on our employee-and-manager sample. The first thing we need to do is make the identities of our workers and managers a little more predictable. In the sample, they were assigned GUIDs using Guid.NewGuid() , which is convenient, but doesn't let us find them in a subsequent run. Therefore, we'll create a set of GUIDs first, then use them as the worker identities. The modified Main program looks like this: static void Main(string[] args) { ... var ids = new string[] { \"42783519-d64e-44c9-9c29-399e3afaa625\", \"d694a4e0-1bc3-4c3f-a1ad-ba95103622bc\", \"9a72b0c6-33df-49db-ac05-14316edd332d\", \"6526a751-b9ac-4881-9bfb-836ecce2ca9f\", \"ae4b106f-3c96-464a-b48d-3583ed584b17\", \"b715c40f-d8d2-424d-9618-76afbc0a2a0a\", \"5ad92744-a0b1-487b-a9e7-e6b91e9a9826\", \"e23a55af-217c-4d76-8221-c2b447bf04c8\", \"2eef0ac5-540f-4421-b9a9-79d89400f7ab\" }; var e0 = GrainClient.GrainFactory.GetGrain<IEmployee>(Guid.Parse(ids[0])); var e1 = GrainClient.GrainFactory.GetGrain<IEmployee>(Guid.Parse(ids[1])); var e2 = GrainClient.GrainFactory.GetGrain<IEmployee>(Guid.Parse(ids[2])); var e3 = GrainClient.GrainFactory.GetGrain<IEmployee>(Guid.Parse(ids[3])); var e4 = GrainClient.GrainFactory.GetGrain<IEmployee>(Guid.Parse(ids[4])); var m0 = GrainClient.GrainFactory.GetGrain<IManager>(Guid.Parse(ids[5])); var m1 = GrainClient.GrainFactory.GetGrain<IManager>(Guid.Parse(ids[6])); ... } Next, we'll do some silo configuration, in order to configure the storage provider that will give us access to persistent storage. The silo host project includes a file OrleansHostWrapper.cs which is where we find the following section: var config = ClusterConfiguration.LocalhostPrimarySilo(); config.AddMemoryStorageProvider(); // Add this line to use the Azure storage emulator // config.AddAzureTableStorageProvider(\"AzureStore\", \"UseDevelopmentStorage=true\"); // Add this line to use an Azure storage account // config.AddAzureBlobStorageProvider(\"AzureStore\", \"[insert data connection string]\"); siloHost = new SiloHost(siloName, config); If this is hosted in Azure Cloud Services, then one can use: config.AddAzureBlobStorageProvider(\"AzureStore\"); and it will pick up the same connection string used in config.Globals.DataConnectionString . The MemoryStorage provider is fairly uninteresting, since it doesn't actually provide any permanent storage; it's intended for debugging persistent grains while having no access to a persistent store. In our case, that makes it hard to demonstrate persistence, so we will rely on a real storage provider. Depending on whether you have already set up (and want to use) an Azure storage account, or would like to rely on the Azure storage emulator, you should add one of the other two lines, but not both. You can use either the AddAzureTableStorageProvider() function or the AddAzureBlobStorageProvider() function depending on how you want to store information. In the case of the former, you have to start the Azure storage emulator after installing the latest version of the Azure SDK. In the case of the latter, you will have to create a Azure storage account and enter the name and keys in the configuration file. With one of those enabled, we're ready to tackle the grain code. Note: The built-in storage provider classes Orleans.Storage.AzureBlobStorage and Orleans.Storage.AzureTableStorage are in the OrleansAzureUtils.dll assembly, make sure this assembly is referenced in your silo worker role project with CopyLocal='True' . Declaring State Identifying that a grain should use persistent state takes three steps: declaring a class for the state, changing the grain base class, and identifying the storage provider. The first step, declaring a state class in the grain implementations project, simply means identifying the information of an actor that should be persisted and creating what looks like a record of the persistent data -- each state component is represented by a property with a getter and a setter. For employees, we want to persist all the state: public class EmployeeState { public int Level { get; set; } public IManager Manager { get; set; } } and for managers, we must store the direct reports, but the _me reference may continue to be created during activation. public class ManagerState { public List<IEmployee> Reports { get; set; } } Then, we change the grain class declaration to identify the state interface (e.g., from Orleans.Grain to Orleans.Grain<EmployeeState> ) and remove the variables that we want persisted. Make sure to remove level , and manager from the Employee class and _reports from the Manager class. In addition, we must update the other functions to reflect these removals. We also add an attribute to identify the storage provider: [StorageProvider(ProviderName = \"AzureStore\")] public class Employee : Orleans.Grain<EmployeeState>, Interfaces.IEmployee and [StorageProvider(ProviderName=\"AzureStore\")] public class Manager : Orleans.Grain<ManagerState>, IManager At risk of stating the obvious, the name of the storage provider attribute should match the name in the configuration file. This indirection is what allows you to delay choices around where to store grain state until deployment. Given these declarative changes, the grain should no longer rely on a private fields to keep compensation level and manager. Instead, the grain base class gives us access to the state via a State property that is available to the grain. For example: public Task SetManager(IManager manager) { State.Manager = manager; return TaskDone.Done; } Controlling Checkpoints The question that remains is when the persistent state gets saved to the storage provider. One choice that the Orleans designers could have made would be to have the runtime save state after every method invocation, but that turns out to be undesirable because it is far too conservative -- not all invocations will actually modify the state on all invocations, and some will never modify it. Rather than employing a complex system to evaluate state differentials after each method, Orleans asks the grain developer to add the necessary logic to determine whether state needs to be saved or not. Saving the state using the storage provider is easily accomplished by calling base.WriteStateAsync() . Thus, the final version of the Promote() and SetManager() methods looks like this: public Task Promote(int newLevel) { State.Level = newLevel; return base.WriteStateAsync(); } public Task SetManager(IManager manager) { State.Manager = manager; return base.WriteStateAsync(); } In the Manager class, there's only one method that need to be modified to write out data, AddDirectReport() . It should look like this: public async Task AddDirectReport(IEmployee employee) { if (State.Reports == null) { State.Reports = new List<IEmployee>(); } State.Reports.Add(employee); await employee.SetManager(this); var data = new GreetingData { From = this.GetPrimaryKey(), Message = \"Welcome to my team!\" }; await employee.Greeting(data); Console.WriteLine(\"{0} said: {1}\", data.From.ToString(), data.Message); await base.WriteStateAsync(); } Let's try this out! Set a breakpoint in Employee.Promote() . When we run the client code the first time and hit the breakpoint, the level field should be 0 and the newLevel parameter either 10 or 11 : Let the application finish (reach the 'Hit Enter...' prompt) and exit. Run it again, and compare what happens when you look at state this second time around: Just Making Sure... It's worth checking what Azure thinks about the data. Using a storage explorer such as Azure Storage Explorer (ASE) or the one built in to Server Explorer in Visual Studio 2013, open the storage account (or developer storage of the emulator) and find the 'OrleansGrainState' table. It should look something like this (you have to hit 'Query' in ASE): If everything is working correctly, the grain keys should appear in the PartitionKey column, and the qualified class name of the grains should appear in the RowKey column. Mixing Things A grain may contain a combination of persisted and transient state. Any transient state should be represented by private fields in the grain class. A common use for mixing the two is to cache some computed version of the persisted state in private fields while it is present in memory. For example, a stack of elements may be externally represented as a List<T> , but internally, as a Stack<T> . In the case of our Manager class, the _me field is simply a cached value, something we don't even need to keep as a field in the first place, it can be created any time we need it, but since it's going to be a commonly used value, it's worth keeping it around in a transient field. Automatic loading of state If a grain type has state, at activation time the state will be loaded from storage and then OnActivateAsync is called so you can be sure that the state is loaded when initializing your grain. This is the only case that Orleans calls ReadStateAsync automatically. If you want to write the state or read it in some other place, you should do it on your own. Normally you should not need to call ReadStateAsync yourself unless you are doing something specific regarding handling corrupted state or something else. Handling failures using persistence Generally speaking reading and writing a grain's state is a good mechanism to handle failures as well as serving its original intent. There is a possibility that your grain call fails in the middle of a method due to different reasons and you end up with a state which is half changed. In this case reading from storage can return your state to the last correct state. Alternatively, having gotten into such a state, the grain can request to get immediately deactivated by calling DeactivateOnIdle(), so that its a next request to it would trigger reactivation of the grain, which would reread the persistent state and reconstruct its in-memory copy. Deactivation is the cleanest way of resetting a grain to its last know good state, but if you want to avoid the cost of the reactivation process, you can reset its state and rerun any initialization logic (for example, by calling OnActivateAsync ) instead of deactivating the grain. Next Next, we'll see how we can call our grains from an MVC web application. Handling Failure"
  },
  "1.5/Documentation/Runtime-Implementation-Details/Scheduler.html": {
    "href": "1.5/Documentation/Runtime-Implementation-Details/Scheduler.html",
    "title": "Scheduler | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Scheduler Orleans Scheduler is a component within the Orleans runtime responsible for executing application code and parts of the runtime code to ensure the single threaded execution semantics . It implements a custom TPL Task scheduler. Orleans Task scheduler is a hierarchical 2 level scheduler. At the first level there is the global OrleansTaskScheduler that is responsible for execution of system activities. At the second level every grain activation has its own ActivationTaskScheduler , which provides the single threaded execution semantics. At a high level, the execution path is the following: A request arrives to the correct silo and the destination activation is found. A request is translated into a Task that is queued for execution by that activation, on its ActivationTaskScheduler. Any subsequent Task created as part of the grain method execution is natively enqueued to the same ActivationTaskScheduler, via the standard TaskScheduler mechanism. Every ActivationTaskScheduler has a queue of tasks queued for execution. Orleans Scheduler has a set of worker threads that are collectively used by all the activation schedulers. Those threads periodically scan all the scheduler queues for work to execute. A thread takes a queue (each queue is taken by one thread at a time) and starts executing Tasks in that queue in FIFO order. The combination of one thread at a time taking a queue and the thread executing Tasks sequentially is what provides the single threaded execution semantics. Work Items: Orleans uses a notion of Work Items to designate the entry point into the scheduler. Every new request is enqueued initially as a work item which simply wraps the execution of the first Task for that request. Work items simply provide more contextual information about the scheduling activity (the caller, the name of the activity, logging) and sometimes some extra work that has to be done on behalf of that scheduling activity (post invocation activity in Invoke work item). There are currently the following work item types: Invoke work item – this is the mostly frequently used work item type. It represents execution of an application request. Request/Response work items – executes a system request (request to a SystemTarget) TaskWorkItem – represent a Task queued to the top level OrleansTaskScheduler. Used instead of a direct Task just for convenience of data structures (more details below). WorkItemGroup – group of work items that share the same scheduler. Used to wrap a queue of Tasks for each ActivationTaskScheduler. ClosureWorkItem – a wrapper around a closure (arbitrary lambda) that is queued to the system context. Scheduling Context: Scheduling Context is a tag, just an opaque object that represents scheduling target – activation data, system target or system null context. High level Principles: Tasks are always queued to the correct scheduler 1.1 Tasks are never moved around from one scheduler to another. 1.2 We never create tasks on behalf of other tasks to execute them. 1.3 WorkItems are wrapped within Task (that is, in order to execute a work item, we create a Task whose lambda function will just run the work item lambda). By always going via tasks we ensure that any activity is executed via an appropriate Task scheduler. Tasks are executed on the scheduler where they were queued by using base.TryExecute (and not by RunSynchronously) There is a one to one mapping between ATS, WorkItem Group and Scheduling Context: 3.1 Activation Task Scheduler (ATS) is a custom TPL scheduler. We keep ATS thin and store all the data in WorkItemGroup. ATS points to its WorkItemGroup. 3.2 WorkItem Group is the actual holder (data object) of the activation Tasks. The Tasks are stored in a List - the queue of all tasks for its ATS. WorkItemGroup points back to its ATS. Data Flow and Execution of Tasks and Work items: The entry point is always a work item enqueued into OrleansTaskScheduler. It can be one of the Invoke/Request/Response/Closure WorkItem. Wrapped into a Task and enqueued into the correct ActivationTaskScheduler based on the context via Task.Start. A Task that is queued to its ActivationTaskScheduler is put into the WorkItemGroup queue. When a Task is put into a WorkItemGroup queue, WorkItemGroup makes sure it appears in OrleansTaskScheduler global RunQueue. RunQueue is the global queue of runnable WorkItemGroups, those that have at least one Task queued, and thus ready to be executed. Worker threads scan the RunQueue of OrleansTaskScheduler which hold WorkItemGroups and call WorkItemGroups.Execute WorkItemGroups.Execute scans the queue of its tasks and executes them via ActivationTaskScheduler.RunTask(Task) 6.1 ActivationTaskScheduler.RunTask(Task) calls base.TryExecute. 6.2 Task that were enqueued directly to the scheduler via TPL will just execute 6.3 Tasks that wrap work items will call workItem.Execute which will execute the Closure work item delegate. Low level design – Work Items: Queueing work items to OrleansTaskScheduler is how the whole chain of execution for every request starts in the Orleans runtime. This is our entry point into the Scheduler. Work items are first submitted to OrleansTaskScheduler (since this is the interface presented to the rest of the system). 2.1 Only closure/invoke/resume work items can be submitted this way. 2.2 TaskWorkItem cannot be submitted to OrleansTaskScheduler directly (read more below on handling of TaskWorkItem). Every work item must be wrapped into Task and enqueued to the right scheduler via Task.Start. 3.1 This will make sure the TaskScheduler.Current is set correctly on any Task that is created implicitly during execution of this workItem. 3.2 Wrapping is done by creating a Task via WrapWorkItemAsTask that will execute the work item and enqueuing it to the right scheduler via Task.Start(scheduler). 3.3 Work items for the null context are queued to OrleansTaskScheduler. 3.4 Work items for non-null contexts are queued to ActivationTaskScheduler Low level design – Queueing Tasks: Tasks are queued directly to the right scheduler 1.1 Tasks are queued implicitly by TPL via protected override void QueueTask(Task task) 1.2 A Task that has a non-null context is always enqueued to ActivationTaskScheduler 1.3 A Task that has the null context is always enqueued to OrleansTaskScheduler Queueing Tasks to ActivationTaskScheduler: 2.1 We never wrap a Task in another Task. A Task gets added directly to the WorkItem Group queue Queueing Tasks to OrleansTaskScheduler: 3.1 When a Task is enqueued to the OrleansTaskScheduler, we wrap it into a TaskWorkItem and put it into this scheduler’s queue of work items. 3.2 This is just a matter of data structures, nothing inherent about it: 3.3 OrleansTaskScheduler usually holds work item groups to schedule them, so its RunQueue has a BlockingCollection . 3.4 Since tasks to the null context are also queued to OrleansTaskScheduler, we reuse the same data structure, thus we have to wrap each Task in a TaskWorkItem. 3.5 We should be able to get rid of this wrapping completely by adjusting the RunQueue data structure. This may simplify the code a bit, but in general should not matter. Also, in the future we should move away from the null context anyway, so this issue will be gone anyway Inlining tasks: Since Tasks are always queued to the right scheduler, in theory it should always be safe to inline any Task."
  },
  "1.5/Documentation/Runtime-Implementation-Details/Cluster-Management.html": {
    "href": "1.5/Documentation/Runtime-Implementation-Details/Cluster-Management.html",
    "title": "Cluster Management in Orleans | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Cluster Management in Orleans Orleans provides cluster management via a built-in membership protocol, which we sometimes refer to as Silo Membership . The goal of this protocol is for all silos (Orleans servers) to agree on the set of currently alive silos, detect failed silos, and allow new silos to join the cluster. The protocol relies on an external service to provide an abstraction of MembershipTable . MembershipTable is a flat No-SQL like durable table that we use for 2 purposes. First, it is used as a rendezvous point for silos to find each other and Orleans clients to find silos. Second, it is used to store the current membership view (list of alive silos) and helps coordinate the agreement on the membership view. We currently have 6 implementations of the MembershipTable : based on Azure Table Storage , SQL server, Apache ZooKeeper , Consul IO , AWS DynamoDB , and in-memory emulation for development. In addition to the MembershipTable each silo participates in fully distributed peer-to-peer membership protocol that detects failed silos and reaches agreement on a set alive silos. We start by describing the internal implementation of the Orleans's membership protocol below and later on describe the implementation of the MembershipTable . The Basic Membership Protocol: Upon startup every silo writes itself into a well-known MembershipTable (passed via config). A combination of silo identity ( ip:port:epoch ) and service deployment id are used as unique keys in the table. Epoch is just time in ticks when this silo started, and as such ip:port:epoch is guaranteed to be unique in a given Orleans deployment. Silos monitor each other directly, via application pings (\"are you alive\" heartbeats ). Pings are sent as direct messages from silo to silo, over the same TCP sockets that silos communicate. That way, pings fully correlate with actual networking problems and server health. Every silo pings X other silos. A silo picks whom to ping by calculating consistent hashes on other silos' identity, forming a virtual ring of all identities and picking X successor silos on the ring (this is a well-known distributed technique called consistent hashing and is widely used in many distributed hash tables, like Chord DHT ). If a silo S does not get Y ping replies from a monitored servers P, it suspects it by writing its timestamped suspicion into P’s row in the MembershipTable . If P has more than Z suspicions within K seconds, then S writes that P is dead into P’s row, and broadcasts a request for all silos to re-read the membership table (which they’ll do anyway periodically). In more details: 5.1 Suspicion is written to the MembershipTable , in a special column in the row corresponding to P. When S suspects P it writes: “at time TTT S suspected P”. 5.2 One suspicion is not enough to declare P as dead. You need Z suspicions from different silos in a configurable time window T, typically 3 minutes, to declare P as dead. The suspicion is written using optimistic concurrency control provided by the MembershipTable . 5.3 The suspecting silo S reads P's row. 5.4 If S is the last suspector (there have already been Z-1 suspectors within time period T, as written in the suspicion column), S decides to declare P as Dead. In this case, S adds itself to list of suspectors and also writes in P's Status column that P is Dead. 5.5 Otherwise, if S is not the last suspector, S just adds itself to the suspectors column. 5.6 In either case the write back uses the version number or etag that was read, so the updates to this row are serialized. In case the write has failed due to version/etag mismatch, S retries (read again, and try to write, unless P was already marked dead). 5.7 At a high level this sequence of \"read, local modify, write back\" is a transaction. However, we are not using storage transactions to do that. “Transaction” code executes locally on a server and we use optimistic concurrency provided by the MembershipTable to ensure isolation and atomicity. Every silo periodically reads the entire membership table for its deployment. That way silos learn about new silos joining and about other silos being declared dead. Configuration : we provide a default configuration, which was hand tuned during our production usage in Azure. Currently the default is: every silo is monitored by 3 other silos, 2 suspicions are enough to declare a silo dead, suspicions only from last 3 minutes (otherwise they are outdated). Pings are send every 10 seconds and you needs to miss 3 pings to suspect a silo. Enforcing Perfect Failure detection – it is theoretically possible that a silo will be declared dead if it lost communication with other silos, while the silo process itself is still running. To solve this problem once the silo is declared dead in the table it is considered dead by everyone, even if it is in fact not dead (just partitioned temporarily or heartbeat messages got lost). Everyone stops communicating with it and once it learns that it is dead (by reading its own new status from the table) it commits suicide and shuts down its process. As a result, there must be an infrastructure in place to restart the silo as a new process (a new epoch number is generated upon start). When it's hosted in Azure, that happens automatically. When it isn't, another infrastructure is required. For example, a Windows Service configured to auto restart on failure. Optimization to reduce the frequency of periodical table reads and speed up all silos learning about new joining silos and dead silos . Every time any silo writes anything successfully to the table (suspicion, new join, …) it also broadcasts to all other silos – “go and reread the table now”. The silo does NOT tell others what it wrote in the table (since this information could already be outdated/wrong), it just tells them to re-read the table. That way we learn very quickly about membership changes without the need to wait for the full periodic read cycle. We still need the periodic read, in case the “re-read the table” message gets lost. Properties of the Basic Membership Protocol and FAQ: Can handle any number of failures – our algorithm can handle any number of failures (that is, f<=n), including full cluster restart. This is in contrast with “traditional” Paxos based solutions, which require quorum, which is usually a majority. We have seen in production situations when more than half of the silos were down. Our system stayed functional, while Paxos based membership would not be able to make progress. Traffic to the table is very light - The actual pings go directly between servers and not to the table. This would generate a lot of traffic plus would be less accurate from the failure detection perspective - if a silo could not reach the table, it would miss to write its I am alive heartbeat and others would kill him. Tunable accuracy vs. completeness – both perfect and accurate failure detection is not possible in general . One usually wants an ability to tradeoff accuracy (don’t want to declare a silo that is really alive as dead) with completeness (want to declare dead a silo that is indeed dead as soon as possible). The configurable #votes to declare dead and #missed pings allows to trade those two. Scale - the basic protocol can handle thousands and probably even tens of thousands of servers. This is in contrast with traditional Paxos based solutions, such as group communication protocols, which are known not to scale beyond tens. Diagnostics - the table is also very convenient for diagnostics and troubleshooting. System administrator can instantaneously find in the table the current list of alive silos, as well as see the history of all killed silos and suspicions. This is especially useful when diagnosing problems. Why do we need reliable persistent storage for implementation of the MembershipTable ? - we use persistent storage (Azure table, SQL server, AWS DynamoDB, Apache ZooKeeper or Consul IO KV) for the MembershipTable for 2 purposes. First, it is used as a rendezvous point for silos to find each other and Orleans clients to find silos. Second, we use the reliable storage to help us coordinate the agreement on the membership view. While we perform failure detection directly in a peer to peer fashion between the silos, we store the membership view in a reliable storage and use the concurrency control mechanism provided by this storage to reach agreement of who is alive and who is dead. That way, in a sense, our protocol outsources the hard problem of distributed consensus to the cloud. In that we fully utilize the power of the underlying cloud platform, using it truly as \"Platform as a Service\". What happens if the table is not accessible for some time? (storage service is down, unavailable, or there are communication problems with it) – our protocol will NOT declare silos as dead by mistake in such a case. Currently operational silos will keep working without any problems. However, we won't be able to declare a silo dead (if we detected some silo is dead via missed pings we won’t be able to write this fact to the table) and also won't be able to allow new silos to join. So completeness will suffer, but accuracy will not - partitioning from the table will never cause us to declare silo as dead by mistake. Also, in case of a partial network partition (if some silos can access the table and some not), it could happen that we will declare a dead silo as dead, but it will take some time until all other silos learn about it. So detection could be delayed, but we will never wrongly kill someone due to table un-availability. Direct IAmAlive writes into the table for diagnostics only - in addition to heartbeats that are sent between the silos, each silo also periodically updates an \"I Am Alive\" column in his row in the table. This \"I Am Alive\" column is only used for manual troubleshooting and diagnostics and is not used by the membership protocol itself. It is usually written at much lower frequency (once every 5 minutes) and serves as a very useful tool for system administrators to check the liveness of the cluster or easily find out when the silo was last alive. Extension to totally order membership views: The basic membership protocol described above was later extended to support totally ordered membership views. We will briefly describe the reasons for this extension and how it is implemented. The extension does not change anything in the above design, just adds an additional property that all membership configurations are globally totally ordered. Why it is useful to totally order membership views? This allows serializing the joining of new silos to the cluster. That way, when a new silo joins the cluster it can validate two-way connectivity to every other silo that has already started. If some of the already joined silos do not answer it (potentially indicating a network connectivity problem with the new silo), the new silo is not allowed to join. This ensures that at least when a silo starts, there is a full connectivity between all silos in the cluster (this is implemented). Higher level protocols in the silo, such as distributed grain directory, can utilize the fact that membership views are ordered and use this information to perform smarter duplicate activations resolution. In particular, when directory finds out that 2 activations were created when membership was in flux, it may decide to deactivate the older activation that was created based on the now-outdated membership information (this is currently not implemented). Extended Membership Protocol: For implementation of this feature we utilize the support for transactions over multiple rows that is provided by the MembershipTable .. We add a membership-version row to the table that tracks table changes. When silo S wants to write suspicion or death declaration for silo P: 3.1 S reads the latest table content. If P is already dead, do nothing. Otherwise, 3.2 In the same transaction, write the changes to P's row as well as increment the version number and write it back to the table. 3.3 Both writes are conditioned with eTags. 3.4 If transaction aborts due to eTag mismatch on either P's row or on the version row, attempt again. All writes to the table modify and increment the version row. That way all writes to the table are serialized (via serializing the updates to the version row) and since silos only increment the version number, the writes are also totally ordered in increasing order. Scalability of the Extended Membership Protocol: In the extended version of the protocol all writes are serialized via one row. This can potentially hurt the scalability of the cluster managemenet protocol, since it increases the risk of conflicts between concurrent table writes. To partially mitigate this problem silos retry all their writes to the table by using exponential backoff. We have observed the extended protocols to work smoothly in production environment in Azure with up to 200 silos. However, we do think the protocol might have problems to scale beyond a thousand silos. In such large setups the updates to version row may be easily disabled, essentially maintaining the rest of the cluster managemenet protocol and giving up on the total ordering property. Please also note that we refer here to the scalability of the cluster management protocol, not the rest of Orleans. We believe that other parts of the Orleans runtime (messaging, distributed directory, grain hosting, client to gateway connectivity) are scalable way beyond hundreds of silos. Membership Table: As already mentioned, MembershipTable is used as a rendezvous point for silos to find each other and Orleans clients to find silos and also helps coordinate the agreement on the membership view. We currently have 6 implementation of the MembershipTable : based on Azure Table, SQL server, Apache ZooKeeper, Consul IO, AWS DynamoDB, and in-memory emulation for development. The interface for MembershipTable is defined in IMembershipTable . Azure Table Storage - in this implementation we use Azure deployment ID as partition key and the silo identity ( ip:port:epoch ) as row key. Together they guarantee a unique key per silo. For concurrency control we use optimistic concurrency control based on Azure Table ETags . Every time we read from the table we store the etag for every read row and use that eTag when we try to write back. etags are automatically assigned and checked by Azure Table service on every write. For multi-row transactions we utilize the support for batch transactions provided by Azure table , which guarantees serializale transactions over rows with the same partition key. SQL Server - in this implementation the configured deployment ID is used to distinguish between deployments and which silos belong to which deployments. The silo identity is defined as a combination of deploymentID, ip, port, epoch in appropriate tables and columns. The relational backend uses optimistic concurrency control and transactions, similar to the procedure of using ETags on Azure Table implementation. The relational implementation expects the database engine to generate the ETag used. In case of SQL Server, on SQL Server 2000 the generated ETag is one acquired from a call to NEWID() . On SQL Server 2005 and later ROWVERSION is used. Orleans reads and writes relational ETags as opaque VARBINARY(16) tags and stores them in memory as base64 encoded strings. Orleans supports multi-row inserts using UNION ALL (for Oracle including DUAL), which is currently used to insert statistics data. The exact implementation and rationale for SQL Server can be seen at CreateOrleansTables_SqlServer.sql . Apache ZooKeeper - in this implementation we use the configured deployment ID as a root node and the silo identity ( ip:port@epoch ) as its child node. Together they guarantee a unique path per silo. For concurrency control we use optimistic concurrency control based on the node version . Every time we read from the deployment root node we store the version for every read child silo node and use that version when we try to write back. Each time a node's data changes, the version number increases atomically by the ZooKeeper service. For multi-row transactions we utilize the multi method , which guarantees serializale transactions over silo nodes with the same parent deployment ID node. Consul IO - we used Consul's Key/Value store to impelement the membershop table. Refer to Consul-Deployment for more details. AWS DynamoDB - In this implementation we use the cluster Deployment ID as the Partition Key and Silo Identity ( ip-port-generation ) as the RangeKey making the record unity. The optimistic concurrency is made by the ETag attribute by making conditional writes on DynamoDB. The implementation logic is quite similar to Azure Table Storage. We only implemented the basic membership protocol (and not the extended protocol). In-memory emulation for development setup. We use a special system grain, called MembershipTableGrain , for that implementation. This grain lives on a designated primary silo, which is only used for a development setup . In any real production usage primary silo is not required . Configuration: Membership protocol is configured via the Liveness element in the Globals section in OrleansConfiguration.xml file. The default values were tuned in years of production usage in Azure and we believe they represent good default settings. There is no need in general to change them. Sample config element: <Liveness ProbeTimeout = \"5s\" TableRefreshTimeout =\"10s DeathVoteExpirationTimeout =\"80s\" NumMissedProbesLimit = \"3\" NumProbedSilos=\"3\" NumVotesForDeathDeclaration=\"2\" /> There are 4 types of liveness implemented. The type of the liveness protocol is configured via the SystemStoreType attribute of the SystemStore element in the Globals section in OrleansConfiguration.xml file. MembershipTableGrain - membership table is stored in a grain on primary silo. This is a development setup only . AzureTable - membership table is stored in Azure table. SqlServer - membership table is stored in a relational database. ZooKeeper - membership table is stored in a ZooKeeper ensemble . Consul - configured as Custom system store with MembershipTableAssembly = \"OrleansConsulUtils\" . Refer to Consul-Deployment for more details. DynamoDB - configured as a Custom system store with MembershipTableAssembly = \"OrleansAWSUtils\" . For all liveness types the common configuration variables are defined in Globals.Liveness element: ProbeTimeout - The number of seconds to probe other silos for their liveness or for the silo to send \"I am alive\" heartbeat messages about itself. Default is 10 seconds. TableRefreshTimeout - The number of seconds to fetch updates from the membership table. Default is 60 seconds. DeathVoteExpirationTimeout - Expiration time in seconds for death vote in the membership table. Default is 120 seconds NumMissedProbesLimi t - The number of missed \"I am alive\" heartbeat messages from a silo or number of un-replied probes that lead to suspecting this silo as dead. Default is 3. NumProbedSilos - The number of silos each silo probes for liveness. Default is 3. NumVotesForDeathDeclaration - The number of non-expired votes that are needed to declare some silo as dead (should be at most NumMissedProbesLimit). Default is 2. UseLivenessGossip - Whether to use the gossip optimization to speed up spreading liveness information. Default is true. IAmAliveTablePublishTimeout - The number of seconds to periodically write in the membership table that this silo is alive. Used only for diagnostics. Default is 5 minutes. NumMissedTableIAmAliveLimit - The number of missed \"I am alive\" updates in the table from a silo that causes warning to be logged. Does not impact the liveness protocol. Default is 2. MaxJoinAttemptTime - The number of seconds to attempt to join a cluster of silos before giving up. Default is 5 minutes. ExpectedClusterSize - The expected size of a cluster. Need not be very accurate, can be an overestimate. Used to tune the exponential backoff algorithm of retries to write to Azure table. Default is 20. Design Rationale: A natural question that might be asked is why not to rely completely on Apache ZooKeeper for the cluster membership implementation, potentially by using it's out of the box support for group membership with ephemeral nodes ? Why did we bother implementing our own membership protocol? There were primarily three reasons: 1) Deployment/Hosting in the Cloud - Zookeeper is not a hosted service (at least at the time of this writing July 2015 and definitely when we first implemented this protocol in the summer of 2011 there was no version of Zookeeper running as a hosted service by any major cloud provider). It means that in the Cloud environment Orleans customers would have to deploy/run/manage their own instance of a ZK cluster. This is just yet another unnecessary burden, that we did not want to force on our customers. By using Azure Table we rely on a hosted, managed service which makes our customers lives much simpler. Basically, in the Cloud, use Cloud as a Platform, not as an Infrastructure. On the other hand, when running on premises and managing your own servers, relying on ZK as an implementation of the MembershipTable is a viable option. 2) Direct failure detection - when using ZK's group membership with ephemeral nodes the failure detection is performed between the Orleans servers (ZK clients) and ZK servers. This may not necessarily correlate with the actual network problems between Orleans servers. Our desire was that the failure detection would accurately reflect the intra-cluster state of the communication. Specifically, in our design, if an Orleans silo cannot communicate with the MembershipTable it is not considered dead and can keep working. As opposite to that, have we used ZK group membership with ephemeral nodes a disconnection from a ZK server may cause an Orleans silo (ZK client) to be declared dead, while it may actually be alive and fully functional. 3) Portability and flexibility - as part of Orleans's philosophy, we do not want to force a strong dependence on any particular technology, but rather have a flexible design where different components can be easily switched with different implementations. This is exactly the purpuse that MembershipTable abstraction serves. Acknowledgements: We would to acknowledge the contribution of Alex Kogan to the design and implementation of the first version of this protocol. This work was done as part of summer internship in Microsoft Research in the Summer of 2011. The implementation of ZooKeeper based MembershipTable was done by Shay Hazor , the implementation of SQL MembershipTable was done by Veikko Eeva , the implementation of AWS DynamoDB MembershipTable was done by Gutemberg Ribeiro and the implementation of Consul based MembershipTable was done by Paul North ."
  },
  "1.5/Documentation/Core-Features/StatelessWorker.html": {
    "href": "1.5/Documentation/Core-Features/StatelessWorker.html",
    "title": "Stateless Worker Grains | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Stateless Worker Grains By default, the Orleans runtime creates no more than one activation of a grain within the cluster. This is the most intuitive expression of the Virtual Actor model with each grain corresponding to an entity with a unique type/identity. However, there are also cases when an application needs to perform functional stateless operations that are not tied to a particular entity in the system. For example, if client sends requests with compressed payloads that need to be decompressed before they could be routed to the target grain for processing, such decompression/routing logic is not tied to a specific entity in the application, and can easily scale out. When the [StatelessWorker] attribute is applied to a grain class, it indicates to the Orleans runtime that grains of that class should be treated as Stateless Worker grains. Stateless Worker grains have the following properties that make their execution very different from that of normal grain classes. The Orleans runtime can and will create multiple activations of a Stateless Worker grain on different silos of the cluster. Requests made to Stateless Worker grains are always executed locally, that is on the same silo where the request originated, either made by a grain running on the silo or received by the silo's client gateway. Hence, calls to Stateless Worker grains from other grains or from client gateways never incur a remote message. The Orleans Runtime automatically creates additional activations of a Stateless Worker grain if the already existing ones are busy. The maximum number of activations of a Stateless Worker grain the runtime creates per silo is limited by default by the number of CPU cores on the machine, unless specified explicitly by the optional maxLocalWorkers argument. Because of 2 and 3, Stateless Worker grain activations are not individually addressable. Two subsequent requests to a Stateless Worker grain may be processed by different activations of it. Stateless Worker grains provide a straightforward way of creating an auto-managed pool of grain activations that automatically scales up and down based on the actual load. The runtime always scans for available Stateless Worker grain activations in the same order. Because of that, it always dispatches a requests to the first idle local activation it can find, and only gets to the last one if all previous activations are busy. If all activations are busy and the activation limit hasn't been reached, it creates one more activation at the end of the list, and dispatches the request to it. That means that when the rate of requests to a Stateless Worker grain increases, and existing activations are all currently busy, the runtime expands the pool of its activations up to the limit. Conversely, when the load drops, and it can be handled by a smaller number of activations of the Stateless Worker grain, the activations at the tail of the list will not be getting requests dispatched to them. They will become idle, and eventually deactivated by the standard activation collection process. Hence, the pool of activations will eventually shrink to match the load. The following example defines a Stateless Worker grain class MyStatelessWorkerGrain with the default maximum activation number limit. [StatelessWorker] public class MyStatelessWorkerGrain : Grain, IMyStatelessWorkerGrain { ... } Making a call to a Stateless Worker grain is the same as to any other grain. The only difference is that in most cases a single grain ID is used, 0 or Guid.Empty . Multiple grain IDs can be used when having multiple Stateless Worker grain pools, one per ID, is desirable. var worker = GrainFactory.GetGrain<IMyStatelessWorkerGrain>(0); await worker.Process(args); This one defines a Stateless Worker grain class with no more than one grain activation per silo. [StatelessWorker(1)] // max 1 activation per silo public class MyLonelyWorkerGrain : ILonelyWorkerGrain { ... } Note that [StatelessWorker] attribute does not change reentrancy of the target grain class. Just like any other grains, Stateless Worker grains are non-reentrant by default. They can be explicitly made reentrant by adding a [Reentrant] attribute to the grain class. State The \"Stateless\" part of \"Stateless Worker\" does not mean that a Stateless Worker cannot have state and is limited only to executing functional operations. Like any other grain, a Stateless Worker grain can load and keep in memory any state it needs. It's just because multiple activations of a Stateless Worker grain can be created on the same and different silos of the cluster, there is no easy mechanism to coordinate state held by different activations. There are several useful patterns that involve Stateless Worker holding state. Scaled out hot cache items For hot cache items that experience high throughput, holding each such item in a Stateless Worker grain makes it a) automatically scale out within a silo and across all silos in the cluster; and b) makes the data always locally available on the silo that received the client request via its client gateway, so that the requests can be answered without an extra network hop to another silo. Reduce style aggregation In some scenarios applications need to calculate certain metrics across all grains of a particular type in the cluster, and report the aggregates periodically. Examples are reporting number of players per game map, average duration of a VoIP call, etc. If each of the many thousands or millions of grains were to report their metrics to a single global aggregator, the aggregator would get immediately overloaded unable to process the flood of reports. The alternative approach is to turn this task into a 2 (or more) step reduce style aggregation. The first layer of aggregation is done by reporting grain sending their metrics to a Stateless Worker pre-aggregation grain. The Orleans runtime will automatically create multiple activations of the Stateless Worker grain with each silo. Since all such calls will be processed locally with no remote calls or serialization of the messages, the cost of such aggregation will be significantly less than in a remote case. Now each of the pre-aggregation Stateless Worker grain activations, independently or in coordination with other local activations, can send their aggregated reports to the global final aggregator (or to another reduction layer if necessary) without overloading it."
  },
  "1.5/Documentation/Advanced-Concepts/Activation-Garbage-Collection.html": {
    "href": "1.5/Documentation/Advanced-Concepts/Activation-Garbage-Collection.html",
    "title": "Activation Garbage Collection | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Activation Garbage Collection As described in Grains , a grain activation is an in-memory instance of a grain class that gets automatically created by the Orleans runtime on an as-needed basis as a temporary physical embodiment of a grain. Activation Garbage Collection (Activation GC) is the process of removal from memory of unused grain activations. It is conceptually similar to how garbage collection of memory works in .NET. However, Activation GC only takes into consideration how long a particular grain activation has been idle. Memory usage is not used as a factor. How Activation GC Works The general process of Activation GC involves Orleans runtime in a silo periodically scanning for grain activations that have not been used at all for the configured period of time (Collection Age Limit). Once a grain activation has been idle for that long, it gets deactivated. The deactivation process begins by the runtime calling the grain’s OnDeactivateAsync() method, and completes by removing references to the grain activation object from all data structures of the silo, so that the memory is reclaimed by the .NET GC. As a result, with no burden put on the application code, only recently used grain activations stay in memory while activations that aren't used anymore get automatically removed, and system resources used by them get reclaimed by the runtime. What counts as “being active” for the purpose of grain activation collection receiving a method call receiving a reminder receiving an event via streaming What does NOT count as “being active” for the purpose of grain activation collection performing a call (to another grain or to an Orleans client) timer events arbitrary IO operations or external calls not involving Orleans framework Collection Age Limit This period of time after which an idle grain activation becomes subject to Activation GC is called Collection Age Limit. The default Collection Age Limit is 2 hours, but it can be changed globally or for individual grain classes. Explicit Control of Activation Garbage Collection Delaying Activation GC A grain activation can delay its own Activation GC, by calling this.DelayDeactivation() method: protected void DelayDeactivation(TimeSpan timeSpan) This call will ensure that this activation is not deactivated for at least the specified time duration. It takes priority over Activation Garbage Collection settings specified in the config, but does not cancel them. Therefore, this call provides an additional hook to delay the deactivation beyond what is specified in the Activation Garbage Collection settings . This call can not be used to expedite Activation Garbage Collection. A positive timeSpan value means “prevent GC of this activation for that time span”. A negative timeSpan value means “cancel the previous setting of the DelayDeactivation call and make this activation behave based on the regular Activation Garbage Collection settings”. Scenarios: 1) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation (20 min), it will cause this activation to not be collected for at least 20 min. 2) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation (5 min), the activation will be collected after 10 min, if no extra calls were made. 3) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation (5 min), and after 7 minutes there is another call on this grain, the activation will be collected after 17 min from time zero, if no extra calls were made. 4) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation (20 min), and after 7 minutes there is another call on this grain, the activation will be collected after 20 min from time zero, if no extra calls were made. Note that DelayDeactivation does not 100% guarantee that the grain activation will not get deactivated before the specified period of time expires. There are certain failure cases that may cause 'premature' deactivation of grains. That means that DelayDeactivation cannot not be used as a means to 'pin' a grain activation in memory forever or to a specific silo . DelayDeactivation is merely an optimization mechanism that can help reduce the aggregate cost of a grain getting deactivated and reactivated over time, if that matters. In most cases there should be no need to use DelayDeactivation at all. Expediting Activation GC A grain activation can also instruct the runtime to deactivate it next time it becomes idle by calling this.DeactivateOnIdle() method: protected void DeactivateOnIdle() A grain activation is considered idle if it is not processing any message at the moment. If you call DeactivateOnIdle while a grain is processing a message, it will get deactivated as soon as processing of the current message is finished. If there are any requests queued for the grain, they will be forwarded to the next activation. DeactivateOnIdle take priority over any Activation Garbage Collection settings specified in the config or DelayDeactivation . Note that this setting only applies to the grain activation from which it has been called and it does not apply to other grain activation of this type. Configuration Programmatic Configuration Default Collection Age Limit (for all grain types) can be set via: void GlobalConfiguration.Application.SetDefaultCollectionAgeLimit(TimeSpan ageLimit) For individual grain types the limit can be set via: void GlobalConfiguration.Application.SetCollectionAgeLimit(Type type, TimeSpan ageLimit) The limit can also be reset for a grain type, so that the default limit would apply to it, via: void GlobalConfiguration.Application.ResetCollectionAgeLimitToDefault(Type type) XML Configuration (deprecated) Any length of time in the configuration XML file may use a suffix that specifies a unit of time: Suffix Unit none millisecond(s) ms millisecond(s) s second(s) m minute(s) hr hour(s) Specifying Default Collection Age Limit The default collection age limit that applies to all grain types can be customized by adding the OrleansConfiguation/Globals/Application/Defaults/Deactivation element to the OrleansConfiguration.xml file. The minimal allowed age limit is 1 minute. The following example specifies that all activations that have been idle for 10 minutes or more should be considered eligible for deactivation. <?xml version=\"1.0\" encoding=\"utf-8\"?> <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <Application> <Defaults> <Deactivation AgeLimit=\"10m\"/> </Defaults> </Application> </Globals> </OrleansConfiguration> Specifying per-Type Age Limits Individual grain types may specify a collection age limit that is independent from the global default, using the OrleansConfiguation/Globals/Application/GrainType/Deactivation element. The minimal allowed age limit is 1 minute. In the following example, activations that have been idle for 10 minutes are eligible for collection, except activations that are instantiations of the MyGrainAssembly.DoNotDeactivateMeOften class, which are not considered collectable unless idle for a full 24 hours: <?xml version=\"1.0\" encoding=\"utf-8\"?> <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <Application> <Defaults> <Deactivation AgeLimit=\"10m\"/> </Defaults> <GrainType Type=\"MyGrainAssembly.DoNotDeactivateMeOften\"> <Deactivation AgeLimit=\"24hr\"/> </GrainType> </Application> </Globals> </OrleansConfiguration> Any number of GrainType elements may be specified."
  },
  "index.html": {
    "href": "index.html",
    "title": "Microsoft Orleans | Microsoft Orleans Documentation",
    "keywords": ""
  },
  "Documentation/tutorials_and_samples/MathGrains.html": {
    "href": "Documentation/tutorials_and_samples/MathGrains.html",
    "title": "MathGrains | Microsoft Orleans Documentation",
    "keywords": "MathGrains A calculator that encapsulates functionality into specialized grains."
  },
  "Documentation/tutorials_and_samples/index.html": {
    "href": "Documentation/tutorials_and_samples/index.html",
    "title": "Samples Overview | Microsoft Orleans Documentation",
    "keywords": "Samples Overview What do I need? The samples are self-contained, except where noted. You will need An Azure subscription will help with some of the samples, but is not required. For the Azure-based samples, you will need to install the SDK. The samples themselves can be downloaded from GitHub . Hello World This is the Orleans version of an old classic. It demonstrates that while there is no such thing as \"trivial\" when you are dealing with distributed computing, Orleans makes it pretty straight-forward. MathGrains This is a simple calculator that uses Orleans core components to encapsulate the functionality. Adventure Before there was graphical user interfaces, before the era of game consoles and massive-multiplayer games, there were VT100 terminals and there was Colossal Cave Adventure . Possibly lame by today's standards, back then it was a magical world of monsters, chirping birds, and things you could pick up. It's the inspiration for this sample."
  },
  "Documentation/streaming/streams_programming_APIs.html": {
    "href": "Documentation/streaming/streams_programming_APIs.html",
    "title": "Orleans Streams Programming APIs | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Programming APIs Applications interact with streams via APIs that are very similar to the well known Reactive Extensions (Rx) in .NET . The main difference is that Orleans stream extensions are asynchronous , to make processing more efficient in Orleans' distributed and scalable compute fabric. Async Stream An application starts by using a stream provider to get a handle to a stream. You can read more about stream providers here , but for now you can think of it as stream factory that allows implementers to customize streams behavior and semantics: IStreamProvider streamProvider = base.GetStreamProvider(\"SimpleStreamProvider\"); IAsyncStream<T> stream = streamProvider.GetStream<T>(Guid, \"MyStreamNamespace\"); Application can get a reference to the stream provider either by calling the GetStreamProvider method on the Grain class when inside a grain, or by calling GrainClient.GetStreamProvider() method when on the client. Orleans.Streams.IAsyncStream<T> is a logical, strongly-typed handle to a virtual stream . It is similar in spirit to Orleans Grain Reference. Calls to GetStreamProvider and GetStream are purely local. The arguments to GetStream are a GUID and an additional string that we call a stream namespace (which can be null). Together the GUID and the namespace string comprise the stream identity (similar in sprit to the arguments to GrainFactory.GetGrain ). The combination of GUID and namespace string provide extra flexibility in determining stream identities. Just like grain 7 may exist within the Grain type PlayerGrain and a different grain 7 may exist within the grain type ChatRoomGrain , Stream 123 may exist with the stream namespace PlayerEventsStream and a different stream 123 may exist within the stream namespace ChatRoomMessagesStream . Producing and Consuming IAsyncStream<T> implements both Orleans.Streams.IAsyncObserver<T> and Orleans.Streams.IAsyncObservable<T> interfaces. That way an application can use the stream either to produce new events into the stream by using Orleans.Streams.IAsyncObserver<T> or to subscribe to and consume events from a stream by using Orleans.Streams.IAsyncObservable<T> . public interface IAsyncObserver<in T> { Task OnNextAsync(T item, StreamSequenceToken token = null); Task OnCompletedAsync(); Task OnErrorAsync(Exception ex); } public interface IAsyncObservable<T> { Task<StreamSubscriptionHandle<T>> SubscribeAsync(IAsyncObserver<T> observer); } To produce events into the stream, an application just calls await stream.OnNextAsync<T>(event) To subscribe to a stream, an application calls StreamSubscriptionHandle<T> subscriptionHandle = await stream.SubscribeAsync(IAsyncObserver) The argument to SubscribeAsync can either be an object that implements the IAsyncObserver interface or a combination of lambda functions to process incoming events. More options for SubscribeAsync are available via AsyncObservableExtensions class. SubscribeAsync returns a StreamSubscriptionHandle<T> , which is an opaque handle that can be used to unsubscribe from the stream (similar in spirit to an asynchronous version of IDisposable ). await subscriptionHandle.UnsubscribeAsync() It is important to note that the subscription is for a grain, not for an activation . Once the grain code subscribed to the stream, this subscription surpasses the life of this activation and stays durable forever, until the grain code (potentially in a different activation) explicitly unsubscribes. This is the heart of a virtual stream abstraction : not only all the streams always exists, logically, but also that a stream subscription is durable and lives beyond a particular physical activation that issued this subscription. Multiplicity An Orleans stream may have multiple producers and multiple consumers. A message published by a producer will be delivered to all consumers that were subscribed to the stream before the message was published. In addition, the consumer can subscribe to the same stream multiple times. Each time it subscribes it gets back a unique StreamSubscriptionHandle<T> . If a grain (or client) is subscribed X times to the same stream, it will receive the same event X times, once for each subscription. The consumer can also unsubscribe from an individual subscription or find out all its current subscriptions, by calling: IList<StreamSubscriptionHandle<T>> allMyHandles = await IAsyncStream<T>.GetAllSubscriptionHandles() Recovering From Failures If the producer of a stream dies (or its grain is deactivated), there is nothing it needs to do. Next time this grain wants to produce more events it can get the stream handle again and produce new events in the same way. Consumer logic is a little bit more involved. As we said before, once consumer grain subscribed to a stream, this subscription is valid until it explicitly unsubscribes. If the consumer of the stream dies (or its grain is deactivated) and new event is generated on the stream, the consumer grain will be automatically re-activated (just like any regular Orleans grain is automatically activated upon message to it). The only thing that the grain code needs to do now is to provide a IAsyncObserver<T> to process the data. The consumer basically need to re-attach processing logic as part of OnActivateAsync method. To do that it can call: StreamSubscriptionHandle<int> newHandle = await subscriptionHandle.ResumeAsync(IAsyncObserver) The consumer uses the previous handle it got when it first subscribed in order to \"resume processing\". Notice that ResumeAsync merely updates an existing subscription with the new instance of IAsyncObserver logic and does not change the fact that this consumer is already subscribed to this stream. How the consumer has an old subscriptionHandle? There are 2 options. The consumer may have persisted the handle it was given back from the original SubscribeAsync operation and can use it now. Alternatively, if the consumer does not have the handle, it can ask the IAsyncStream<T> for all its active subscription handles, by calling: IList<StreamSubscriptionHandle<T>> allMyHandles = await IAsyncStream<T>.GetAllSubscriptionHandles() The consumer can now resume all of them, or unsubscribe from some if he wishes to. COMMENT: If the consumer grain implements the the IAsyncObserver interface directly ( public class MyGrain<T> : Grain, IAsyncObserver<T> ), it should in theory not be required to re-attach the IAsyncObserver and thus will not need to call ResumeAsync . The streaming runtime should be able to automatically figure out that the grain already implements IAsyncObserver and will just invoke those IAsyncObserver methods. However, the streaming runtime currently does not support this and the grain code still needs to explicitly call ResumeAsync , even if the grain implements IAsyncObserver directly. Supporting this is on our TODO list. Explicit and Implicit Subscriptions By default, stream consumer has to explicitly subscribe to the stream. This subscription would usually be triggered by some external message that the grain (or client) receive that instructs them to subscribe. For example, in a chat service when user joins a chat room his grain receives a JoinChatGroup message with the chat name and it will cause the user grain to subscribe to this chat stream. In addition, Orleans Streams also support \"Implicit Subscriptions\" . In this model the grain does not explicitely subscribe to the stream. This grain is subscribed automatically, implicitly, just based on its grain identity and an ImplicitStreamSubscription attribute. Implicit subscriptions main value is allowing the stream activity to trigger the grain activation (hence triggering the subscription) automaticaly. For example, using SMS streams, if one grain wanted to produce a stream and another grain process this stream, the producer would need to know the identity of the consumer grain and make a grain call to it telling it to subscribe to the stream. Only after that it can start sending events. Instead, using implicit subscriptions, the producer can just start producing events onto a stream, and the consumer grain will automatically be activated and subscribe to the stream. In that case, the producer doesn't care at all who is reading the events Grain implementation class of type MyGrainType can declare an attribute [ImplicitStreamSubscription(\"MyStreamNamespace\")] . This tells the streaming runtime that when an event is generated on a stream whose identity is GUID XXX and \"MyStreamNamespace\" namespace, it should be delivered to grain whose identity is XXX of type MyGrainType . That is, the runtime maps stream <XXX, MyStreamNamespace> to consumer grain <XXX, MyGrainType> . The presence of ImplicitStreamSubscription causes the streaming runtime to automatically subscribe this grain to a stream and deliver the stream events to it. However, the grain code still needs to tell the runtime how it wants events to be processed. Essentially, it need to attach the IAsyncObserver . Therefore, when the grain is activated, the grain code inside OnActivateAsync needs to call: IStreamProvider streamProvider = base.GetStreamProvider(\"SimpleStreamProvider\"); IAsyncStream<T> stream = streamProvider.GetStream<T>(this.GetPrimaryKey(), \"MyStreamNamespace\"); StreamSubscriptionHandle<T> subscription = await stream.SubscribeAsync(IAsyncObserver<T>); Writing Subscription Logic Below are the guidelines on how to write the subscription logic for various cases: explicit and implicit subscriptions, rewindable and non-rewindable streams. The main difference between explicit and implicit subscriptions is that for implicit the grain always has exactly one implicit subscription for every stream namespace, there is no way to create multiple subscriptions (there is no subscription multiplicity), there is no way to unsubscribe, and the grain logic always only needs to attach the processing logic. That also means that for implicit subscriptions there is never a need to Resume a subscription. On the other hand, for explicit subscriptions, one needs to Resume the subscription, otherwise if the grain subscribes again it will result in the grain being subscribed multiple times. Implicit Subscriptions: For implicit subscriptions the grain needs to subscribe to attach the processing logic. This should be done in the grain's OnActivateAsync method. The grain should simply execute await stream.SubscribeAsync(OnNext ...) in its OnActivateAsync method. That will cause this particular activation to attach the OnNext function to process that stream. The grain can optionally specify the StreamSequenceToken as an argument to SubscribeAsync , which will cause this implicit subscription to start consuming from that token. There is never a need for implicit subscription to call ResumeAsync . public async override Task OnActivateAsync() { var streamProvider = GetStreamProvider(PROVIDER_NAME); var stream = streamProvider.GetStream<string>(this.GetPrimaryKey(), \"MyStreamNamespace\"); await stream.SubscribeAsync(OnNextAsync) } Explicit Subscriptions: For explicit subscriptions, a grain must call SubscribeAsync to subscribe to the stream. This creates a subscription, as well as attaches the processing logic. The explicit subscription will exist until the grain unsubscribes, so if a grain gets deactivated and reactivated, the grain is still explicitly subscribed, but no processing logic will be attached. In this case the grain needs to re-attach the processing logic. To do that, in its OnActivateAsync , the grain first needs to find out what subscriptions it has, by calling stream.GetAllSubscriptionHandles() . The grain must execute ResumeAsync on each handle it wishes to continue processing or UnsubscribeAsync on any handles it is done with. The grain can also optionally specify the StreamSequenceToken as an argument to the ResumeAsync calls, which will cause this explicit subscription to start consuming from that token. public async override Task OnActivateAsync() { var streamProvider = GetStreamProvider(PROVIDER_NAME); var stream = streamProvider.GetStream<string>(this.GetPrimaryKey(), \"MyStreamNamespace\"); var subscriptionHandles = await stream.GetAllSubscriptionHandles(); if (!subscriptionHandles.IsNullOrEmpty()) subscriptionHandles.ForEach(async x => await x.ResumeAsync(OnNextAsync)); } Stream Order and Sequence Tokens The order of events delivery between an individual producer and an individual consumer depends on a stream provider. With SMS the producer explicitly controls the order of events seen by the consumer by controlling the way he publishes them. By default (if the FireAndForget options for SMS provider is set to false) and if the producer awaits every OnNextAsync call, the events arrive in FIFO order. In SMS it is up to the producer to decide how to handle delivery failures that will be indicated by a broken Task returned by the OnNextAsync call. Azure Queue streams do not guarantee FIFO order, since the underlying Azure Queues do not guarantee order in failure cases (they do guarantee FIFO order in failure free executions). When a producer produces the event into Azure Queue, if the enqueue operation failed, it is up to the producer to attempt another enqueue and later on deal with potential duplicates messages. On the delivery side, Orleans Streaming runtime dequeues the event from the Azure Queue and attempts to deliver it for processing to consumers. Orleans Streaming runtime deletes the event from the queue only upon successful processing. If the delivery or processing failed, the event is not delete from the queue and will automatically re-appear in the queue much later. The Streaming runtime will try to deliver it again, thus potentially breaking the FIFO order. The described behaivour matches the regular semantics of Azure Queues. Application Defined Order : To deal with the above ordering issues, application can optionally specify its own ordering. This is achived via a notion of StreamSequenceToken . StreamSequenceToken is an opaque IComparable object that can be used to order events. A producer can pass an optional StreamSequenceToken to the OnNext call. This StreamSequenceToken will be passed all the way to the consumer and will be delivered together with the event. That way, application can reason and reconstruct it's order independently from the streaming runtime. Rewindable Streams Some streams only allow application to subscribe to them starting at the latest point in time, while other streams allow \"going back in time\". The latter capability is dependent on the underlying queuing technology and the particular stream provider. For example, Azure Queues only allow consuming the latest enqueued events, while EventHub allows replaying events from an arbitrary point in time (up to some expiration time). Streams that support going back in time are called Rewindable Streams . The consumer of a rewindable stream can pass a StreamSequenceToken to the SubscribeAsync call and the runtime will deliver events to it starting from that StreamSequenceToken (a null token means the consumer wants to receive events starting from the latest). The ability to rewind a stream is very useful in recovery scenarios. For example, consider a grain that subscribes to a stream and periodically checkpoints its state together with the latest sequence token. When recovering from a failure, the grain can re-subscribe to the same stream from the latest checkpointed sequence token, thereby recovering without losing any events that were generated since the last checkpoint. Current Status of Rewindable Streams: Both SMS and Azure Queue providers are not-rewindable and Orleans currently does not include an implementation of rewindable streams. We are actively working on this. Stateless Automatically Scaled-Out Processing By default Orleans Streaming is targeted to support a large number of relatively small streams, each is processed by one or more statefull grains. Collectively, the processing of all the streams together is sharded among a large number of regular (statefull) grains. The application code controls this sharding by assigning stream ids, grain ids and explicitly subscribing. The goal is sharded statefull processing . However, there is also an interesting scenario of automatically scaled-out stateless processing . In this scenario application has a small number of streams (or even one large stream) and the goal is stateless processing. For example, a global stream of all messages for all events and the processing involving some kind of decoding/deciphering and potentially forwarding them for further statefull processing into another set of streams. The stateless scaled-out stream processing can be supported in Orleans via StatelessWorker grains. Current Status of Stateless Automatically Scaled-Out Processing: This is currently not implemented (due to priority constrains). An attempt to subscribe to a stream from a StatelessWorker grain will result in undefined behavior. We are currently considering to support this option . Grains and Orleans Clients Orleans streams work uniformly across grains and Orleans clients . That is, exactly the same APIs can be used inside a grain and in an Orleans client to produce and consume events. This greatly simplifies the application logic, making special client-side APIs, such as Grain Observers, redundant. Fully Managed and Reliable Streaming Pub-Sub To track stream subscriptions, Orleans uses a runtime component called Streaming Pub-Sub which serves as a rendezvous point for stream consumers and stream producers. Pub Sub tracks all stream subscriptions, persists them, and matches stream consumers with stream producers. Applications can choose where and how the Pub-Sub data is stored. The Pub-Sub component itself is implemented as grains (called PubSubRendezvousGrain ) and it is using Orleans Declarative Persistence for those grains. PubSubRendezvousGrain uses storage provider named PubSubStore . As with any grain, you can designate an implementation for a storage provider. For Streaming Pub-Sub you can change the implementation of the PubSubStore at silo construction time using the silo host builder: The below configures the Pub Sub to store its state in azure tables. hostBuilder.AddAzureTableGrainStorage(\"PubSubStore\", options=>{ options.ConnectionString = \"Secret\"; }); That way Pub-Sub data will be durably stored in Azure Table. For initial development you can use the memory storage as well. In addition to the Pub-Sub, Orleans Streaming Runtime delivers events from producers to consumers, manages all runtime resources allocated to actively used streams, and transparently garbage collects runtime resources from unused streams. Configuration In order to use streams you need to enable stream providers via the silo host or cluster client builders. You can read more about stream providers here . Sample stream provider setup: hostBuilder.AddSimpleMessageStreamProvider(\"SMSProvider\") .AddAzureQueueStreams<AzureQueueDataAdapterV2>(\"AzureQueueProvider\", optionsBuilder => optionsBuilder.Configure( options=>{ options.ConnectionString = \"Secret\"; })) .AddAzureTableGrainStorage(\"PubSubStore\", options=>{ options.ConnectionString = \"Secret\"; }); Next Orleans Stream Providers"
  },
  "1.5/Tutorials/Cloud-Deployment.html": {
    "href": "1.5/Tutorials/Cloud-Deployment.html",
    "title": "Cloud Deployment | Microsoft Orleans Documentation",
    "keywords": "Cloud Deployment Deploying Orleans to Windows Azure This walkthrough shows the steps required to deploy the sample created in the Front Ends for Orleans Services to Windows Azure Cloud Services. In Azure, one or more worker roles will be used to host the Orleans silos, and an Azure web role will act as the presentation layer for the application and client to the application grains running in the Orleans silos. The same grain interfaces and implementation can run on both Windows Server and Windows Azure, so no special considerations are needed in order to be able to run your application in a Windows Azure hosting environment. The Azure Web Sample sample app provides a working example of how to run a web application with supporting Orleans silo cluster backend in an Azure hosted service, and the details are described below. Pre-requisites The following prerequisites are required: Visual Studio 2013 or 2015 Windows Azure SDK v2.4 or higher For more info on installing and working with Windows Azure in general, see the Microsoft Azure documentation web site: ( https://docs.microsoft.com/en-us/azure/ ) Create Azure Worker Role for Orleans Silos Right click on your solution, and select 'Add | New Project...'. Choose the 'Windows Azure Cloud Service' project template: When prompted, select a new 'Worker Role' to add to the project. This will be used to host the Orleans Silos: Add project references for Orleans Silo binaries Add references to the OrleansAzureSilo project for the required Orleans server library files. Copies of these files can be found in the .\\Binaries\\OrleansServer folder under the Orleans SDK. Orleans.dll OrleansAzureUtils.dll OrleansRuntime.dll OrleansProviders.dll (Only required if you your grains use the Declarative Persistence functionality.) Note: All of these references MUST have Copy Local = 'True' settings to ensure the necessary library DLLs get copied into the OrleansAzureSilo project output directory. Configure Azure Worker Role for Orleans Silos The Worker Role initialization class is a normal Azure worker role - it needs to inherit from the usual Microsoft.WindowsAzure.ServiceRuntime.RoleEntryPoint base class. The worker role initialization class needs to create an instance of Orleans.Runtime.Host.AzureSilo class, and call the appropriate Start / Run / Stop functions in the appropriate places: public class WorkerRole : RoleEntryPoint { AzureSilo silo; public override bool OnStart() { // Do other silo initialization – for example: Azure diagnostics, etc return base.OnStart(); } public override void OnStop() { silo.Stop(); base.OnStop(); } public override void Run() { var config = AzureSilo.DefaultConfiguration(); config.AddMemoryStorageProvider(); config.AddAzureTableStorageProvider(\"AzureStore\", RoleEnvironment.GetConfigurationSettingValue(\"DataConnectionString\")); // Configure storage providers silo = new AzureSilo(); bool ok = silo.Start(config); silo.Run(); // Call will block until silo is shutdown } } It is IMPORTANT to start the silo not in OnStart but in Run. Azure may not have the firewalls open yet (on the remote silos) at the OnStart phase. Then, in the ServiceDefinition.csdef file for this role, add some required configuration items used by the Orleans Azure hosting library to the WorkerRole configuration: Add a ConfigurationSettings declaration named 'DataConnectionString'. This is the Azure storage location where Orleans Azure hosting library will place / look for its silo instance table. Add an InternalEndpoint declaration for a TCP endpoint named 'OrleansSiloEndpoint' Add an InternalEndpoint declaration for a TCP endpoint named 'OrleansProxyEndpoint' <ServiceDefinition ...> <WorkerRole name=\"OrleansAzureSilos\" ...> ... <ConfigurationSettings> <Setting name=\"Microsoft.WindowsAzure.Plugins.Diagnostics.ConnectionString\" /> <Setting name=\"DataConnectionString\" /> </ConfigurationSettings> <Endpoints> <InternalEndpoint name=\"OrleansSiloEndpoint\" protocol=\"tcp\" port=\"11111\" /> <InternalEndpoint name=\"OrleansProxyEndpoint\" protocol=\"tcp\" port=\"30000\" /> </Endpoints> ... </WorkerRole> ... </ServiceDefinition> In the ServiceConfiguration.cscfg file for this role, add some required configuration items used by the Orleans Azure hosting library: Add a ConfigurationSettings definition for 'DataConnectionString' This will be a normal Azure storage connection – either for the development storage emulator (only valid if running locally), or a full Azure storage account connection string for cloud-storage. In general, this connection string is likely to use the same configuration values as the Microsoft.WindowsAzure.Plugins.Diagnostics.ConnectionString diagnostics connection string setting, but is not required to. Be careful to not mix up Azure storage and local storage. This can cause deployments to not work. See the Configure Azure Storage Connection Strings for more information. For example, to use local Developer Storage emulator (for local testing only) <ConfigurationSettings> <Setting name=\"Microsoft.WindowsAzure.Plugins.Diagnostics.ConnectionString\" value=\"UseDevelopmentStorage=true\" /> <Setting name=\"DataConnectionString\" value=\"UseDevelopmentStorage=true\" /> </ConfigurationSettings> Or using an Azure cloud storage account: <ConfigurationSettings> <Setting name=\"Microsoft.WindowsAzure.Plugins.Diagnostics.ConnectionString\" value=\"DefaultEndpointsProtocol=https;AccountName=MyAccount;AccountKey=MyKey\" /> <Setting name=\"DataConnectionString\" value=\"DefaultEndpointsProtocol=https;AccountName=MyAccount;AccountKey=MyKey\" /> </ConfigurationSettings> Changing DataConnectionString The \"DataConnectionString\" setting in ServiceDefinition.csdef is the default name use by the Orleans silo for the Azure table account connection string that will be used for Orleans system tables such as OrleanSiloInstances . If you wish to use a different setting name for this value, then in the silo role initialization code set the property OrleansAzureSilo.DataConnectionConfigurationSettingName before the call to OrleansAzureSilo.Start(...) Add your grain binaries to Azure Worker Role for Orleans Silos Add the grain interfaces DLL and implementation classes DLL for the grains to be hosted in the Azure silo into the OrleansAzureSilo project, along with any supporting libraries those grains need. Note: You MUST ensure that all the referenced binaries are copied into the OrleansAzureSilo project output directory, to ensure they get picked up by the Azure packaging tools. Running Orleans Client as Azure Web Role The user interface / presentation layer for your application will usually run as a Web Role in Azure. The Orleans.Runtime.Host.AzureClient utility class is the main mechanism for bootstrapping connection to the Orleans silo worker roles from an Azure Web Role. A few additional configuration steps are needed to make the AzureClient utility class work – see below for details. Create Azure Web Role for Orleans Client Any type of web role can be used as an Orleans client, and there are no specific naming requirements or conventions for this project. Add a web role to the solution using the existing web application project that we created in the Front Ends for Orleans Services tutorial. Add project references for Orleans Client binaries. Add references to the web role project for the required Orleans client library files. Copies of these files can be found in either SDK-ROOT\\Samples\\References or SDK-ROOT\\Binaries\\OrleansClient directories. Orleans.dll OrleansAzureUtils.dll Note: All of these references MUST have Copy Local = 'True' settings to ensure the necessary library DLLs get copied into the web role project output directory. Configure Azure Web Role to be an Orleans Client In the ServiceDefinition.csdef file for this web role, add some required configuration items used by the Orleans Azure hosting library: Add a ConfigurationSettings declaration named 'DataConnectionString'. This is the Azure storage location where Orleans Azure hosting library will place / look for its silo instance table. In addition, a http/s InputEndpoint will also need to be declared, just as for any other Azure web role config. <ServiceDefinition ...> <WebRole name=\"MyWebRole\" ...> ... <Sites> <Site name=\"Web\"> <Bindings> <Binding name=\"Endpoint1\" endpointName=\"Endpoint1\" /> </Bindings> </Site> </Sites> <ConfigurationSettings> <Setting name=\"Microsoft.WindowsAzure.Plugins.Diagnostics.ConnectionString\" /> <Setting name=\"DataConnectionString\" /> </ConfigurationSettings> <Endpoints> <InputEndpoint name=\"Endpoint1\" protocol=\"http\" port=\"80\" /> </Endpoints> ... </WebRole> ... </ServiceDefinition> In the ServiceConfiguration.cscfg file for this role, add some required configuration items used by the Orleans Azure hosting library: Add a ConfigurationSettings definition for 'DataConnectionString'. This will be a normal Azure storage connection – either for the development storage emulator (if running locally), or a full Azure storage account connection string for cloud-storage. This setting MUST match the DataConnectionString value used by the OrleansSiloWorker role in order for the client to discover and bootstrap the connection to the Orleans silos. For example, to use local Developer Storage emulator (for local testing only) <ServiceConfiguration ...> <Role name=\"OrleansWebClient\" ...> ... <ConfigurationSettings> <Setting name=\"Microsoft.WindowsAzure.Plugins.Diagnostics.ConnectionString\" value=\"UseDevelopmentStorage=true\" /> <Setting name=\"DataConnectionString\" value=\"UseDevelopmentStorage=true\" /> </ConfigurationSettings> ... </Role> ... </ServiceConfiguration> Or using an Azure cloud storage account: <ServiceConfiguration ...> <Role name=\"OrleansWebClient\" ...> ... <ConfigurationSettings> <Setting name=\"Microsoft.WindowsAzure.Plugins.Diagnostics.ConnectionString\" value=\"DefaultEndpointsProtocol=https;AccountName=MyAccount;AccountKey=MyKey\" /> <Setting name=\"DataConnectionString\" value=\"DefaultEndpointsProtocol=https;AccountName=MyAccount;AccountKey=MyKey\" /> </ConfigurationSettings> ... </Role> ... </ServiceConfiguration> Add your grain interface binaries to Azure Web Role for Orleans Client Add the grain interfaces DLL for the application grains into this web role project. Access to the DLL containing the grain implementation classes should not be required by the client web role. Note: You MUST ensure that all the referenced binaries for grain interfaces and the generated proxy / factory libraries are copied into the web role project output directory, to ensure they get picked up by the Azure packaging tools. The grain implementation DLLs should not be required by the client and so should not be referenced by the web role. Initialize Client Connection to Orleans Silos It is recommended to bootstrap and initialize the client connection to the Orleans silo worker roles, to ensure a connection is set up before use in the Global.asax initialization methods. Edit the configuration of the client in the Global.asax.cs file to use AzureClient . namespace WebApplication1 { public class WebApiApplication : System.Web.HttpApplication { protected void Application_Start() { ... var config = AzureClient.DefaultConfiguration(); // Attempt to connect a few times to overcome transient failures and to give the silo enough // time to start up when starting at the same time as the client (useful when deploying or during development). const int initializeAttemptsBeforeFailing = 5; int attempt = 0; while (true) { try { AzureClient.Initialize(config); break; } catch (SiloUnavailableException e) { attempt++; if (attempt >= initializeAttemptsBeforeFailing) { throw; } Thread.Sleep(TimeSpan.FromSeconds(2)); } } ... Repeated calls to AzureClient.Initialize() will return and do nothing if the Orleans client connection is already set up. An additional variant of AzureClient.Initialize(System.IO.FileInfo) allows a base client config file location to be specified explicitly. The internal endpoint addresses of the Orleans silo nodes will still be determined dynamically from the Orleans Silo instance table each silo node registers with. <!--TODO: Create link to Orleans API when the link is created/found--> See the Orleans API docs for details of the various Initialize methods available. Deploying to Azure The normal Azure deployment tools are used to deploy the application to Windows Azure – either into the local Azure Compute Emulator for local development / test (Press F5 to run), or into the Azure cloud hosting environment right click on the Cloud project and select 'Publish': Next Let's look at the steps required to run Orleans on Windows Server: On-Premise Deployment"
  },
  "1.5/Tutorials/index.html": {
    "href": "1.5/Tutorials/index.html",
    "title": "Step by Step Tutorials | Microsoft Orleans Documentation",
    "keywords": "These tutorials are for the 1.5 release Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Step by Step Tutorials The collection of technology walkthrough tutorials found here is intended to introduce you to the features of this exciting technology, spanning the programming model, its configuration, deployment, and customization. They build on each other, so it is best to go through them in the order outlined below. Each walkthrough is focused narrowly on just a couple of specific concepts in isolation from the scenarios that motivate your using Orleans in the first place, they are intended to teach you the mechanics of Orleans, not to explain when or why you should be using them. My First Orleans Application This walkthrough shows you how to create a \"Hello World\" application using Orleans and run it in the simplest possible single-process environment, one that is convenient for debugging your code. Minimal Orleans Application This walkthrough is an alternative to the My First Orleans Application tutorial. It walks step by step through a basic application, using only the nuget packages. Running in a Stand-Alone Silo In this walkthrough, the simple \"Hello World\" application is modified to use a more typical environment for services: separate processes for the client and service code. It is still a development and debugging environment, simpler than a production configuration, which would involve multiple processes on multiple computers. Actor Identity Actors are a lot like regular objects, but there are a couple of quirks that make them different. One is the notion of actor identity, which surfaces in Orleans in the form of grains' primary keys. A Service is a Collection of Communicating Actors The previous examples used only a single actor type and instance to demonstrate their concepts. In almost all real systems, this is the opposite of what you would want to do; actors are intended to be as light-weight as objects and you would expect hundreds of thousands or millions of them to be active on a single system simultaneously, with as potentially billions waiting inactive in persistent store. This walkthrough explains the actor lifecycle and identity, how actors are activated and deactivated. Concurrency What distinguishes the actor model from most other (distributed) object models is that it enforces a specific set of rules for concurrent access to state, allowing it to be free of data races by exchanging data between actors using message-passing and only allowing a single thread of execution to access each actor's internal state at any given point in time. On the other hand, there are many situations where data races are not a risk, and the single-threaded model is too conservative. Further, single-threaded execution can cause other problems, such as deadlocks. Orleans offers a few tools that allow developers to control this behavior, explained in this walkthrough. Interaction with Libraries and Services Applications using Orleans are regular .NET applications, and can interact freely with other .NET components. In order to not undermine the scalability inherent in the actor model, programmers have to take care to follow a few rules, mostly related to using asynchronous APIs whenever they are available. This walkthrough demonstrates the basic principles. Declarative Persistence Actors are often transient, i.e., their state lives only for a short period of time, or is reconstructible at will from other actors. In many circumstances, however, actor state needs to persist for longer periods of time and be stored in an external database of some sort. Orleans offers the developer flexible options on where to store actor state, and this walkthrough will introduce the simplest way to deal with long-lived actor state: declaratively. Handling Failures Everything is easy and beautiful in a distributed system until something fails and handling failures is one of the hardest things in any computer program. In this section we will learn how we can handle failures. Front Ends for Orleans Services Many Orleans services will be private and available only to front-end services that rely on the Orleans-based code as one of several backend services. In some circumstances, what is needed is to put a thin HTTP layer in front of the backend service, essentially making the Orleans service itself publically available via HTTP. In this walk-through, the steps of producing a thin HTTP layer based on ASP.NET Web API is described. Cloud Deployment The next walkthrough demonstrates how to get your Orleans application deployed in the cloud using Azure. On-Premise Deployment Orleans applications can be deployed both on your server equipment as well as in the cloud. In this walkthrough, you will see how to set up an on premise cluster and deploy your application to it. Custom Storage Providers Defining your own storage provider is the easiest way to extend the persistence choices of your Orleans application. While Orleans comes with a couple of storage providers in the box, they are not intended to be the only choices or constrain you unnecessarily. Therefore, the library offers a way to extend the set of storage providers to include This walkthrough demonstrates how to extend the choices by building a storage provider based on regular files. Unit Testing Grains Writing tests is one of the essential parts of the software development process which allows you to maintain your code easily, refactor with ease and sleep well when a new team member is changing 3 years old code. Orleans makes it very easy to write different kinds of tests for your Orleans application. this tutorial describes how to write simple unit tests to check if each grain method is having the right behavior. More complex scenarios like load testing and object mocking are not described here."
  },
  "Documentation/grains/event_sourcing/replicated_instances.html": {
    "href": "Documentation/grains/event_sourcing/replicated_instances.html",
    "title": "Replicated Grains | Microsoft Orleans Documentation",
    "keywords": "Replicated Grains Sometimes, there can be multiple instances of the same grain active, such as when operating a multi-cluster, and using the [OneInstancePerCluster] attribute. The JournaledGrain is designed to support replicated instances with minimal friction. It relies on log-consistency providers to run the necessary protocols to ensure all instances agree on the same sequence of events. In particular, it takes care of the following aspects: Consistent Versions : All versions of the grain state (except for tentative versions) are based on the same global sequence of events. In particular, if two instances see the same version number, then they see the same state. Racing Events : Multiple instances can simultaneously raise an event. The consistency provider resolves this race and ensures everyone agrees on the same sequence. Notifications/Reactivity : After an event is raised at one grain instance, the consistency provider not only updates storage, but also notifies all the other grain instances. For a general discussion of the consistency model see our TechReport and the GSP paper (Global Sequence Protocol). Conditional Events Racing events can be problematic if they have a conflict, i.e. should not both commit for some reason. For example, when withdrawing money from a bank account, two instances may independently determine that there are sufficient funds for a withdrawal, and issue a withdrawal event. But the combination of both events could overdraw. To avoid this, the JournaledGrain API supports a RaiseConditionalEvent method. bool success = await RaiseConditionalEvent(new WithdrawalEvent() { ... }); Conditional events double-check if the local version matches the version in storage. If not, it means the event sequence has grown in the meantime, which means this event has lost a race against some other event. In that case, the conditional event is not appended to the log, and RaiseConditionalEvent returns false. This is the analogue of using e-tags with conditional storage updates, and likewise provides a simple mechanism to avoid committing conflicting events. It is possible and sensible to use both conditional and unconditional events for the same grain, such as a DepositEvent and a WithdrawalEvent . Deposits need not be conditional: even if a DepositEvent loses a race, it does not have to be cancelled, but can still be appended to the global event sequence. Awaiting the task returned by RaiseConditionalEvent is sufficient to confirm the event, i.e. it is not necessary to also call ConfirmEvents . Explicit Synchronization Sometimes, it is desirable to ensure that a grain is fully caught up with the latest version. This can be enforced by calling await RefreshNow(); which both (1) confirms all unconfirmed events, and (2) loads the latest version from storage."
  },
  "Documentation/clusters_and_clients/powershell_client.html": {
    "href": "Documentation/clusters_and_clients/powershell_client.html",
    "title": "PowerShell Client Module | Microsoft Orleans Documentation",
    "keywords": "PowerShell Client Module The Orleans PowerShell Client Module is a set of PowerShell Cmdlets that wraps GrainClient in a set of convenient commands making possible to interact with not just ManagementGrain but any IGrain just as a regular Orleans application can by using Powershell scripts. These Cmdlets enable a series of scenarios from start maintenance tasks, tests, monitoring or any other kind of automation by leveraging Powershell scripts. Here is how to use it: Installing the module From Source You can build from source the OrleansPSUtils project and just import it with: PS> Import-Module .\\projectOutputDir\\Orleans.psd1 Althought you can do that, there is a much easier and interesting way for doing that by installing it from PowerShell Gallery . From PowerShell Gallery Powershell modules today are easily shared just as Nuget packages but instead of nuget.org, they are hosted on PowerShell Gallery . To install it on a specific folder just run: PS> Save-Module -Name OrleansPSUtils -Path <path> To install it on your PowerShell modules path ( the recommended way ), just run: PS> Install-Module -Name OrleansPSUtils If you plan to use this module on an Azure Automation , just click on the button bellow: Using the module Regardless of the way you decide to install it, the first thing you need to do in order to actually use it is import the module on the current PowerShell session so the Cmdlets get available by running this: PS> Import-Module OrleansPSUtils Note : In case of building from source, you must import it as suggested on the Install section by using the path to the .psd1 instead of using the module name since it will not be on the $env:PSModulePath PowerShell runtime variable. Again, it is highly recommended that you install from PowerShell Gallery instead. After the module is imported (which means it is loaded on PowerShell session), you will have the following Cmdlets available: Start-GrainClient Stop-GrainClient Get-Grain Start-GrainClient This module is a wrapper around GrainClient.Initialize() and its overloads. Usage : Start-GrainClient The same as call GrainClient.Initialize() which will look for the known Orleans Client configuration file names Start-GrainClient [-ConfigFilePath] <string> [[-Timeout] <timespan>] Will use the provided file path as in GrainClient.Initialize(filePath) Start-GrainClient [-ConfigFile] <FileInfo> [[-Timeout] <timespan>] Use an instance of the System.FileInfo class representing the config file just as GrainClient.Initialize(fileInfo) Start-GrainClient [-Config] <ClientConfiguration> [[-Timeout] <timespan>] Use an instance of a Orleans.Runtime.Configuration.ClientConfiguration like in GrainClient.Initialize(config) Start-GrainClient [-GatewayAddress] <IPEndPoint> [[-OverrideConfig] <bool>] [[-Timeout] <timespan>] Takes a Orleans Cluster Gateway Address Endpoint Note : The Timeout parameter is optional and if it is informed and greater than System.TimeSpan.Zero , it will call Orleans.GrainClient.SetResponseTimeout(Timeout) internally. Stop-GrainClient Takes no parameters and when called, if the GrainClient is initialized will gracefuly uninitialize. Get-Grain Wrapper around GrainClient.GrainFactory.GetGrain<T>() and its overloads. The mandatory parameter is -GrainType and the -XXXKey for the current Grain key types supported by Orleans ( string , Guid , long ) and also the -KeyExtension that can be used on Grains with compound keys. This Cmdlet return a grain reference of the type passed by as parameter on -GrainType . Example: A simple example on calling MyInterfacesNamespace.IMyGrain.SayHeloTo grain method: PS> Import-Module OrleansPSUtils PS> $configFilePath = Resolve-Path(\".\\ClientConfig.xml\").Path PS> Start-GrainClient -ConfigFilePath $configFilePath PS> Add-Type -Path .\\MyGrainInterfaceAssembly.dll PS> $grainInterfaceType = [MyInterfacesNamespace.IMyGrain] PS> $grainId = [System.Guid]::Parse(\"A4CF7B5D-9606-446D-ACE9-C900AC6BA3AD\") PS> $grain = Get-Grain -GrainType $grainInterfaceType -GuidKey $grainId PS> $message = $grain.SayHelloTo(\"Gutemberg\").Result PS> Write-Output $message Hello Gutemberg! PS> Stop-GrainClient We plan to update this page as we introduce more Cmdlets like use Observers, Streams and other Orleans core features more natively on Powershell. We hope that this help people as a starting point for automation. As always, this is a work-in-progress and we love contributions! :) Please note that the intent is not to reimplement the whole client on PowerShell but instead, give IT and DevOps teams a way to interact with the Grains without need to implement a .Net application."
  },
  "1.5/Documentation/Event-Sourcing/MultiVersion.html": {
    "href": "1.5/Documentation/Event-Sourcing/MultiVersion.html",
    "title": "Immediate vs. Delayed Confirmation | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Immediate Confirmation For many applications, we want to ensure that events are confirmed immediately, so that the persisted version does not lag behind the current version in memory, and we do not risk losing the latest state if the grain should fail. We can guarantee this by following these rules: Confirm all RaiseEvent calls using ConfirmEvents before the grain method returns. Make sure tasks returned by RaiseConditionalEvent complete before the grain method returns. Avoid [Reentrant] or [AlwaysInterleave] attributes, so only one grain call can be processed at a time. If we follow these rules, it means that after an event is raised, no other grain code can execute until the event has been written to storage. Therefore, it is impossible to observe inconsistencies between the version in memory and the version in storage. While this is often exactly what we want, it also has some potential disadvantages. Potential Disadvantages if the connection to a remote cluster or to storage is temporarily interrupted , then the grain becomes unavailable: effectively, the grain cannot execute any code while it is stuck waiting to confirm the events, which can take an indefinite amount of time (the log-consistency protocol keeps retrying until storage connectivity is restored). when handling a lot of of updates to a single grain instance , confirming them one at a time can become very inefficient, i.e. have poor throughput. Delayed Confirmation To improve availability and throughput in the situations mentioned above, grains can choose to do one or both of the following: allow grain methods to raise events without waiting for confirmation. allow reentrancy, so the grain can keep processing new calls even if previous calls get stuck waiting for confirmation. This means it is possible for grain code to execute while some events are still in the process of being confirmed. The JournaledGrain API has some specific provisions to give developers precise control over how to deal with unconfirmed events that are currently \"in flight\". The following property can be examined to find out what events are currently unconfirmed: IEnumerable<EventType> UnconfirmedEvents { get; } Also, since the state returned by the State property does not include the effect of unconfirmed events, there is an alternative property StateType TentativeState { get; } which returns a \"tentative\" state, obtained from \"State\" by applying all the unconfirmed events. The tentative state is essentially a \"best guess\" at what will likely become the next confirmed state, after all unconfirmed events are confirmed. However, there is no guarantee that it actually will, because the grain may fail, or because the events may race against other events and lose, causing them to be canceled (if they are conditional) or appear at a later position in the sequence than anticipated (if they are unconditional). Concurrency Guarantees Note that Orleans turn-based scheduling (cooperative concurrency) guarantees always apply, even when using reentrancy or delayed confirmation. This means that even though several methods may be in progress, only one can be actively executing --- all others are stuck at an await, so there are never any true races caused by parallel threads. In particular, note that: The properties State , TentativeState , Version , and UnconfirmedEvents can change during the execution of a method. But such changes can only happen while stuck at an await. These guarantees assume that the user code stays within the recommended practice with respect to tasks and async/await (in particular, does not use thread pool tasks, or only uses them for code that does not call grain functionality and that are properly awaited)."
  },
  "1.5/Documentation/Event-Sourcing/LogConsistencyProviders.html": {
    "href": "1.5/Documentation/Event-Sourcing/LogConsistencyProviders.html",
    "title": "Included Log-Consistency Providers | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Built-In Log-Consistency Providers The Microsoft.Orleans.EventSourcing package includes several log-consistency providers that cover basic scenarios suitable to get started, and allow some extensibility. Orleans.EventSourcing. StateStorage .LogConsistencyProvider This provider stores grain state snapshots , using a standard storage provider that can be configured independently. The data that is kept in storage is an object that contains both the grain state (as specified by the first type parameter to JournaledGrain ) and some meta-data (the version number, and a special tag that is used to avoid duplication of events when storage accesses fail). Since the entire grain state is read/written every time we access storage, this provider is not suitable for objects whose grain state is very large. This provider does not support RetrieveConfirmedEvents : it cannot retrieve the events from storage because the events are not persisted. Orleans.EventSourcing. LogStorage .LogConsistencyProvider This provider stores the complete event sequence as a single object , using a standard storage provider that can be configured independently. The data that is kept in storage is an object that contains a List<EventType> object , and some meta-data (a special tag that is used to avoid duplication of events when storage accesses fail). This provider does support RetrieveConfirmedEvents . All events are always available and kept in memory. Since the whole event sequence is read/written every time we access storage, this provider is not suitable for use in production , unless the event sequences are guaranteed to remain pretty short. The main purpose of this provider is to illustrate the semantics of the event sourcing, and for samples/testing environments. Orleans.EventSourcing. CustomStorage .LogConsistencyProvider This provider allows the developer to plug in their own storage interface, which is then called by the conistency protocol at appropriate times. This provider does not make specific assumptions about whether what is stored are state snapshots or events - the programmer assumes control over that choice (and may store either or both). To use this provider, a grain must derive from JournaledGrain<StateType,EventType> , as before, but additionally must also implement the following interface: public interface ICustomStorageInterface<StateType, EventType> { Task<KeyValuePair<int,StateType>> ReadStateFromStorage(); Task<bool> ApplyUpdatesToStorage(IReadOnlyList<EventType> updates, int expectedversion); } The consistency provider expects these to behave a certain way. Programmers should be aware that: The first method, ReadStateFromStorage , is expected to return both the version, and the state read. If there is nothing stored yet, it should return zero for the version and a state that matches corresponds to the default constructor for StateType . ApplyUpdatesToStorage must return false if the expected version does not match the actual version (this is analogous to an e-tag check). If ApplyUpdatesToStorage fails with an exception, the consistency provider retries. This means some events could be duplicated if such an exception is thrown, but the event was actually persisted. The developer is responsible to make sure this is safe: e.g. either avoid this case by not throwing an exception, or ensure duplicated events are harmless for the application logic, or add some extra mechanism to filter duplicates. This provider does not support RetrieveConfirmedEvents . Of course, since the developer controls the storage interface anyway, they don't need to call this in the first place, but can implement their own event retrieval."
  },
  "1.5/Documentation/Deployment-and-Operations/Configuration-Guide/Configuring-.NET-Garbage-Collection.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Configuration-Guide/Configuring-.NET-Garbage-Collection.html",
    "title": "Configuring .NET Garbage Collection | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Configuring .NET Garbage Collection For good performance, it is important to configure .NET garbage collection for the silo process the right way. The best combination of settings we found is to set gcServer=true and gcConcurrent=true. These are easy to set via the application config file when a silo runs as a standalone process. You can use OrleansHost.exe.config included in the Microsoft.Orleans.OrleansHost NuGet package as an example. .NET Framework <configuration> <runtime> <gcServer enabled=\"true\"/> <gcConcurrent enabled=\"true\"/> </runtime> </configuration> .NET Core // .csproj <PropertyGroup> <ServerGarbageCollection>true</ServerGarbageCollection> <ConcurrentGarbageCollection>true</ConcurrentGarbageCollection> </PropertyGroup> However, this is not as easy to do if a silo runs as part of an Azure Worker Role, which by default is configured to use workstation GC. This blog post shows how to set the same configuration for an Azure Worker Role - https://blogs.msdn.microsoft.com/cclayton/2014/06/05/server-garbage-collection-mode-in-microsoft-azure/ IMPORTANT NOTE Server garbage collection is available only on multiprocessor computers . Therefore, even if you configure the Garbage Collection either via Application Configuration file (app.config or web.config) or via the scripts on the referred blog post, if the silo is running on a (virtual) machine with a single core, you will not get the benefits of gcServer=true ."
  },
  "1.5/Documentation/Deployment-and-Operations/Troubleshooting-Deployments.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Troubleshooting-Deployments.html",
    "title": "Troubleshooting Deployments | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Troubleshooting Deployments This page gives some general guidelines for troubleshooting any issues that occur while deploying to Azure Cloud Services. These are very common issues to watch out for. Be sure to check the logs for more information. Getting a SiloUnavailableException First check to make sure that you are actually starting the silos before attempting to initialize the client. Sometimes the silos take a long time to start so it can be beneficial to try to initialize the client multiple times. If it still throws an exception, then there might be another issue with the silos. Check the silo configuration and make sure that the silos are starting up properly. Common Connection String Issues Using the local connection string when deploying to Azure – the website will fail to connect Using different connection strings for the silos and the front end (web and worker roles) – the website will fail to initialize the client because it cannot connect to the silos The connection string configuration can be checked in the Azure Portal. The logs may not display properly if the connection strings are not set up correctly. Modifying the Configuration Files Improperly Make sure that the proper endpoints are configured in the ServiceDefinition.csdef file or else the deployment will not work. It will give errors saying that it cannot get the endpoint information. Missing Logs Make sure that the connection strings are set up properly. It is likely that the Web.config file in the web role or the app.config file in the worker role were modified improperly. Incorrect versions in these files can cause issues with the deployment. Be careful when dealing with updates. Version Issues Make sure that the same version of Orleans is used in every project in the solution. Not doing this can lead to the worker role recycling. Check the logs for more information. Visual Studio provides some silo startup error messages in the deployment history. Role Keeps Recycling Check that all the appropriate Orleans assemblies are in the solution and have Copy Local set to True. Check the logs to see if there is an unhandled exception while initializing. Make sure that the connection strings are correct. Check the Azure Cloud Services troubleshooting pages for more information. How to Check Logs Use the cloud explorer in Visual Studio to navigate to the appropriate storage table or blob in the storage account. The WADLogsTable is a good starting point for looking at the logs. You might only be logging errors. If you want informational logs as well, you will need to modify the configuration to set the logging severity level. Programmatic configuration: When creating a ClusterConfiguration object, set config.Defaults.DefaultTraceLevel = Severity.Info . When creating a ClientConfiguration object, set config.DefaultTraceLevel = Severity.Info . Declarative configuration: Add <Tracing DefaultTraceLevel=\"Info\" /> to the OrleansConfiguration.xml and/or the ClientConfiguration.xml files. In the diagnostics.wadcfgx file for the web and worker roles, make sure to set the scheduledTransferLogLevelFilter attribute in the Logs element to Information , as this is an additional layer of trace filtering that defines which traces are sent to the WADLogsTable in Azure Storage. You can find more information about this in the Configuration Guide . Compatibility with ASP.NET The razor view engine included in ASP.NET uses the same code generation assemblies as Orleans ( Microsoft.CodeAnalysis and Microsoft.CodeAnalysis.CSharp ). This can present a version compatibility problem at runtime. To resolve this, try upgrading Microsoft.CodeDom.Providers.DotNetCompilerPlatform (this is the NuGet package ASP.NET uses to include the above assemblies) to the latest version, and setting binding redirects like this: <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis.CSharp\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly> <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly>"
  },
  "1.5/Tutorials/Running-in-a-Stand-alone-Silo.html": {
    "href": "1.5/Tutorials/Running-in-a-Stand-alone-Silo.html",
    "title": "Running in a Stand-Alone Silo | Microsoft Orleans Documentation",
    "keywords": "Running in a Stand-Alone Silo In the first tutorial , we got a very simple \"Hello World!\" Orleans application running in the simplest possible environment, a dev/test host where everything is running in one process, which makes starting and stopping it really easy. For most of your initial development of grain-based applications and services, that environment will be ideal. However, one thing that is hard to test in such an environment is what happens when the client and server do not get started and stopped at the same time. Often, state is maintained on the server across client sessions, something that is hard to model using the single-process setup. Therefore, what we're going to do now is modify the solution we finished up with in the first tutorial and make it just a bit more like a production environment, running the server and client code in different processes. Getting Started The first thing we need to do is get the grain code running in a silo that is in a separate process and prevent it from being started by the code in Program.cs . To do the latter, remove the code that starts the silo in its own app domain, as well as the code that shuts it down at the end. One consequence of not running the silo from the same process is that the client code has to wait for the silo to be ready to accept incoming requests. Rather than adding some clever backoff-retry code, here we simply expect you to wait for the silo to start, then hit 'Enter' in the client console window when the silo is advertising its readiness. This is the result: static void Main(string[] args) { Console.WriteLine(\"Waiting for Orleans Silo to start. Press Enter to proceed...\"); Console.ReadLine(); // Orleans comes with a rich XML and programmatic configuration. Here we're just going to set up with basic programmatic config var config = Orleans.Runtime.Configuration.ClientConfiguration.LocalhostSilo(30000); GrainClient.Initialize(config); } Now you should add reference to Microsoft.Orleans.Server NuGet package to your collection project and then in its project properties in Debug tab set the bin/Debug/OrleansHost.exe or bin/Release/OrleansHost.exe file as startup program for your collections class library. Try to not mix NuGet package versions, make sure all Orlean packages (client, graininterface and grain projects) are aligned in the solution. You also need to add a OrleansConfiguration.xml file, you can create it using the instruction in Minimal Orleans Application tutorial . Then, in this file, make sure that the ProxyingGateway element inside its Defaults section matches this value: <ProxyingGateway Address=\"localhost\" Port=\"30000\" /> Don't forget to set the file's \"Copy to Output Directory\" property to \"Copy if newer\". OrleansHost.exe is a ready-made host executable intended for running Orleans silo code. It is also useful for development purposes. If you set both the grain collection project and the the host project as startup projects, you will see two windows come up: This allows us to debug the grains in their own process, while keeping the client code in its own process. If you let the client make its request, then terminate it using 'Enter' when asked, you should see only the client process windows disappear. The debugging session won't end, because the grains are still being debugged in the OrleansHost.exe process. To start the client again, you will have to use the right-button context menu in the Solution Explorer to get it started. Keeping Things Around To demonstrate keeping state around across client sessions, let's modify the SayHello() method to take a string argument. Then, we will have our grain save each string it is sent and return the last one. Only at the first greeting will we see something we didn't send to the grain from the client. First, change the interface definition of SayHello public interface IGrain1 : IGrainWithIntegerKey { Task<string> SayHello(string greeting); } Then change the Implementation private string text = \"Hello World!\"; public Task<string> SayHello(string greeting) { var oldText = text; text = greeting; return Task.FromResult(oldText); } We also change the client to send a greeting several times in Program.cs: var hello = GrainClient.GrainFactory.GetGrain<IGrain1>(0); Console.WriteLine(hello.SayHello(\"First\").Result); Console.WriteLine(hello.SayHello(\"Second\").Result); Console.WriteLine(hello.SayHello(\"Third\").Result); Console.WriteLine(hello.SayHello(\"Fourth\").Result); What we would expect to see here is four greetings, the first of which is \"Hello World!\". Let's check it out: Terminate the client (make sure it's just the client, we need the grain host to stay up) and restart it using the context menu. There's no reason to wait for the silo now, since it's already running. Here's what we get: Still four greetings, but instead of \"Hello World!\" the first greeting is the last one from our previous client session. In other words, the grain in the silo kept some state around for us. Next So far, we've only seen one single grain type and a single instance of that type. It has served to keep things simple for the purpose of explaining how the environment works, but it is not typical of Orleans code. In the next tutorial, we will see something more realistic. Actor Identity"
  },
  "1.5/Documentation/Runtime-Implementation-Details/Consul-Deployment.html": {
    "href": "1.5/Documentation/Runtime-Implementation-Details/Consul-Deployment.html",
    "title": "Using Consul as a Membership Provider | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Using Consul as a Membership Provider Introduction to Consul Consul is a distributed, highly available and datacenter-aware service discovery platform which includes simple service registration, health checking, failure detection and key/value storage. It is built on the premise that every node in the datacenter is running a Consul agent which is either acting as a server or client which communicate via a scalable gossip protocol. There is a very detailed overview of Consul including comparisons with similar solutions here . Consul is written in GO and is open source ; compiled downloads are available for Mac OS X, FreeBSD, Linux, Solaris and Windows Why Choose Consul? As an Orleans Membership Provider , Consul is a good choice when you need to deliver an on-premise solution which does not require your potential customers to have existing infrastructure and a co-operative IT provider. Consul is a very lightweight single executable, has no dependencies and as such can easily be built into your own middleware solution. And when Consul is already your solution for discovering, checking and maintaining your microservices, it makes sense to fully integrate with Orleans membership for simplicity and ease of operation. We therefore implemented a membership table in Consul (also known as \"Orleans Custom System Store\"), which fully integrates with Orleans's Cluster Management . Setting up Consul There is very extensive documentation available on Consul.io about setting up a stable Consul cluster and it doesn't make sense to repeat that here; however for your convenience we include this guide so you can very quickly get Orleans running with a standalone Consul agent. 1) Create a folder to install Consul into, e.g. C:\\Consul 2) Create a subfolder: C:\\Consul\\Data (Consul will not create this if it doesn't exist) 3) Download and unzip Consul.exe into C:\\Consul\\ 4) Open a command prompt at C:\\Consul\\ 5) Enter Consul.exe agent -server -bootstrap -data-dir \"C:\\Consul\\Data\" -client=0.0.0.0 agent Instructs Consul to run the agent process that hosts the services. Without this the Consul process will attempt to use RPC to configure a running agent. -server Defines the agent as a server and not a client (A Consul client is an agent that hosts all the services and data, but does not have voting rights to decide, and cannot become, the cluster leader -bootstrap The first (and only the first!) node in a cluster must be bootstrapped so that it assumes the cluster leadership. -data-dir [path] Specifies the path where all Consul data is stored, including the cluster membership table -client=0.0.0.0 Informs Consul which IP to open the service on. There are many other parameters, and the option to use a json configuration file. Please consult the Consul documentation for a full listing of the options. 6) Verify that Consul is running and ready to accept membership requests from Orleans by opening the services endpoint in your browser. Configuration of Orleans Server There is currently a known issue with the \"Custom\" membership provider OrleansConfiguration.xml configuration file that will fail to parse correctly. For this reason you have to provide a placeholder SystemStore in the xml and then configure the provider in code before starting the Silo. OrleansConfiguration.xml <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <SystemStore SystemStoreType=\"None\" DataConnectionString=\"http://localhost:8500\" DeploymentId=\"MyOrleansDeployment\" /> </Globals> <Defaults> <Networking Address=\"localhost\" Port=\"22222\" /> <ProxyingGateway Address=\"localhost\" Port=\"30000\" /> </Defaults> </OrleansConfiguration> Code public void Start(ClusterConfiguration config) { _siloHost = new SiloHost(System.Net.Dns.GetHostName(), config); _siloHost.Config.Globals.LivenessType = GlobalConfiguration.LivenessProviderType.Custom; _siloHost.Config.Globals.MembershipTableAssembly = \"OrleansConsulUtils\"; _siloHost.Config.Globals.ReminderServiceType = GlobalConfiguration.ReminderServiceProviderType.Disabled; _siloHost.InitializeOrleansSilo(); var startedok = _siloHost.StartOrleansSilo(); if (!startedok) throw new SystemException(String.Format(\"Failed to start Orleans silo '{0}' as a {1} node\", _siloHost.Name, _siloHost.Type)); Log.Information(\"Orleans Silo is running.\\n\"); } Alternatively you could configure the silo entirely in code. Client The client configuration is much simpler ClientConfiguration.xml <ClientConfiguration xmlns=\"urn:orleans\"> <SystemStore SystemStoreType=\"Custom\" CustomGatewayProviderAssemblyName=\"OrleansConsulUtils\" DataConnectionString=\"http://192.168.1.26:8500\" DeploymentId=\"MyOrleansDeployment\" /> </ClientConfiguration> Client SDK If you are interested in using Consul for your own service discovery there are Client SDKs for most popular languages. Implementation Detail The Membership Table Provider makes use of Consul's Key/Value store functionality with CAS. When each Silo starts it registers two KV entries, one which contains the Silo details and one which holds the last time the Silo reported it was alive (the latter refers to diagnostics \"I am alive\" entries and not to failure detection hearbeats which are sent directly between the silos and are not written into the table). All writes to the table are performed with CAS to provide concurrency control, as necessitated by Orleans's Cluster Management Protocol . Once the Silo is running you can view these entries in your web browser here , this will display something like: [ \"orleans/MyOrleansDeployment/192.168.1.26:11111@191780753\", \"orleans/MyOrleansDeployment/192.168.1.26:11111@191780753/iamalive\" ] You will notice that the keys are prefixed with \"orleans/\" this is hard coded in the provider and is intended to avoid key space collision with other users of Consul. Each of these keys can be read by appending their key name (sans quotes of course) to the Consul KV root . Doing so will present you with the following: [ { \"LockIndex\": 0, \"Key\": \"orleans/MyOrleansDeployment/192.168.1.26:22222@191780753\", \"Flags\": 0, \"Value\": \"[BASE64 UTF8 Encoded String]\", \"CreateIndex\": 10, \"ModifyIndex\": 12 } ] Decoding the string will give you the actual Orleans Membership data: http://localhost:8500/v1/KV/orleans/MyOrleansDeployment/[SiloAddress] { \"Hostname\": \"[YOUR_MACHINE_NAME]\", \"ProxyPort\": 22222, \"StartTime\": \"2016-01-29T16:25:54.9538838Z\", \"Status\": 3, \"SuspectingSilos\": [] } http://localhost:8500/v1/KV/orleans/MyOrleansDeployment/[SiloAddress]/IAmAlive \"2016-01-29T16:35:58.9193803Z\" When the Clients connect, they read the KVs for all silos in the cluster in one HTTP GET by using the uri http://192.168.1.26:8500/v1/KV/orleans/MyOrleansDeployment/?recurse . Limitations Orleans Extended Membership Protocol (Table Version & ETag) Consul KV currrently does not currently support atomic updates. Therefore, the Orleans Consul Membership Provider only implements the the Orleans Basic Membership Protocol, as described here and does not support the Extended Membership Protocol. This Extended protocol was introduced as an additional, but not essential, silo connectivity validation and as a foundation to functionality that has not yet been implemented. Providing your infrastructure is correctly configured you will not experience any detrimental effect of the lack of support. Multiple Datacenters The Key Value Pairs in Consul are not currently replicated between Consul datacenters. There is a separate project to address this but it has not yet been proven to support Orleans. When running on Windows When Consul starts on Windows it logs the following message: ==> WARNING: Windows is not recommended as a Consul server. Do not use in production. This is displayed simply due to lack of focus on testing when running in a Windows environment and not because of any actual known issues. Read the discussion here before deciding if Consul is the right choice for you. Potential Future Enhanecements 1) Prove that the Consul KV replication project is able to support an Orleans cluster in a WAN environment between multiple Consul datacenters. 2) Implement the Reminder Table in Consul. 3) Implement the Extended Membership Protocol. The team behind Consul does plan on implementing atomic operations, once this functionality is available it will be possible to remove the limitations in the provider."
  },
  "1.5/Documentation/Advanced-Concepts/Serialization.html": {
    "href": "1.5/Documentation/Advanced-Concepts/Serialization.html",
    "title": "Serialization and Writing Custom Serializers | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Serialization and Writing Custom Serializers Orleans has an advanced and extensible serialization framework. Orleans serializes data types passed in grain request and response messages as well as grain persistent state objects. As part of this framework, Orleans automatically generates serialization code for those data types. In addition to generating a more efficient serialization/deserialization for types that are already .NET-serializable, Orleans also tries to generate serializers for types used in grain interfaces that are not .NET-serializable. The framework also includes a set of efficient built-in serializers for frequently used types: lists, dictionaries, strings, primitives, arrays, etc. There are 2 important features of Orleans's serializer that set it apart from a lot of other third party serialization frameworks: dynamic types/arbitrary polymorphism and object identity. Dynamic types and arbitrary polymorphism - Orleans does not put any restrictions on the types that can be passed in grain calls and maintains the dynamic nature of the actual data type. That means, for example, that if the method in the grain interfaces is declared to accept IDictionary but at runtime the sender passes SortedDictionary , the receiver will indeed get SortedDictionary (although the \"static contract\"/grain interface did not specify this behaviour). Maintaining Object identity - if the same object is passed multiple types in the arguments of a grain call or is indirectly pointed more than once from the arguments, Orleans will serialize it only once. At the receiver side Orleans will restore all references correctly, so that two pointers to the same object still point to the same object after deserialization as well. Object identity is important to preserve in scenarios like the following. Imagine actor A is sending a dictionary with 100 entries to actor B, and 10 of the keys in the dictionary point to the same object, obj, on A's side. Without preserving object identity, B would receive a dictionary of 100 entries with those 10 keys pointing to 10 different clones of obj. With object identity preserved, the dictionary on B's side looks exactly like on A's side with those 10 keys pointing to a single object obj. The above two behaviours are provided by the standard .NET binary serializer and it was therefore important for us to support this standard and familiar behaviour in Orleans as well. Generated Serializers Orleans uses the following rules to decide which serializers to generate. The rules are: 1) Scan all types in all assemblies which reference the core Orleans library. 2) Out of those assemblies: generate serializers for types that are directly referenced in grain interfaces method signatures or state class signature or for any type that is marked with [Serializable] attribute. 3) In addition, a grain interface or implementation project can point to arbitrary types for serialization generation by adding a [KnownType] or [KnownAssembly] assembly level attributes to tell code generator to generate serializers for a specific types or all eligible types within an assembly. Serialization Providers Orleans supports integration with third-party serializers using a provider model. This requires an implementation of the IExternalSerializer type described in the custom serialization section of this document. Integrations for some common serializers are maintained alongside Orleans, for example: Protocol Buffers : Orleans.Serialization.ProtobufSerializer from the Microsoft.Orleans.OrleansGoogleUtils NuGet package. Bond : Orleans.Serialization.BondSerializer from the Microsoft.Orleans.Serialization.Bond NuGet package. Newtonsoft.Json AKA Json.NET : Orleans.Serialization.OrleansJsonSerializer from the core Orleans library. Custom implementation of IExternalSerializer is described in the Writing Custom Serializers section below. Configuration It is important to ensure that serialization configuration is identical on all clients and silos. If configurations are not consistent, serialization errors may occur. Serialization providers, which implement IExternalSerializer , can be specified using the SerializationProviders property of ClientConfiguration and GlobalConfiguration in code: var cfg = new ClientConfiguration(); cfg.SerializationProviders.Add(typeof(FantasticSerializer).GetTypeInfo()); var cfg = new GlobalConfiguration(); cfg.SerializationProviders.Add(typeof(FantasticSerializer).GetTypeInfo()); Alternatively, they can be specified in XML configuration under the <SerializationProviders /> property of <Messaging> : <Messaging> <SerializationProviders> <Provider type=\"GreatCompany.FantasticSerializer, GreatCompany.SerializerAssembly\"/> </SerializationProviders> </Messaging> In both cases, multiple providers can be configured. The collection is ordered, meaning that if a provider which can serialize types A and B is specified before a provider which can only serialize type B , then the latter provider will not be used. Writing Custom Serializers In addition to automatic serialization generation, application code can provide custom serialization for types it chooses. Orleans recommends using the automatic serialization generation for the majority of your application types and only write custom serializers in rare cases when you believe it is possible to get improved performance by hand-coding serializers. This note describes how to do so, and identifies some specific cases when it might be helpful. There are 3 ways in which applications can customize serialization: Add serialization methods to your type and mark them with appropriate attributes ( CopierMethod , SerializerMethod , DeserializerMethod ). This method is preferable for types that your application owns, that is, the types that you can add new methods to. Implement IExternalSerializer and register it during configuration time. This method is useful for integrating an external serialization library. Write a separate static class annotated with an [Serializer(typeof(YourType))] with the 3 serialization methods in it and the same attributes as above. This method is useful for types that the application does not own, for example, types defined in other libraries your application has no control over. Each of these methods are detailed in the sections below. Introduction Orleans serialization happens in three stages: objects are immediately deep copied to ensure isolation; before being put on the wire; objects are serialized to a message byte stream; and when delivered to the target activation, objects are recreated (deserialized) from the received byte stream. Data types that may be sent in messages -- that is, types that may be passed as method arguments or return values -- must have associated routines that perform these three steps. We refer to these routines collectively as the serializers for a data type. The copier for a type stands alone, while the serializer and deserializer are a pair that work together. You can provide just a custom copier, or just a custom serializer and a custom deserializer, or you can provide custom implementations of all three. Serializers are registered for each supported data type at silo start-up and whenever an assembly is loaded. Registration is necessary for custom serializer routines for a type to be used. Serializer selection is based on the dynamic type of the object to be copied or serialized. For this reason, there is no need to create serializers for abstract classes or interfaces, because they will never be used. When to Consider Writing a Custom Serializer It is rare that a hand-crafted serializer routine will perform meaningfully better than the generated versions. If you are tempted to do so, you should first consider the following options: If there are fields or properties within your data types that don't have to be serialized or copied, you can mark them with the NonSerialized attribute. This will cause the generated code to skip these fields when copying and serializing. Use Immutable<T> & [Immutable] where possible to avoid copying immutable data. The section on Optimizing Copying below for details. If you're avoiding using the standard generic collection types, don't. The Orleans runtime contains custom serializers for the generic collections that use the semantics of the collections to optimize copying, serializing, and deserializing. These collections also have special \"abbreviated\" representations in the serialized byte stream, resulting in even more performance advantages. For instance, a Dictionary<string, string> will be faster than a List<Tuple<string, string>> . The most common case where a custom serializer can provide a noticeable performance gain is when there is significant semantic information encoded in the data type that is not available by simply copying field values. For instance, arrays that are sparsely populated may often be more efficiently serialized by treating the array as a collection of index/value pairs, even if the application keeps the data as a fully realized array for speed of operation. A key thing to do before writing a custom serializer is to make sure that the generated serializer is really hurting your performance. Profiling will help a bit here, but even more valuable is running end-to-end stress tests of your application with varying serialization loads to gauge the system-level impact, rather than the micro-impact of serialization. For instance, building a test version that passes no parameters to or results from grain methods, simply using canned values at either end, will zoom in on the impact of serialization and copying on system performance. Method 1: Adding Serialization Methods to the Type All serializer routines should be implemented as static members of the class or struct they operate on. The names shown here are not required; registration is based on the presence of the respective attributes, not on method names. Note that serializer methods need not be public. Unless you implement all three serialization routines, you should mark your type with the Serializable attribute so that the missing methods will be generated for you. Copier Copier methods are flagged with the Orleans.CopierMethod attribute: [CopierMethod] static private object Copy(object input, ICopyContext context) { ... } Copiers are usually the simplest serializer routines to write. They take an object, guaranteed to be of the same type as the type the copier is defined in, and must return a semantically-equivalent copy of the object. If, as part of copying the object, a sub-object needs to be copied, the best way to do so is to use the SerializationManager's DeepCopyInner routine: var fooCopy = SerializationManager.DeepCopyInner(foo, context); It is important to use DeepCopyInner, instead of DeepCopy, in order to maintain the object identity context for the full copy operation. Maintaining Object Identity An important responsibility of a copy routine is to maintain object identity. The Orleans runtime provides a helper class for this. Before copying a sub-object \"by hand\" (i.e., not by calling DeepCopyInner), check to see if it has already been referenced as follows: var fooCopy = context.CheckObjectWhileCopying(foo); if (fooCopy == null) { // Actually make a copy of foo context.RecordObject(foo, fooCopy); } The last line, the call to RecordObject , is required so that possible future references to the same object as foo references will get found properly by CheckObjectWhileCopying . Note that this should only be done for class instances, not struct instances or .NET primitives (strings, Uris, enums). If you use DeepCopyInner to copy sub-objects, then object identity is handled for you. Serializer Serialization methods are flagged with the SerializerMethod attribute: [SerializerMethod] static private void Serialize(object input, ISerializationContext context, Type expected) { ... } As with copiers, the \"input\" object passed to a serializer is guaranteed to be an instance of the defining type. The \"expected\" type may be ignored; it is based on compile-time type information about the data item, and is used at a higher level to form the type prefix in the byte stream. To serialize sub-objects, use the SerializationManager 's SerializeInner routine: SerializationManager.SerializeInner(foo, context, typeof(FooType)); If there is no particular expected type for foo, then you can pass null for the expected type. The BinaryTokenStreamWriter class provides a wide variety of methods for writing data to the byte stream. An instance of the class can be obtained via the context.StreamWriter property. See the class for documentation. Deserializer Deserialization methods are flagged with the DeserializerMethod attribute: [DeserializerMethod] static private object Deserialize(Type expected, IDeserializationContext context) { ... } The \"expected\" type may be ignored; it is based on compile-time type information about the data item, and is used at a higher level to form the type prefix in the byte stream. The actual type of the object to be created will always be the type of the class in which the deserializer is defined. To deserialize sub-objects, use the SerializationManager 's DeserializeInner routine: var foo = SerializationManager.DeserializeInner(typeof(FooType), context); Or, alternatively, var foo = SerializationManager.DeserializeInner<FooType>(context); If there is no particular expected type for foo, use the non-generic DeserializeInner variant and pass null for the expected type. The BinaryTokenStreamReader class provides a wide variety of methods for reading data from the byte stream. An instance of the class can be obtained via the context.StreamReader property. See the class for documentation. Method 2: Writing a Serializer Provider In this method, you implement Orleans.Serialization.IExternalSerializer and add it to the SerializationProviders property on both ClientConfiguration on the client and GlobalConfiguration on the silos. Configuration is detailed in the Serialization Providers section above. Implementation of IExternalSerializer follows the pattern described for serialization methods from Method 1 above with the addition of an Initialize method and an IsSupportedType method which Orleans uses to determine if the serializer supports a given type. This is the interface definition: public interface IExternalSerializer { /// <summary> /// Initializes the external serializer. Called once when the serialization manager creates /// an instance of this type /// </summary> void Initialize(Logger logger); /// <summary> /// Informs the serialization manager whether this serializer supports the type for serialization. /// </summary> /// <param name=\"itemType\">The type of the item to be serialized</param> /// <returns>A value indicating whether the item can be serialized.</returns> bool IsSupportedType(Type itemType); /// <summary> /// Tries to create a copy of source. /// </summary> /// <param name=\"source\">The item to create a copy of</param> /// <param name=\"context\">The context in which the object is being copied.</param> /// <returns>The copy</returns> object DeepCopy(object source, ICopyContext context); /// <summary> /// Tries to serialize an item. /// </summary> /// <param name=\"item\">The instance of the object being serialized</param> /// <param name=\"context\">The context in which the object is being serialized.</param> /// <param name=\"expectedType\">The type that the deserializer will expect</param> void Serialize(object item, ISerializationContext context, Type expectedType); /// <summary> /// Tries to deserialize an item. /// </summary> /// <param name=\"context\">The context in which the object is being deserialized.</param> /// <param name=\"expectedType\">The type that should be deserialized</param> /// <returns>The deserialized object</returns> object Deserialize(Type expectedType, IDeserializationContext context); } Method 3: Writing a Serializer for Individual Types In this method you write a new class annotated with an attribute [SerializerAttribute(typeof(TargetType))] , where TargetType is the type which is being serialized, and implement the 3 serialization routines. The rules for how to write those routines are identical to method 1. Orleans uses the [SerializerAttribute(typeof(TargetType))] to determine that this class is a serializer for TargetType and this attribute can be specified multiple times on the same class if it's able to serialize multiple types. Below is an example for such a class: public class User { public User BestFriend { get; set; } public string NickName { get; set; } public int FavoriteNumber { get; set; } public DateTimeOffset BirthDate { get; set; } } [Orleans.CodeGeneration.SerializerAttribute(typeof(User))] internal class UserSerializer { [CopierMethod] public static object DeepCopier(object original, ICopyContext context) { var input = (User) original; var result = new User(); // Record 'result' as a copy of 'input'. Doing this immediately after construction allows for // data structures which have cyclic references or duplicate references. // For example, imagine that 'input.BestFriend' is set to 'input'. In that case, failing to record // the copy before trying to copy the 'BestFriend' field would result in infinite recursion. context.RecordCopy(original, result); // Deep-copy each of the fields. result.BestFriend = (User)context.SerializationManager.DeepCopy(input.BestFriend); result.NickName = input.NickName; // strings in .NET are immutable, so they can be shallow-copied. result.FavoriteNumber = input.FavoriteNumber; // ints are primitive value types, so they can be shallow-copied. result.BirthDate = (DateTimeOffset)context.SerializationManager.DeepCopy(input.BirthDate); return result; } [SerializerMethod] public static void Serializer(object untypedInput, ISerializationContext context, Type expected) { var input = (User) untypedInput; // Serialize each field. SerializationManager.SerializeInner(input.BestFriend, context); SerializationManager.SerializeInner(input.NickName, context); SerializationManager.SerializeInner(input.FavoriteNumber, context); SerializationManager.SerializeInner(input.BirthDate, context); } [DeserializerMethod] public static object Deserializer(Type expected, IDeserializationContext context) { var result = new User(); // Record 'result' immediately after constructing it. As with with the deep copier, this // allows for cyclic references and de-duplication. context.RecordObject(result); // Deserialize each field in the order that they were serialized. result.BestFriend = SerializationManager.DeserializeInner<User>(context); result.NickName = SerializationManager.DeserializeInner<string>(context); result.FavoriteNumber = SerializationManager.DeserializeInner<int>(context); result.BirthDate = SerializationManager.DeserializeInner<DateTimeOffset>(context); return result; } } Serializing Generic Types The TargetType parameter of [Serializer(typeof(TargetType))] can be an open-generic type, for example, MyGenericType<> . In that case, the serializer class must have the same generic parameters as the target type. Orleans will create a concrete version of the serializer at runtime for every concrete MyGenericType<T> type which is serialized, for example, one for each of MyGenericType<int> and MyGenericType<string> . Hints for Writing Serializers and Deserializers Often the simplest way to write a serializer/deserializer pair is to serialize by constructing a byte array and writing the array length to the stream, followed by the array itself, and then deserialize by reversing the process. If the array is fixed-length, you can omit it from the stream. This works well when you have a data type that you can represent compactly and that doesn't have sub-objects that might be duplicated (so you don't have to worry about object identity). Another approach, which is the approach the Orleans runtime takes for collections such as dictionaries, works well for classes with significant and complex internal structure: use instance methods to access the semantic content of the object, serialize that content, and deserialize by setting the semantic contents rather than the complex internal state. In this approach, inner objects are written using SerializeInner and read using DeserializeInner. In this case, it is common to write a custom copier, as well. If you write a custom serializer, and it winds up looking like a sequence of calls to SerializeInner for each field in the class, you don't need a custom serializer for that class. Fallback Serialization Orleans supports transmission of arbitrary types at runtime and therefore the in-built code generator cannot determine the entire set of types which will be transmitted ahead of time. Additionally, certain types cannot have serializers generated for them because they are inaccessible (for example, private ) or have fields which are inaccessible (for example, readonly ). Therefore, there is a need for just-in-time serialization of types which were unexpected or could not have serializers generated ahead-of-time. The serializer responsible for these types is called the fallback serializer . Orleans ships with two fallback serializers: Orleans.Serialization.BinaryFormatterSerializer which uses .NET's BinaryFormatter ; and Orleans.Serialization.ILBasedSerializer which emits CIL instructions at runtime to create serializers which leverage Orleans' serialization framework to serialize each field. This means that if an inaccessible type MyPrivateType contains a field MyType which has a custom serializer, that custom serializer will be used to serialize it. The fallback serializer can be configured using the FallbackSerializationProvider property on both ClientConfiguration on the client and GlobalConfiguration on the silos. var cfg = new ClientConfiguration(); cfg.FallbackSerializationProvider = typeof(FantasticSerializer).GetTypeInfo(); var cfg = new GlobalConfiguration(); cfg.FallbackSerializationProvider = typeof(FantasticSerializer).GetTypeInfo(); Alternatively, the fallback serialization provider can be specified in XML configuration: <Messaging> <FallbackSerializationProvider type=\"GreatCompany.FantasticFallbackSerializer, GreatCompany.SerializerAssembly\"/> </Messaging> .NET Core uses the ILBasedSerializer by default, whereas .NET 4.6 uses BinaryFormatterSerializer by default. Optimize Copying Using Immutable Types Orleans has a feature that can be used to avoid some of the overhead associated with serializing messages containing immutable types. This section describes the feature and its application, starting with context on where it is relevant. Serialization in Orleans When a grain method is invoked, the Orleans runtime makes a deep copy of the method arguments and forms the request out of the copies. This protects against the calling code modifying the argument objects before the data is passed to the called grain. If the called grain is on a different silo, then the copies are eventually serialized into a byte stream and sent over the network to the target silo, where they are deserialized back into objects. If the called grain is on the same silo, then the copies are handed directly to the called method. Return values are handled the same way: first copied, then possibly serialized and deserialized. Note that all 3 processes, copying, serializing, and deserializing, respect object identity. In other words, if you pass a list that has the same object in it twice, on the receiving side you'll get a list with the same object in it twice, rather than with two objects with the same values in them. Optimizing Copying In many cases, the deep copying is unnecessary. For instance, a possible scenario is a web front-end that receives a byte array from its client and passes that request, including the byte array, on to a grain for processing. The front-end process doesn't do anything with the array once it has passed it on to the grain; in particular, it doesn't reuse the array to receive a future request. Inside the grain, the byte array is parsed to fetch the input data, but not modified. The grain returns another byte array that it has created to get passed back to the web client; it discards the array as soon as it returns it. The web front-end passes the result byte array back to its client, without modification. In such a scenario, there is no need to copy either the request or response byte arrays. Unfortunately, the Orleans runtime can't figure this out by itself, since it can't tell whether or not the arrays are modified later on by the web front-end or by the grain. In the best of all possible worlds, we'd have some sort of .NET mechanism for indicating that a value is no longer modified; lacking that, we've added Orleans-specific mechanisms for this: the Immutable<T> wrapper class and the [Immutable] attribute. Using Immutable<T> The Orleans.Concurrency.Immutable<T> wrapper class is used to indicate that a value may be considered immutable; that is, the underlying value will not be modified, so no copying is required for safe sharing. Note that using Immutable<T> implies that neither the provider of the value nor the recipient of the value will modify it in the future; it is not a one-sided commitment, but rather a mutual dual-side commitment. Using Immutable<T> is simple: in your grain interface, instead of passing T , pass Immutable<T> . For instance, in the above described scenario, the grain method that was: Task<byte[]> ProcessRequest(byte[] request); Becomes: Task<Immutable<byte[]>> ProcessRequest(Immutable<byte[]> request); To create an Immutable<T> , simply use the constructor: Immutable<byte[]> immutable = new Immutable<byte[]>(buffer); To get the value inside the immutable, use the .Value property: byte[] buffer = immutable.Value; Using [Immutable] For user-defined types, the [Orleans.Concurrency.Immutable] attribute can be added to the type. This instructs Orleans' serializer to avoid copying instances of this type. The following code snippet demonstrates using [Immutable] to denote an immutable type. This type will not be copied during transmission. [Immutable] public class MyImmutableType { public MyImmutableType(int value) { this.MyValue = value; } public int MyValue { get; } } Immutability in Orleans For Orleans' purposes, immutability is a rather strict statement: the contents of the data item will not be modified in any way that could change the item's semantic meaning, or that would interfere with another thread simultaneously accessing the item. The safest way to ensure this is to simply not modify the item at all: bitwise immutability, rather than logical immutability. In some cases it is safe to relax this to logical immutability, but care must be taken to ensure that the mutating code is properly thread-safe; because dealing with multithreading is complex, and uncommon in an Orleans context, we strongly recommend against this approach and recommend sticking to bitwise immutability. Serialization Best Practices Serialization serves two primary purposes in Orleans: As a wire format for transmitting data between grains and clients at runtime. As a storage format for persisting long-lived data for later retrieval. The serializers generated by Orleans are suitable for the first purpose due to their flexibility, performance, and versatility. They are not as suitable for the second purpose, since they are not explicitly version-tolerant. It is recommended that users configure a version-tolerant serializer such as Protocol Buffers for persistent data. Protocol Buffers is supported via Orleans.Serialization.ProtobufSerializer from the Microsoft.Orleans.OrleansGoogleUtils NuGet package. The best-practices for the particular serializer of choice should be used in order to ensure version-tolerance. Third-party serializers can be configured using the SerializationProviders configuration property as described above."
  },
  "1.5/Documentation/Benefits.html": {
    "href": "1.5/Documentation/Benefits.html",
    "title": "Main Benefits | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Benefits The main benefits of Orleans are: developer productivity , even for non-expert programmers; and transparent scalability by default with no special effort from the programmer. We expand on each of these benefits below. Developer Productivity The Orleans programming model raises productivity of both expert and non-expert programmers by providing the following key abstractions, guarantees and system services. Familiar object-oriented programming (OOP) paradigm . Actors are .NET classes that implement declared .NET actor interfaces with asynchronous methods. Thus actors appear to the programmer as remote objects whose methods can be directly invoked. This provides the programmer the familiar OOP paradigm by turning method calls into messages, routing them to the right endpoints, invoking the target actor’s methods and dealing with failures and corner cases in a completely transparent way. Single-threaded execution of actors . The runtime guarantees that an actor never executes on more than one thread at a time. Combined with the isolation from other actors, the programmer never faces concurrency at the actor level, and hence never needs to use locks or other synchronization mechanisms to control access to shared data. This feature alone makes development of distributed applications tractable for non-expert programmers. Transparent activation . The runtime activates an actor as-needed, only when there is a message for it to process. This cleanly separates the notion of creating a reference to an actor, which is visible to and controlled by application code, and physical activation of the actor in memory, which is transparent to the application. In many ways, this is similar to virtual memory in that it decides when to “page out” (deactivate) or “page in” (activate) an actor; the application has uninterrupted access to the full “memory space” of logically created actors, whether or not they are in the physical memory at any particular point in time. Transparent activation enables dynamic, adaptive load balancing via placement and migration of actors across the pool of hardware resources. This features is a significant improvement on the traditional actor model, in which actor lifetime is application-managed. Location transparency . An actor reference (proxy object) that the programmer uses to invoke the actor’s methods or pass to other components only contains the logical identity of the actor. The translation of the actor’s logical identity to its physical location and the corresponding routing of messages are done transparently by the Orleans runtime. Application code communicates with actors oblivious to their physical location, which may change over time due to failures or resource management, or because an actor is deactivated at the time it is called. Transparent integration with persistent store . Orleans allows for declarative mapping of actors’ in-memory state to persistent store. It synchronizes updates, transparently guaranteeing that callers receive results only after the persistent state has been successfully updated. Extending and/or customizing the set of existing persistent storage providers available is straight-forward. Automatic propagation of errors . The runtime automatically propagates unhandled errors up the call chain with the semantics of asynchronous and distributed try/catch. As a result, errors do not get lost within an application. This allows the programmer to put error handling logic at the appropriate places, without the tedious work of manually propagating errors at each level. Transparent Scalability by Default The Orleans programming model is designed to guide the programmer down a path of likely success in scaling their application or service through several orders of magnitude. This is done by incorporating the proven best practices and patterns, and providing an efficient implementation of the lower level system functionality. Here are some key factors that enable scalability and performance. Implicit fine grain partitioning of application state . By using actors as directly addressable entities, the programmer implicitly breaks down the overall state of their application. While the Orleans programming model does not prescribe how big or small an actor should be, in most cases it makes sense to have a relative large number of actors – millions or more – with each representing a natural entity of the application, such as a user account, a purchase order, etc. With actors being individually addressable and their physical location abstracted away by the runtime, Orleans has enormous flexibility in balancing load and dealing with hot spots in a transparent and generic way without any thought from the application developer. Adaptive resource management . With actors making no assumption about locality of other actors they interact with and because of the location transparency, the runtime can manage and adjust allocation of available HW resources in a very dynamic way by making fine grain decisions on placement/migration of actors across the compute cluster in reaction to load and communication patterns without failing incoming requests. By creating multiple replicas of a particular actor the runtime can increase throughput of the actor if necessary without making any changes to the application code. Multiplexed communication . Actors in Orleans have logical endpoints, and messaging between them is multiplexed across a fixed set of all-to-all physical connections (TCP sockets). This allows the runtime to host a very large number (millions) of addressable entities with low OS overhead per actor. In addition, activation/deactivation of an actor does not incur the cost of registering/unregistering of a physical endpoint, such as a TCP port or a HTTP URL, or even closing a TCP connection. Efficient scheduling . The runtime schedules execution of a large number of single-threaded actors across a custom thread pool with a thread per physical processor core. With actor code written in the non-blocking continuation based style (a requirement of the Orleans programming model) application code runs in a very efficient “cooperative” multi-threaded manner with no contention. This allows the system to reach high throughput and run at very high CPU utilization (up to 90%+) with great stability. The fact that a growth in the number of actors in the system and the load does not lead to additional threads or other OS primitives helps scalability of individual nodes and the whole system. Explicit asynchrony . The Orleans programming model makes the asynchronous nature of a distributed application explicit and guides programmers to write non-blocking asynchronous code. Combined with asynchronous messaging and efficient scheduling, this enables a large degree of distributed parallelism and overall throughput without the explicit use of multi-threading."
  },
  "Documentation/resources/orleans_thinking_big_and_small.html": {
    "href": "Documentation/resources/orleans_thinking_big_and_small.html",
    "title": "Orleans - Thinking Big and Small | Microsoft Orleans Documentation",
    "keywords": "TL;DR: You don’t need hundreds of servers to benefit from Orleans. A handful is enough. As we just announced availability of the Project Orleans as a public preview ( Available Now: Preview of Project “Orleans” – Cloud Services at Scale ), some of the initial questions and discussions at //build/ were around what type of services the Orleans programming model is suitable for. I heard statements that Orleans is for super-high scale systems. While technically correct, they felt incomplete to me, and compelled me to write this post. Applicability Spectrum One extreme of the Orleans applicability spectrum is a single machine application. Some people see isolation of actors and safe concurrency as big enough benefits that they are worth the price of message passing. That’s not the use case we optimized for while building Orleans, but it’s a legitimate usage pattern, just not very interesting in the cloud context. At the other end of the spectrum we find massive deployments that span thousands of servers. We tested Orleans on deployments of hundreds of servers, and I’m sure it will run fine on thousands, even if that will require some configuration tweaks. However, I’m personally rather skeptical about how many products actually need a single cloud service spanning thousands of servers as opposed to running multiple related services interacting with each other where each service instance is deployed on tens or hundreds of servers. Distributed system – same problems regardless of the size The moment a system moves from a single server to multiple servers, developers face very much the same set of challenges, regardless of its size -- whether it's a 3-5, 30-50 or 300-500 server system. They now have to deal with distribution of their computations, coordination between them, scalability, fault tolerance and reconfigurations, diagnostics, etc. They are building a distributed system now, which is never easy. And building a stateful distributed system is even harder. Orleans was designed to help with building such systems by providing an easy to use set of abstractions that greatly simplifies developers’ lives and helps them avoid common distributed systems pitfalls. The distributed runtime was built to perform most of the heavy lifting. Developers can equally benefit from these features of Orleans when building services of different sizes because the problems Orleans solves for them are really the same. The abstraction of grains simplifies reasoning about your system while encouraging fine-grain partitioning of state for scalability. The virtual actor feature helps with resource management and fault tolerance. Automatic propagation of exceptions minimizes error handling code without losing failures. The distributed runtime takes care of server failures, messaging, routing, single-threaded execution, and other system level guarantees. You don’t need hundreds of servers to start reaping the developer productivity gains. Elasticity Predicting load for your future system is hard and often simply impossible. Every startup dreams of getting slashdotted one day, which is a blessing for the business and a curse for the system. Or your CMO may like your BI data so much that she suddenly wants to have it in 5 second aggregates instead of 30 minutes. Building for high load that may never materialize is expensive. The Orleans model helps solve the elasticity problem by encouraging designing your system in a scalable way, so that you can start with a small deployment and stay small or scale out big if needed without changing your application code. Bottom Line You should be able to benefit from Orleans the moment you go from a single-server setup to a distributed system, whether it’s 2 or 3 servers or thousands of them. You can even start building your single-server solution with Orleans if you believe you may need one day scale it out or make fault tolerant. The beauty here is that your code won’t need to change. Just add more servers and your grains will spread across them. -Sergey Bykov"
  },
  "Documentation/grains/event_sourcing/notifications.html": {
    "href": "Documentation/grains/event_sourcing/notifications.html",
    "title": "Notifications | Microsoft Orleans Documentation",
    "keywords": "Notifications It is often convenient to have the ability to react to state changes. All callbacks are subject to Orleans' turn-based guarantees; see also the section on Concurrency Guarantees. Tracking Confirmed State To be notified of any changes to the confirmed state, JournaledGrain subclasses can override this method: protected override void OnStateChanged() { // read state and/or event log and take appropriate action } OnStateChanged is called whenever the confirmed state is updated, i.e. the version number increases. This can happen when A newer version of the state was loaded from storage. An event that was raised by this instance has been successfully written to storage. A notification message was received from some other instance. Note that since all grains initially have version zero, until the initial load from storage completes, this means that OnStateChanged is called whenever the initial load completes with a version larger than zero. Tracking Tentative State To be notified of any changes to the tentative state, JournaledGrain subclasses can override this method: protected override void OnTentativeStateChanged() { // read state and/or events and take appropriate action } OnTentativeStateChanged is called whenever the tentative state changes, i.e. if the combined sequence (ConfirmedEvents + UnconfirmedEvents) changes. In particular, a callback to OnTentativeStateChanged() always happens during RaiseEvent ."
  },
  "Documentation/grains/event_sourcing/log_consistency_providers.html": {
    "href": "Documentation/grains/event_sourcing/log_consistency_providers.html",
    "title": "Log-Consistency Providers | Microsoft Orleans Documentation",
    "keywords": "Built-In Log-Consistency Providers The Microsoft.Orleans.EventSourcing package includes several log-consistency providers that cover basic scenarios suitable to get started, and allow some extensibility. Orleans.EventSourcing. StateStorage .LogConsistencyProvider This provider stores grain state snapshots , using a standard storage provider that can be configured independently. The data that is kept in storage is an object that contains both the grain state (as specified by the first type parameter to JournaledGrain ) and some meta-data (the version number, and a special tag that is used to avoid duplication of events when storage accesses fail). Since the entire grain state is read/written every time we access storage, this provider is not suitable for objects whose grain state is very large. This provider does not support RetrieveConfirmedEvents : it cannot retrieve the events from storage because the events are not persisted. Orleans.EventSourcing. LogStorage .LogConsistencyProvider This provider stores the complete event sequence as a single object , using a standard storage provider that can be configured independently. The data that is kept in storage is an object that contains a List<EventType> object , and some meta-data (a special tag that is used to avoid duplication of events when storage accesses fail). This provider does support RetrieveConfirmedEvents . All events are always available and kept in memory. Since the whole event sequence is read/written every time we access storage, this provider is not suitable for use in production , unless the event sequences are guaranteed to remain pretty short. The main purpose of this provider is to illustrate the semantics of the event sourcing, and for samples/testing environments. Orleans.EventSourcing. CustomStorage .LogConsistencyProvider This provider allows the developer to plug in their own storage interface, which is then called by the conistency protocol at appropriate times. This provider does not make specific assumptions about whether what is stored are state snapshots or events - the programmer assumes control over that choice (and may store either or both). To use this provider, a grain must derive from JournaledGrain<StateType,EventType> , as before, but additionally must also implement the following interface: public interface ICustomStorageInterface<StateType, EventType> { Task<KeyValuePair<int,StateType>> ReadStateFromStorage(); Task<bool> ApplyUpdatesToStorage(IReadOnlyList<EventType> updates, int expectedversion); } The consistency provider expects these to behave a certain way. Programmers should be aware that: The first method, ReadStateFromStorage , is expected to return both the version, and the state read. If there is nothing stored yet, it should return zero for the version and a state that matches corresponds to the default constructor for StateType . ApplyUpdatesToStorage must return false if the expected version does not match the actual version (this is analogous to an e-tag check). If ApplyUpdatesToStorage fails with an exception, the consistency provider retries. This means some events could be duplicated if such an exception is thrown, but the event was actually persisted. The developer is responsible to make sure this is safe: e.g. either avoid this case by not throwing an exception, or ensure duplicated events are harmless for the application logic, or add some extra mechanism to filter duplicates. This provider does not support RetrieveConfirmedEvents . Of course, since the developer controls the storage interface anyway, they don't need to call this in the first place, but can implement their own event retrieval."
  },
  "Documentation/grains/event_sourcing/event_sourcing_configuration.html": {
    "href": "Documentation/grains/event_sourcing/event_sourcing_configuration.html",
    "title": "Configuration | Microsoft Orleans Documentation",
    "keywords": "Configuration Configuring Project References Grain Interfaces As before, interfaces depend only on the Microsoft.Orleans.Core package, because the grain interface is independent of the implementation. Grain Implementations JournaledGrains need to derive from JournaledGrain<S,E> or JournaledGrain<S> , which is defined in the Microsoft.Orleans.EventSourcing package. Log-Consistency Providers We currently include three log-consistency providers (for state storage, log storage, and custom storage). All three are contained in the Microsoft.Orleans.EventSourcing package as well. Therefore, all Journaled Grains already have access to those. For a description of what these providers do and how they differ, see Included Log-Consistency Providers . Cluster Configuration Log-consistency providers are configured just like any other Orleans providers. For example, to include all three providers (of course, you probably won't need all three), add this to the <Globals> element of the configuration file: <LogConsistencyProviders> <Provider Type=\"Orleans.EventSourcing.StateStorage.LogConsistencyProvider\" Name=\"StateStorage\" /> <Provider Type=\"Orleans.EventSourcing.LogStorage.LogConsistencyProvider\" Name=\"LogStorage\" /> <Provider Type=\"Orleans.EventSourcing.CustomStorage.LogConsistencyProvider\" Name=\"CustomStorage\" /> </LogConsistencyProviders> The same can be achieved programmatically. Assuming the project contains the Microsoft.Orleans.EventSourcing package, and config is a ClusterConfiguration object: using Orleans.Runtime.Configuration; // pick up the necessary extension methods config.AddLogStorageBasedLogConsistencyProvider(\"LogStorage\"); config.AddStateStorageBasedLogConsistencyProvider(\"StateStorage\"); config.AddCustomStorageBasedLogConsistencyProvider(\"CustomStorage\"); Grain Class Attributes Each journaled grain class must have a LogConsistencyProvider attribute to specify the log-consistency provider. Some providers additionally require a StorageProvider attribute. LogConsistencyProvider Attributes To specify the log-consistency provider, add a [LogConsistencyProvider(ProviderName=...)] attribute to the grain class, and give the name of the provider as configured by the Cluster Configuration. For example: [LogConsistencyProvider(ProviderName = \"CustomStorage\")] public class ChatGrain : JournaledGrain<XDocument, IChatEvent>, IChatGrain, ICustomStorage { ... } StorageProvider Attributes Some log-consistency providers (including LogStorage and StateStorage ) use a standard StorageProvider to communicate with storage. This provider is specified using a separate StorageProvider attribute, as follows: [LogConsistencyProvider(ProviderName = \"LogStorage\")] [StorageProvider(ProviderName = \"AzureBlobStorage\")] public class ChatGrain : JournaledGrain<XDocument, IChatEvent>, IChatGrain { ... } Default Providers It is possible to omit the LogConsistencyProvider and/or the StorageProvider attributes, if a default is specified in the configuration. This is done by using the special name Default for the respective provider. For example: <LogConsistencyProviders> <Provider Type=\"Orleans.EventSourcing.LogStorage.LogConsistencyProvider\" Name=\"Default\" /> </LogConsistencyProviders> <StorageProviders> <Provider Type=\"Orleans.Storage.MemoryStorage\" Name=\"Default\" /> </StorageProviders>"
  },
  "Community/Orleans-Thinking-Big-and-Small.html": {
    "href": "Community/Orleans-Thinking-Big-and-Small.html",
    "title": "Orleans - Thinking Big and Small | Microsoft Orleans Documentation",
    "keywords": "TL;DR: You don’t need hundreds of servers to benefit from Orleans. A handful is enough. As we just announced availability of the Project Orleans as a public preview ( Available Now: Preview of Project “Orleans” – Cloud Services at Scale ), some of the initial questions and discussions at //build/ were around what type of services the Orleans programming model is suitable for. I heard statements that Orleans is for super-high scale systems. While technically correct, they felt incomplete to me, and compelled me to write this post. Applicability Spectrum One extreme of the Orleans applicability spectrum is a single machine application. Some people see isolation of actors and safe concurrency as big enough benefits that they are worth the price of message passing. That’s not the use case we optimized for while building Orleans, but it’s a legitimate usage pattern, just not very interesting in the cloud context. At the other end of the spectrum we find massive deployments that span thousands of servers. We tested Orleans on deployments of hundreds of servers, and I’m sure it will run fine on thousands, even if that will require some configuration tweaks. However, I’m personally rather skeptical about how many products actually need a single cloud service spanning thousands of servers as opposed to running multiple related services interacting with each other where each service instance is deployed on tens or hundreds of servers. Distributed system – same problems regardless of the size The moment a system moves from a single server to multiple servers, developers face very much the same set of challenges, regardless of its size -- whether it's a 3-5, 30-50 or 300-500 server system. They now have to deal with distribution of their computations, coordination between them, scalability, fault tolerance and reconfigurations, diagnostics, etc. They are building a distributed system now, which is never easy. And building a stateful distributed system is even harder. Orleans was designed to help with building such systems by providing an easy to use set of abstractions that greatly simplifies developers’ lives and helps them avoid common distributed systems pitfalls. The distributed runtime was built to perform most of the heavy lifting. Developers can equally benefit from these features of Orleans when building services of different sizes because the problems Orleans solves for them are really the same. The abstraction of grains simplifies reasoning about your system while encouraging fine-grain partitioning of state for scalability. The virtual actor feature helps with resource management and fault tolerance. Automatic propagation of exceptions minimizes error handling code without losing failures. The distributed runtime takes care of server failures, messaging, routing, single-threaded execution, and other system level guarantees. You don’t need hundreds of servers to start reaping the developer productivity gains. Elasticity Predicting load for your future system is hard and often simply impossible. Every startup dreams of getting slashdotted one day, which is a blessing for the business and a curse for the system. Or your CMO may like your BI data so much that she suddenly wants to have it in 5 second aggregates instead of 30 minutes. Building for high load that may never materialize is expensive. The Orleans model helps solve the elasticity problem by encouraging designing your system in a scalable way, so that you can start with a small deployment and stay small or scale out big if needed without changing your application code. Bottom Line You should be able to benefit from Orleans the moment you go from a single-server setup to a distributed system, whether it’s 2 or 3 servers or thousands of them. You can even start building your single-server solution with Orleans if you believe you may need one day scale it out or make fault tolerant. The beauty here is that your code won’t need to change. Just add more servers and your grains will spread across them. -Sergey Bykov"
  },
  "Documentation/clusters_and_clients/configuration_guide/local_development_configuration.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/local_development_configuration.html",
    "title": "Local development configuration | Microsoft Orleans Documentation",
    "keywords": "Local development configuration For a working sample application that targets Orleans 2.0 see: https://github.com/dotnet/orleans/tree/master/Samples/2.0/HelloWorld The sample hosts the client and the silo in .NET Core console applications that work in different platforms, but the same can be done with .NET Framework 4.6.1+ console applications (that work only on Windows). Silo configuration For local development, please refer to the below example of how to configure a silo for that case. It configures and starts a silo listening on `loopback' address and 11111 and 30000 as silo and gateway ports respectively. Add the Microsoft.Orleans.Server NuGet meta-package to the project. After you get comfortable with the API, you can pick and choose which exact packages included in Microsoft.Orleans.Server you actually need, and reference them instead. PM> Install-Package Microsoft.Orleans.Server You need to configure ClusterOptions via ISiloBuilder.Configure method, specify that you want DevelopmentClustering as your clustering choice with this silo being the primary, and then configure silo endpoints. ConfigureApplicationParts call explicitly adds the assembly with grain classes to the application setup. It also adds any referenced assembly due to the WithReferences extension. After these steps are completed, the silo host gets built and the silo gets started. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for hosting a silo, as well as a .NET Core console application. Here is an example of how a local silo can be started: public class Program { public static async Task Main(string[] args) { try { var host = await StartSilo(); Console.WriteLine(\"Press Enter to terminate...\"); Console.ReadLine(); await host.StopAsync(); return; } catch (Exception ex) { Console.WriteLine(ex); return; } } private static async Task<ISiloHost> StartSilo() { var builder = new SiloHostBuilder() // Use localhost clustering for a single local silo .UseLocalhostClustering() // Configure ClusterId and ServiceId .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"MyAwesomeService\"; }) // Configure connectivity .Configure<EndpointOptions>(options => options.AdvertisedIPAddress = IPAddress.Loopback) // Configure logging with any logging framework that supports Microsoft.Extensions.Logging. // In this particular case it logs using the Microsoft.Extensions.Logging.Console package. .ConfigureLogging(logging => logging.AddConsole()); var host = builder.Build(); await host.StartAsync(); return host; } } Client configuration For local development, please refer to the below example of how to configure a client for that case. It configures a client that would connect to a loopback silo. Add the Microsoft.Orleans.Client NuGet meta-package to the project. After you get comfortable with the API, you can pick and choose which exact packages included in Microsoft.Orleans.Client you actually need, and reference them instead. PM> Install-Package Microsoft.Orleans.Client You need to configure ClientBuilder with a cluster ID that matches the one you specified for local silo and specify static clustering as your clustering choice pointing it to the gateway port of the silo ConfigureApplicationParts call explicitly adds the assembly with grain interfaces to the application setup. After these steps are completed, we can build the client and Connect() method on it to connect to the cluster. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for running a client or reuse the console application project you created for hosting a silo. Here is an example of how a client can connect to a local silo: client = new ClientBuilder() // Use localhost clustering for a single local silo .UseLocalhostClustering() // Configure ClusterId and ServiceId .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"MyAwesomeService\"; }) .ConfigureLogging(logging => logging.AddConsole()) var client = builder.Build(); await client.Connect();"
  },
  "Documentation/clusters_and_clients/configuration_guide/configuring_.NET_garbage_collection.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/configuring_.NET_garbage_collection.html",
    "title": "Configuring .NET Garbage Collection | Microsoft Orleans Documentation",
    "keywords": "Configuring .NET Garbage Collection For good performance, it is important to configure .NET garbage collection for the silo process the right way. The best combination of settings we found is to set gcServer=true and gcConcurrent=true. These are easy to set via the application csproj file. See below as an example: .NET Framework and .NET Core // .csproj <PropertyGroup> <ServerGarbageCollection>true</ServerGarbageCollection> <ConcurrentGarbageCollection>true</ConcurrentGarbageCollection> </PropertyGroup> .NET Framework with old .csproj project format // App.config <configuration> <runtime> <gcServer enabled=\"true\"/> <gcConcurrent enabled=\"true\"/> </runtime> </configuration> However, this is not as easy to do if a silo runs as part of an Azure Worker Role, which by default is configured to use workstation GC. This blog post shows how to set the same configuration for an Azure Worker Role - https://blogs.msdn.microsoft.com/cclayton/2014/06/05/server-garbage-collection-mode-in-microsoft-azure/ IMPORTANT NOTE Server garbage collection is available only on multiprocessor computers . Therefore, even if you configure the Garbage Collection either via application csproj file or via the scripts on the referred blog post, if the silo is running on a (virtual) machine with a single core, you will not get the benefits of gcServer=true ."
  },
  "1.5/Tutorials/Actor-Identity.html": {
    "href": "1.5/Tutorials/Actor-Identity.html",
    "title": "Actor Identity | Microsoft Orleans Documentation",
    "keywords": "Actor Identity In object-oriented environments, the identity of an object is hard to distinguish from a reference to it. Thus, when an object is created using new, the reference you get back represents all aspects of its identity except those that map the object to some external entity that it represents. In distributed systems, object references cannot represent instance identity, since references are typically limited to a single address space. That is certainly the case for .NET references. Furthermore, a virtual actor must have an identity regardless of whether it is active, so that we can activate it on demand. Therefore grains have a primary key. The primary key can be either a GUID (A Globally Unique Identifier), a long integer, or a string. The primary key is scoped to the grain type. Therefore, the complete identity of a grain is formed from the actor type and its key. The caller of the grain decides a long, a GUID, or a string scheme should be used. In fact the underlying data is the same, so the schemes can be used interchangeably. When a long is used, a GUID is actually created, and padded with zeros. Situations that require a singleton grain instance, such as a dictionary or registry, benefit from using 0 (a valid GUID) as its key. This is merely a convention, but by adhering, it becomes clear at the call site that it is what is going on, as we saw in the first tutorial: Using GUIDs GUIDs are useful when there are several processes that could request a grain, such as a number of web servers in a web farm. You don't need to coordinate the allocation of keys, which could introduce a single point of failure in the system, or a system-side lock on a resource which could present a bottleneck. There is a very low chance of GUIDs colliding, so they would probably be the default choice when architecting an Orleans system. Referencing a grain by GUID in client code: var grain = GrainClient.GrainFactory.GetGrain<IExample>(Guid.NewGuid()); Retrieving the primary key from grain code: public override Task OnActivateAsync() { Guid primaryKey = this.GetPrimaryKey(); return base.OnActivateAsync(); } Using Longs A long integer is also available, which would make sense if the grain is persisted to a relational database, where numerical indexes are preferred over GUIDs. Referencing a grain by long integer in client code: var grain = GrainClient.GrainFactory.GetGrain<IExample>(1); Retrieving the primary key form grain code: public override Task OnActivateAsync() { long primaryKey = this.GetPrimaryKeyLong(); return base.OnActivateAsync(); } Using Strings A string is also available. Referencing a grain by String in client code: var grain = GrainClient.GrainFactory.GetGrain<IExample>(\"myGrainKey\"); Retrieving the primary key form grain code: public override Task OnActivateAsync() { string primaryKey = this.GetPrimaryKeyString(); return base.OnActivateAsync(); } The stock ticker example used in the Interaction with Libraries and Services uses a string keys to activate grains representing different stock symbols. Using Compound Primary Key If you have a system that doesn't fit well with either GUIDs or longs, you can opt for a compound primary key which allows you to use a combination of a GUID or long and a string to reference a grain. You can inherit your interface from 'IGrainWithGuidCompoundKey' or 'IGrainWithIntegerCompoundKey\" interface like this: public interface IExampleGrain : Orleans.IGrainWithIntegerCompoundKey { Task Hello(); } In client code, this adds a second argument to the GetGrain method on the grain factory. var grain = GrainClient.GrainFactory.GetGrain<IExample>(0, \"a string!\", null); To access the compound key in the grain, we can call an overload on the GetPrimaryKey method: public class ExampleGrain : Orleans.Grain, IExampleGrain { public Task Hello() { string keyExtension; long primaryKey = this.GetPrimaryKey(out keyExtension); Console.WriteLine(\"Hello from \" + keyExtension); return TaskDone.Done; } } Next Let's add another type of grain into the solution, and demonstrate inter-grain communication. A Service is a Collection of Communicating Actors"
  },
  "1.5/Tutorials/A-Service-is-a-Collection-of-Communicating-Actors.html": {
    "href": "1.5/Tutorials/A-Service-is-a-Collection-of-Communicating-Actors.html",
    "title": "A Service is a Collection of Communicating Actors | Microsoft Orleans Documentation",
    "keywords": "A Service is a Collection of Communicating Actors The previous tutorials all relied on interacting with a single actor from the client. In most real-world situations this is not what would be expected as actors are intended to be more or less as light-weight as objects and treated as such. Thus, you would no more find an application with just one actor type and one actor instance than you would expect to find a .NET application with one instance of one class. In this tutorial, we're going to construct multiple actors from a couple of classes with different communication interfaces. Not everything will be explained while putting together the application, we will go back and elaborate on a few things after we have it working. Employees and Managers This example will use the relationship of employees and managers to demonstrate the concept of multiple actors - it's one we all understand and relate to. Start by creating a new solution with a silo host, a communications interface project and a grain implementation project as described in previous tutorials. Don't forget to add the necessary project-to-project references and make sure to add a build dependency on the implementation project so that it is built when the host project is built. Change the first interface to IEmployee and add an interface called IManager . Add a couple of methods to describe relationships and employment level: public interface IEmployee : IGrainWithGuidKey { Task<int> GetLevel(); Task Promote(int newLevel); Task<IManager> GetManager(); Task SetManager(IManager manager); } and public interface IManager : IGrainWithGuidKey { Task<IEmployee> AsEmployee(); Task<List<IEmployee>> GetDirectReports(); Task AddDirectReport(IEmployee employee); } Note that this looks a bit different to normal .NET interfaces: usually, you have a property with a setter and a getter, but when defining grain interfaces, you need to avoid using properties altogether, only methods are supported. This is because .NET property setters and getters aren't meant to do I/O. It is often possible to use traditional object-oriented design methodology with Orleans, but sometimes there are reasons for not doing so. In this case, we're choosing to not rely on inheritance when defining the Manager class, even though a Manager is clearly also an Employee . The reason for this will be explained when we discuss Orleans' support for Declarative Persistence . With these two interfaces as our starting point, the implementation classes are straightforward to implement, as the interfaces are simple. Here's what it looks like: public class Employee : Grain, IEmployee { public Task<int> GetLevel() { return Task.FromResult(_level); } public Task Promote(int newLevel) { _level = newLevel; return TaskDone.Done; } public Task<IManager> GetManager() { return Task.FromResult(_manager); } public Task SetManager(IManager manager) { _manager = manager; return TaskDone.Done; } private int _level; private IManager _manager; } and public class Manager : Grain, IManager { public override Task OnActivateAsync() { _me = this.GrainFactory.GetGrain<IEmployee>(this.GetPrimaryKey()); return base.OnActivateAsync(); } public Task<List<IEmployee>> GetDirectReports() { return Task.FromResult(_reports); } public Task AddDirectReport(IEmployee employee) { _reports.Add(employee); employee.SetManager(this); return TaskDone.Done; } public Task<IEmployee> AsEmployee() { return Task.FromResult(_me); } private IEmployee _me; private List<IEmployee> _reports = new List<IEmployee>(); } A manager is expressed as an employee through composition: the manager grain has a reference to a grain representing its \"employeeness.\" The role of OnActivateAsync() will be explained later on; for now, you may consider it to be a constructor. In the client (Program.cs) , we can add a few lines to create a couple of employees and their manager: // Orleans comes with a rich XML and programmatic configuration. Here we're just going to set up with basic programmatic config var config = Orleans.Runtime.Configuration.ClientConfiguration.LocalhostSilo(30000); GrainClient.Initialize(config); var grainFactory = GrainClient.GrainFactory; var e0 = grainFactory.GetGrain<IEmployee>(Guid.NewGuid()); var e1 = grainFactory.GetGrain<IEmployee>(Guid.NewGuid()); var e2 = grainFactory.GetGrain<IEmployee>(Guid.NewGuid()); var e3 = grainFactory.GetGrain<IEmployee>(Guid.NewGuid()); var e4 = grainFactory.GetGrain<IEmployee>(Guid.NewGuid()); var m0 = grainFactory.GetGrain<IManager>(Guid.NewGuid()); var m1 = grainFactory.GetGrain<IManager>(Guid.NewGuid()); var m0e = m0.AsEmployee().Result; var m1e = m1.AsEmployee().Result; m0e.Promote(10); m1e.Promote(11); m0.AddDirectReport(e0).Wait(); m0.AddDirectReport(e1).Wait(); m0.AddDirectReport(e2).Wait(); m1.AddDirectReport(m0e).Wait(); m1.AddDirectReport(e3).Wait(); m1.AddDirectReport(e4).Wait(); Console.WriteLine(\"Orleans Silo is running.\\nPress Enter to terminate...\"); Console.ReadLine(); In the code we have seen so far, it is noteworthy that you can send grain references (interfaces) in messages. Thus, when a direct report is added to a manager, the manager can communicate directly with the employee without calling GetGrain() . This ability is essential in making the programming model a smooth transition from .NET. Let's add the ability for employees to send messages to each other: public interface IEmployee : IGrainWithGuidKey { ... Task Greeting(IEmployee from, string message); ... } then: public class Employee : Grain, Interfaces.IEmployee { public Task Greeting(IEmployee from, string message) { Console.WriteLine(\"{0} said: {1}\", from.GetPrimaryKey().ToString(), message); return TaskDone.Done; } and public class Manager : Grain, IManager { public Task AddDirectReport(IEmployee employee) { _reports.Add(employee); employee.SetManager(this); employee.Greeting(_me, \"Welcome to my team!\"); return TaskDone.Done; } Executing it, you should see something like this: The use of a GUID to represent the name of a person leaves something for you to fix, as an exercise. If you want to do this exercise, please keep the rule for always using asynchronous code inside grains. The Result of a Task will block execution if the task hasn’t completed. This should be avoided in Orleans grains; tasks should always be awaited before Result is read. TaskDone.Done , used in the code above, is a convenience object defined by Orleans to allow code to succinctly return an already completed Task . Asynchrony Bites Us! In the image above, you may notice that the last message comes out after the request to press Enter -- why is that? All the client requests to add a direct report dutifully wait for the addition to finish, i.e. they are fully synchronous. The problem lies elsewhere -- in the implementation of AddDirectReport() , which doesn't wait for the greeting to be acknowledged. Such concurrency is often innocuous and sometimes beneficial, as long as we don't consider the risk of exceptions, which we always must. A correct version of the method would look like this: public async Task AddDirectReport(IEmployee employee) { _reports.Add(employee); await employee.SetManager(this); await employee.Greeting(_me, \"Welcome to my team!\"); } The Life of an Actor Orleans actors are virtual, meaning that even though an actor logically exists, it may not be present in memory at a given point in time. In fact, Orleans takes this concept to an extreme by claiming that all actors exist at all time (past and present) and are never created or destroyed. An actor may be inactive, such as before the first time anyone refers to it or after the last use, but is never not existing. While counter-intuitive and, frankly, strange to most of us with a object-oriented background, this notion actually removes a source of complexity from the system. An actor is either active (present in memory) or inactive, and that status can not be observed by a client. Actor activation is on-demand, just like virtual memory is mapped on demand to physical memory. Thus, the .NET object that holds the actor state is logically just a copy of the actor in memory while it is in the active state. Implementations of Orleans grains should refrain from having constructors, even parameter-less ones, with any logic. That is simply the wrong way of thinking about them: grains are never created or destroyed, just moved from the inactive to the active state or vice versa. Therefore, the implementation should catch the activation event (a call to OnActivateAsync() ) and perform any initialization steps necessary there. It is guaranteed to be called before any method on the grain instance is called. In the Manager grain above, it was used to establish the reference to the Employee grain. There is also an OnDeactivateAsync() method, used more infrequently. Next Next up is a look at Concurrency in Orleans."
  },
  "1.5/Documentation/Getting-Started-With-Orleans/Grains.html": {
    "href": "1.5/Documentation/Getting-Started-With-Orleans/Grains.html",
    "title": "Grains | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Grains Grains are the key primitives of the Orleans programming model. Grains are the building blocks of an Orleans application, they are atomic units of isolation, distribution, and persistence. Grains are objects that represent application entities. Just like in the classic Object Oriented Programming, a grain encapsulates state of an entity and encodes its behavior in the code logic. Grains can hold references to each other and interact by invoking each other’s methods exposed via interfaces. Orleans aims to greatly simplify building a scalable application and eliminate most of the concurrency challenges By not sharing data between grains instances except via message passing. By providing the single-threaded execution guarantee to each individual grain. A typical grain encapsulates state and behavior of a single entity (e.g. a specific user or a device or a session). Grain Identity An individual grain is a uniquely addressable instance of a grain type (class). Each grain has a unique identity, also referred to as a grain key, within its type. Grain identity within its type can be a long integer, a GUID, a string, or a combination of a long+string or GUID+string. Accessing a Grain A grain class implements one or more grain interfaces, formal code contracts for interacting with grains of that type. To invoke a grain, a caller needs to know the grain interface that the grain class implements that includes the method that the caller wants to call and the unique identity (key) of the target grain. For example, here's how a user profile grain can be called to update user's address if email is used as a user identity. var user = grainFactory.GetGrain<IUserProfile>(userEmail); await user.UpdateAddress(newAddress); A call to GetGrain is an inexpensive local operation of constructing a grain reference with an embedded identity and type of the target grain. Note that there is no need to create or instantiate the target grain. We make a call to it to update user's address as if the user's grain is already instantiated for us. This is one of the biggest advantages of the Orleans programming model - we never need to create, instantiate or delete grains. We can write our code as if all possible grains, for example millions of user profiles, are always in memory waiting for us to call them. Behind the scenes, the Orleans runtime performs all the heavy lifting of managing resources to transparently bring grains to memory when needed. Behind the Scenes - Grain Lifecycle Grains live in execution containers called silos. Silos form a cluster that combines resources of multiple physical or virtual machines. When there is work (request) for a grain, Orleans ensures there is an instance of the grain on one of the Silos in the cluster. If there is no instance of the grain on any silo, the Orleans runtime creates one. This process is called Activation. In case a grain is using Grain Persistence , the runtime automatically reads the state from the backing store upon activation. Once activated on a silo, a grain processes incoming requests (method calls) from other grains or from outside of the cluster (usually from frontend web servers). In the course of processing a request a grain may call other grains or some external services. If a grain stops receiving requests and stays idle, after a configurable period of inactivity Orleans removes the grain from memory (deactivates it) to free up resources for other grains. If and when there's a new request for that grain, Orleans will activate it again, potentially on a different silo, so the caller gets the impression that the grain stayed in memory the whole time. A grain goes through the lifecycle from existing only as its persisted state (if it has any) in storage to being instantiated in memory to being removed from memory. Orleans controls the process of activating and deactivating grains transparently. When coding a grain, a developer assumes all grains are always activated. The sequence of key events in grain lifecycle looks like this. Another grain or a client makes a call to a method of the grain (via a grain reference) The grain gets activated (if it is not already activated somewhere in the cluster) and an instance of the grain class, called a grain activation, is created Constructor of the grain is executed leveraging Dependency Injection if applicable If Declarative Persistence is used, the grain state is read from storage If overridden, OnActivateAsync is called The grain processes incoming requests The grain remains idle for some time Silo runtime decides to deactivate the grain Silo runtime calls OnDeactivateAsync , if overridden Silo runtime removes the grain from memory Upon a graceful shutdown of a silo, all grain activations it holds get deactivated. Any requests waiting to be processed in grains' queues get forwarded to other silos in the cluster, where new activations of deactivated grains get created on an as-needed basis. If a silo shuts down or dies ungracefully, other silos in the cluster detect the failure, and start creating new activations of grains lost on the failed silo, as new requests for those grains arrive. Note that detection of a silo failure takes some time (configurable), and hence the process of reactivating lost grains isn't instantaneous. Grain Execution A grain activation performs work in chunks and finishes each chunk before it moves on to the next. Chunks of work include method invocations in response to requests from other grains or external clients, and closures scheduled on completion of a previous chunk. The basic unit of execution corresponding to a chunk of work is known as a turn. While Orleans may execute many turns belonging to different activations in parallel, each activation will always execute its turns one at a time. This means that there is no need to use locks or other synchronization methods to guard against data races and other multi-threading hazards. Next Next we look at how to implement a grain class. Developing a Grain"
  },
  "1.5/Documentation/Event-Sourcing/Overview.html": {
    "href": "1.5/Documentation/Event-Sourcing/Overview.html",
    "title": "Event Sourcing | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Event Sourcing Event sourcing provides a flexible way to manage and persist grain state. An event-sourced grain has many potential advantages over a standard grain. For one, it can be used with many different storage provider configurations, and supports geo-replication across multiple clusters. Moreover, it cleanly separates the grain class from definitions of the grain state (represented by a grain state object) and grain updates (represented by event objects). The documentation is structured as follows: JournaledGrain Basics explains how to define an event-sourced grains by deriving from JournaledGrain , how to access the current state, and how to raise events that update the state. Replicated Instances explains how the event-sourcing mechanism handles replicated grain instances and ensures consistency. It discusses the possibility of racing events and conflicts, and how to address them. Immediate/Delayed Confirmation explains how delayed confirmation of events, and reentrancy, can improve availability and throughput. Notifications explains how to subscribe to notifications, allowing grains to react to new events. Configuration explains how to configure projects, clusters, and log-consistency providers. Built-In Log-Consistency Providers explains how the three currently included log-consistency providers work. Diagnostics explains how to monitor for connection errors, and get simple statistics. The behavior documented above is reasonably stable, as far as the JournaledGrain API is concerned. However, we expect to extend or change the list of log consistency providers soon, to more easily allow developers to plug in standard event storage systems."
  },
  "Documentation/grains/types_of_grains.html": {
    "href": "Documentation/grains/types_of_grains.html",
    "title": "Types of Grains | Microsoft Orleans Documentation",
    "keywords": "There are different types of grains ///TODO find page about grain types - make sure it includes stateless workers and stateful/persistent grains"
  },
  "Community/Student-Projects.html": {
    "href": "Community/Student-Projects.html",
    "title": "Student Projects | Microsoft Orleans Documentation",
    "keywords": "Student Projects We suggest 2 types of projects for students: The first type includes exploratory, open-ended, research-oriented projects with the goal of enabling new capabilities in Orleans. These projects would usually have broad scope and would be suitable for M.S. or Ph.D. student or advanced undergraduate students in their last year of studies. The end goal of these projects would be to contribute ideas and design to Orleans. We do not necessarily expect the code produced in these projects to be directly contributed to this repository, however this would be nice. The second type includes ideas for student education . These are either ideas for interesting applications that can be built on top of Orleans or some new capabilities for Orleans. These projects are suitable to be given in advanced undergraduate or graduate courses, where students learn about Cloud Computing and modern distributed technologies and want to gain real-world hands-on experience in building Cloud applications. We do not expect the code produced in these projects to be contributed directly to this repository. Research projects: Auto-scale. In this project students can start by exploring the existing auto-scaling mechanisms for controlling resource allocation in Windows Azure ( Autoscaling Application Block ). The next step involves exploring various statistics and resource consumption metrics collected by Orleans, and using them as an input for Azure Autoscaling. An advanced stage of this project may involve improving the internal Orleans mechanisms for reacting to elasticity changes, for example by implementing live actor migration to reduce the time taken to utilize new resources. Auto-generated front-ends for Orleans-based cloud services . This project seamlessly extends the Orleans actor model into the HTTP world. The ramp-up part of the project includes dynamically generating HTTP endpoints for actors based on their .NET interfaces and metadata. The main part involves automatically generating front-ends to support web sockets and bi-directional streaming of data, which requires complex code generation with optimizations for high performance. It also requires attention to fault tolerance, to maintain high availability of streaming sessions across server reboots and client reconnects and migration -- a significant research challenge. Storage provider for Entity Framework . This project involves enabling Orleans objects to store their state in a database and to subsequently query it. This might include adding support for Orleans object persistence on SQL Azure Database using Entity Framework (EF), which is Microsoft's open-source object-relational mapper for .NET, and exposing that data via LINQ queries. The implementation can be evaluated and tuned using standard database benchmarks and/or custom Orleans' applications. Distributed system benchmark . Define a list of benchmarks suitable for distributed systems like Orleans. The benchmark applications may be analogous in spirit to the TPC database benchmark or UCB \"Parallel Dwarfs\" implemented here and may be used to characterize the performance and scalability of distributed frameworks. Consider developing a new benchmark targeted for Orleans, for example, to compare the performance of storage providers. Declarative dataflow language over streams . Define and build a Trident-Storm like declarative language over Orleans streams. Develop an optimizer that configures the stream processing to minimize overall cost. Programming model for client devices . Extend Orleans to client devices, such as sensors, phones, tablets, and desktops. Enable grain logic to execute on the client. Potentially support tier splitting, that is, dynamically deciding which parts of the code execute on the device and which is offloaded to the cloud. Queries over grain/actor classes, secondary indices . Build a distributed, scalable, and reliable grain index. This includes formally defining the query model and implementing the distributed index. The index itself can be implemented as Orleans grains and/or stored in a database. Large scale simulations . Orleans is a great fit for building large scale simulations. Explore the usage of Orleans for different simulations, for example, protein interactions, network simulations, simulated annealing, etc. Course projects: Internet Of Things applications . For example, the application could enable sensors/devices to report their state to the cloud, where each device is represented in the cloud by an Orleans actor. Users can connect to the actor that represents their device via a web browser and check its status or control it. This project involves mastering a number of modern cloud technologies, including Windows Azure , Orleans, WebApi or ASP.NET, SignalR for streaming commands back from the cloud to the device, and writing a sensor/device/phone app. Twitter-like large scalable chat service in the cloud based on Orleans . Each user could be represented by an Orleans Actor, which contains its list of followers. Faceboook-like social app based on Orleans . Each user could be represented by an Orleans Actor, which includes a list of friends and wall on which friends can write. Simple storage provider . Add a storage provider for a storage system, such as a key-value store or database system. A simple one could use the Orleans serializer , as in the existing Azure Table storage provider . A more sophisticated one would map state variables of an Orleans class to fine-grained structures of the storage system. A complex one is the Entity Framework storage provider mentioned above under Research Projects . Compare the performance of different storage providers for different types and sizes of actor state. Comparison with other distributed application frameworks . Take a sample application written for another application framework, such as Google App Engine or Akka , and translate it into Orleans. Summarize the relative strengths and weaknesses of each framework by comparing the apps. Concluded Research projects: Below are a number of examples of previous successful research projects. Distributed log analysis, correlation and debugging . Debugging large-scale distributed systems is a challenging task due to enormous amounts of data and complex dynamic interactions between the distributed components, running on different processes and different machines. The goal of this project was to analyze prior art on this topic, propose a solution, and then implement prototype tools for collecting, correlating and analyzing application error log file data across a multi-machine distributed application runtime environment. This involved exploring the problem space from a variety of perspectives, including: a. Approaches to efficient logging, collection and analysis of failure information from various log-capture mechanisms in a distributed Orleans runtime environment. b. Possible applications of machine learning to find log patterns that signal serious production issues, and then detecting these patterns in near real time as a production monitoring utility. c. Ways to help individual developers perform real-time debugging of run-time issues with their applications. This project was performed successfully and result in a published paper PAD: Performance Anomaly Detection in Multi-Server Distributed Systems and a proof of concept implementation of a distributed log analysis tool. Horton - Distributed Graph Database . Horton was a research project with a goal to build a system to store, manage and query large-scale distributed graphs. It was implemented entirely as an Orleans application. The project resulted in a number of publications and a number of very successful student projects."
  },
  "1.5/Tutorials/Custom-Storage-Providers.html": {
    "href": "1.5/Tutorials/Custom-Storage-Providers.html",
    "title": "Custom Storage Providers | Microsoft Orleans Documentation",
    "keywords": "Custom Storage Providers Writing a Custom Storage Provider In the tutorial on declarative actor storage, we looked at allowing grains to store their state in an Azure table using one of the built-in storage providers. While Azure is a great place to squirrel away your data, there are many alternatives. In fact, there are so many that there was no way to support them all. Instead, Orleans is designed to let you easily add support for your own form of storage by writing a storage provider. In this tutorial, we'll walk through how to write a simple file-based storage provider. A file system is not necessarily the best place to store data for grains, since it's so local, but it's an easy example to help us illustrate the principles. Getting Started An Orleans storage provider is simply a class that implements IStorageProvider . It should be built into an assembly that is placed in the Orleans binaries folder. To move it there on build will require adding a bit of post-build event code. We'll start by creating the project -- it should be a regular .NET class library. Once the project is created, let's also rename the file Class1.cs to FileStorageProvider.cs . That should also prompt VS to rename the class we find inside. Next, we must add references to Microsoft.Orleans.Core NuGet package . Assuming, of course, that your project is called StorageProviders , make your silo host project reference it, so that StorageProviders.dll gets copied to the silo folder. Our storage provider should implement the interface Orleans.Storage.IStorageProvider . With a little bit of massaging of the code, it should look something like this: using System; using System.Threading.Tasks; using System.Collections.Generic; using Orleans; using Orleans.Storage; using Orleans.Runtime; using Newtonsoft.Json; using Orleans.Serialization; namespace StorageProviders { public class FileStorageProvider : IStorageProvider { private JsonSerializerSettings _jsonSettings; public Logger Log { get; set; } public string Name { get; set; } public Task Init(string name, Orleans.Providers.IProviderRuntime providerRuntime, Orleans.Providers.IProviderConfiguration config) { throw new NotImplementedException(); } public Task Close() { throw new NotImplementedException(); } public Task ReadStateAsync(string grainType, GrainReference grainRef, IGrainState grainState) { throw new NotImplementedException(); } public Task WriteStateAsync(string grainType, GrainReference grainRef, IGrainState grainState) { throw new NotImplementedException(); } public Task ClearStateAsync(string grainType, GrainReference grainRef, IGrainState grainState) { throw new NotImplementedException(); } } } The first thing we have to figure out is what data we need to provide through configuration. The name is a required property, but we will also need the path to the root directory for our file store. That is, in fact, the only piece of information we need, so we'll add a RootDirectory string property and edit the configuration file as in the previous section. In doing so, it's critical to pay attention to the namespace and class name of the provider. Add this to the <StorageProviders> element in the OrleansConfiguration.xml configuration file of your silo host project where you will be testing the provider: <Provider Type=\"StorageProviders.FileStorageProvider\" Name=\"FileStore\" RootDirectory=\".\\Storage\"/> Edit the Grain1.cs file to use this storage provider instead of the Azure provider, then set a breakpoint in the Init() method of the storage provider implementation class and start the silo. If you have followed the instructions, you should hit the breakpoint during silo initialization. There's no reason to go on debugging, since you will throw an exception right away. Initializing the Provider There are four major functions to implement in the provider -- Close() is the only one we won't need to do anything with. As you may have guessed, the starting point is the call to Init() , which provides us with the configuration data and a chance to get things set up properly. In our case, we'll want to set the properties and create the root directory if it doesn't already exist: public Task Init(string name, Orleans.Providers.IProviderRuntime providerRuntime, Orleans.Providers.IProviderConfiguration config) { _jsonSettings = SerializationManager.UpdateSerializerSettings(SerializationManager.GetDefaultJsonSerializerSettings(), config); this.Name = name; if (string.IsNullOrWhiteSpace(config.Properties[\"RootDirectory\"])) throw new ArgumentException(\"RootDirectory property not set\"); var directory = new System.IO.DirectoryInfo(config.Properties[\"RootDirectory\"]); if (!directory.Exists) directory.Create(); this.RootDirectory = directory.FullName; return TaskDone.Done; } Run the program again. This time, you will still crash, but in ReadStateAsync() . After running the code, you should find a Storage directory under the bin\\Debug directory of the silo host project. Make sure you have set the project up to build on F5, or you may not see the edits take effect. Reading State To store data in the file system (or anywhere, really), we have to devise a convention that generates a unique name for each grain. This is easiest done by combining the state type name with the grain id, which combines the grain type and GUID creating a globally unique key. Thus, ReadStateAsync() (which, by the way, should be declared as an async method), starts like this: var collectionName = grainState.GetType().Name; var key = grainRef.ToKeyString(); var fName = key + \".\" + collectionName; var path = System.IO.Path.Combine(RootDirectory, fName); var fileInfo = new System.IO.FileInfo(path); if (!fileInfo.Exists) return; We also need to decide how the data will be stored. To make it easy to inspect the data outside of the application, we're going to use JSON. A more space-conscious design may use a binary serialization format, instead, it's entirely a choice of the provider designer's. using (var stream = fileInfo.OpenText()) { var storedData = await stream.ReadToEndAsync(); grainState.State = JsonConvert.DeserializeObject(storedData, grainState.State.GetType(), _jsonSettings); } Writing State The format decisions have already been made, so coding up the WriteStateAsync method should be straight-forward: serialize as JSON, construct the file name, then write to the file: public async Task WriteStateAsync(string grainType, GrainReference grainRef, IGrainState grainState) { var storedData = JsonConvert.SerializeObject(grainState.State, _jsonSettings); var collectionName = grainState.GetType().Name; var key = grainRef.ToKeyString(); var fName = key + \".\" + collectionName; var path = System.IO.Path.Combine(RootDirectory, fName); var fileInfo = new System.IO.FileInfo(path); using (var stream = new System.IO.StreamWriter( fileInfo.Open(System.IO.FileMode.Create, System.IO.FileAccess.Write))) { await stream.WriteAsync(storedData); } } Putting it Together There's really just one thing left to do, and that is to test the thing. Run the application and let it get to the end, where the greetings are shown, and then terminate it. Under the bin\\Debug\\Storage directory of your silo host project, you should find a file called 0.Grain1State , and it should contain something very recognizable: Run the application again, and you should see the same behaviour as before, that is, the last greeting of the first session is remembered. Clearing State The easiest method to write is the one that deletes grain state, which we didn't see any use of in the previous tutorial. In fact, we don't need it for our Hello World application, so we'll just leave its implementation as an exercise. It should do the obvious, i.e. delete the file. Next We'll look at how you can unit test grains: Unit Testing Grains"
  },
  "1.5/Tutorials/Front-Ends-for-Orleans-Services.html": {
    "href": "1.5/Tutorials/Front-Ends-for-Orleans-Services.html",
    "title": "Front Ends for Orleans Services | Microsoft Orleans Documentation",
    "keywords": "Front Ends for Orleans Services Exposing silo gateway ports as public endpoints of an Orleans cluster is not recommended. Instead, Orleans is intended to be fronted by your own API. Creating an HTTP API, or web application is a common scenario. Let's extend the Employee/Manager scenario from the Declarative-Persistence walk-through to see what steps are required to publish grain data over HTTP. Creating the ASP.NET application First, you should add a new ASP.NET Web Application to your solution. Then, select the Web API template, although you could use MVC or Web Forms. Initializing Orleans Next, add a reference to the Orleans.dll file in the project references. As with the Orleans host we created earlier, we need to initialize Orleans. This is best done in the Global.asax.cs file like this: namespace WebApplication1 { public class WebApiApplication : System.Web.HttpApplication { protected void Application_Start() { ... var config = ClientConfiguration.LocalhostSilo(); // Attempt to connect a few times to overcome transient failures and to give the silo enough // time to start up when starting at the same time as the client (useful when deploying or during development). const int initializeAttemptsBeforeFailing = 5; int attempt = 0; while (true) { try { GrainClient.Initialize(config); break; } catch (SiloUnavailableException e) { attempt++; if (attempt >= initializeAttemptsBeforeFailing) { throw; } Thread.Sleep(TimeSpan.FromSeconds(2)); } } ... Now when the ASP.NET application starts, it will initialize the Orleans Client. Creating the Controller Now lets add a controller to the project, to receive HTTP requests, and call the grain code. Right click on the \"Controllers\" folder, and add a new \"Web API 2 Controller - Empty\". Next, call the controller EmployeeController . This will create a new empty controller called EmployeeController . We can add a Get method to the controller, which we'll use to return the level of an Employee. public class EmployeeController : ApiController { public Task<int> Get(Guid id) { var employee = GrainClient.GrainFactory.GetGrain<IEmployee>(id); return employee.GetLevel(); } } Note that the controller is asynchronous, and we can just pass back the Task which the grain returns. Running the Application Now let's test the application. Build the project. Set the ASP.NET application and the silo host project as the startup projects, and run them. If you navigate to the API URL (the number may be different on your project)... http://localhost:6858/api/employee/42783519-d64e-44c9-9c29-399e3afaa625 ...you should see the result returned from the grain: 42 That's the basics in place, the rest of the API can be completed by adding the rest of the HTTP verbs. Next We'll look at how you can deploy Orleans in the Azure Cloud Cloud Deployment"
  },
  "1.5/Documentation/Samples-Overview/Storage-Providers.html": {
    "href": "1.5/Documentation/Samples-Overview/Storage-Providers.html",
    "title": "Storage Providers | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Storage Providers Note : This sample requires the \"Official MongoDB C# Driver\" NuGet package from 10gen, Inc. If you want to run the sample and store data using MongoDB, you will also need to download and install MongoDB. Custom storage providers allow you to extend the capabilities of Orleans to store application data in new storage services. In this sample, we have code to store data in a file system (presumably networked) and in MongoDB. While binary formatting is almost always better to use for persistent storage, this sample chooses to use JSON as the external format for one reason: it's easier to read and verify, which is a good thing in a sample. As you adopt the sample code for more realistic use, you will probably want to switch to something else than JSON as the external format. Running the sample The sample solution consists of four projects -- the storage provider library, and three test libraries, with the same client+server structure that the Hello World sample has. Edit the DevTestServerConfiguration.xml file in the Test.Client project, uncommenting the element of the file-storage provider. <!-- To test the sample storage providers, uncomment one of the following two lines: <Provider Type=\"Samples.StorageProviders.MongoDBStorage\" Name=\"TestStore\" Database=\"orleanssamples\" ConnectionString=\"mongodb://localhost:27017/\" /> --> <Provider Type=\"Samples.StorageProviders.OrleansFileStorage\" Name=\"TestStore\" RootDirectory=\".\\Samples.FileStorage\"/> Build the solution. This will move everything where it needs to go, including the MongoDB client libraries that NuGet brought in. Set the 'Test.Client' project as the startup project and hit F5. Right before it stops spitting out text, it will have this to say: Successfully started Orleans silo 'host-001' as a Primary node. We just wrote something to the persistent store. Please verify! Orleans Silo is running. Press Enter to terminate... Stop the program and open a command line windows, move to the bin\\Debug folder of the Test.Client project. There should be a folder called Samples.FileStorage there. In that folder, you should find a single file: >>dir Directory: c:\\Orleans\\Samples\\StorageProviders\\Test.Client\\bin\\Debug\\Samples.FileStorage Mode LastWriteTime Length Name ---- ------------- ------ ---- -a--- 3/26/2014 19:50 48 0000...003ffffffc0950639.PersonState If you look at the contents of that file, you should see some JSON text: >> more .\\Samples.FileStorage\\0000000000000000000000000000000003ffffffc0950639.PersonState {\"FirstName\":\"John\",\"LastName\":\"Doe\",\"Gender\":0} Now, run the program again. It's written to detect that state already exists, so this time, it will have something else to say: Successfully started Orleans silo host-001' as a Primary node. This was found in the persistent store: John, Doe, Male Orleans Silo is running. Press Enter to terminate... If you have MongoDB installed , you can repeat this procedure to test the other storage provider. Just change which XML element in the configuration file that is uncommented and ensure that the mongod.exe process is running. When you inspect the data with the MongoDB shell (mongo.exe), it should look something like this: MongoDB shell version: 2.4.6 connecting to: test > use orleanssamples switched to db orleanssamples > db.PersonState.find() { \"_id\" : ObjectId(\"533391afcf20b011307a82bf\"), \"FirstName\" : \"John\", \"LastName\" : \"Doe\", \"Gender\" : 0, \"key\" : \"0000000000000000000000000000000003ffffffc0950639\" } > Design Since both concrete storage providers use JSON, we place the serialization and deserialization code in a base class, BaseJSONStorageProvider . It contains the logic for Init() , ReadStateAsync() , WriteStateAsync() and ClearStateAsync() , the main interface methods of IStorageProvider. The logic to deal with the underlying store is delegated to a DataManager class hiearchy: IJSONStateDataManager , GrainFileStateManager , and GrainStateMongoDataManager . Their methods Delete() , Read() and Write() correspond directly to the methods defined in the storage provider classes. In this description, we won't go into the details of interacting with the file system or MongoDB via .NET, that is described in detail elsewhere. A couple of things in the code requires explanation, though. In both cases, the name of the grain type is used as name for the collection of instances; in the file storage provider case, the collection name is mapped to the folder that data is stored in, while the primary key is used to identify the actual instance; in the MongoDB case, the type name denotes a database collection, while the primary key is used as the document name. In the MongoDB case, the JSON structure is augmented during a write operation with another element, key, which contains the Orleans grain key and allows us to query for that document when reading. Care is also taken to maintain the Mongo-internal _id document identity. public Task Write(string collectionName, string key, string entityData) { var collection = GetOrCreateCollection(collectionName); var query = Query.EQ(\"key\", key); var existing = collection.FindOne(query); var doc = MongoDB.Bson.Serialization.BsonSerializer.Deserialize<BsonDocument>(entityData); doc[\"key\"] = key; if ( existing == null ) { collection.Insert(doc); } else { doc[\"_id\"] = existing[\"_id\"]; collection.Update(query, Update.Replace(doc)); } return TaskDone.Done; } On read, the _id field is removed from the JSON document that is passed back to the caller, since that is not part of the Orleans data model. public Task<string> Read(string collectionName, string key) { var collection = GetCollection(collectionName); if (collection == null) return Task.FromResult<string>(null); var query = Query.EQ(\"key\", key); var existing = collection.FindOne(query); if (existing == null) return Task.FromResult<string>(null); existing.Remove(\"_id\"); existing.Remove(\"key\"); var strwrtr = new System.IO.StringWriter(); var writer = new MongoDB.Bson.IO.JsonWriter(strwrtr, new MongoDB.Bson.IO.JsonWriterSettings()); MongoDB.Bson.Serialization.BsonSerializer.Serialize<BsonDocument>(writer, existing); return Task.FromResult(strwrtr.ToString()); }"
  },
  "1.5/Documentation/Samples-Overview/Presence-Service.html": {
    "href": "1.5/Documentation/Samples-Overview/Presence-Service.html",
    "title": "Presence Service | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Presence Service A presence service serves as the hub of many social applications, including multi-player games and chats. Its essential function is to know who is online at given point in time and alert other users of their online presence. Each logged-in player sends a \"heartbeat pulse\" at regular intervals, In this section we walk through the steps involved in defining and using a new Player grain type. The grain type we define will have one property that returns a reference to the game the player is currently in, and two methods for joining and leaving a game. We will create three separate pieces of code: the grain interface definition, the grain implementation, and a standard C# class that uses the grain. Each of these belongs in a different project, built into a different DLL: the interface needs to be available on both the \"client\" and \"server\" sides, while the implementation class should be hidden from the client, and the client class from the server. The interface project should be created using the Visual Studio \"Orleans Grain Interface Collection\" template that is included in the Orleans SDK, and the grain implementation project should be created using the Visual Studio \"Orleans Grain Class Collection\" template. The grain client project can use any standard .NET code project template, such as the standard Console Application or Class Library templates. A grain cannot be explicitly created or deleted. It always exists \"virtually\" and is activated automatically when a request is sent to it. A grain has either a GUID, string or a long integer key within the grain type. Application code creates a reference to a grain by calling the GetGrain<TGrainType>(Guid id) or GetGrain<TGrainType>(long id) or other overloads of a generic grain factory methods for a specific grain identity. The GetGrain() call is a purely local operation to create a grain reference. It does not trigger creation of a grain activation and has not impact on its life cycle. A grain activation is automatically created by the Orleans runtime upon a first request sent to the grain. A grain interface must inherit from one of the IGrainWithXKey .interfaces where X is the type of the key used. The GUID, string or long integer key of a grain can later be retrieved via the GetPrimaryKey() or GetPrimaryKeyLong() extension methods, respectively. Defining the Grain Interface A grain type is defined by an interface that inherits from one of the IGrainWithXKey marker interfaces like 'IGrainWithGuidKey' or 'IGrainWithStringKey'. All of the methods in the grain interface must return a Task or a Task<T> . The underlying type T for value Task must be serializable. Example: public interface IPlayerGrain : IGrainWithGuidKey { Task<IGameGrain> GetCurrentGame(); Task JoinGame(IGameGrain game); Task LeaveGame(IGameGrain game); } Using the Grain Factory After the grain interface has been defined, building the project originally created with the Orleans Visual Studio project template will use the Orleans-specific MSBuild targets to generate a client proxy classes corresponding to the user-defined grain interfaces and to merge this additional code back into the interface DLL. Application should use the generic grain factory class to get references to grains. Inside the grain code, the factory is available via the protected GrainFactory class member property. On the client side the factory is available via the GrainClient.GrainFactory static field. When running inside a grain the following code should be used to get the grain reference: this.GrainFactory.GetGrain<IPlayerGrain>(grainKey); When running on the Orleans client side the following code should be used to get the grain reference: GrainClient.GrainFactory.GetGrain<IPlayerGrain>(grainKey); The Implementation Class A grain type is materialized by a class that implements the grain type’s interface and inherits directly or indirectly from Orleans.Grain . The PlayerGrain grain class implements the IPlayerGrain interface. public class PlayerGrain : Grain, IPlayerGrain { private IGameGrain currentGame; // Game the player is currently in. May be null. public Task<IGameGrain> GetCurrentGameAsync() { return Task.FromResult(currentGame); } // Game grain calls this method to notify that the player has joined the game. public Task JoinGameAsync(IGameGrain game) { currentGame = game; Console.WriteLine(\"Player {0} joined game {1}\", this.GetPrimaryKey(), game.GetPrimaryKey()); return TaskDone.Done; } // Game grain calls this method to notify that the player has left the game. public Task LeaveGameAsync(IGameGrain game) { currentGame = null; Console.WriteLine(\"Player {0} left game {1}\", this.GetPrimaryKey(), game.GetPrimaryKey()); return TaskDone.Done; } }"
  },
  "1.5/Documentation/Grain-Versioning/Backward-compatibility-guidelines.html": {
    "href": "1.5/Documentation/Grain-Versioning/Backward-compatibility-guidelines.html",
    "title": "Backward compatibility guidelines | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Backward compatibility guidelines Writing backward compatible code can be hard and difficult to test. Never change the signature of existing methods Because of the way on how Orleans serializer work, you should never change the signature of existing methods. The following example is correct: [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 Task MyMethod(int arg); // New method added in V2 Task MyNewMethod(int arg, obj o); } This is not correct: [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 Task MyMethod(int arg, obj o); } NOTE : you should not do this change in your code, as it's an example of a bad practice that leads to very bad side-effects. This is an example of what can happen if you just rename the parameter names: let's say that we have the two following interface version deployed in the cluster: [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // return a - b Task<int> Substract(int a, int b); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // return y - x Task<int> Substract(int y, int x); } This methods seems identical. But if the client was called with V1, and the request is handled by a V2 activation: var grain = client.GetGrain<IMyGrain>(0); var result = await grain.Substract(5, 4); // Will return \"-1\" instead of expected \"1\" This is due to how the internal Orleans serializer works. Avoid changing existing method logic It can seems obvious, but you should be very careful when changing the body of an existing method. Unless you are fixing a bug, it is better to just add a new method if you need to modify the code. (see compatible grains ) Example: // V1 public interface MyGrain : IMyGrain { // First method Task MyMethod(int arg) { SomeSubRoutine(arg); } } // V2 public interface MyGrain : IMyGrain { // Method inherited from V1 // Do not change the body Task MyMethod(int arg) { SomeSubRoutine(arg); } // New method added in V2 Task MyNewMethod(int arg) { SomeSubRoutine(arg); NewRoutineAdded(arg); } } Do not remove methods from grain interfaces Unless you are sure that they are no longer used, you should not remove methods from the grain interface. If you want to remove methods, this should be done in 2 steps: Deploy V2 grains, with V1 method marked as Obsolete [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 [Obsolete] Task MyMethod(int arg); // New method added in V2 Task MyNewMethod(int arg, obj o); } When you are sure that no V1 calls are made (effectively V1 is no longer deployed in the running cluster), deploy V3 with V1 method removed [Version(3)] public interface IMyGrain : IGrainWithIntegerKey { // New method added in V2 Task MyNewMethod(int arg, obj o); }"
  },
  "1.5/Documentation/Deployment-and-Operations/Monitoring/Silo-Error-Code-Monitoring.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Monitoring/Silo-Error-Code-Monitoring.html",
    "title": "Silo Error Code Monitoring | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Silo Error Code Monitoring Group Log Type Log Code Values Threshold Description Azure Problems Warning or Error 100800 - 100899 Any Error or Warning Transient problems reading or writing to Azure table store will be logged as Warning. Transient read errors will automatically be retried. A final Error log message means there is a real problem connecting to Azure table storage. Membership Connectivity Problems Warning or Error 100600 - 100699 Any Error or Warning Warning logs are an early indication of network connectivity problems and/or silo restart / migration. Ping timeouts and silo-dead votes will show up as Warning messages. Silo detesting it was voted dead will show as Error message. Grain call timeouts Warning 100157 Multiple Warnings logged in short space of time Grain-call timeout problems are generally caused by temporary network connectivity issues or silo restart / reboot problems. The system should recover after a short time (depending on Liveness config settings) at which point Timeouts should clear. Ideally, monitoring for just the bulk log code 600157 variety of these warnings should be sufficient. Silo Restart / Migration Warning 100601 or 100602 Any Warning Warning printed when silo detects it was restarted on same machine {100602) or migrated to different machine (100601) Network Socket Problems Warning or Error 101000 to 101999, 100307,100015, 100016 Any Error or Warning Socket disconnects are logged as Warning messages. Problems opening sockets or during message transmission are logged as Errors. Bulk log message compaction Any 500000 or higher Message summary based on bulk message threshold settings If multiple logs of the same log code occur within a designated time interval (the default is >5 within 1 minute) then additional log messages with that log code are suppressed and output as a \"bulk\" entry with log code equal to the original log code + 500000. So for example, multiple 100157 entries will show in the logs as 5 x 100157 + 1 x 600157 log entry per minute. Grain problems Warning or Error 101534 Any Error or Warning Detection of “stuck” requests for non-reentrant grains . The error code is reported every time a request takes longer than 5x request timeout time to execute."
  },
  "1.5/Documentation/Deployment-and-Operations/Configuration-Guide/Server-Configuration.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Configuration-Guide/Server-Configuration.html",
    "title": "Server Configuration | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Server Configuration There are two key aspects of silo configuration: Connectivity: silo’s endpoints for other silos and clients Cluster membership and reliability: how silos discover each other in a deployment and detect node failures. Depending on the environment you want to run Orleans in some of these parameters may or may not be important. For example, for a single silo development environment one usually doesn’t need reliability, and all the endpoints can be localhost. The following sections detail the configuration setting for the four mentioned key aspects. Then in the scenarios section you can find the recommended combinations of the settings for the most typical deployment scenarios. Connectivity The connectivity settings define two TCP/IP endpoints: one for inter-silo communication and one for client connections, also referred to as client gateway or simply gateway. Inter-silo Endpoint <Networking Address=\" \" Port=\"11111\" /> Address: IP address or host name to use. If left empty, silo will pick the first available IPv4 address. Orleans supports IPv6 as well as IPv4. Port: TCP port to use. If left empty, silo will pick a random available port. If there is only one silo running on the machine, it is advisable to specify a port for consistency and for easy configuration of the firewall. For running multiple silos on the same machine, you can either provide each of the silos with different configuration files or leave the Port attribute empty for a random port assignment. For machines that have more than one IP address assigned to them, if you need to choose an address from a specific subnet or an IPv6 address, you can do that by adding a Subnet and PreferredFamily attributes respectively (refer to the XSD schema for exact syntax of those attributes). For local development environment, you can simply use localhost as the host name: <Networking Address=\"localhost\" Port=\"11111\" /> Client Gateway Endpoint The setting for client gateway endpoint is identical to the inter-silo endpoint except for the XML element name: <ProxyingGateway Address=\"localhost\" Port=\"30000\" /> You have to specify a port number different from the one used for the inter-silo endpoint. It is possible to configure clients to connect to the inter-silo endpoint instead of the gateway, but that requires opening a listening socket on the client (thus requires enabling incoming connections on the client machine firewall), and in general is not advisable other than for a very limited set of scenarios. Cluster Membership and Reliability Usually, a service built on Orleans is deployed on a cluster of nodes, either on dedicated hardware or in Azure. For development and basic testing, Orleans can be deployed in a single node configuration. When deployed to a cluster of nodes, Orleans internally implements a set of protocols to discover and maintain membership of Orleans silos in the cluster, including detection of node failures and automatic reconfiguration. For reliable management of cluster membership, Orleans uses Azure Table, SQL Server or Apache ZooKeeper for synchronization of nodes. The reliable membership setup requires configuring the 'SystemStore' element settings in the silo configuration file: <SystemStore SystemStoreType=\"AzureTable\" DeploymentId=\"...\" DataConnectionString=\"...\"/> or <SystemStore SystemStoreType=\"SqlServer\" DeploymentId=\"...\" DataConnectionString=\"...\"/> or <SystemStore SystemStoreType=\"ZooKeeper\" DeploymentId=\"...\" DataConnectionString=\"...\"/> DeploymentId is a unique string that defines a particular deployment. When deploying an Orleans based service to Azure it makes most sense to use the Azure deployment ID of the worker role. For development or if it’s not possible to use Azure Table, silos can be configured to use the membership grain instead. Such a configuration is unreliable as it will not survive a failure of the primary silo that hosts the membership grain. “MembershipTableGrain” is the default value of LivenessType. <Liveness LivenessType =\"MembershipTableGrain\" /> Primary Silo In a reliable deployment, one that is configured with membership using Azure Table, SQL Server or ZooKeeper, all silos are created equal, with no notion of primary or secondary silos. That is the configuration that is recommended for production that will survive a failure of any individual node or a combination of nodes. For example, Azure periodically rolls out OS patches and that causes all of the role instances to reboot eventually. For development or a non-reliable deployment when MembershipTableGrain is used, one of the silos has to be designated as Primary and has to start and initialize before other, Secondary, silos that wait for Primary to initialize before joining the cluster. In case of a failure of the Primary node, the whole deployment stops working properly and has to be restarted. Primary is designated in the configuration file with the following setting within the Globals section. <SeedNode Address=\"<host name or IP address of the primary node>\" Port=\"11111\" /> Here is an example how to configure and launch Orleans silo hosted inside worker-role. This is a reference only example and SHOULD NOT be used AS-IS - you may need to fine-tune client parameters for your specific environment. var dataConnection = \"DefaultEndpointsProtocol=https;AccountName=MYACCOUNTNAME;AccountKey=MYACCOUNTKEY\"; var config = new ClusterConfiguration { Globals = { DeploymentId = RoleEnvironment.DeploymentId, ResponseTimeout = TimeSpan.FromSeconds(30), DataConnectionString = dataConnection, LivenessType = GlobalConfiguration.LivenessProviderType.AzureTable, ReminderServiceType = GlobalConfiguration.ReminderServiceProviderType.AzureTable, }, Defaults = { PropagateActivityId = true, // Tracing DefaultTraceLevel = Severity.Info, TraceToConsole = false, TraceFilePattern = @\"Silo_{0}-{1}.log\", //TraceFilePattern = \"false\", // Set it to false or none to disable file tracing, effectively it sets config.Defaults.TraceFileName = null; TraceLevelOverrides = { Tuple.Create(\"ComponentName\", Severity.Warning), } } }; // Register bootstrap provider class config.Globals.RegisterBootstrapProvider<AutoStartBootstrapProvider>(\"MyAutoStartBootstrapProvider\"); // Add Storage Providers config.Globals.RegisterStorageProvider<MemoryStorage>(\"MemoryStore\"); config.Globals.RegisterStorageProvider<AzureTableStorage>(\"PubSubStore\", new Dictionary<string, string> { { \"DeleteStateOnClear\", \"true\" }, //{ \"UseJsonFormat\", \"true\" }, { \"DataConnectionString\", dataConnection } }); config.Globals.RegisterStorageProvider<AzureTableStorage>(\"AzureTable\", new Dictionary<string, string> { { \"DeleteStateOnClear\", \"true\" }, { \"DataConnectionString\", dataConnection } }); config.Globals.RegisterStorageProvider<AzureTableStorage>(\"DataStorage\", new Dictionary<string, string> { { \"DeleteStateOnClear\", \"true\" }, { \"DataConnectionString\", dataConnection } }); config.Globals.RegisterStorageProvider<BlobStorageProvider>(\"BlobStorage\", new Dictionary<string, string> { { \"DeleteStateOnClear\", \"true\" }, { \"ContainerName\", \"grainstate\" }, { \"DataConnectionString\", dataConnection } }); // Add Stream Providers config.Globals.RegisterStreamProvider<AzureQueueStreamProvider>(\"AzureQueueStreams\", new Dictionary<string, string> { { \"PubSubType\", \"ExplicitGrainBasedAndImplicit\" }, { \"DeploymentId\", \"orleans-streams\" }, { \"NumQueues\", \"4\" }, { \"GetQueueMessagesTimerPeriod\", \"100ms\" }, { \"DataConnectionString\", dataConnection } }); try { _orleansAzureSilo = new AzureSilo(); var ok = _orleansAzureSilo.Start(config, config.Globals.DeploymentId, config.Globals.DataConnectionString); _orleansAzureSilo.Run(); // Call will block until silo is shutdown } catch (Exception exc) { //Log \"Error when starting Silo\" }"
  },
  "1.5/Documentation/Deployment-and-Operations/Configuration-Guide/Client-Configuration.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Configuration-Guide/Client-Configuration.html",
    "title": "Client Configuration | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Client Configuration The key parameter that has to be configured for a client is the silo’s client gateway endpoint(s) to connect to. There are two ways to do that: manually configure one or more gateway endpoints or point the client to the Azure Table used by silos’ cluster membership. In the latter case the client automatically discovers what silos with client gateways enabled are available within the deployment, and adjusts its connections to the gateways as they join or leave the cluster. This option is reliable and recommended for production deployment. Fixed Gateway Configuration A fixed set of gateways is specified in the ClientConfiguration.xml with one or more Gateway nodes: <ClientConfiguration xmlns=\"urn:orleans\"> <Gateway Address=\"gateway1\" Port=\"30000\"/> <Gateway Address=\"gateway2\" Port=\"30000\"/> <Gateway Address=\"gateway3\" Port=\"30000\"/> </ClientConfiguration> One gateway is generally enough. Multiple gateway connections help increase throughput and reliability of the system. Gateway Configuration Based on Cluster Membership To configure the client to automatically find gateways from the silo cluster membership table, you need to specify the Azure Table or SQL Server connection string and the target deployment ID. <ClientConfiguration xmlns=\"urn:orleans\"> <SystemStore SystemStoreType=\"AzureTable\" DeploymentId=\"target deployment ID\" DataConnectionString=\"Azure storage connection string\"/> </ClientConfiguration> or <ClientConfiguration xmlns=\"urn:orleans\"> <SystemStore SystemStoreType=\"SqlServer\" DeploymentId=\"target deployment ID\" DataConnectionString=\"SQL connection string\"/> </ClientConfiguration> or <ClientConfiguration xmlns=\"urn:orleans\"> <SystemStore SystemStoreType=\"ZooKeeper\" DeploymentId=\"target deployment ID\" DataConnectionString=\"ZooKeeper connection string\"/> </ClientConfiguration> Local Silo For the local development/test configuration that uses a local silo, the client gateway should be configured to 'localhost.' <ClientConfiguration xmlns=\"urn:orleans\"> <Gateway Address=\"localhost\" Port=\"30000\"/> </ClientConfiguration> Web Role Client in Azure When the client is a web role running inside the same Azure deployment as the silo worker roles, all gateway address information is read from the OrleansSiloInstances table when OrleansAzureClient.Initialize() is called. The Azure storage connection string used to find the correct OrleansSiloInstances table is specified in the \"DataConnectionString\" setting defined in the service configuration for the deployment & role. <ServiceConfiguration ...> <Role name=\"WebRole\"> ... <ConfigurationSettings> <Setting name=\"DataConnectionString\" value=\"DefaultEndpointsProtocol=https;AccountName=MYACCOUNTNAME;AccountKey=MYACCOUNTKEY\" /> </ConfigurationSettings> </Role> ... </ServiceConfiguration> Both the silo worker roles and web client roles need to be use the same Azure storage account in order to successfully discover each other successfully. When using OrleansAzureClient.Initialize() and OrleansSiloInstances table for gateway address discovery, no additional gateway address info in required in the client config file. Typically the ClientConfiguration.xml file will only contain some minimal debug / tracing configuration settings, although even that is not required. <ClientConfiguration xmlns=\"urn:orleans\"> <Tracing DefaultTraceLevel=\"Info\" > <TraceLevelOverride LogPrefix=\"Application\" TraceLevel=\"Info\" /> </Tracing> </ClientConfiguration> Code-based client configuration. This is a reference only example and SHOULD NOT be used AS-IS - you may need to fine-tune client parameters for your specific environment. var dataConnection = \"DefaultEndpointsProtocol=https;AccountName=MYACCOUNTNAME;AccountKey=MYACCOUNTKEY\"; var config = new ClientConfiguration { // Some top level features GatewayProvider = ClientConfiguration.GatewayProviderType.AzureTable, ResponseTimeout = TimeSpan.FromSeconds(30), DeploymentId = RoleEnvironment.DeploymentId, DataConnectionString = dataConnection, PropagateActivityId = true, // Tracing DefaultTraceLevel = Severity.Info, TraceToConsole = false, TraceFilePattern = @\"Client_{0}-{1}.log\", //TraceFilePattern = \"false\", // Set it to false or none to disable file tracing, effectively it sets config.Defaults.TraceFileName = null; TraceLevelOverrides = { Tuple.Create(\"ComponentName\", Severity.Warning), } }; config.RegisterStreamProvider<AzureQueueStreamProvider>(\"AzureQueueStreams\", new Dictionary<string, string> { { \"PubSubType\", \"ExplicitGrainBasedAndImplicit\" }, { \"DeploymentId\", \"orleans-streams\" }, // This will be a prefix name of your Queues - so be careful and use string that is valid for queue name { \"NumQueues\", \"4\" }, { \"GetQueueMessagesTimerPeriod\", \"100ms\" }, { \"DataConnectionString\", dataConnection } }); config.RegisterStreamProvider<SimpleMessageStreamProvider>(\"SimpleMessagingStreams\", new Dictionary<string, string> { { \"PubSubType\", \"ExplicitGrainBasedAndImplicit\" } }); IClusterClient client = null; while (true) { try { // Build a client and then connect it to the cluster. client = new ClientBuilder() .UseConfiguration(config) .ConfigureServices( services => { // Services can be provided to the client here. These services are made // available via dependency injection. // ConfigureServices can be called multiple times for a single // ClientBuilder instance. }) .Build(); // Connect the client to the cluster. Once connection succeeds, the client will // maintain the connection, automatically reconnecting as necessary. await client.Connect().ConfigureAwait(false); break; } catch (Exception exception) { // If the connection attempt fails, the client instance must be disposed. client?.Dispose(); // TODO: Log the exception. // TODO: Add a counter to break up an infinite cycle (circuit breaker pattern). await Task.Delay(TimeSpan.FromSeconds(5)); } } // Use the client. // Note that clients can be shared between threads and are typically long-lived. var user client.GetGrain<IUserGrain>(\"leeroy77jenkins@battle.net\"); Console.WriteLine(await user.GetProfile());"
  },
  "1.5/Documentation/Deployment-and-Operations/Heterogeneous-Silos.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Heterogeneous-Silos.html",
    "title": "Heterogeneous silos | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Heterogeneous silos Overview On a given cluster, silos can support a different set of grain types: In this example the cluster support grain of type A , B , C , D , E : Grain types A and B can be placed on Silo 1 and 2. Grain type C can be placed on Silo 1, 2 or 3. Grain type D can be only placed on Silo 3 Grain Type E can be only placed on Silo 4. All silos should reference interfaces of all grain types of the cluster, but grain classes should only be referenced by the silos that will host them. The client does not know which silo support a given Grain Type. A given Grain Type implementation must be the same on each silo that support it. The following scenario is NOT valid: On Silo 1 and 2: public class C: Grain, IMyGrainInterface { public Task SomeMethod() { … } } On Silo 3 public class C: Grain, IMyGrainInterface, IMyOtherGrainInterface { public Task SomeMethod() { … } public Task SomeOtherMethod() { … } } Configuration No configuration is needed, you can deploy different binaries on each silo in your cluster. However, if necessary, you can change the interval that silos check for changes in types supported in ClusterConfig.Globals.TypeMapRefreshInterval . For testing purpose, you can use the property ExcludedGrainTypes in NodeConfiguration . In code based config you can find it in ClusterConfig.Defaults.ExcludedGrainTypes , which is a list names of the types you want to exclude. Limitations Connected clients will not be notified if the set of supported Grain Types changed. In the previous example: If Silo 4 leave the cluster, the client will still try to make calls to grain of type E . It will fail at runtime with a OrleansException. If the client was connected to the cluster before Silo 4 joined it, the client will not be able to make calls to grain of type E . It will fail will a ArgumentException Stateless grains is not supported: all silos in the cluster must support the same set of stateless grains."
  },
  "1.5/Documentation/Samples-Overview/GPS-Tracker.html": {
    "href": "1.5/Documentation/Samples-Overview/GPS-Tracker.html",
    "title": "GPS Tracker | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . GPS Tracker A sample application to show how Orleans could be used in conjunction with SignalR to monitor the position of a number of GPS enabled devices, and report these to a web browser. In order to run this sample, you need a Bing Maps API key. The key is used by the GPSTracker.Web project, in Views\\Home\\Index.cshtml. Get a Bing Maps Key Running the Sample Running the sample locally: Open the GPSTracker.sln file in Visual Studio 2013, and build the solution. Start the local Orleans Silo by running the Host project of the solution. In Visual Studio, right click on the GPSTracker.Web project, and click Set as StartUp Project . Press F5 to start GPSTracker.Web web application. Your browser should open on a map of San Francisco. In a command window, navigate to the GPSTracker.FakeDeviceGateway\\bin\\Debug directory, and run the 'GPSTracker.FakeDeviceGateway.exe' program. Pushpins should appear on the map, and move around. Blue ones are moving slow, orange faster. How it Works The GPSTracker.FakeDeviceGateway.exe program simulates data generated from 20 GPS devices. It randomly alters their speed and heading to simulate the devices moving within rectangular boundaries. It sends the position data to Orleans once a second. In Orleans, each device is represented by a Device grain. The grain records the previous position of the device, and can therefore calculate the speed of the device. If the devices has moved, the 'Device' grain forwards position and speed to a PushNotification grain. This 'PushNotification' grain maintains a C# SignalR client, which connects to a SignalR hub hosted in the GPSTracker.Web project. This allows the grain to 'push' messages to the hub without the need for polling the Orleans API. The grain will batch messages together to improve network performance. The GPSTracker.Web application forwards all messages to connected web browsers using SignalR. JavaScript running in the browser positions the pins using a Bing Maps control. If the pin has a low velocity it colors it blue, otherwise orange. Advantages of using Orleans This sample is designed to show Orleans as a low-latency messaging system. Orleans is able to hold state for each device in memory (of which there may be many), allowing a quick calculation to be performed (calculating velocity) based on previous state. The grain in Orleans can also decide whether the message is worthy of forwarding downstream (has the device moved?) and can therefore filter out unnecessary messages and reduce noise. The sample also illustrates how SignalR may be used from inside a grain to allow 'push' messaging directly to clients. In a real life scenario you would probably not forward all messages to the browser, and would filter based on groups or device type."
  },
  "Documentation/deployment/service_fabric_hosting.html": {
    "href": "Documentation/deployment/service_fabric_hosting.html",
    "title": "Service Fabric Hosting | Microsoft Orleans Documentation",
    "keywords": "Service Fabric Hosting Orleans can be hosted on Service Fabric using the Microsoft.Orleans.Hosting.ServiceFabric package. Silos should be hosted as unpartitioned, stateless services since Orleans manages distribution of grains itself using fine-grained, dynamic distribution. Other hosting options (partitioned, stateful) are currently untested and unsupported. A sample which demonstrates hosting on Service Fabric is available at Samples/2.0/ServiceFabric . Hosting support is available in the Microsoft.Orleans.Hosting.ServiceFabric package. It allows an Orleans Silo to run as a Service Fabric ICommunicationListener . The Silo lifecycle follows the typical communication listener lifecycle: it is initialized via the ICommunicationListener.OpenAsync method and is gracefully terminated via the ICommunicationListener.CloseAsync method or abruptly terminated via the ICommunicationListener.Abort method. OrleansCommunicationListener provides the ICommunicationListener implementation. The recommended approach is to create the communication listener using OrleansServiceListener.CreateStateless(Action<StatelessServiceContext, ISiloHostBuilder> configure) in the Orleans.Hosting.ServiceFabric namespace. Each time the communication listener is opened, the configure delegate passed to CreateStateless is invoked to configure the new Silo. Example: Configuring Service Fabric hosting The following example demonstrates a Service Fabric StatelessService class which hosts an Orleans silo. The full sample can be found in the Samples/2.0/ServiceFabric directory of the Orleans repository. /// <summary> /// An instance of this class is created for each service instance by the Service Fabric runtime. /// </summary> internal sealed class StatelessCalculatorService : StatelessService { public StatelessCalculatorService(StatelessServiceContext context) : base(context) { } /// <summary> /// Optional override to create listeners (e.g., TCP, HTTP) for this service replica to handle /// client or user requests. /// </summary> /// <returns>A collection of listeners.</returns> protected override IEnumerable<ServiceInstanceListener> CreateServiceInstanceListeners() { // Listeners can be opened and closed multiple times over the lifetime of a service instance. // A new Orleans silo will be both created and initialized each time the listener is opened // and will be shutdown when the listener is closed. var listener = OrleansServiceListener.CreateStateless( (fabricServiceContext, builder) => { builder.Configure<ClusterOptions>(options => { // The service id is unique for the entire service over its lifetime. This is // used to identify persistent state such as reminders and grain state. options.ServiceId = fabricServiceContext.ServiceName.ToString(); // The cluster id identifies a deployed cluster. Since Service Fabric uses rolling // upgrades, the cluster id can be kept constant. This is used to identify which // silos belong to a particular cluster. options.ClusterId = \"development\"; }); // Configure clustering. Other clustering providers are available, but for the purpose // of this sample we will use Azure Storage. // TODO: Pick a clustering provider and configure it here. builder.UseAzureStorageClustering( options => options.ConnectionString = \"UseDevelopmentStorage=true\"); // Optional: configure logging. builder.ConfigureLogging(logging => logging.AddDebug()); builder.AddStartupTask<StartupTask>(); // Service Fabric manages port allocations, so update the configuration using those // ports. // Gather configuration from Service Fabric. var activation = fabricServiceContext.CodePackageActivationContext; var endpoints = activation.GetEndpoints(); // These endpoint names correspond to TCP endpoints specified in ServiceManifest.xml var siloEndpoint = endpoints[\"OrleansSiloEndpoint\"]; var gatewayEndpoint = endpoints[\"OrleansProxyEndpoint\"]; var hostname = fabricServiceContext.NodeContext.IPAddressOrFQDN; builder.ConfigureEndpoints(hostname, siloEndpoint.Port, gatewayEndpoint.Port); // Add your application assemblies. builder.ConfigureApplicationParts(parts => { parts.AddApplicationPart(typeof(CalculatorGrain).Assembly).WithReferences(); // Alternative: add all loadable assemblies in the current base path // (see AppDomain.BaseDirectory). parts.AddFromApplicationBaseDirectory(); }); }); return new[] { listener }; } /// <summary> /// This is the main entry point for your service instance. /// </summary> /// <param name=\"cancellationToken\"> /// Canceled when Service Fabric needs to shut down this service instance. /// </param> protected override async Task RunAsync(CancellationToken cancellationToken) { while (true) { cancellationToken.ThrowIfCancellationRequested(); await Task.Delay(TimeSpan.FromSeconds(10), cancellationToken); } } }"
  },
  "Documentation/deployment/consul_deployment.html": {
    "href": "Documentation/deployment/consul_deployment.html",
    "title": "Using Consul as a Membership Provider | Microsoft Orleans Documentation",
    "keywords": "Using Consul as a Membership Provider Introduction to Consul Consul is a distributed, highly available and datacenter-aware service discovery platform which includes simple service registration, health checking, failure detection and key/value storage. It is built on the premise that every node in the datacenter is running a Consul agent which is either acting as a server or client which communicate via a scalable gossip protocol. There is a very detailed overview of Consul including comparisons with similar solutions here . Consul is written in GO and is open source ; compiled downloads are available for Mac OS X, FreeBSD, Linux, Solaris and Windows Why Choose Consul? As an Orleans Membership Provider , Consul is a good choice when you need to deliver an on-premise solution which does not require your potential customers to have existing infrastructure and a co-operative IT provider. Consul is a very lightweight single executable, has no dependencies and as such can easily be built into your own middleware solution. And when Consul is already your solution for discovering, checking and maintaining your microservices, it makes sense to fully integrate with Orleans membership for simplicity and ease of operation. We therefore implemented a membership table in Consul (also known as \"Orleans Custom System Store\"), which fully integrates with Orleans's Cluster Management . Setting up Consul There is very extensive documentation available on Consul.io about setting up a stable Consul cluster and it doesn't make sense to repeat that here; however for your convenience we include this guide so you can very quickly get Orleans running with a standalone Consul agent. 1) Create a folder to install Consul into, e.g. C:\\Consul 2) Create a subfolder: C:\\Consul\\Data (Consul will not create this if it doesn't exist) 3) Download and unzip Consul.exe into C:\\Consul\\ 4) Open a command prompt at C:\\Consul\\ 5) Enter Consul.exe agent -server -bootstrap -data-dir \"C:\\Consul\\Data\" -client=0.0.0.0 agent Instructs Consul to run the agent process that hosts the services. Without this the Consul process will attempt to use RPC to configure a running agent. -server Defines the agent as a server and not a client (A Consul client is an agent that hosts all the services and data, but does not have voting rights to decide, and cannot become, the cluster leader -bootstrap The first (and only the first!) node in a cluster must be bootstrapped so that it assumes the cluster leadership. -data-dir [path] Specifies the path where all Consul data is stored, including the cluster membership table -client=0.0.0.0 Informs Consul which IP to open the service on. There are many other parameters, and the option to use a json configuration file. Please consult the Consul documentation for a full listing of the options. 6) Verify that Consul is running and ready to accept membership requests from Orleans by opening the services endpoint in your browser. Configuration of Orleans Server There is currently a known issue with the \"Custom\" membership provider OrleansConfiguration.xml configuration file that will fail to parse correctly. For this reason you have to provide a placeholder SystemStore in the xml and then configure the provider in code before starting the Silo. OrleansConfiguration.xml <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <SystemStore SystemStoreType=\"None\" DataConnectionString=\"http://localhost:8500\" DeploymentId=\"MyOrleansDeployment\" /> </Globals> <Defaults> <Networking Address=\"localhost\" Port=\"22222\" /> <ProxyingGateway Address=\"localhost\" Port=\"30000\" /> </Defaults> </OrleansConfiguration> Code public void Start(ClusterConfiguration config) { _siloHost = new SiloHost(System.Net.Dns.GetHostName(), config); _siloHost.Config.Globals.LivenessType = GlobalConfiguration.LivenessProviderType.Custom; _siloHost.Config.Globals.MembershipTableAssembly = \"OrleansConsulUtils\"; _siloHost.Config.Globals.ReminderServiceType = GlobalConfiguration.ReminderServiceProviderType.Disabled; _siloHost.InitializeOrleansSilo(); var startedok = _siloHost.StartOrleansSilo(); if (!startedok) throw new SystemException(String.Format(\"Failed to start Orleans silo '{0}' as a {1} node\", _siloHost.Name, _siloHost.Type)); Log.Information(\"Orleans Silo is running.\\n\"); } Alternatively you could configure the silo entirely in code. Client The client configuration is much simpler ClientConfiguration.xml <ClientConfiguration xmlns=\"urn:orleans\"> <SystemStore SystemStoreType=\"Custom\" CustomGatewayProviderAssemblyName=\"OrleansConsulUtils\" DataConnectionString=\"http://192.168.1.26:8500\" DeploymentId=\"MyOrleansDeployment\" /> </ClientConfiguration> Client SDK If you are interested in using Consul for your own service discovery there are Client SDKs for most popular languages. Implementation Detail The Membership Table Provider makes use of Consul's Key/Value store functionality with CAS. When each Silo starts it registers two KV entries, one which contains the Silo details and one which holds the last time the Silo reported it was alive (the latter refers to diagnostics \"I am alive\" entries and not to failure detection hearbeats which are sent directly between the silos and are not written into the table). All writes to the table are performed with CAS to provide concurrency control, as necessitated by Orleans's Cluster Management Protocol . Once the Silo is running you can view these entries in your web browser here , this will display something like: [ \"orleans/MyOrleansDeployment/192.168.1.26:11111@191780753\", \"orleans/MyOrleansDeployment/192.168.1.26:11111@191780753/iamalive\" ] You will notice that the keys are prefixed with \"orleans/\" this is hard coded in the provider and is intended to avoid key space collision with other users of Consul. Each of these keys can be read by appending their key name (sans quotes of course) to the Consul KV root . Doing so will present you with the following: [ { \"LockIndex\": 0, \"Key\": \"orleans/MyOrleansDeployment/192.168.1.26:22222@191780753\", \"Flags\": 0, \"Value\": \"[BASE64 UTF8 Encoded String]\", \"CreateIndex\": 10, \"ModifyIndex\": 12 } ] Decoding the string will give you the actual Orleans Membership data: http://localhost:8500/v1/KV/orleans/MyOrleansDeployment/[SiloAddress] { \"Hostname\": \"[YOUR_MACHINE_NAME]\", \"ProxyPort\": 22222, \"StartTime\": \"2016-01-29T16:25:54.9538838Z\", \"Status\": 3, \"SuspectingSilos\": [] } http://localhost:8500/v1/KV/orleans/MyOrleansDeployment/[SiloAddress]/IAmAlive \"2016-01-29T16:35:58.9193803Z\" When the Clients connect, they read the KVs for all silos in the cluster in one HTTP GET by using the uri http://192.168.1.26:8500/v1/KV/orleans/MyOrleansDeployment/?recurse . Limitations Orleans Extended Membership Protocol (Table Version & ETag) Consul KV currrently does not currently support atomic updates. Therefore, the Orleans Consul Membership Provider only implements the the Orleans Basic Membership Protocol, as described here and does not support the Extended Membership Protocol. This Extended protocol was introduced as an additional, but not essential, silo connectivity validation and as a foundation to functionality that has not yet been implemented. Providing your infrastructure is correctly configured you will not experience any detrimental effect of the lack of support. Multiple Datacenters The Key Value Pairs in Consul are not currently replicated between Consul datacenters. There is a separate project to address this but it has not yet been proven to support Orleans. When running on Windows When Consul starts on Windows it logs the following message: ==> WARNING: Windows is not recommended as a Consul server. Do not use in production. This is displayed simply due to lack of focus on testing when running in a Windows environment and not because of any actual known issues. Read the discussion here before deciding if Consul is the right choice for you. Potential Future Enhanecements 1) Prove that the Consul KV replication project is able to support an Orleans cluster in a WAN environment between multiple Consul datacenters. 2) Implement the Reminder Table in Consul. 3) Implement the Extended Membership Protocol. The team behind Consul does plan on implementing atomic operations, once this functionality is available it will be possible to remove the limitations in the provider."
  },
  "1.5/Documentation/Grain-Versioning/Grain-versioning.html": {
    "href": "1.5/Documentation/Grain-Versioning/Grain-versioning.html",
    "title": "Grain versioning | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Grain versioning Warning This page describes how to use grain interface versioning. The versioning of Grain state is out of scope. Overview On a given cluster, silos can support different versions of a grain type. In this example the client and Silo{1,2,3} were compiled with grain interface A version 1. Silo 4 was compiled with A version 2. Limitations: No versioning on stateless worker Streaming interfaces are not versioned Enable versioning By default, grains are not versioned. You can version grain by using the VersionAttribute on the grain interface: [Version(X)] public interface IVersionUpgradeTestGrain : IGrainWithIntegerKey {} Where X is the version number of the grain interface, which is typically monotonically increasing. Grain version compatibility and placement When a call from a versioned grain arrive in a cluster: If no activation exists, a compatible activation will be created If an activation exists: If the current one is not compatible, it will be deactivated and new compatible will be created (see version selector strategy ) If the current one is compatible (see compatible grains ), the call will be handled normally. By default: All versioned grains are supposed to be backward-compatible only (see backward compatibility guidelines and compatible grains ). That means that a v1 grain can make calls to a v2 grain, but a v2 grain cannot call a v1. This default behavior can be changed with GlobalConfiguration.DefaultCompatibilityStrategy When multiple versions exist in the cluster, the new activation will be randomly placed on a compatible silo. This default behavior can be changed with GlobalConfiguration.DefaultVersionSelectorStrategy"
  },
  "1.5/Documentation/Grain-Versioning/Deployment.html": {
    "href": "1.5/Documentation/Grain-Versioning/Deployment.html",
    "title": "Deploy new version of grains | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Deploy new version of grains Rolling upgrade In this method you deploy newer silos directly on your environment. This is the simplest method, but it can be difficult to interrupt an on-going deployment and to rollback. Recommended configuration: DefaultCompatibilityStrategy set to BackwardCompatible DefaultVersionSelectorStrategy set to AllCompatibleVersions When using this configuration, \"old\" clients will be able to talk to activations on both versions of silos. Newer clients and silos will only trigger new activations on newer silos. Using a staging environment In this method you will need a second environment (Staging environment), on which you will deploy newer silos before stopping the Production environment. The Production and the Staging silos and clients will be part of the same cluster . It is important that silos from both environment can talk to each other. Recommended configuration: DefaultCompatibilityStrategy set to BackwardCompatible DefaultVersionSelectorStrategy set to MinimumVersion Suggested deployment steps: \"V1\" silos and clients are deployed and are running in the Production slot. \"V2\" silos and clients begin to start in the Staging slot. They will join the same cluster as the Production slot. No \"V2\" activations will be created so far. Once the deployment in the Staging slot is finished, the developper can redirect some traffic on the V2 clients (smoke tests, targeted beta users, ect.). This will create V2 activations, but since Grains are backward compatibles and that all silos are in the same cluster, no duplicate activations will be created. If the validation is successful, proceed to VIP swap. If not, you can safely shutdown the Staging cluster: existing V2 activations will be destroyed and V1 activations will be created if needed. V1 activations will naturally \"migrate\" to V2 silos eventually. You can safely shutdown V1 silos. Warning Remember that stateless workers are not versioned and that streaming agents will also start in the staging environment."
  },
  "1.5/Documentation/Grain-Versioning/Compatible-grains.html": {
    "href": "1.5/Documentation/Grain-Versioning/Compatible-grains.html",
    "title": "Compatible grains | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Compatible grains When an existing grain activation is about to process a request, the runtime will check if the version in the request and the actual version of the grain are compatible. Orleans does not infer at runtime which policy to use , The default behavior to determine if two versions are compatible is determined by GlobalConfiguration.CompatibilityStrategy Backward compatible (default) Definition A grain interface version Vn can be be backward compatible with Vm if: The name of the interface didn't change (or the overridden typecode) All public methods present in the Vm version are in the Vn version. It is important that the signatures of the methods inherited from Vm are not modified : since Orleans use an internal built-in serializer, modifying/renaming a field (even private) can make the serialization to break. Since Vn can have added methods compared to Vm, Vm is not compatible with Vn. Example If in the cluster we have two versions of a given interface, V1 and V2 and that V2 is backward compatible with V1: If the current activation is a V2 and the requested version is V1, the current activation will be able to process the request normally If the current activation is a V1 and the requested version is V2, the current activation will be deactivated and a new activation compatible with V2 will be created (see version selector strategy ). Fully compatible Definition A grain interface version Vn can be fully compatible with Vm if: Vn is backward compatible with Vm No public methods where added in the Vn version If Vn is fully compatible with Vm then Vm is also fully compatible with Vn. Example If in the cluster we have two versions of a given interface, V1 and V2 and that V2 is fully compatible with V1: If the current activation is a V2 and the requested version is V1, the current activation will be able to process the request normally If the current activation is a V2 and the requested version is V1, the current activation will also be able to process the request normally"
  },
  "1.5/Documentation/Getting-Started-With-Orleans/Running-the-Application.html": {
    "href": "1.5/Documentation/Getting-Started-With-Orleans/Running-the-Application.html",
    "title": "Running the Application | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Orleans Application As was illustrated in the previous topic , a typical Orleans application consists of a cluster of server processes (silos) where grains live, and a set of client processes, usually web servers, that receive external requests, turn them into grain method calls, and return results back. Hence, the first thing one needs to do to run an Orleans application is to start a cluster of silos. For testing purposes, a cluster can consist of a single silo. For a reliable production deployment, we obviously want more than one silos in a cluster for fault tolerance and scale. Once the cluster is running, we can start one or more client processes that connect to the cluster and can send requests to the grains. Clients connect to a special TCP endpoint on silos - gateway. By default, every silo in a cluster has a client gateway enabled. So clients can connect to all silos in parallel for better performance and resilience. Configuring and Starting a Silo A silo is configured programmatically via a ClusterConfiguration object. It can be instantiated and populated directly, load settings from a file, or created with several available helper methods for different deployment environments. For local testing, the easiest way to go is to use ClusterConfiguration.LocalhostPrimarySilo() helper method. The configuration object is then passed to a new instance of SiloHost class, that can be initialized and started after that. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for hosting a silo. Add the Microsoft.Orleans.Server NuGet meta-package to the project. PM> Install-Package Microsoft.Orleans.Server Here is an example of how a local silo can be started: var siloConfig = ClusterConfiguration.LocalhostPrimarySilo(); var silo = new SiloHost(\"Test Silo\", siloConfig); silo.InitializeOrleansSilo(); silo.StartOrleansSilo(); Console.WriteLine(\"Press Enter to close.\"); // wait here Console.ReadLine(); // shut the silo down after we are done. silo.ShutdownOrleansSilo(); Configuring and Connecting a Client Client for connecting to a cluster of silos and sending requests to grains is configured programmatically via a ClientConfiguration object and a ClientBuilder . ClientConfiguration object can be instantiated and populated directly, load settings from a file, or created with several available helper methods for different deployment environments. For local testing, the easiest way to go is to use ClientConfiguration.LocalhostSilo() helper method. The configuration object is then passed to a new instance of ClientBuilder class. ClientBuilder exposes more methods for configuring additional client features. After that Build method of the ClientBuilder object is called to get an implementation of IClusterClient interface. Finally, we call Connect() method on the returned object to connect to the cluster. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for running a client or reuse the console application project you created for hosting a silo. Add the Microsoft.Orleans.Client NuGet meta-package to the project. PM> Install-Package Microsoft.Orleans.Client Here is an example of how a client can connect to a local silo: var config = ClientConfiguration.LocalhostSilo(); var builder = new ClientBuilder().UseConfiguration(config). var client = builder.Build(); await client.Connect(); Production Configurations The configuration examples we used here are for testing silos and clients running on the same machine as localhost . In production, silos and clients usually run on different servers and are configured with one of the reliable cluster configuration options. You can find more about that in the Configuration Guide and in the description of Cluster Management . Next Debugging"
  },
  "1.5/Documentation/Event-Sourcing/Configuration.html": {
    "href": "1.5/Documentation/Event-Sourcing/Configuration.html",
    "title": "Configuration | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Configuration Configuring Project References Grain Interfaces As before, interfaces depend only on the Microsoft.Orleans.Core package, because the grain interface is independent of the implementation. Grain Implementations JournaledGrains need to derive from JournaledGrain<S,E> or JournaledGrain<S> , which is defined in the Microsoft.Orleans.EventSourcing package. Log-Consistency Providers We currently include three log-consistency providers (for state storage, log storage, and custom storage). All three are contained in the Microsoft.Orleans.EventSourcing package as well. Therefore, all Journaled Grains already have access to those. For a description of what these providers do and how they differ, see Included Log-Consistency Providers . Cluster Configuration Log-consistency providers are configured just like any other Orleans providers. For example, to include all three providers (of course, you probably won't need all three), add this to the <Globals> element of the configuration file: <LogConsistencyProviders> <Provider Type=\"Orleans.EventSourcing.StateStorage.LogConsistencyProvider\" Name=\"StateStorage\" /> <Provider Type=\"Orleans.EventSourcing.LogStorage.LogConsistencyProvider\" Name=\"LogStorage\" /> <Provider Type=\"Orleans.EventSourcing.CustomStorage.LogConsistencyProvider\" Name=\"CustomStorage\" /> </LogConsistencyProviders> The same can be achieved programmatically. Assuming the project contains the Microsoft.Orleans.EventSourcing package, and config is a ClusterConfiguration object: using Orleans.Runtime.Configuration; // pick up the necessary extension methods config.AddLogStorageBasedLogConsistencyProvider(\"LogStorage\"); config.AddStateStorageBasedLogConsistencyProvider(\"StateStorage\"); config.AddCustomStorageBasedLogConsistencyProvider(\"CustomStorage\"); Grain Class Attributes Each journaled grain class must have a LogConsistencyProvider attribute to specify the log-consistency provider. Some providers additionally require a StorageProvider attribute. LogConsistencyProvider Attributes To specify the log-consistency provider, add a [LogConsistencyProvider(ProviderName=...)] attribute to the grain class, and give the name of the provider as configured by the Cluster Configuration. For example: [LogConsistencyProvider(ProviderName = \"CustomStorage\")] public class ChatGrain : JournaledGrain<XDocument, IChatEvent>, IChatGrain, ICustomStorage { ... } StorageProvider Attributes Some log-consistency providers (including LogStorage and StateStorage ) use a standard StorageProvider to communicate with storage. This provider is specified using a separate StorageProvider attribute, as follows: [LogConsistencyProvider(ProviderName = \"LogStorage\")] [StorageProvider(ProviderName = \"AzureBlobStorage\")] public class ChatGrain : JournaledGrain<XDocument, IChatEvent>, IChatGrain { ... } Default Providers It is possible to omit the LogConsistencyProvider and/or the StorageProvider attributes, if a default is specified in the configuration. This is done by using the special name Default for the respective provider. For example: <LogConsistencyProviders> <Provider Type=\"Orleans.EventSourcing.LogStorage.LogConsistencyProvider\" Name=\"Default\" /> </LogConsistencyProviders> <StorageProviders> <Provider Type=\"Orleans.Storage.MemoryStorage\" Name=\"Default\" /> </StorageProviders>"
  },
  "1.5/Documentation/Deployment-and-Operations/Monitoring/Client-Error-Code-Monitoring.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Monitoring/Client-Error-Code-Monitoring.html",
    "title": "Client Error Code Monitoring | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Client Error Code Monitoring Group Log Type Log Code Values Threshold Description Azure Problems Warning or Error 100800 - 100899 Any Error or Warning Transient problems reading or writing to Azure table store will be logged as Warning. Transient read errors will automatically be retried. A final Error log message means there is a real problem connecting to Azure table storage. Gateway connectivity problems Warning or Error 100901 - 100904, 100912, 100913, 100921, 100923, 100158, 100161, 100178, , 101313 Any Error or Warning Problems connecting to gateways. No active gateways in the Azure table. Connection to active gateway lost. Grain call timeouts Warning 100157 Multiple Warnings logged in short space of time Grain-call timeout problems are generally caused by temporary network connectivity issues or silo restart / reboot problems. System should recover after a short time (depending on Liveness config settings) at which point Timeouts should clear. Ideally, monitoring for just the bulk log code 600157 variety of these warnings should be sufficient. Network Socket Problems Warning or Error 101000 to 101999, 100307, 100015, 100016 Any Error or Warning Socket disconnects are logged as Warning messages. Problems opening sockets or during message transmission are logged as Errors. Bulk log message compaction Any 500000 or higher Message summary based on bulk message threshold settings If multiple logs of the same log code occur within a designated time interval (the default is >5 within 1 minute) then additional log messages with that log code are suppressed and output as a \"bulk\" entry with log code equal to the original log code + 500000. So for example, multiple 100157 entries will show in the logs as 5 x 100157 + 1 x 600157 log entry per minute."
  },
  "1.5/Documentation/Advanced-Concepts/Interceptors.html": {
    "href": "1.5/Documentation/Advanced-Concepts/Interceptors.html",
    "title": "Interceptors | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Interceptors Grain call filters provide a means for intercepting grain calls. Filters can execute code both before and after a grain call. Multiple filters can be installed simultaneously. Filters are asynchronous and can modify RequestContext , arguments, and the return value of the method being invoked. Filters can also inspect the MethodInfo of the method being invoked on the grain class and can be used to throw or handle exceptions. Some example usages of grain call filters are: Authorization: a filter can inspect the method being invoked and the arguments or some authorization information in the RequestContext to determine whether or not to allow the call to proceed. Logging/Telemetry: a filter can log information and capture timing data and other statistics about method invocation. Error Handling: a filter can intercept exceptions thrown by a method invocation and transform it into another exception or handle the exception as it passes through the filter. Grain call filters must implement the IGrainCallFilter interface, which has one method: public interface IGrainCallFilter { Task Invoke(IGrainCallContext context); } The IGrainCallContext argument passed to the Invoke method has the following shape: public interface IGrainCallContext { /// <summary> /// Gets the grain being invoked. /// </summary> IAddressable Grain { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> of the method being invoked. /// </summary> MethodInfo Method { get; } /// <summary> /// Gets the arguments for this method invocation. /// </summary> object[] Arguments { get; } /// <summary> /// Invokes the request. /// </summary> Task Invoke(); /// <summary> /// Gets or sets the result. /// </summary> object Result { get; set; } } The IGrainCallFilter.Invoke() method must await or return the result of IGrainCallContext.Invoke() to execute the next configured filter and eventually the grain method itself. The IGrainCallContext.Result property can be modified after awaiting the Invoke() method. The IGrainCallContext.Method property returns the MethodInfo of the implementation class, not the interface. The MethodInfo of the interface method can be accessed using reflection. Grain call filters are called for all method calls to a grain and this includes calls to grain extensions (implementations of IGrainExtension ) which are installed in the grain. For example, grain extensions are used to implement Streams and Cancellation Tokens . Therefore, it should be expected that the value of IGrainCallContext.Method is not always a method in the grain class itself. Configuring Grain Call Filters Implementations of IGrainCallFilter can either be registered as silo-wide filters via Dependency Injection or they can be registered as grain-level filters via a grain implementing IGrainCallFilter directly. Silo-wide Grain Call Filters A delegate can be registered as a silo-wide grain call filters using Dependency Injection like so: services.AddGrainCallFilter(async context => { // If the method being called is 'MyInterceptedMethod', then set a value // on the RequestContext which can then be read by other filters or the grain. if (string.Equals(context.Method.Name, nameof(IMyGrain.MyInterceptedMethod))) { RequestContext.Set(\"intercepted value\", \"this value was added by the filter\"); } await context.Invoke(); // If the grain method returned an int, set the result to double that value. if (context.Result is int resultValue) context.Result = resultValue * 2; }); Similarly, a class can be registered as a grain call filter using the AddGrainCallFilter helper method. Here is an example of a grain call filter which logs the results of every grain method: public class LoggingCallFilter : IGrainCallFilter { private readonly Logger log; public LoggingCallFilter(Factory<string, Logger> loggerFactory) { this.log = loggerFactory(nameof(LoggingCallFilter)); } public async Task Invoke(IGrainCallContext context) { try { await context.Invoke(); var msg = string.Format( \"{0}.{1}({2}) returned value {3}\", context.Grain.GetType(), context.Method.Name, string.Join(\", \", context.Arguments), context.Result); this.log.Info(msg); } catch (Exception exception) { var msg = string.Format( \"{0}.{1}({2}) threw an exception: {3}\", context.Grain.GetType(), context.Method.Name, string.Join(\", \", context.Arguments), exception); this.log.Info(msg); // If this exception is not re-thrown, it is considered to be // handled by this filter. throw; } } } This filter can then be registered using the AddGrainCallFilter extension method: services.AddGrainCallFilter<LoggingCallFilter>(); Alternatively, the filter can be registered without the extension method: services.AddSingleton<IGrainCallFilter, LoggingCallFilter>(); Per-grain Grain Call Filters A grain class can register itself as a grain call filter and filter any calls made to it by implementing IGrainCallFilter like so: public class MyFilteredGrain : Grain, IMyFilteredGrain, IGrainCallFilter { public async Task Invoke(IGrainCallContext context) { await context.Invoke(); // Change the result of the call from 7 to 38. if (string.Equals(context.Method.Name, nameof(this.GetFavoriteNumber))) { context.Result = 38; } } public Task<int> GetFavoriteNumber() => Task.FromResult(7); } In the above example, all calls to the GetFavoriteNumber method will return 38 instead of 7 , because the return value has been altered by the filter. Another use case for filters is in access control, as in this example: [AttributeUsage(AttributeTargets.Method)] public class AdminOnlyAttribute : Attribute { } public class MyAccessControlledGrain : Grain, IMyFilteredGrain, IGrainCallFilter { public Task Invoke(IGrainCallContext context) { // Check access conditions. var isAdminMethod = context.Method.GetCustomAttribute<AdminOnlyAttribute>(); if (isAdminMethod && !(bool) RequestContext.Get(\"isAdmin\")) { throw new AccessDeniedException($\"Only admins can access {context.Method.Name}!\"); } return context.Invoke(); } [AdminOnly] public Task<int> SpecialAdminOnlyOperation() => Task.FromResult(7); } In the above example, the SpecialAdminOnlyOperation method can only be called if \"isAdmin\" is set to true in the RequestContext . In this way, grain call filters can be used for authorization. In this example, it is the responsibility of the caller to ensure that the \"isAdmin\" value is set correctly and that authentication is performed correctly. Note that the [AdminOnly] attribute is specified on the grain class method. This is because the IGrainCallContext.Method property returns the MethodInfo of the implementation, not the interface. The interface method can be accessed using reflection. Ordering of Grain Call Filters Grain call filters follow a defined ordering: IGrainCallFilter implementations configured in the dependency injection container, in the order in which they are registered. (Obsolete) Silo-wide InvokeInterceptor , configured via IProviderRuntime.SetInvokeInterceptor(...) . Grain-level filter, if the grain implements IGrainCallFilter . (Obsolete) Grain-level interceptor, if the grain implements IGrainInvokeInterceptor . Grain method implementation or grain extension method implementation. Each call to IGrainCallContext.Invoke() encapsulates the next defined filter so that each filter has a chance to execute code before and after the next filter in the chain and eventually the grain method itself. Client-side interceptors If a client side interceptor is defined, any grain call made from an Orleans client will invoke this interceptor before the call is dispatched remotely. The interceptor is invoked synchronously in the same thread where the call is made after call arguments are deep copied. Since the interceptor is invoked synchronously it should return promptly and do minimal work, to avoid blocking the calling thread or impacting throughput. The interceptor is allowed to mutate the call arguments and also mutate the Orleans.RequestContext . Any changes made by the interceptor to Orleans.RequestContext will be picked up as part of the call dispatch logic that occurs after the interceptor. If the interceptor logic throws an exception, the remote call will not be made and the client calling code will throw promptly. The interceptor can be set by setting GrainClient.ClientInvokeCallback , which is a property of type Action<InvokeMethodRequest, IGrain> . The first argument is the invocation request that includes various details about the invoked call, such as InterfaceId and MethodId, as well as deep-copied arguments. The second argument is the target grain reference to which this call is made. Currently, the main scenario that we know of that uses client side pre-call inteceptors is to add some extra information to Orleans.RequestContext , such as any special call context or token. Use Cases Exception Conversion When an exception which has been thrown from the server is getting deserialized on the client, you may sometimes get the following exception instead of the actual one: TypeLoadException: Could not find Whatever.dll. This happens if the assembly containing the exception is not available to the client. For example, say you are using Entity Framework in your grain implementations; then it is possible that an EntityException is thrown. The client on the other hand does not (and should not) reference EntityFramework.dll since it has no knowledge about the underlying data access layer. When the client tries to deserialize the EntityException , it will fail due to the missing DLL; as a consequence a TypeLoadException is thrown hiding the original EntityException . One may argue that this is pretty okay, since the client would never handle the EntityException ; otherwise it would have to reference EntityFramework.dll . But what if the client wants at least to log the exception? The problem is that the original error message is lost. One way to workaround this issue is to intercept server-side exceptions and replace them by plain exceptions of type Exception if the exception type is presumably unknown on the client side. However, there is one important thing we have to keep in mind: we only want to replace an exception if the caller is the grain client . We don't want to replace an exception if the caller is another grain (or the Orleans infrastructure which is making grain calls, too; e.g. on the GrainBasedReminderTable grain). On the server side this can be done with a silo-level interceptor: public class ExceptionConversionFilter : IGrainCallFilter { private static readonly HashSet<string> KnownExceptionTypeAssemblyNames = new HashSet<string> { typeof(string).Assembly.GetName().Name, \"System\", \"System.ComponentModel.Composition\", \"System.ComponentModel.DataAnnotations\", \"System.Configuration\", \"System.Core\", \"System.Data\", \"System.Data.DataSetExtensions\", \"System.Net.Http\", \"System.Numerics\", \"System.Runtime.Serialization\", \"System.Security\", \"System.Xml\", \"System.Xml.Linq\", \"MyCompany.Microservices.DataTransfer\", \"MyCompany.Microservices.Interfaces\", \"MyCompany.Microservices.ServiceLayer\" }; public async Task Invoke(IGrainCallContext context) { var isConversionEnabled = RequestContext.Get(\"IsExceptionConversionEnabled\") as bool? == true; if (!isConversionEnabled) { // If exception conversion is not enabled, execute the call without interference. await context.Invoke(); return; } RequestContext.Remove(\"IsExceptionConversionEnabled\"); try { await context.Invoke(); } catch (Exception exc) { var type = exc.GetType(); if (KnownExceptionTypeAssemblyNames.Contains(type.Assembly.GetName().Name)) { throw; } // Throw a base exception containing some exception details. throw new Exception( string.Format( \"Exception of non-public type '{0}' has been wrapped.\" + \" Original message: <<<<----{1}{2}{3}---->>>>\", type.FullName, Environment.NewLine, exc, Environment.NewLine)); } } } As mentioned earlier, this filter can then be registered using the AddGrainCallFilter extension method: services.AddGrainCallFilter<ExceptionConversionFilter>(); On the client side you have to set up a client-side interceptor: GrainClient.ClientInvokeCallback = (request, grain) => { RequestContext.Set(\"IsExceptionConversionEnabled\", true); }; This way the client tells the server that it wants to use exception conversion. Calling Grains from Interceptors It is possible to make grain calls from an interceptor through the injection of IGrainFactory into our interceptor class: private readonly IGrainFactory grainFactory; public CustomCallFilter(IGrainFactory grainFactory) { this.grainFactory = grainFactory; } public async Task Invoke(IGrainCallContext context) { // Hook calls to any grain other than ICustomFilterGrain implementations. // This avoids potential infinite recursion when calling OnReceivedCall() below. if (!(context.Grain is ICustomFilterGrain)) { var filterGrain = this.grainFactory.GetGrain<ICustomFilterGrain>(context.Grain.GetPrimaryKeyLong()); // Perform some grain call here. await filterGrain.OnReceivedCall(); } // Continue invoking the call on the target grain. await context.Invoke(); } Obsolete Interceptor Features The following sections describe functionality which has been superseded by the above features and may be removed in a future release. Silo-level Interceptors Silo-level interceptors are called for all grain calls within a silo. They can be installed using IProviderRuntime.SetInvokeInterceptor(interceptor) , typically from within a Bootstrap Provider 's Init method, like so: providerRuntime.SetInvokeInterceptor(async (method, request, grain, invoker) => { log.LogInfo($\"{grain.GetType()}.{method.Name}(...) called\"); // Invoke the request and return the result back to the caller. var result = await invoker.Invoke(grain, request); log.LogInfo($\"Grain method returned {result}\"); return result; }); Note how the interceptor wraps the call to the grain. This allows the user to inspect the return value of each method as well as handle any exceptions which are thrown. SetInvokeInterceptor takes a single parameter, a delegate of type InvokeInterceptor with the following signature: public delegate Task<object> InvokeInterceptor( MethodInfo targetMethod, InvokeMethodRequest request, IGrain target, IGrainMethodInvoker invoker); In this delegate: targetMethod is the MethodInfo of the method being called on the grain implementation, not the interface. request.Arguments is an object[] containing the arguments to the method, if any. target is the grain implementation instance being called. invoker is used to invoke the method itself. Grain-level Interceptors Grain-level interceptors intercept calls for individual grains only. Grain-level interceptors are enabled by implementing IGrainInvokeInterceptor in a grain class: public interface IGrainInvokeInterceptor { Task<object> Invoke( MethodInfo method, InvokeMethodRequest request, IGrainMethodInvoker invoker); } For example: public Task<object> Invoke( MethodInfo methodInfo, InvokeMethodRequest request, IGrainMethodInvoker invoker) { // Check access conditions. var isAdminMethod = methodInfo.GetCustomAttribute<AdminOnlyAttribute>(); if (isAdminMethod && !(bool)RequestContext.Get(\"isAdmin\")) { throw new AccessDeniedException($\"Only admins can access {methodInfo.Name}!\"); } return invoker.Invoke(this, request); } If a silo-level interceptor is also present, the grain-level interceptor is invoked inside of silo-level interceptors, during the call to invoker.Invoke(...) . Grain-level interceptors will also be invoked for grain extensions (implementations of IGrainExtension ), not only for method in the current class."
  },
  "Documentation/deployment/grain_versioning/grain_versioning.html": {
    "href": "Documentation/deployment/grain_versioning/grain_versioning.html",
    "title": "Grain versioning | Microsoft Orleans Documentation",
    "keywords": "Grain versioning Warning This page describes how to use grain interface versioning. The versioning of Grain state is out of scope. Overview On a given cluster, silos can support different versions of a grain type. In this example the client and Silo{1,2,3} were compiled with grain interface A version 1. Silo 4 was compiled with A version 2. Limitations: No versioning on stateless worker Streaming interfaces are not versioned Enable versioning By default, grains are not versioned. You can version grain by using the VersionAttribute on the grain interface: [Version(X)] public interface IVersionUpgradeTestGrain : IGrainWithIntegerKey {} Where X is the version number of the grain interface, which is typically monotonically increasing. Grain version compatibility and placement When a call from a versioned grain arrive in a cluster: If no activation exists, a compatible activation will be created If an activation exists: If the current one is not compatible, it will be deactivated and new compatible will be created (see version selector strategy ) If the current one is compatible (see compatible grains), the call will be handled normally. By default: All versioned grains are supposed to be backward-compatible only (see backward compatibility guidelines) and compatible grains(Compatible-grains.md)). That means that a v1 grain can make calls to a v2 grain, but a v2 grain cannot call a v1. When multiple versions exist in the cluster, the new activation will be randomly placed on a compatible silo. You can change this default behavior via the option GrainVersioningOptions : var silo = new SiloHostBuilder() [...] .Configure<GrainVersioningOptions>(options => { options.DefaultCompatibilityStrategy = nameof(BackwardCompatible); options.DefaultVersionSelectorStrategy = nameof(MinimumVersion); }) [...]"
  },
  "Documentation/deployment/grain_versioning/deploying_new_versions_of_grains.html": {
    "href": "Documentation/deployment/grain_versioning/deploying_new_versions_of_grains.html",
    "title": "Deploy new version of grains | Microsoft Orleans Documentation",
    "keywords": "Deploy new version of grains Rolling upgrade In this method you deploy newer silos directly on your environment. This is the simplest method, but it can be difficult to interrupt an on-going deployment and to rollback. Recommended configuration: DefaultCompatibilityStrategy set to BackwardCompatible DefaultVersionSelectorStrategy set to AllCompatibleVersions var silo = new SiloHostBuilder() [...] .Configure<GrainVersioningOptions>(options => { options.DefaultCompatibilityStrategy = nameof(BackwardCompatible); options.DefaultVersionSelectorStrategy = nameof(AllCompatibleVersions); }) [...] When using this configuration, \"old\" clients will be able to talk to activations on both versions of silos. Newer clients and silos will only trigger new activations on newer silos. Using a staging environment In this method you will need a second environment (Staging environment), on which you will deploy newer silos before stopping the Production environment. The Production and the Staging silos and clients will be part of the same cluster . It is important that silos from both environment can talk to each other. Recommended configuration: DefaultCompatibilityStrategy set to BackwardCompatible DefaultVersionSelectorStrategy set to MinimumVersion var silo = new SiloHostBuilder() [...] .Configure<GrainVersioningOptions>(options => { options.DefaultCompatibilityStrategy = nameof(BackwardCompatible); options.DefaultVersionSelectorStrategy = nameof(MinimumVersion); }) [...] Suggested deployment steps: \"V1\" silos and clients are deployed and are running in the Production slot. \"V2\" silos and clients begin to start in the Staging slot. They will join the same cluster as the Production slot. No \"V2\" activations will be created so far. Once the deployment in the Staging slot is finished, the developper can redirect some traffic on the V2 clients (smoke tests, targeted beta users, ect.). This will create V2 activations, but since Grains are backward compatibles and that all silos are in the same cluster, no duplicate activations will be created. If the validation is successful, proceed to VIP swap. If not, you can safely shutdown the Staging cluster: existing V2 activations will be destroyed and V1 activations will be created if needed. V1 activations will naturally \"migrate\" to V2 silos eventually. You can safely shutdown V1 silos. Warning Remember that stateless workers are not versioned and that streaming agents will also start in the staging environment."
  },
  "Documentation/deployment/grain_versioning/compatible_grains.html": {
    "href": "Documentation/deployment/grain_versioning/compatible_grains.html",
    "title": "Compatible grains | Microsoft Orleans Documentation",
    "keywords": "Compatible grains When an existing grain activation is about to process a request, the runtime will check if the version in the request and the actual version of the grain are compatible. Orleans does not infer at runtime which policy to use , The default behavior to determine if two versions are compatible is determined by GrainVersioningOptions.CompatibilityStrategy Backward compatible (default) Definition A grain interface version Vn can be be backward compatible with Vm if: The name of the interface didn't change (or the overridden typecode) All public methods present in the Vm version are in the Vn version. It is important that the signatures of the methods inherited from Vm are not modified : since Orleans use an internal built-in serializer, modifying/renaming a field (even private) can make the serialization to break. Since Vn can have added methods compared to Vm, Vm is not compatible with Vn. Example If in the cluster we have two versions of a given interface, V1 and V2 and that V2 is backward compatible with V1: If the current activation is a V2 and the requested version is V1, the current activation will be able to process the request normally If the current activation is a V1 and the requested version is V2, the current activation will be deactivated and a new activation compatible with V2 will be created (see version selector strategy ). Fully compatible Definition A grain interface version Vn can be fully compatible with Vm if: Vn is backward compatible with Vm No public methods where added in the Vn version If Vn is fully compatible with Vm then Vm is also fully compatible with Vn. Example If in the cluster we have two versions of a given interface, V1 and V2 and that V2 is fully compatible with V1: If the current activation is a V2 and the requested version is V1, the current activation will be able to process the request normally If the current activation is a V2 and the requested version is V1, the current activation will also be able to process the request normally"
  },
  "Documentation/deployment/grain_versioning/backward_compatibility_guidelines.html": {
    "href": "Documentation/deployment/grain_versioning/backward_compatibility_guidelines.html",
    "title": "Backward compatibility guidelines | Microsoft Orleans Documentation",
    "keywords": "Backward compatibility guidelines Writing backward compatible code can be hard and difficult to test. Never change the signature of existing methods Because of the way on how Orleans serializer work, you should never change the signature of existing methods. The following example is correct: [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 Task MyMethod(int arg); // New method added in V2 Task MyNewMethod(int arg, obj o); } This is not correct: [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 Task MyMethod(int arg, obj o); } NOTE : you should not do this change in your code, as it's an example of a bad practice that leads to very bad side-effects. This is an example of what can happen if you just rename the parameter names: let's say that we have the two following interface version deployed in the cluster: [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // return a - b Task<int> Substract(int a, int b); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // return y - x Task<int> Substract(int y, int x); } This methods seems identical. But if the client was called with V1, and the request is handled by a V2 activation: var grain = client.GetGrain<IMyGrain>(0); var result = await grain.Substract(5, 4); // Will return \"-1\" instead of expected \"1\" This is due to how the internal Orleans serializer works. Avoid changing existing method logic It can seems obvious, but you should be very careful when changing the body of an existing method. Unless you are fixing a bug, it is better to just add a new method if you need to modify the code. Example: // V1 public interface MyGrain : IMyGrain { // First method Task MyMethod(int arg) { SomeSubRoutine(arg); } } // V2 public interface MyGrain : IMyGrain { // Method inherited from V1 // Do not change the body Task MyMethod(int arg) { SomeSubRoutine(arg); } // New method added in V2 Task MyNewMethod(int arg) { SomeSubRoutine(arg); NewRoutineAdded(arg); } } Do not remove methods from grain interfaces Unless you are sure that they are no longer used, you should not remove methods from the grain interface. If you want to remove methods, this should be done in 2 steps: Deploy V2 grains, with V1 method marked as Obsolete [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 [Obsolete] Task MyMethod(int arg); // New method added in V2 Task MyNewMethod(int arg, obj o); } When you are sure that no V1 calls are made (effectively V1 is no longer deployed in the running cluster), deploy V3 with V1 method removed [Version(3)] public interface IMyGrain : IGrainWithIntegerKey { // New method added in V2 Task MyNewMethod(int arg, obj o); }"
  },
  "1.5/Documentation/Multi-Cluster/Overview.html": {
    "href": "1.5/Documentation/Multi-Cluster/Overview.html",
    "title": "Multi-Cluster Support | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Multi-Cluster Support Orleans v.1.3.0 added support for federating several Orleans clusters into a loosely connected multi-cluster that acts like a single service. Multi-clusters facilitate geo-distribution of a service, that is, make it easier to run an Orleans application in multiple data-centers around the world. Also, a multi-cluster can be run within a single datacenter to get better failure and performance isolation. All mechanisms are designed with particular attention to (1) minimize communication between clusters, and (2) let each cluster run autonomously even if other clusters fail or become unreachable. Configuration and Operation Below we document how to configure and operate a multi-cluster. Communication . Clusters communicate via the same silo-to-silo connections that are used within a cluster. To exchange status and configuration information, Clusters use a gossip mechanism and gossip channel implementations. Silo Configuration . Silos need to be configured so they know which cluster they belong to (each cluster is identified by a unique string). Also, each silo needs to be configured with connection strings that allow them to connect to one or more gossip channels on startup. Multi-Cluster Configuration Injection . At runtime, the service operator can specify and/or change the multi-cluster configuration , which contains a list of cluster ids, to specify which clusters are part of the current multi-cluster. This is done by calling the management grain in any one of the clusters. Multi-Cluster Grains Below we document how to use multi-cluster functionality at the application level. Global-Single-Instance Grains . Developers can indicate when and how clusters should coordinate their grain directories with respect to a particular grain class. The [GlobalSingleInstance] attribute means we want the same behavior as as when running Orleans in a single global cluster: that is, route all calls to a single activation of the grain. Conversely, the [OneInstancePerCluster] attribute indicates that each cluster can have its own independent activation. This is appropriate if communication between clusters is undesired. Log-View Grains (not in v.1.3.0) . A special type of grain that uses a new API, similar to event sourcing, for synchronizing or persisting grain state. It can be used to automatically and efficiently synchronize the state of a grain between clusters and with storage. Because its synchronization algorithms are safe to use with reentrant grains, and are optimized to use batching and replication, it can perform better than standard grains when a grain is frequently accessed in multiple clusters, and/or when it is written to storage frequently. Support for log-view grains is not part of the master branch yet. We have a prerelease including samples and a bit of documentation in the geo-orleans branch . It is currently being evaluated in production by an early adopter."
  },
  "1.5/Documentation/Deployment-and-Operations/Configuration-Guide/Configuring-SQL-Tables.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Configuration-Guide/Configuring-SQL-Tables.html",
    "title": "SQL Tables | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . SQL System Storage Any reliable production-style Orleans deployment requires using persistent storage to keep system state, specifically Orleans cluster status and the data used for the reminders functionality. In addition to out of the box support for Azure storage Orleans also provides an option to store this information in SQL server. In order to use SQL server for the system store, one needs to adjust server-side and client-side configurations. The server configuration should look like this: <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <SystemStore SystemStoreType =\"SqlServer\" DeploymentId=\"OrleansTest\" DataConnectionString=\"Data Source=(localdb)\\MSSQLLocalDB;Initial Catalog=Orleans;Integrated Security=True;Pooling=False;Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\" AdoInvariant=\"System.Data.SqlClient\" /> </Globals> </OrleansConfiguration> The client configuration should look like this: <ClientConfiguration xmlns=\"urn:orleans\"> <SystemStore SystemStoreType =\"SqlServer\" DeploymentId=\"OrleansTest\" DataConnectionString=\"Data Source=(localdb)\\MSSQLLocalDB;Initial Catalog=Orleans;Integrated Security=True;Pooling=False;Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\" AdoInvariant=\"System.Data.SqlClient\" /> </ClientConfiguration> Where the DataConnectionString is set to any valid SQL Server connection string. In order to use SQL Server as the store for system data, there’s now a script file CreateOrleansTables_*.sql (where asterisk denotes database vendor) in the Binaries\\OrleansServer folder which establishes the necessary database objects. Make sure that all servers that will be hosting Orleans silos can reach the database and has access rights to it! We’ve tripped up a few times on this seemingly trivial concern during our testing. Note that in Orleans 2.0.0 those SQL scripts have been split into per-feature pieces to match the finer grain provider model: Clustering , Persistence , Reminders , and Statistics . SQL Metrics and Statistics tables System tables can currently only be stored in Azure table or SQL server. For Metrics and Statistics tables however, we provide a generic support to host it in any persistent storage. This is provided via the notion of a StatisticsProvider . Any application can write an arbitrary provider to store statistics and metrics data in a persistent store of their choice. Orleans provides an implemention of one such provider: SQL Table Statistics Provider. In order to use SQL server for statistics and metrics tables, one needs to adjust server-side and client-side configurations. The server configuration should look like this: <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <StatisticsProviders> <Provider Type=\"Orleans.Providers.SqlServer.SqlStatisticsPublisher\" Name=\"MySQLStatsProvider\" ConnectionString=\"Data Source=(localdb)\\MSSQLLocalDB;Initial Catalog=Orleans;Integrated Security=True;Pooling=False;Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\" /> </StatisticsProviders> </Globals> <Defaults> <Statistics ProviderType=\"MySQLStatsProvider\" WriteLogStatisticsToTable=\"true\"/> </Defaults> </OrleansConfiguration> The client configuration should look like this: <ClientConfiguration xmlns=\"urn:orleans\"> <StatisticsProviders> <Provider Type=\"Orleans.Providers.SqlServer.SqlStatisticsPublisher\" Name=\"SQL\" ConnectionString=\"Data Source=(localdb)\\MSSQLLocalDB;Initial Catalog=Orleans;Integrated Security=True;Pooling=False;Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\" /> </StatisticsProviders> <Statistics ProviderType=\"MySQLStatsProvider\" WriteLogStatisticsToTable=\"true\"/> </ClientConfiguration>"
  },
  "1.5/Documentation/Advanced-Concepts/External-Tasks-and-Grains.html": {
    "href": "1.5/Documentation/Advanced-Concepts/External-Tasks-and-Grains.html",
    "title": "External Tasks and Grains | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . External Tasks and Grains By design, any sub-Tasks spawned from grain code (for example, by using await or ContinueWith or Task.Factory.StartNew ) will be dispatched on the same per-activation TPL Task Scheduler as the parent task and therefore inherit the same single-threaded execution model as the rest of grain code. This is the main point behind single threaded execution of grain turn based concurency . In some cases grain code might need to “break out” of the Orleans task scheduling model and “do something special”, such as explicitly pointing a Task to a different task scheduler or using the .NET Thread pool. An example of such cases is when grain code has to execute a synchronous remote blocking call (such as remote IO). Doing that in the grain context will block the grain as well as one of the Orleans threads and thus should never be made. Instead, the grain code can execute this piece of blocking code on the thread pool thread and join ( await ) the completion of that execution and proceed in the grain context. We expect that escaping from the Orleans scheduler will be a very advanced and seldom required usage scenario beyond the “normal” usage patterns. Task based APIs: 1) await , Task.Factory.StartNew , Task.ContinuewWith , Task.WhenAny , Task.WhenAll , Task.Delay all respect the current Task Scheduler. That means that using them in the default way, without passing a different TaskScheduler, will cause them to execute in the grain context. 2) Both Task.Run and the endMethod delegate of Task.Factory.FromAsync do NOT respect the current task Scheduler. They both use the TaskScheduler.Default scheduler, which is the .NET thread pool task Scheduler. Therefore, the code inside Task.Run and the endMethod will ALWAYS run on the .NET thread pool outside of the single-threaded execution model for Orleans grains, as detailed here . However, any code after the await Task.Run or await Task.Factory.FromAsync will run back under the scheduler at the point the task was created, which is the grain scheduler. 3) configureAwait(false) is an explicit API to escape the current task Scheduler. It will cause the code after an awaited Task to be executed on the TaskScheduler.Default scheduler, which is the .NET thread pool, and will thus break the single-threaded execution of the Orleans grain. You should in general never ever use configureAwait(false) directly in grain code. 4) Methods with signature async void should not be used with grains. They are intended for graphical user interface event handlers. Example: Below is sample code that demonstrates the usage of TaskScheduler.Current , Task.Run and a special custom scheduler to escape from Orlean grain context and how to get back to it. public async Task MyGrainMethod() { // Grab the Orleans task scheduler var orleansTs = TaskScheduler.Current; await TaskDelay(10000); // Current task scheduler did not change, the code after await is still running in the same task scheduler. Assert.AreEqual(orleansTs, TaskScheduler.Current); Task t1 = Task.Run( () => { // This code runs on the thread pool scheduler, not on Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); Assert.AreEqual(TaskScheduler.Default, TaskScheduler.Current); } ); await t1; // We are back to the Orleans task scheduler. // Since await was executed in Orleans task scheduler context, we are now back to that context. Assert.AreEqual(orleansTS, TaskScheduler.Current); // Example of using ask.Factory.StartNew with a custom scheduler to escape from the Orleans scheduler Task t2 = Task.Factory.StartNew(() => { // This code runs on the MyCustomSchedulerThatIWroteMyself scheduler, not on the Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); Assert.AreEqual(MyCustomSchedulerThatIWroteMyself, TaskScheduler.Current); }, CancellationToken.None, TaskCreationOptions.None, scheduler: MyCustomSchedulerThatIWroteMyself); await t2; // We are back to Orleans task scheduler. Assert.AreEqual(orleansTS, TaskScheduler.Current); } Advanced Example - making a grain call from code that runs on a thread pool An even more advanced scenario is a piece of grain code that needs to “break out” of the Orleans task scheduling model and run on a thread pool (or some other, non-Orleans context), but still needs to call another grain. If you try to make a grain call but are not within an Orleans context, you will get an exception that says you are \"trying to send a message on a silo not from within a grain and not from within a system target (RuntimeContext is not set to SchedulingContext)\". Below is code that demonstrates how a grain call can be made from a piece of code that runs inside a grain but not in the grain context. public async Task MyGrainMethod() { // Grab the Orleans task scheduler var orleansTs = TaskScheduler.Current; Task<int> t1 = Task.Run(async () => { // This code runs on the thread pool scheduler, not on Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); // You can do whatever you need to do here. Now let's say you need to make a grain call. Task<Task<int>> t2 = Task.Factory.StartNew(() => { // This code runs on the Orleans task scheduler since we specified the scheduler: orleansTs. Assert.AreEqual(orleansTS, TaskScheduler.Current); return GrainFactory.GetGrain<IFooGrain>(0).MakeGrainCall(); }, CancellationToken.None, TaskCreationOptions.None, scheduler: orleansTs); int res = await (await t2); // double await, unrelated to Orleans, just part of TPL APIs. // This code runs back on the thread pool scheduler, not on the Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); return res; } ); int result = await t1; // We are back to the Orleans task scheduler. // Since await was executed in the Orleans task scheduler context, we are now back to that context. Assert.AreEqual(orleansTS, TaskScheduler.Current); } Dealing with libraries Some external libraries that your code is using might be using ConfigureAwait(false) internally. In fact, it is a good and correct practice in .NET to use ConfigureAwait(false) when implementing general purpose libraries . This is not a problem in Orleans. As long as the code in the grain that invokes the library method is awaiting the library call with a regular await , the grain code is correct. The result will be exactly as desired -- the library code will run continuations on the Default scheduler (which happens to be ThreadPoolTaskScheduler but it does not guarantee that the continuations will definitely run on a ThreadPool thread, as continuations are often inlined in the previous thread), while the grain code will run on the Orleans scheduler. Another frequently-asked question is whether there is a need to execute library calls with Task.Run -- that is, whether there is a need to explicitly offload the library code to ThreadPool (for grain code to do Task.Run(()=> myLibrary.FooAsync()) ). The answer is No. There is no need to offload any code to ThreadPool, except for the case of library code that is making a blocking synchronous calls. Usually, any well-written and correct .NET async library (methods that return Task and are named with an Async suffix) do not make blocking calls. Thus there is no need to offload anything to ThreadPool, unless you suspect the async library is buggy or if you are deliberately using a synchronous blocking library. Summary What are you trying to do? How to do it Run background work on .NET thread-pool threads. No grain code or grain calls allowed. Task.Run Grain interface call Method return types = Task or Task<T> Run worker task from grain code with Orleans turn-based concurrency guarantees. Task.Factory.StartNew Timeouts for executing work items Task.Delay + Task.WhenAny Use with async / await The normal .NET Task-Async programming model. Supported & recommended ConfigureAwait(false) Do not use inside grain code. Allowed only inside libraries. Calling async library await the library call"
  },
  "Documentation/grains/cancellation_tokens.html": {
    "href": "Documentation/grains/cancellation_tokens.html",
    "title": "Grain cancellation tokens | Microsoft Orleans Documentation",
    "keywords": "Grain cancellation tokens The Orleans runtime provides mechanism called grain cancellation token, that enables the developer to cancel an executing grain operation. Description GrainCancellationToken is a wrapper around standard .NET System.Threading.CancellationToken , which enables cooperative cancellation between threads, thread pool work items or Task objects, and can be passed as grain method argument. A GrainCancellationTokenSource is a object that provides a cancellation token through its Token property and sends a cancellation message by calling its Cancel method. Usage Instantiate a CancellationTokenSource object, which manages and sends cancellation notification to the individual cancellation tokens. var tcs = new GrainCancellationTokenSource(); Pass the token returned by the GrainCancellationTokenSource.Token property to each grain method that listens for cancellation. var waitTask = grain.LongIoWork(tcs.Token, TimeSpan.FromSeconds(10)); A cancellable grain operation needs to handle underlying CancellationToken property of GrainCancellationToken just like it would do in any other .NET code. public async Task LongIoWork(GrainCancellationToken tc, TimeSpan delay) { while(!tc.CancellationToken.IsCancellationRequested) { await IoOperation(tc.CancellationToken); } } Call the GrainCancellationTokenSource.Cancel method to initiate cancellation. await tcs.Cancel(); Call the Dispose method when you are finished with the GrainCancellationTokenSource object. tcs.Dispose(); Important Considerations: The GrainCancellationTokenSource.Cancel method returns Task , and in order to ensure cancellation the cancel call must be retried in case of transient communication failure. Callbacks registered in underlying System.Threading.CancellationToken are subjects to single threaded execution guarantees within the grain activation on which they were registered. Each GrainCancellationToken can be passed through multiple methods invocations."
  },
  "1.5/Documentation/Deployment-and-Operations/Configuration-Guide/Typical-Configurations.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Configuration-Guide/Typical-Configurations.html",
    "title": "Typical Configurations | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Typical Configurations Below are examples of typical configurations that can be used for development and production deployments. Local Development For local development, where there is only one silo running locally on the programmer’s machine, the configuration is already included in the Orleans Dev/Test Host project template of Microsoft Orleans Tools for Visual Studio . The local silo that can be started by running a project created with the Orleans Dev/Test Host template is configured as follows in DevTestServerConfiguration.xml. <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <SeedNode Address=\"localhost\" Port=\"11111\" /> </Globals> <Defaults> <Networking Address=\"localhost\" Port=\"11111\" /> <ProxyingGateway Address=\"localhost\" Port=\"30000\" /> </Defaults> </OrleansConfiguration> Silo configuration via code is as follows. var config = ClusterConfiguration.LocalhostPrimarySilo(11111, 30000); To connect to the local silo, the client needs to be configured to localhost and can only connect from the same machine. The Orleans client that can be started by running a project created with the Orleans Dev/Test Host template is configured as follows in DevTestClientConfiguration.xml <ClientConfiguration xmlns=\"urn:orleans\"> <Gateway Address=\"localhost\" Port=\"30000\"/> </ClientConfiguration> Client configuration via code is as follows. var config = ClientConfiguration.LocalhostSilo(30000); Reliable Production Deployment Using Azure For a reliable production deployment using Azure, you need to use the Azure Table option for cluster membership. This configuration is typical of deployments to either on-premise servers or Azure virtual machine instances. The format of the DataConnection string is \"DefaultEndpointsProtocol=https;AccountName= ;AccountKey= \" <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <SystemStore SystemStoreType=\"AzureTable\" DeploymentId=\"<your deployment ID>\" DataConnectionString=\"<<see comment above>>\" /> <Liveness LivenessType =\"AzureTable\" /> </Globals> <Defaults> <Networking Address=\"\" Port=\"11111\" /> <ProxyingGateway Address=\"\" Port=\"30000\" /> </Defaults> </OrleansConfiguration> Clients need to be configured to use Azure Table for discovering the gateways, the addresses of the Orleans servers are not statically known to the clients. <ClientConfiguration xmlns=\"urn:orleans\"> <SystemStore SystemStoreType=\"AzureTable\" DeploymentId=\"target deployment ID\" DataConnectionString=\"<<see comment above>>\" /> </ClientConfiguration> Reliable Production Deployment Using ZooKeeper For a reliable production deployment using ZooKeeper, you need to use the ZooKeeper option for cluster membership. This configuration is typical of deployments to on-premise servers. The format of the DataConnection string is documented in the ZooKeeper Programmer's Guide . A minimum of 5 ZooKeeper servers is recommended . <?xml version=\"1.0\" encoding=\"utf-8\"?> <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <SystemStore SystemStoreType=\"ZooKeeper\" DeploymentId=\"<your deployment ID>\" DataConnectionString=\"<<see comment above>>\"/> </Globals> <Defaults> <Networking Address=\"localhost\" Port=\"11111\" /> <ProxyingGateway Address=\"localhost\" Port=\"30000\" /> </Defaults> </OrleansConfiguration> Clients need to be configured to use ZooKeeper for discovering the gateways, the addresses of the Orleans servers are not statically known to the clients. ﻿<?xml version=\"1.0\" encoding=\"utf-8\" ?> <ClientConfiguration xmlns=\"urn:orleans\"> <SystemStore SystemStoreType=\"ZooKeeper\" DeploymentId=\"target deployment ID\" DataConnectionString=\"<<see comment above>>\"/> </ClientConfiguration> Reliable Production Deployment Using SQL Server For a reliable production deployment using SQL server, a SQL server connection string needs to be supplied. Silo configuration via code is as follows, and includes logging configuration. var connectionString = @\"Data Source=MSSQLDBServer;Initial Catalog=Orleans;Integrated Security=True; Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\"; var config = new ClusterConfiguration{ Globals = { DataConnectionString = connectionString, DeploymentId = \"<your deployment ID>\", LivenessType = GlobalConfiguration.LivenessProviderType.SqlServer, LivenessEnabled = true, ReminderServiceType = GlobalConfiguration.ReminderServiceProviderType.SqlServer }, Defaults = { Port = 11111, ProxyGatewayEndpoint = new IPEndPoint(address, 30000), PropagateActivityId = true }}; var siloHost = new SiloHost(System.Net.Dns.GetHostName(), config); Clients need to be configured to use SQL server for discovering the gateways, as with Azure and Zookeeper, the addresses of the Orleans servers are not statically known to the clients. var connectionString = @\"Data Source=MSSQLDBServer;Initial Catalog=Orleans;Integrated Security=True; Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\"; var config = new ClientConfiguration{ GatewayProvider = ClientConfiguration.GatewayProviderType.SqlServer, AdoInvariant = \"System.Data.SqlClient\", DataConnectionString = connectionString, DeploymentId = \"<your deployment ID>\", PropagateActivityId = true }; var client = new ClientBuilder().UseConfiguration(config).Build(); await client.Connect(); Unreliable Deployment on a Cluster of Dedicated Servers For testing on a cluster of dedicated servers when reliability isn’t a concern you can leverage MembershipTableGrain and avoid dependency on Azure Table. You just need to designate one of the nodes as a Primary. <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <SeedNode Address=\"<primary node>\" Port=\"11111\" /> <Liveness LivenessType =\"MembershipTableGrain\" /> </Globals> <Defaults> <Networking Address=\" \" Port=\"11111\" /> <ProxyingGateway Address=\" \" Port=\"30000\" /> </Defaults> </OrleansConfiguration> For the client: <ClientConfiguration xmlns=\"urn:orleans\"> <Gateway Address=\"node-1\" Port=\"30000\"/> <Gateway Address=\"node-2\" Port=\"30000\"/> <Gateway Address=\"node-3\" Port=\"30000\"/> </ClientConfiguration> Azure Worker Role Deployment When Orleans is deployed into an Azure Worker role, as opposed to VM instances, most of the server-side configuration is actually done in files other than the OrleansConfiguration, which looks something like this: <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <Liveness LivenessType=\"AzureTable\" /> </Globals> <Defaults> <Tracing DefaultTraceLevel=\"Info\" TraceToConsole=\"true\" TraceToFile=\"{0}-{1}.log\" /> </Defaults> </OrleansConfiguration> Some information is kept in the service configuration file, in which the worker role section looks like this: <Role name=\"OrleansAzureSilos\"> <Instances count=\"2\" /> <ConfigurationSettings> <Setting name=\"DataConnectionString\" value=\"<<see earlier comment>>\" /> <Setting name=\"Microsoft.WindowsAzure.Plugins.Diagnostics.ConnectionString\" value=\"<<see earlier comment>>\" /> </ConfigurationSettings> </Role> The data connection string and the diagnostics connection string do not have to be the same. Some configuration information is kept in the service definition file. The worker role has to be configured there, too: <WorkerRole name=\"OrleansAzureSilos\" vmsize=\"Large\"> <Imports> <Import moduleName=\"Diagnostics\" /> </Imports> <ConfigurationSettings> <Setting name=\"DataConnectionString\" /> </ConfigurationSettings> <LocalResources> <LocalStorage name=\"LocalStoreDirectory\" cleanOnRoleRecycle=\"false\" /> </LocalResources> <Endpoints> <InternalEndpoint name=\"OrleansSiloEndpoint\" protocol=\"tcp\" port=\"11111\" /> <InternalEndpoint name=\"OrleansProxyEndpoint\" protocol=\"tcp\" port=\"30000\" /> </Endpoints> </WorkerRole> That's it for the worker role hosting the Orleans runtime. However, when deploying to Azure, there is typically a front end of some sort, either a web site or a web service, since making the Orleans ports public is not a good idea. Therefore, the client configuration is configuration of the web or worker role (or web site) that sits in front of Orleans. Important Note As of November 2017, there is a limitation in Azure Cloud Services which prevents firewall configuration of InternalEndpoint s if there is only 1 role in the Cloud Service. If you are connecting to your cloud service via a Virtual Network, you will have to scale your Cloud Services to two instances in order for the firewall rules to be created Assuming that the frontend is a web role, a simple ClientConfiguration file should be used: <ClientConfiguration xmlns=\"urn:orleans\"> <Tracing DefaultTraceLevel=\"Info\" TraceToConsole=\"true\" TraceToFile=\"{0}-{1}.log\" WriteTraces=\"false\"/> </ClientConfiguration> The web role needs the same connection string information as the worker role, in the service configuration file: <Role name=\"WebRole\"> <Instances count=\"2\" /> <ConfigurationSettings> <Setting name=\"DataConnectionString\" value=\"<<see earlier comment>>\" /> <Setting name=\"Microsoft.WindowsAzure.Plugins.Diagnostics.ConnectionString\" value=\"<<see earlier comment>>\" /> </ConfigurationSettings> </Role> and in the service definition file: <WebRole name=\"WebRole\" vmsize=\"Large\"> <Imports> <Import moduleName=\"Diagnostics\" /> </Imports> <ConfigurationSettings> <Setting name=\"DataConnectionString\" /> </ConfigurationSettings> <!-- There is additional web role data that has nothing to do with Orleans --> </WebRole>"
  },
  "1.5/Documentation/Samples-Overview/Twitter-Sentiment.html": {
    "href": "1.5/Documentation/Samples-Overview/Twitter-Sentiment.html",
    "title": "Twitter Sentiment | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Twitter Sentiment The Twitter Sentiment application records Twitter sentiment by consuming the Twitter streaming API, calulates a sentiment score for each tweet (i.e. is it a positive/negative/neutral tone of lanuage), and then records that sentiment against each hashtag in the tweet using an Orleans grain to maintain a total score for each unique hashtag. The sample illustrates using Orleans to manipulate data with high volumes of input traffic, where each grain owns a row in a table (or a key in a key/value store, or a document in a document store) and all updates go through one single grain, reducing contention for individual rows, keys, or documents. Client The sentiment processing on each tweet is performed in a Node.js application, in server.js, and uses the sentiment library to perform the analysis, which uses key words to determine sentiment. The sentiment score and the actual tweet are posted to the ASP.NET MVC program for processing. The ASP.NET MVC application serves two main roles. It acts as the end point to post sentiment scores into Orleans, and it provides the UI to view hashtag sentiment scores from Orleans. When updating a sentiment score, the SetScore function in GrainContoller.cs gets a handle for a stateless TweetDispatcher grain, and calls its AddScore method. The GetScores method retrieves the score for an arbitrary list of hashtags, each score being expressed as a combination of the overall positive sentiment score, the overall negative sentiment score, and the total number of tweets tracked containing that hashtag. Recall that some sentiment analysis will often result in a neutral weighting, so it is good to track the total number of tweets containing the hashtag. The controller also retrieves a count of the total number of hashtags that the system is tracking, to help give a sense of the scale of data coming in from the Twitter fire hose. Orleans There are three main Orleans grains in the sample. The TweetDispatcher is the public “endpoint” for sentiment analysis. [StatelessWorker] public interface ITweetDispatcherGrain : Orleans.IGrain { Task AddScore(int score, string[] hashtags, string tweet); Task<Totals[]> GetTotals(string[] hashtags); } Note that it is a stateless grain, and its main role is to pass the work to stateful grains for processing. AddScore takes a tweet, and parses out each hashtag for processing by the appropriate grain. GetTotals retrieves get the number of tweets that have included a specific list of hashtags. This grain exists in part to support the “batch processing” of several hashtags within a single tweet. One Orleans grain is created for each unique hashtag, and this grain is used to track the current sentiment score. [ExtendedPrimaryKey] public interface IHashtagGrain : Orleans.IGrain { Task AddScore(int score, string lastTweet); Task<Totals> GetTotals(); } Note that the ExtendedPrimaryKey attribute indicates that a string, in this case the twitter hashtag, is being used as a composite key for the grain, instead of the more usual Guid or long, which is a more natural fit for grains that have strings rather than numeric keys. The AddMethod updates the current state with the latest sentiment score, and GetTotals returns a Totals structure, with the breakdown of the sentiment analysis, along with the date stamp for the last processed tweet, and the test of the last tweet. The last tweet is kept just to allow the UI to display it, to help give the sentiment more context. When first activated, the grain tracks this activation by calling the IncrementCounter method on a Counter grain. public interface ICounter : Orleans.IGrain { Task IncrementCounter(); Task ResetCounter(); Task<int> GetTotalCounter(); } To increase performance, the counter grain only persists its internal state periodically, in this case, every 100 calls. The running total does not have to be one hundred percent accurate, so if the data were lost due to a silo failure between updates, that would not be critical. If this grain were to be called repeatedly from other grains, it could become a bottleneck, and some form of aggregation pattern would be needed, but as its only called once from each grain, upon grain initialization, this should not be an issue. Prerequisites The following must be installed prior to running the sample: Visual Studio 2013 Orleans SDK Node.js Tools for Visual Studio . Make sure to read the instructions and also install Node.js, not just the VS tools! A Windows Azure storage account A Twitter account and Twitter application development credentials. Sign up as a Twitter Developer and create an application. Make a note of the 'API key', 'API secret', 'Access token' and 'Access secret'. It is important to set the application permissions to include all rights, and then regenerating the keys and tokens before using them. If you don't, the client will silently fail. Running the Sample Open the OrleansTwitterDemo.sln file in Visual Studio 2013, and build the solution. Enter the details from Twitter into the TwitterClient\\app.js file. Start Azure Storage Emulator or replace \"UseDevelopmentStorage=true\" in DevTestServerConfiguration.xml in the Host project with your Azure Storage account Start the local Orleans Silo by running the Host project. Start the TwitterClient project. The Twitter Client should start, showing you every tweet it is consuming. Start the TwitterWebApplication project. Your browser should open on http://localhost:5190/ showing you a few preset hashtags you can monitor. Try adding a couple of hashtags to track using the browser UI. Got get a cup of coffee or do something else for a while, because it may take some time before the tags you care about are seen in the feed."
  },
  "Documentation/grains/scheduler.html": {
    "href": "Documentation/grains/scheduler.html",
    "title": "Scheduler | Microsoft Orleans Documentation",
    "keywords": "Scheduler Orleans Scheduler is a component within the Orleans runtime responsible for executing application code and parts of the runtime code to ensure the single threaded execution semantics . It implements a custom TPL Task scheduler. Orleans Task scheduler is a hierarchical 2 level scheduler. At the first level there is the global OrleansTaskScheduler that is responsible for execution of system activities. At the second level every grain activation has its own ActivationTaskScheduler , which provides the single threaded execution semantics. At a high level, the execution path is the following: A request arrives to the correct silo and the destination activation is found. A request is translated into a Task that is queued for execution by that activation, on its ActivationTaskScheduler. Any subsequent Task created as part of the grain method execution is natively enqueued to the same ActivationTaskScheduler, via the standard TaskScheduler mechanism. Every ActivationTaskScheduler has a queue of tasks queued for execution. Orleans Scheduler has a set of worker threads that are collectively used by all the activation schedulers. Those threads periodically scan all the scheduler queues for work to execute. A thread takes a queue (each queue is taken by one thread at a time) and starts executing Tasks in that queue in FIFO order. The combination of one thread at a time taking a queue and the thread executing Tasks sequentially is what provides the single threaded execution semantics. Work Items: Orleans uses a notion of Work Items to designate the entry point into the scheduler. Every new request is enqueued initially as a work item which simply wraps the execution of the first Task for that request. Work items simply provide more contextual information about the scheduling activity (the caller, the name of the activity, logging) and sometimes some extra work that has to be done on behalf of that scheduling activity (post invocation activity in Invoke work item). There are currently the following work item types: Invoke work item – this is the mostly frequently used work item type. It represents execution of an application request. Request/Response work items – executes a system request (request to a SystemTarget) TaskWorkItem – represent a Task queued to the top level OrleansTaskScheduler. Used instead of a direct Task just for convenience of data structures (more details below). WorkItemGroup – group of work items that share the same scheduler. Used to wrap a queue of Tasks for each ActivationTaskScheduler. ClosureWorkItem – a wrapper around a closure (arbitrary lambda) that is queued to the system context. Scheduling Context: Scheduling Context is a tag, just an opaque object that represents scheduling target – activation data, system target or system null context. High level Principles: Tasks are always queued to the correct scheduler 1.1 Tasks are never moved around from one scheduler to another. 1.2 We never create tasks on behalf of other tasks to execute them. 1.3 WorkItems are wrapped within Task (that is, in order to execute a work item, we create a Task whose lambda function will just run the work item lambda). By always going via tasks we ensure that any activity is executed via an appropriate Task scheduler. Tasks are executed on the scheduler where they were queued by using base.TryExecute (and not by RunSynchronously) There is a one to one mapping between ATS, WorkItem Group and Scheduling Context: 3.1 Activation Task Scheduler (ATS) is a custom TPL scheduler. We keep ATS thin and store all the data in WorkItemGroup. ATS points to its WorkItemGroup. 3.2 WorkItem Group is the actual holder (data object) of the activation Tasks. The Tasks are stored in a List - the queue of all tasks for its ATS. WorkItemGroup points back to its ATS. Data Flow and Execution of Tasks and Work items: The entry point is always a work item enqueued into OrleansTaskScheduler. It can be one of the Invoke/Request/Response/Closure WorkItem. Wrapped into a Task and enqueued into the correct ActivationTaskScheduler based on the context via Task.Start. A Task that is queued to its ActivationTaskScheduler is put into the WorkItemGroup queue. When a Task is put into a WorkItemGroup queue, WorkItemGroup makes sure it appears in OrleansTaskScheduler global RunQueue. RunQueue is the global queue of runnable WorkItemGroups, those that have at least one Task queued, and thus ready to be executed. Worker threads scan the RunQueue of OrleansTaskScheduler which hold WorkItemGroups and call WorkItemGroups.Execute WorkItemGroups.Execute scans the queue of its tasks and executes them via ActivationTaskScheduler.RunTask(Task) 6.1 ActivationTaskScheduler.RunTask(Task) calls base.TryExecute. 6.2 Task that were enqueued directly to the scheduler via TPL will just execute 6.3 Tasks that wrap work items will call workItem.Execute which will execute the Closure work item delegate. Low level design – Work Items: Queueing work items to OrleansTaskScheduler is how the whole chain of execution for every request starts in the Orleans runtime. This is our entry point into the Scheduler. Work items are first submitted to OrleansTaskScheduler (since this is the interface presented to the rest of the system). 2.1 Only closure/invoke/resume work items can be submitted this way. 2.2 TaskWorkItem cannot be submitted to OrleansTaskScheduler directly (read more below on handling of TaskWorkItem). Every work item must be wrapped into Task and enqueued to the right scheduler via Task.Start. 3.1 This will make sure the TaskScheduler.Current is set correctly on any Task that is created implicitly during execution of this workItem. 3.2 Wrapping is done by creating a Task via WrapWorkItemAsTask that will execute the work item and enqueuing it to the right scheduler via Task.Start(scheduler). 3.3 Work items for the null context are queued to OrleansTaskScheduler. 3.4 Work items for non-null contexts are queued to ActivationTaskScheduler Low level design – Queueing Tasks: Tasks are queued directly to the right scheduler 1.1 Tasks are queued implicitly by TPL via protected override void QueueTask(Task task) 1.2 A Task that has a non-null context is always enqueued to ActivationTaskScheduler 1.3 A Task that has the null context is always enqueued to OrleansTaskScheduler Queueing Tasks to ActivationTaskScheduler: 2.1 We never wrap a Task in another Task. A Task gets added directly to the WorkItem Group queue Queueing Tasks to OrleansTaskScheduler: 3.1 When a Task is enqueued to the OrleansTaskScheduler, we wrap it into a TaskWorkItem and put it into this scheduler’s queue of work items. 3.2 This is just a matter of data structures, nothing inherent about it: 3.3 OrleansTaskScheduler usually holds work item groups to schedule them, so its RunQueue has a BlockingCollection . 3.4 Since tasks to the null context are also queued to OrleansTaskScheduler, we reuse the same data structure, thus we have to wrap each Task in a TaskWorkItem. 3.5 We should be able to get rid of this wrapping completely by adjusting the RunQueue data structure. This may simplify the code a bit, but in general should not matter. Also, in the future we should move away from the null context anyway, so this issue will be gone anyway Inlining tasks: Since Tasks are always queued to the right scheduler, in theory it should always be safe to inline any Task."
  },
  "Documentation/grains/request_context.html": {
    "href": "Documentation/grains/request_context.html",
    "title": "Request Context | Microsoft Orleans Documentation",
    "keywords": "Request Context RequestContext is an Orleans feature that allows application metadata, such as a trace ID, to flow with requests. Application metadata may be added on the client; it will flow with Orleans requests to the receiving grain. The feature is implemented by a public static class, RequestContext, in the Orleans namespace. This class exposes two simple methods: void Set(string key, object value) is used to store a value in the request context. The value can be any Serializable type. Object Get(string key) is used to retrieve a value from the current request context. The backing storage for RequestContext is thread-static. When a thread (whether client-side or within Orleans) sends a request, the contents of the sending thread’s RequestContext is included with the Orleans message for the request; when the grain code receives the request, that metadata is accessible from the local RequestContext. If the grain code does not modify the RequestContext, then any grain it makes a request of will receive the same metadata, and so on. Application metadata also is maintained when you schedule a future computation using StartNew or ContinueWith; in both cases, the continuation will execute with the same metadata as the scheduling code had at the moment the computation was scheduled (that is, the system makes a copy of the current metadata and passes that to the continuation, so changes after the call to StartNew or ContinueWith will not be seen by the continuation). Note that application metadata does not flow back with responses; that is, code that runs as a result of a response being received, either within a ContinueWith continuation or after a call to Wait or GetValue, will still run within the current context that was set by the original request. For example, to set a trace ID in the client to a new GUID, one would simply call: RequestContext.Set(\"TraceId\", new Guid()); Within grain code (or other code that runs within Orleans on a scheduler thread), the trace ID of the original client request could be used, for instance, when writing a log: Logger.Info(\"Currently processing external request {0}\", RequestContext.Get(\"TraceId\")); While any serializable object may be sent as application metadata, it’s worth mentioning that large or complex objects may add noticeable overhead to message serialization time. For this reason, the use of simple types (strings, GUIDs, or numeric types) is recommended."
  },
  "Documentation/grains/interceptors.html": {
    "href": "Documentation/grains/interceptors.html",
    "title": "Grain Call Filters | Microsoft Orleans Documentation",
    "keywords": "Grain Call Filters Grain call filters provide a means for intercepting grain calls. Filters can execute code both before and after a grain call. Multiple filters can be installed simultaneously. Filters are asynchronous and can modify RequestContext , arguments, and the return value of the method being invoked. Filters can also inspect the MethodInfo of the method being invoked on the grain class and can be used to throw or handle exceptions. Some example usages of grain call filters are: Authorization: a filter can inspect the method being invoked and the arguments or some authorization information in the RequestContext to determine whether or not to allow the call to proceed. Logging/Telemetry: a filter can log information and capture timing data and other statistics about method invocation. Error Handling: a filter can intercept exceptions thrown by a method invocation and transform it into another exception or handle the exception as it passes through the filter. Filters come in two flavors: Incoming call filters Outgoing call filters Incoming call filters are executed when receiving a call. Outgoing call filters are executed when making a call. Incoming Call Filters Incoming grain call filters implement the IIncomingGrainCallFilter interface, which has one method: public interface IIncomingGrainCallFilter { Task Invoke(IIncomingGrainCallContext context); } The IIncomingGrainCallContext argument passed to the Invoke method has the following shape: public interface IIncomingGrainCallContext { /// <summary> /// Gets the grain being invoked. /// </summary> IAddressable Grain { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the interface method being invoked. /// </summary> MethodInfo InterfaceMethod { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the implementation method being invoked. /// </summary> MethodInfo ImplementationMethod { get; } /// <summary> /// Gets the arguments for this method invocation. /// </summary> object[] Arguments { get; } /// <summary> /// Invokes the request. /// </summary> Task Invoke(); /// <summary> /// Gets or sets the result. /// </summary> object Result { get; set; } } The IIncomingGrainCallFilter.Invoke(IIncomingGrainCallContext) method must await or return the result of IIncomingGrainCallContext.Invoke() to execute the next configured filter and eventually the grain method itself. The Result property can be modified after awaiting the Invoke() method. The ImplementationMethod property returns the MethodInfo of the implementation class. The MethodInfo of the interface method can be accessed using the InterfaceMethod property. Grain call filters are called for all method calls to a grain and this includes calls to grain extensions (implementations of IGrainExtension ) which are installed in the grain. For example, grain extensions are used to implement Streams and Cancellation Tokens. Therefore, it should be expected that the value of ImplementationMethod is not always a method in the grain class itself. Configuring Incoming Grain Call Filters Implementations of IIncomingGrainCallFilter can either be registered as silo-wide filters via Dependency Injection or they can be registered as grain-level filters via a grain implementing IIncomingGrainCallFilter directly. Silo-wide Grain Call Filters A delegate can be registered as a silo-wide grain call filters using Dependency Injection like so: siloHostBuilder.AddIncomingGrainCallFilter(async context => { // If the method being called is 'MyInterceptedMethod', then set a value // on the RequestContext which can then be read by other filters or the grain. if (string.Equals(context.InterfaceMethod.Name, nameof(IMyGrain.MyInterceptedMethod))) { RequestContext.Set(\"intercepted value\", \"this value was added by the filter\"); } await context.Invoke(); // If the grain method returned an int, set the result to double that value. if (context.Result is int resultValue) context.Result = resultValue * 2; }); Similarly, a class can be registered as a grain call filter using the AddIncomingGrainCallFilter helper method. Here is an example of a grain call filter which logs the results of every grain method: public class LoggingCallFilter : IIncomingGrainCallFilter { private readonly Logger log; public LoggingCallFilter(Factory<string, Logger> loggerFactory) { this.log = loggerFactory(nameof(LoggingCallFilter)); } public async Task Invoke(IIncomingGrainCallContext context) { try { await context.Invoke(); var msg = string.Format( \"{0}.{1}({2}) returned value {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), context.Result); this.log.Info(msg); } catch (Exception exception) { var msg = string.Format( \"{0}.{1}({2}) threw an exception: {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), exception); this.log.Info(msg); // If this exception is not re-thrown, it is considered to be // handled by this filter. throw; } } } This filter can then be registered using the AddIncomingGrainCallFilter extension method: siloHostBuilder.AddIncomingGrainCallFilter<LoggingCallFilter>(); Alternatively, the filter can be registered without the extension method: siloHostBuilder.ConfigureServices( services => services.AddSingleton<IIncomingGrainCallFilter, LoggingCallFilter>()); Per-grain Grain Call Filters A grain class can register itself as a grain call filter and filter any calls made to it by implementing IIncomingGrainCallFilter like so: public class MyFilteredGrain : Grain, IMyFilteredGrain, IIncomingGrainCallFilter { public async Task Invoke(IIncomingGrainCallContext context) { await context.Invoke(); // Change the result of the call from 7 to 38. if (string.Equals(context.InterfaceMethod.Name, nameof(this.GetFavoriteNumber))) { context.Result = 38; } } public Task<int> GetFavoriteNumber() => Task.FromResult(7); } In the above example, all calls to the GetFavoriteNumber method will return 38 instead of 7 , because the return value has been altered by the filter. Another use case for filters is in access control, as in this example: [AttributeUsage(AttributeTargets.Method)] public class AdminOnlyAttribute : Attribute { } public class MyAccessControlledGrain : Grain, IMyFilteredGrain, IIncomingGrainCallFilter { public Task Invoke(IIncomingGrainCallContext context) { // Check access conditions. var isAdminMethod = context.ImplementationMethod.GetCustomAttribute<AdminOnlyAttribute>(); if (isAdminMethod && !(bool) RequestContext.Get(\"isAdmin\")) { throw new AccessDeniedException($\"Only admins can access {context.ImplementationMethod.Name}!\"); } return context.Invoke(); } [AdminOnly] public Task<int> SpecialAdminOnlyOperation() => Task.FromResult(7); } In the above example, the SpecialAdminOnlyOperation method can only be called if \"isAdmin\" is set to true in the RequestContext . In this way, grain call filters can be used for authorization. In this example, it is the responsibility of the caller to ensure that the \"isAdmin\" value is set correctly and that authentication is performed correctly. Note that the [AdminOnly] attribute is specified on the grain class method. This is because the ImplementationMethod property returns the MethodInfo of the implementation, not the interface. The filter could also check the InterfaceMethod property. Ordering of Grain Call Filters Grain call filters follow a defined ordering: IIncomingGrainCallFilter implementations configured in the dependency injection container, in the order in which they are registered. Grain-level filter, if the grain implements IIncomingGrainCallFilter . Grain method implementation or grain extension method implementation. Each call to IIncomingGrainCallContext.Invoke() encapsulates the next defined filter so that each filter has a chance to execute code before and after the next filter in the chain and eventually the grain method itself. Outgoing Call Filters Outgoing grain call filters are similar to incoming grain call filters with the major difference being that they are invoked on the caller (client) rather than the callee (grain). Outgoing grain call filters implement the IOutgoingGrainCallFilter interface, which has one method: public interface IOutgoingGrainCallFilter { Task Invoke(IOutgoingGrainCallContext context); } The IOutgoingGrainCallContext argument passed to the Invoke method has the following shape: public interface IOutgoingGrainCallContext { /// <summary> /// Gets the grain being invoked. /// </summary> IAddressable Grain { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the interface method being invoked. /// </summary> MethodInfo InterfaceMethod { get; } /// <summary> /// Gets the arguments for this method invocation. /// </summary> object[] Arguments { get; } /// <summary> /// Invokes the request. /// </summary> Task Invoke(); /// <summary> /// Gets or sets the result. /// </summary> object Result { get; set; } } The IOutgoingGrainCallFilter.Invoke(IOutgoingGrainCallContext) method must await or return the result of IOutgoingGrainCallContext.Invoke() to execute the next configured filter and eventually the grain method itself. The Result property can be modified after awaiting the Invoke() method. The MethodInfo of the interface method being called can be accessed using the InterfaceMethod property. Outgoing grain call filters are invoked for all method calls to a grain and this includes calls to system methods made by Orleans. Configuring Outgoing Grain Call Filters Implementations of IOutgoingGrainCallFilter can either be registered on both silos and clients using Dependency Injection. A delegate can be registered as a call filter like so: builder.AddOutgoingGrainCallFilter(async context => { // If the method being called is 'MyInterceptedMethod', then set a value // on the RequestContext which can then be read by other filters or the grain. if (string.Equals(context.InterfaceMethod.Name, nameof(IMyGrain.MyInterceptedMethod))) { RequestContext.Set(\"intercepted value\", \"this value was added by the filter\"); } await context.Invoke(); // If the grain method returned an int, set the result to double that value. if (context.Result is int resultValue) context.Result = resultValue * 2; }); In the above code, builder may be either an instance of ISiloHostBuilder or IClientBuilder . Similarly, a class can be registered as an outgoing grain call filter. Here is an example of a grain call filter which logs the results of every grain method: public class LoggingCallFilter : IOutgoingGrainCallFilter { private readonly Logger log; public LoggingCallFilter(Factory<string, Logger> loggerFactory) { this.log = loggerFactory(nameof(LoggingCallFilter)); } public async Task Invoke(IOutgoingGrainCallContext context) { try { await context.Invoke(); var msg = string.Format( \"{0}.{1}({2}) returned value {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), context.Result); this.log.Info(msg); } catch (Exception exception) { var msg = string.Format( \"{0}.{1}({2}) threw an exception: {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), exception); this.log.Info(msg); // If this exception is not re-thrown, it is considered to be // handled by this filter. throw; } } } This filter can then be registered using the AddOutgoingGrainCallFilter extension method: builder.AddOutgoingGrainCallFilter<LoggingCallFilter>(); Alternatively, the filter can be registered without the extension method: builder.ConfigureServices( services => services.AddSingleton<IOutgoingGrainCallFilter, LoggingCallFilter>()); As with the delegate call filter example, builder may be an instance of either ISiloHostBuiler or IClientBuilder . Use Cases Exception Conversion When an exception which has been thrown from the server is getting deserialized on the client, you may sometimes get the following exception instead of the actual one: TypeLoadException: Could not find Whatever.dll. This happens if the assembly containing the exception is not available to the client. For example, say you are using Entity Framework in your grain implementations; then it is possible that an EntityException is thrown. The client on the other hand does not (and should not) reference EntityFramework.dll since it has no knowledge about the underlying data access layer. When the client tries to deserialize the EntityException , it will fail due to the missing DLL; as a consequence a TypeLoadException is thrown hiding the original EntityException . One may argue that this is pretty okay, since the client would never handle the EntityException ; otherwise it would have to reference EntityFramework.dll . But what if the client wants at least to log the exception? The problem is that the original error message is lost. One way to workaround this issue is to intercept server-side exceptions and replace them by plain exceptions of type Exception if the exception type is presumably unknown on the client side. However, there is one important thing we have to keep in mind: we only want to replace an exception if the caller is the grain client . We don't want to replace an exception if the caller is another grain (or the Orleans infrastructure which is making grain calls, too; e.g. on the GrainBasedReminderTable grain). On the server side this can be done with a silo-level interceptor: public class ExceptionConversionFilter : IIncomingGrainCallFilter { private static readonly HashSet<string> KnownExceptionTypeAssemblyNames = new HashSet<string> { typeof(string).Assembly.GetName().Name, \"System\", \"System.ComponentModel.Composition\", \"System.ComponentModel.DataAnnotations\", \"System.Configuration\", \"System.Core\", \"System.Data\", \"System.Data.DataSetExtensions\", \"System.Net.Http\", \"System.Numerics\", \"System.Runtime.Serialization\", \"System.Security\", \"System.Xml\", \"System.Xml.Linq\", \"MyCompany.Microservices.DataTransfer\", \"MyCompany.Microservices.Interfaces\", \"MyCompany.Microservices.ServiceLayer\" }; public async Task Invoke(IIncomingGrainCallContext context) { var isConversionEnabled = RequestContext.Get(\"IsExceptionConversionEnabled\") as bool? == true; if (!isConversionEnabled) { // If exception conversion is not enabled, execute the call without interference. await context.Invoke(); return; } RequestContext.Remove(\"IsExceptionConversionEnabled\"); try { await context.Invoke(); } catch (Exception exc) { var type = exc.GetType(); if (KnownExceptionTypeAssemblyNames.Contains(type.Assembly.GetName().Name)) { throw; } // Throw a base exception containing some exception details. throw new Exception( string.Format( \"Exception of non-public type '{0}' has been wrapped.\" + \" Original message: <<<<----{1}{2}{3}---->>>>\", type.FullName, Environment.NewLine, exc, Environment.NewLine)); } } } This filter can then be registered on the silo: siloHostBuilder.AddIncomingGrainCallFilter<ExceptionConversionFilter>(); Enable the filter for calls made by the client by adding an outgoing call filter: clientBuilder.AddOutgoingGrainCallFilter(context => { RequestContext.Set(\"IsExceptionConversionEnabled\", true); return context.Invoke(); }); This way the client tells the server that it wants to use exception conversion. Calling Grains from Interceptors It is possible to make grain calls from an interceptor by injecting IGrainFactory into the interceptor class: private readonly IGrainFactory grainFactory; public CustomCallFilter(IGrainFactory grainFactory) { this.grainFactory = grainFactory; } public async Task Invoke(IIncomingGrainCallContext context) { // Hook calls to any grain other than ICustomFilterGrain implementations. // This avoids potential infinite recursion when calling OnReceivedCall() below. if (!(context.Grain is ICustomFilterGrain)) { var filterGrain = this.grainFactory.GetGrain<ICustomFilterGrain>(context.Grain.GetPrimaryKeyLong()); // Perform some grain call here. await filterGrain.OnReceivedCall(); } // Continue invoking the call on the target grain. await context.Invoke(); }"
  },
  "Documentation/grains/index.html": {
    "href": "Documentation/grains/index.html",
    "title": "Overview - Grains | Microsoft Orleans Documentation",
    "keywords": "This is the overview page about Grains ///TODO"
  },
  "Documentation/streaming/streams_implementation.html": {
    "href": "Documentation/streaming/streams_implementation.html",
    "title": "Streams Implementation Details | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Implementation Details This section provides a high level overview of Orleans Stream implementation. It describes concepts and details that are not visible on the application level. If you only plan to use streams, you do not have to read this section. Terminology : We refer by the word \"queue\" to any durable storage technology that can ingest stream events and allows either to pull events or provides a push-based mechanism to consume events. Usually, to provide scalability, those technologies provide sharded/partitioned queues. For example, Azure Queues allow to create multiple queues, Event Hubs have multiple hubs, Kafka topics, ... Persistent Streams All Orleans Persistent Stream Providers share a common implementation PersistentStreamProvider . This generic stream provider needs be configured with a with a technology specific IQueueAdapterFactory . For instance, for testing purposes we have queue adapters that generate their own test data rather than reading the from a queue. The below code shows how we configure a persistent stream provider to use our custom (generator) queue adapter. It does this by configuring the persistent stream provider with a factory function use to create the adapter. hostBuilder.AddPersistentStreams(StreamProviderName, GeneratorAdapterFactory.Create); When stream producers generate a new stream item and calls stream.OnNext() , Orleans Streaming Runtime invokes the appropriate method on the IQueueAdapter of that stream provider which enqueues the item directly onto the appropriate queue. Pulling Agents At the heart of the Persistent Stream Provider are the pulling agents. Pulling agents pull events from a set of durable queues and deliver them to the application code in grains that consumes them. One can think of the pulling agents as a distributed \"micro-service\" -- a partitioned, highly available, and elastic distributed component. The pulling agents run inside the same silos that host application grains and are fully managed by the Orleans Streaming Runtime. StreamQueueMapper and StreamQueueBalancer Pulling agents are parametrized with IStreamQueueMapper and IStreamQueueBalancer . IStreamQueueMapper provides a list of all queues and is also responsible for mapping streams to queues. That way, the producer side of the Persistent Stream Provider know which queue to enqueue the message into. IStreamQueueBalancer expresses the way queues are balanced across Orleans silos and agents. The goal is to assign queues to agents in a balanced way, to prevent bottlenecks and support elasticity. When new silo is added to the Orleans cluster, queues are automatically rebalanced across the old and new silos. StreamQueueBalancer allows to customize that process. Orleans has a number of built in StreamQueueBalancers, to support different balancing scenarios (large and small number of queues) and different environments (Azure, on prem, static). Using the test generator example from above, the below code shows how one could configure the queue mapper and queue balancer. hostBuilder .AddPersistentStreams(StreamProviderName, GeneratorAdapterFactory.Create, providerConfigurator=>providerConfigurator .Configure<HashRingStreamQueueMapperOptions>(ob=>ob.Configure( options=>{ options.TotalQueueCount = 8; })) .UseDynamicClusterConfigDeploymentBalancer() ); The above code configures the GeneratorAdapter to use a queue mapper with 8 queues, and balences the queues across the cluster using the DynamicClusterConfigDeploymentBalancer. Pulling Protocol Every silo runs a set of pulling agents, every agent is pulling from one queue. Pulling agents themselves are implemented by the internal runtime component, called SystemTarget . SystemTargets are essentially runtime grains, are subject to single threaded concurrency, can use regular grain messaging and are as lightweight as grains. As opposite to grain, SystemTargets are not virtual: they are explicitly created (by the runtime) and are also not location transparent. By implementing pulling agents as SystemTargets Orleans Streaming Runtime can rely on a lot of built-in Orleans features and can also scale to a very large number of queues, since creating a new pulling agent is as cheap as creating a new grain. Every pulling agent runs periodic timer that pulls from the queue (by invoking IQueueAdapterReceiver ) GetQueueMessagesAsync() method. The returned messages are put in the internal per-agent data structure called IQueueCache . Every message is inspected to find out its destination stream. The agent uses the Pub Sub to find out the list of stream consumers that subscribed to this stream. Once the consumer list if retrieved, the agent stores it locally (in its pub-sub cache) so it does not need to consult with Pub Sub on every message. The agent also subscribes with the pub-sub to receive notification of any new consumers that subscribe to that stream. This handshake between the agent and the pub-sub guarantees strong streaming subscription semantics : once the consumer has subscribed to the stream it will see all events that were generated after it has subscribed (in addition, using StreamSequenceToken allows to subscribe in the past). Queue Cache IQueueCache is an internal per-agent data structure that allows to decouple bringing new events from the queue from delivering them to consumers. It also allows to decouple delivery to different streams and to different consumers. Imagine a situation when one stream has 3 stream consumers and one of them is slow. If care not taken, it is possible that this slow consumer will impact agent's progress, slowing the consumption of other consumers of that stream, and even potentially slowing the de-queuing and delivering of events for other stream. To prevent that and allow maximum parallelism in the agent, we use IQueueCache . IQueueCache buffers stream events and provides a way to the agent to deliver events to each consumer at its pace. The per-consumer delivery is implemented by the internal component called IQueueCacheCursor , which tracks per consumer progress. That way each consumer receives events at its own pace :fast consumers receive events as quickly as they are dequeued from the queue, while slow consumers receive them later on. Once the message was delivered to all consumers, it can be deleted from the cache. Backpressure Backpressure in Orleans Streaming Runtime applies in two places: bringing stream events from the queue to the agent and delivering the events from the agent to stream consumers . The latter is provided by the built-in Orleans messaging delivery mechanism. Every stream event is delivered from the agent to consumers via the standard Orleans grain messaging, one at a time. That is, the agents sends one event (or a limited size batch of events) to each individual stream consumer and awaits this call. The next event will not start being delivered until the Task for the previous event was resolved or broken. That way we naturally limit the per-consumer delivery rate to one message at a time. With regard to bringing stream events from the queue to the agent Orleans Streaming provides a new special Backpressure mechanism. Since the agent decouples de-queuing of events from the queue and delivering them to consumers, it is possible that a single slow consumer will fall behind so much that the IQueueCache will fill up. To prevent IQueueCache from growing indefinitely, we limit its size (the size limit is configurable). However, the agent never throws away undelivered events. Instead, when the cache starts to fill up, the agents slows the rate of dequeing events from the queue. That way, we can \"ride\" the slow delivery periods by adjusting the rate at which we consume from the queue (\"backpressure\") and get back into fast consumption rate later on. To detect the \"slow delivery\" valleys the IQueueCache uses an internal data structure of cache buckets that track the progress of delivery of events to individual stream consumer. This results in a very responsive and self-adjusting systems."
  },
  "Documentation/core_concepts/what_are_orleans_packages.html": {
    "href": "Documentation/core_concepts/what_are_orleans_packages.html",
    "title": "Orleans NuGet Packages | Microsoft Orleans Documentation",
    "keywords": "Orleans NuGet packages as of v2.0.0-rc2 Key Packages There are 5 key NuGet packages you will need to use in most scenarios: Microsoft Orleans Core Abstractions PM> Install-Package Microsoft.Orleans.Core.Abstractions Contains Orleans.Core.Abstractions.dll, which defines Orleans public types that are needed for developing application code (grain interfaces and classes). This package is needs to be directly or indirectly referenced by any Orleans project. Add it to your projects that define grain interfaces and classes. Microsoft Orleans Build-time Code Generation PM> Install-Package Microsoft.Orleans.OrleansCodeGenerator.Build Build time support for grain interfaces and implementation projects. Add it to your grain interfaces and implementation projects to enable code generation of grain references and serializers. Microsoft Orleans Server Libraries PM> Install-Package Microsoft.Orleans.Server A meta-package for easily building and starting a silo. Includes the following packages: Microsoft.Orleans.Core.Abstractions Microsoft.Orleans.Core Microsoft.Orleans.OrleansRuntime Microsoft.Orleans.OrleansProviders Microsoft Orleans Client Libraries PM> Install-Package Microsoft.Orleans.Client A meta-package for easily building and starting an Orleans client (frontend). Includes the following packages: Microsoft.Orleans.Core.Abstractions Microsoft.Orleans.Core Microsoft.Orleans.OrleansProviders Microsoft Orleans Core Library PM> Install-Package Microsoft.Orleans.Core Contains implementation for most Orleans public types used by application code and Orleans clients (frontends). Reference it for building libraries and client applications that use Orleans types but don't deal with hosting or silos. Included in Microsoft.Orleans.Client and Microsoft.Orleans.Server meta-packages, and is referenced, directly or indirectly, by most other packages. Hosting Microsoft Orleans Runtime PM> Install-Package Microsoft.Orleans.OrleansRuntime Library for configuring and starting a silo. Reference it in your silo host project. Included in Microsoft.Orleans.Server meta-package. Microsoft Orleans Runtime Abstractions PM> Install-Package Microsoft.Orleans.Runtime.Abstractions Contains interfaces and abstractions for types implemented in Microsoft.Orleans.OrleansRuntime. Microsoft Orleans Hosting on Azure Cloud Services PM> Install-Package Microsoft.Orleans.Hosting.AzureCloudServices Contains helper classes for hosting silos and Orleans clients as Azure Cloud Services (Worker Roles and Web Roles). Microsoft Orleans Service Fabric Hosting Support PM> Install-Package Microsoft.Orleans.Hosting.ServiceFabric Contains helper classes for hosting silos as a stateless Service Fabric service. Clustering Providers The below packages include plugins for persisting cluster membership data in various storage technologies. Microsoft Orleans clustering provider for Azure Table Storages PM> Install-Package Microsoft.Orleans.Clustering.AzureStorage Includes the plugin for using Azure Tables for storing cluster membership data. Microsoft Orleans clustering provider for ADO.NET Providers PM> Install-Package Microsoft.Orleans.Clustering.AdoNet Includes the plugin for using ADO.NET for storing cluster membership data in one of the supported databases. Microsoft Orleans Consul Utilities PM> Install-Package Microsoft.Orleans.OrleansConsulUtils Includes the plugin for using Consul for storing cluster membership data. Microsoft Orleans ZooKeeper Utilities PM> Install-Package Microsoft.Orleans.OrleansZooKeeperUtils Includes the plugin for using ZooKeeper for storing cluster membership data. Microsoft Orleans clustering provider for AWS DynamoDB PM> Install-Package Microsoft.Orleans.Clustering.DynamoDB Includes the plugin for using AWS DynamoDB for storing cluster membership data. Reminder Providers The below packages include plugins for persisting reminders in various storage technologies. Microsoft Orleans Reminders Azure Table Storage PM> Install-Package Microsoft.Orleans.Reminders.AzureStorage Includes the plugin for using Azure Tables for storing cluster membership data. Microsoft Orleans Reminders ADO.NET Providers PM> Install-Package Microsoft.Orleans.Reminders.AdoNet Includes the plugin for using ADO.NET for storing reminders in one of the supported databases. Microsoft Orleans reminders provider for AWS DynamoDB PM> Install-Package Microsoft.Orleans.Reminders.DynamoDB Includes the plugin for using AWS DynamoDB for storing reminders. Grain Storage Providers The below packages include plugins for persisting grain state in various storage technologies. Microsoft Orleans Persistence Azure Storage PM> Install-Package Microsoft.Orleans.Persistence.AzureStorage Includes the plugins for using Azure Tables or Azure Blobs for storing grain state. Microsoft Orleans Persistence ADO.NET Providers PM> Install-Package Microsoft.Orleans.Persistence.AdoNet Includes the plugin for using ADO.NET for storing grain state in one of the supported databases. Microsoft Orleans Persistence DynamoDB PM> Install-Package Microsoft.Orleans.Persistence.DynamoDB Includes the plugin for using AWS DynamoDB for storing grain state. Stream Providers The below packages include plugins for delivering streaming events. Microsoft Orleans ServiceBus Utilities PM> Install-Package Microsoft.Orleans.OrleansServiceBus Includes the stream provider for Azure Event Hubs. Microsoft Orleans Streaming Azure Storage PM> Install-Package Microsoft.Orleans.Streaming.AzureStorage Includes the stream provider for Azure Queues. Microsoft Orleans Streaming AWS SQS PM> Install-Package Microsoft.Orleans.Streaming.SQS Includes the stream provider for AWS SQS service. Microsoft Orleans Google Cloud Platform Utilities PM> Install-Package Microsoft.Orleans.OrleansGCPUtils Includes the stream provider for GCP PubSub service. Additional Packages Microsoft Orleans Code Generation PM> Install-Package Microsoft.Orleans.OrleansCodeGenerator Includes the run time code generator. Microsoft Orleans Event-Sourcing PM> Install-Package Microsoft.Orleans.EventSourcing Contains a set of base types for creating grain classes with event-sourced state. Development and Testing Microsoft Orleans Providers PM> Install-Package Microsoft.Orleans.OrleansProviders Contains a set of persistence and stream providers that keep data in memory. Intended for testing. In general, not recommended for production use, unless data loss is care of a silo failure is acceptable. Microsoft Orleans Testing Host Library PM> Install-Package Microsoft.Orleans.TestingHost Includes the library for hosting silos and clients in a testing project. Legacy Packages The below packages are for backward compatibility and easier migration from Orleans 1.x to 2.0 Microsoft Orleans Core Legacy Library PM> Install-Package Microsoft.Orleans.Core.Legacy Contains 1.x style client configuration objects and logging APIs. Makes migration easier by not requiring to change client code to the new client builder API and logging. Microsoft Orleans Runtime Legacy Library PM> Install-Package Microsoft.Orleans.Runtime.Legacy Contains 1.x style silo configuration objects and hosting APIs. Makes migration easier by not requiring to change silo configuration and hosting code to the new silo host builder API. Microsoft Orleans Azure Utilities PM> Install-Package Microsoft.Orleans.OrleansAzureUtils A meta-package that includes all packages with Azure providers to simplify upgrading of 1.x projects. Microsoft Orleans Sql Utilities PM> Install-Package Microsoft.Orleans.OrleansSqlUtils A meta-package that includes all packages with ADO.NET providers to simplify upgrading of 1.x projects. Microsoft Orleans AWS Utilities PM> Install-Package Microsoft.Orleans.OrleansAWSUtils A meta-package that includes all packages with AWS providers to simplify upgrading of 1.x projects. Microsoft Orleans Service Fabric Support PM> Install-Package Microsoft.Orleans.ServiceFabric A meta-package that includes all packages with Service Fabric providers to simplify upgrading of 1.x projects. Microsoft Orleans Management Tool PM> Install-Package Microsoft.Orleans.OrleansManager Includes Orleans management tool - OrleansManager.exe. Serializers Microsoft Orleans Bond Serializer PM> Install-Package Microsoft.Orleans.Serialization.Bond Includes support for Bond serializer . Microsoft Orleans Google Utilities PM> Install-Package Microsoft.Orleans.OrleansGoogleUtils Includes Google Protocol Buffers serializer. Microsoft Orleans protobuf-net Serializer PM> Install-Package Microsoft.Orleans.ProtobufNet Includes protobuf-net version of Protocol Buffers serializer. Telemetry Microsoft Orleans Telemetry Consumer - Performance Counters PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.Counters Windows Performance Counters implementation of Orleans Telemetry API. Microsoft Orleans Telemetry Consumer - Azure Application Insights PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.AI Includes the telemetry consumer for Azure Application Insights. Microsoft Orleans Telemetry Consumer - NewRelic PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.NewRelic Includes the telemetry consumer for NewRelic. Tools Microsoft Orleans Performance Counter Tool PM> Install-Package Microsoft.Orleans.CounterControl Includes OrleansCounterControl.exe, which registers Windows performance counter categories for Orleans statistics and for deployed grain classes. Requires elevation. Can be executed in Azure as part of a role startup task. Transactions Microsoft Orleans Transactions support PM> Install-Package Microsoft.Orleans.Transactions Includes support for cross-grain transactions (beta). Microsoft Orleans Transactions on Azure PM> Install-Package Microsoft.Orleans.Transactions.AzureStorage Includes a plugin for persisting transaction log in Azure Table (beta)."
  },
  "Documentation/core_concepts/index.html": {
    "href": "Documentation/core_concepts/index.html",
    "title": "Core Concepts | Microsoft Orleans Documentation",
    "keywords": "This is the overview page about Core Concepts - only pages with information about grains, silos, cluster, clients, packages, and code generation go here."
  },
  "Documentation/core_concepts/code_generation.html": {
    "href": "Documentation/core_concepts/code_generation.html",
    "title": "Code Generation | Microsoft Orleans Documentation",
    "keywords": "Code Generation The Orleans runtime makes use of generated code in order to ensure proper serialization of types that are used across the cluster as well as for generating boilerplate which abstracts away the implementation details of method shipping, exception propagation, and other internal runtime concepts. Enabling Code Generation Code generation can be performed either when your projects are being built or when your application initializes. During Build The preferred method for performing code generation is at build time. Enable build time code generation by installing the Microsoft.Orleans.OrleansCodeGenerator.Build package into all projects which contain grains, grain interfaces, custom serializers, or types which are sent between grains. Installing this package injects a target into the project which will generate code at build time. The Microsoft.Orleans.OrleansCodeGenerator.Build package only supports C# projects. Other languages are supported either using the Microsoft.Orleans.OrleansCodeGenerator package described below, or by creating a C# project which can act as the target for code generated from assemblies written in other languages. Additional diagnostics can be emitted at build-time by specifying value for OrleansCodeGenLogLevel in the target project's csproj file. For example, <OrleansCodeGenLogLevel>Trace</OrleansCodeGenLogLevel> . During Initialization Code generation can be performed during initialization on the client and silo by installing the Microsoft.Orleans.OrleansCodeGenerator package and using the IApplicationPartManager.WithCodeGeneration extension method. builder.ConfigureApplicationParts( parts => parts .AddApplicationPart(typeof(IRuntimeCodeGenGrain).Assembly) .WithCodeGeneration()); In the above example, builder may be an instance of either ISiloHostBuilder or IClientBuilder . An optional ILoggerFactory instance can be passed to WithCodeGeneration to enable logging during code generation, for example: ILoggerFactory codeGenLoggerFactory = new LoggerFactory(); codeGenLoggerFactory.AddProvider(new ConsoleLoggerProvider()); builder.ConfigureApplicationParts( parts => parts .AddApplicationPart(typeof(IRuntimeCodeGenGrain).Assembly) .WithCodeGeneration(codeGenLoggerFactory)); Influencing Code Generation Generate code for a specific type Code is automatically generated for grain interfaces, grain classes, grain state, and types passed as arguments in grain methods. If a type does not fit this criteria, the following methods can be used to further guide code generation. Adding [Serializable] to a type instructs the code generator to generate a serializer for that type. Adding [assembly: GenerateSerializer(Type)] to a project instructs the code generator to treat that type as serializable and will cause an error if a serializer could not be generated for that type, for example because the type is not accessible. This error will halt a build if code generation is enabled. This attribute also allows generating code for specific types from another assembly. [assembly: KnownType(Type)] also instructs the code generator to include a specific type (which may be from a referenced assembly), but does not cause an exception if the type is inaccessible. Generate serializers for all subtypes Adding [KnownBaseType] to an interface or class instructs the code generator to generates serialization code for all types which inherit/implement that type. Generate code for all types in another assembly There are cases where generated code can not be included in a particular assembly at build time. For example, this can include shared libraries which do not reference Orleans, assemblies written in languages other than C#, and assemblies which the developer does not have the source code for. In these cases, generated code for those assemblies can be placed into a separate assembly which is referenced during initialization. In order to enable this for an assembly: Create a C# project Install the Microsoft.Orleans.OrleansCodeGenerator.Build package Add a reference to the target assembly Add [assembly: KnownAssembly(\"OtherAssembly\")] at the top level of a C# file The KnownAssembly attribute instructs the code generator to inspect the specified assembly and generate code for the types within it. The attribute can be used multiple times within a project. The generated assembly must then be added to the client/silo during initialization: builder.ConfigureApplicationParts( parts => parts.AddApplicationPart(\"CodeGenAssembly\")); In the above example, builder may be an instance of either ISiloHostBuilder or IClientBuilder . KnownAssemblyAttribute has an optional property, TreatTypesAsSerializable , which can be set to true to instruct the code generator to act as though all types within that assembly are marked as serializable."
  },
  "Documentation/clusters_and_clients/configuration_guide/server_configuration.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/server_configuration.html",
    "title": "Server Configuration | Microsoft Orleans Documentation",
    "keywords": "Note If you just want to start a local silo and a local client for development purpose, look at the Local Development Configuration page Server Configuration A silo is configured programmatically via a SiloHostBuilder and a number of supplemental option classes. Option classes in Orleans follow the ASP.NET Options pattern, and can be loaded via files, environment variables etc. Please refer to the Options pattern documentation for more information. There are several key aspects of silo configuration: Orleans clustering information Clustering provider Endpoints to use for silo-to-silo and client-to-silo communications Application parts Example of a silo configuration that defines cluster information, uses Azure clustering and configure the application parts: var silo = new SiloHostBuilder() // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"MyAwesomeOrleansService\"; }) // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) // Endpoints .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) // Application parts: just reference one of the grain implementations that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(ValueGrain).Assembly).WithReferences()) // Now create the silo! .Build(); Let's breakdown the steps used in this sample: Orleans clustering information [...] // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"orleans-docker\"; options.ServiceId = \"AspNetSampleApp\"; }) [...] Here we set two things: the ClusterId to \"my-first-cluster\" : this is a unique ID for the Orleans cluster. All clients and silo that uses this ID will be able to directly talk to each other. Some will choose to use a different ClusterId for each deployments for example. the ServiceId to \"AspNetSampleApp\" : this is a unique ID for your application, that will be used by some provider (for example for persistence providers). This ID should be stable (not change) accross deployments . Clustering provider [...] // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) [...] Usually, a service built on Orleans is deployed on a cluster of nodes, either on dedicated hardware or in Azure. For development and basic testing, Orleans can be deployed in a single node configuration. When deployed to a cluster of nodes, Orleans internally implements a set of protocols to discover and maintain membership of Orleans silos in the cluster, including detection of node failures and automatic reconfiguration. For reliable management of cluster membership, Orleans uses Azure Table, SQL Server or Apache ZooKeeper for synchronization of nodes. In this sample we are using Azure Table as the membership provider. Endpoints var silo = new SiloHostBuilder() [...] // Endpoints .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) [...] An Orleans silo typically configure two endpoints: the silo-to-silo endpoints, used for communication between silo in the same cluster the client-to-silo endpoints (or gateway), use for communication between clients and silos in the same cluster. In the sample we are using the helper method .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) that set the port used for silo-to-silo communication and the port for the gateway to 11111 and 30000 respectively. This method will detect on which interface listen. This method should be sufficient in most cases, but you can customize it further if you need it. Here is for example if you want to use an external IP address with some port-forwarding: [...] .Configure<EndpointOptions>(options => { // Port to use for Silo-to-Silo options.SiloPort = 11111; // Port to use for the gateway options.GatewayPort = 30000; // IP Address to advertise in the cluster options.AdvertisedIPAddress = IPAddress.Parse(\"172.16.0.42\"); // The socket used for silo-to-silo will bind to this endpoint options.GatewayListeningEndpoint = new IPEndPoint(IPAddress.Any, 40000); // The socket used by the gateway will bind to this endpoint options.SiloListeningEndpoint = new IPEndPoint(IPAddress.Any, 50000); }) [...] Internally, the silo will listen on 0.0.0.0:40000 and 0.0.0.0:50000 but the value published in the membership provider will be 172.16.0.42:11111 and 172.16.0.42:30000 . Application parts [...] // Application parts: just reference one of the grain implementations that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(ValueGrain).Assembly).WithReferences()) [...]; Although this step is not technically required (if not configured, Orleans will scan all assembly in the current folder), developers are encouraged to configure this. This step will help Orleans to load user assemblies and types. These assemblies are referred to as Application Parts. All Grains, Grain Interfaces, and Serializers are discovered using Application Parts. Application Parts are configured using an IApplicationPartsManager , which can be accessed using the ConfigureApplicationParts extension method on IClientBuilder and ISiloHostBuilder . The ConfigureApplicationParts method accepts a delegate, Action<IApplicationPartManager> . The following extension methods on IApplicationPartManager support common uses: AddApplicationPart(assembly) a single assembly can be added using this extension method. AddFromAppDomain() adds all assemblies currently loaded in the AppDomain . AddFromApplicationBaseDirectory() loads and adds all assemblies in the current base path (see AppDomain.BaseDirectory ). Assemblies added by the above methods can be supplemented using the following extension methods on their return type, IApplicationPartManagerWithAssemblies : WithReferences() adds all referenced assemblies from the added parts. This immediately loads any transitively referenced assemblies. Assembly loading errors are ignored. WithCodeGeneration() generates support code for the added parts and adds it to the part manager. Note that this requires the Microsoft.Orleans.OrleansCodeGenerator package to be installed, and is commonly referred to as runtime code generation. Type discovery requires that the provided Application Parts include specific attributes. Adding the build-time code generation package ( Microsoft.Orleans.OrleansCodeGenerator.Build ) to each project containing Grains, Grain Interfaces, or Serializers is the recommended approach for ensuring that these attributes are present. Build-time code generation only supports C#. For F#, Visual Basic, and other .NET languages, code can be generated during configuration time via the WithCodeGeneration() method described above."
  },
  "Documentation/clusters_and_clients/configuration_guide/serialization.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/serialization.html",
    "title": "Serialization and Writing Custom Serializers | Microsoft Orleans Documentation",
    "keywords": "Serialization and Writing Custom Serializers Orleans has an advanced and extensible serialization framework. Orleans serializes data types passed in grain request and response messages as well as grain persistent state objects. As part of this framework, Orleans automatically generates serialization code for those data types. In addition to generating a more efficient serialization/deserialization for types that are already .NET-serializable, Orleans also tries to generate serializers for types used in grain interfaces that are not .NET-serializable. The framework also includes a set of efficient built-in serializers for frequently used types: lists, dictionaries, strings, primitives, arrays, etc. There are 2 important features of Orleans's serializer that set it apart from a lot of other third party serialization frameworks: dynamic types/arbitrary polymorphism and object identity. Dynamic types and arbitrary polymorphism - Orleans does not put any restrictions on the types that can be passed in grain calls and maintains the dynamic nature of the actual data type. That means, for example, that if the method in the grain interfaces is declared to accept IDictionary but at runtime the sender passes SortedDictionary , the receiver will indeed get SortedDictionary (although the \"static contract\"/grain interface did not specify this behaviour). Maintaining Object identity - if the same object is passed multiple types in the arguments of a grain call or is indirectly pointed more than once from the arguments, Orleans will serialize it only once. At the receiver side Orleans will restore all references correctly, so that two pointers to the same object still point to the same object after deserialization as well. Object identity is important to preserve in scenarios like the following. Imagine actor A is sending a dictionary with 100 entries to actor B, and 10 of the keys in the dictionary point to the same object, obj, on A's side. Without preserving object identity, B would receive a dictionary of 100 entries with those 10 keys pointing to 10 different clones of obj. With object identity preserved, the dictionary on B's side looks exactly like on A's side with those 10 keys pointing to a single object obj. The above two behaviours are provided by the standard .NET binary serializer and it was therefore important for us to support this standard and familiar behaviour in Orleans as well. Generated Serializers Orleans uses the following rules to decide which serializers to generate. The rules are: 1) Scan all types in all assemblies which reference the core Orleans library. 2) Out of those assemblies: generate serializers for types that are directly referenced in grain interfaces method signatures or state class signature or for any type that is marked with [Serializable] attribute. 3) In addition, a grain interface or implementation project can point to arbitrary types for serialization generation by adding a [KnownType] or [KnownAssembly] assembly level attributes to tell code generator to generate serializers for a specific types or all eligible types within an assembly. Serialization Providers Orleans supports integration with third-party serializers using a provider model. This requires an implementation of the IExternalSerializer type described in the custom serialization section of this document. Integrations for some common serializers are maintained alongside Orleans, for example: Protocol Buffers : Orleans.Serialization.ProtobufSerializer from the Microsoft.Orleans.OrleansGoogleUtils NuGet package. Bond : Orleans.Serialization.BondSerializer from the Microsoft.Orleans.Serialization.Bond NuGet package. Newtonsoft.Json AKA Json.NET : Orleans.Serialization.OrleansJsonSerializer from the core Orleans library. Custom implementation of IExternalSerializer is described in the Writing Custom Serializers section below. Configuration It is important to ensure that serialization configuration is identical on all clients and silos. If configurations are not consistent, serialization errors may occur. Serialization providers, which implement IExternalSerializer , can be specified using the SerializationProviders property of ClientConfiguration and GlobalConfiguration in code: var cfg = new ClientConfiguration(); cfg.SerializationProviders.Add(typeof(FantasticSerializer).GetTypeInfo()); var cfg = new GlobalConfiguration(); cfg.SerializationProviders.Add(typeof(FantasticSerializer).GetTypeInfo()); Alternatively, they can be specified in XML configuration under the <SerializationProviders /> property of <Messaging> : <Messaging> <SerializationProviders> <Provider type=\"GreatCompany.FantasticSerializer, GreatCompany.SerializerAssembly\"/> </SerializationProviders> </Messaging> In both cases, multiple providers can be configured. The collection is ordered, meaning that if a provider which can serialize types A and B is specified before a provider which can only serialize type B , then the latter provider will not be used. Writing Custom Serializers In addition to automatic serialization generation, application code can provide custom serialization for types it chooses. Orleans recommends using the automatic serialization generation for the majority of your application types and only write custom serializers in rare cases when you believe it is possible to get improved performance by hand-coding serializers. This note describes how to do so, and identifies some specific cases when it might be helpful. There are 3 ways in which applications can customize serialization: Add serialization methods to your type and mark them with appropriate attributes ( CopierMethod , SerializerMethod , DeserializerMethod ). This method is preferable for types that your application owns, that is, the types that you can add new methods to. Implement IExternalSerializer and register it during configuration time. This method is useful for integrating an external serialization library. Write a separate static class annotated with an [Serializer(typeof(YourType))] with the 3 serialization methods in it and the same attributes as above. This method is useful for types that the application does not own, for example, types defined in other libraries your application has no control over. Each of these methods are detailed in the sections below. Introduction Orleans serialization happens in three stages: objects are immediately deep copied to ensure isolation; before being put on the wire; objects are serialized to a message byte stream; and when delivered to the target activation, objects are recreated (deserialized) from the received byte stream. Data types that may be sent in messages -- that is, types that may be passed as method arguments or return values -- must have associated routines that perform these three steps. We refer to these routines collectively as the serializers for a data type. The copier for a type stands alone, while the serializer and deserializer are a pair that work together. You can provide just a custom copier, or just a custom serializer and a custom deserializer, or you can provide custom implementations of all three. Serializers are registered for each supported data type at silo start-up and whenever an assembly is loaded. Registration is necessary for custom serializer routines for a type to be used. Serializer selection is based on the dynamic type of the object to be copied or serialized. For this reason, there is no need to create serializers for abstract classes or interfaces, because they will never be used. When to Consider Writing a Custom Serializer It is rare that a hand-crafted serializer routine will perform meaningfully better than the generated versions. If you are tempted to do so, you should first consider the following options: If there are fields or properties within your data types that don't have to be serialized or copied, you can mark them with the NonSerialized attribute. This will cause the generated code to skip these fields when copying and serializing. Use Immutable<T> & [Immutable] where possible to avoid copying immutable data. The section on Optimizing Copying below for details. If you're avoiding using the standard generic collection types, don't. The Orleans runtime contains custom serializers for the generic collections that use the semantics of the collections to optimize copying, serializing, and deserializing. These collections also have special \"abbreviated\" representations in the serialized byte stream, resulting in even more performance advantages. For instance, a Dictionary<string, string> will be faster than a List<Tuple<string, string>> . The most common case where a custom serializer can provide a noticeable performance gain is when there is significant semantic information encoded in the data type that is not available by simply copying field values. For instance, arrays that are sparsely populated may often be more efficiently serialized by treating the array as a collection of index/value pairs, even if the application keeps the data as a fully realized array for speed of operation. A key thing to do before writing a custom serializer is to make sure that the generated serializer is really hurting your performance. Profiling will help a bit here, but even more valuable is running end-to-end stress tests of your application with varying serialization loads to gauge the system-level impact, rather than the micro-impact of serialization. For instance, building a test version that passes no parameters to or results from grain methods, simply using canned values at either end, will zoom in on the impact of serialization and copying on system performance. Method 1: Adding Serialization Methods to the Type All serializer routines should be implemented as static members of the class or struct they operate on. The names shown here are not required; registration is based on the presence of the respective attributes, not on method names. Note that serializer methods need not be public. Unless you implement all three serialization routines, you should mark your type with the Serializable attribute so that the missing methods will be generated for you. Copier Copier methods are flagged with the Orleans.CopierMethod attribute: [CopierMethod] static private object Copy(object input, ICopyContext context) { ... } Copiers are usually the simplest serializer routines to write. They take an object, guaranteed to be of the same type as the type the copier is defined in, and must return a semantically-equivalent copy of the object. If, as part of copying the object, a sub-object needs to be copied, the best way to do so is to use the SerializationManager's DeepCopyInner routine: var fooCopy = SerializationManager.DeepCopyInner(foo, context); It is important to use DeepCopyInner, instead of DeepCopy, in order to maintain the object identity context for the full copy operation. Maintaining Object Identity An important responsibility of a copy routine is to maintain object identity. The Orleans runtime provides a helper class for this. Before copying a sub-object \"by hand\" (i.e., not by calling DeepCopyInner), check to see if it has already been referenced as follows: var fooCopy = context.CheckObjectWhileCopying(foo); if (fooCopy == null) { // Actually make a copy of foo context.RecordObject(foo, fooCopy); } The last line, the call to RecordObject , is required so that possible future references to the same object as foo references will get found properly by CheckObjectWhileCopying . Note that this should only be done for class instances, not struct instances or .NET primitives (strings, Uris, enums). If you use DeepCopyInner to copy sub-objects, then object identity is handled for you. Serializer Serialization methods are flagged with the SerializerMethod attribute: [SerializerMethod] static private void Serialize(object input, ISerializationContext context, Type expected) { ... } As with copiers, the \"input\" object passed to a serializer is guaranteed to be an instance of the defining type. The \"expected\" type may be ignored; it is based on compile-time type information about the data item, and is used at a higher level to form the type prefix in the byte stream. To serialize sub-objects, use the SerializationManager 's SerializeInner routine: SerializationManager.SerializeInner(foo, context, typeof(FooType)); If there is no particular expected type for foo, then you can pass null for the expected type. The BinaryTokenStreamWriter class provides a wide variety of methods for writing data to the byte stream. An instance of the class can be obtained via the context.StreamWriter property. See the class for documentation. Deserializer Deserialization methods are flagged with the DeserializerMethod attribute: [DeserializerMethod] static private object Deserialize(Type expected, IDeserializationContext context) { ... } The \"expected\" type may be ignored; it is based on compile-time type information about the data item, and is used at a higher level to form the type prefix in the byte stream. The actual type of the object to be created will always be the type of the class in which the deserializer is defined. To deserialize sub-objects, use the SerializationManager 's DeserializeInner routine: var foo = SerializationManager.DeserializeInner(typeof(FooType), context); Or, alternatively, var foo = SerializationManager.DeserializeInner<FooType>(context); If there is no particular expected type for foo, use the non-generic DeserializeInner variant and pass null for the expected type. The BinaryTokenStreamReader class provides a wide variety of methods for reading data from the byte stream. An instance of the class can be obtained via the context.StreamReader property. See the class for documentation. Method 2: Writing a Serializer Provider In this method, you implement Orleans.Serialization.IExternalSerializer and add it to the SerializationProviders property on both ClientConfiguration on the client and GlobalConfiguration on the silos. Configuration is detailed in the Serialization Providers section above. Implementation of IExternalSerializer follows the pattern described for serialization methods from Method 1 above with the addition of an Initialize method and an IsSupportedType method which Orleans uses to determine if the serializer supports a given type. This is the interface definition: public interface IExternalSerializer { /// <summary> /// Initializes the external serializer. Called once when the serialization manager creates /// an instance of this type /// </summary> void Initialize(Logger logger); /// <summary> /// Informs the serialization manager whether this serializer supports the type for serialization. /// </summary> /// <param name=\"itemType\">The type of the item to be serialized</param> /// <returns>A value indicating whether the item can be serialized.</returns> bool IsSupportedType(Type itemType); /// <summary> /// Tries to create a copy of source. /// </summary> /// <param name=\"source\">The item to create a copy of</param> /// <param name=\"context\">The context in which the object is being copied.</param> /// <returns>The copy</returns> object DeepCopy(object source, ICopyContext context); /// <summary> /// Tries to serialize an item. /// </summary> /// <param name=\"item\">The instance of the object being serialized</param> /// <param name=\"context\">The context in which the object is being serialized.</param> /// <param name=\"expectedType\">The type that the deserializer will expect</param> void Serialize(object item, ISerializationContext context, Type expectedType); /// <summary> /// Tries to deserialize an item. /// </summary> /// <param name=\"context\">The context in which the object is being deserialized.</param> /// <param name=\"expectedType\">The type that should be deserialized</param> /// <returns>The deserialized object</returns> object Deserialize(Type expectedType, IDeserializationContext context); } Method 3: Writing a Serializer for Individual Types In this method you write a new class annotated with an attribute [SerializerAttribute(typeof(TargetType))] , where TargetType is the type which is being serialized, and implement the 3 serialization routines. The rules for how to write those routines are identical to method 1. Orleans uses the [SerializerAttribute(typeof(TargetType))] to determine that this class is a serializer for TargetType and this attribute can be specified multiple times on the same class if it's able to serialize multiple types. Below is an example for such a class: public class User { public User BestFriend { get; set; } public string NickName { get; set; } public int FavoriteNumber { get; set; } public DateTimeOffset BirthDate { get; set; } } [Orleans.CodeGeneration.SerializerAttribute(typeof(User))] internal class UserSerializer { [CopierMethod] public static object DeepCopier(object original, ICopyContext context) { var input = (User) original; var result = new User(); // Record 'result' as a copy of 'input'. Doing this immediately after construction allows for // data structures which have cyclic references or duplicate references. // For example, imagine that 'input.BestFriend' is set to 'input'. In that case, failing to record // the copy before trying to copy the 'BestFriend' field would result in infinite recursion. context.RecordCopy(original, result); // Deep-copy each of the fields. result.BestFriend = (User)context.SerializationManager.DeepCopy(input.BestFriend); result.NickName = input.NickName; // strings in .NET are immutable, so they can be shallow-copied. result.FavoriteNumber = input.FavoriteNumber; // ints are primitive value types, so they can be shallow-copied. result.BirthDate = (DateTimeOffset)context.SerializationManager.DeepCopy(input.BirthDate); return result; } [SerializerMethod] public static void Serializer(object untypedInput, ISerializationContext context, Type expected) { var input = (User) untypedInput; // Serialize each field. SerializationManager.SerializeInner(input.BestFriend, context); SerializationManager.SerializeInner(input.NickName, context); SerializationManager.SerializeInner(input.FavoriteNumber, context); SerializationManager.SerializeInner(input.BirthDate, context); } [DeserializerMethod] public static object Deserializer(Type expected, IDeserializationContext context) { var result = new User(); // Record 'result' immediately after constructing it. As with with the deep copier, this // allows for cyclic references and de-duplication. context.RecordObject(result); // Deserialize each field in the order that they were serialized. result.BestFriend = SerializationManager.DeserializeInner<User>(context); result.NickName = SerializationManager.DeserializeInner<string>(context); result.FavoriteNumber = SerializationManager.DeserializeInner<int>(context); result.BirthDate = SerializationManager.DeserializeInner<DateTimeOffset>(context); return result; } } Serializing Generic Types The TargetType parameter of [Serializer(typeof(TargetType))] can be an open-generic type, for example, MyGenericType<> . In that case, the serializer class must have the same generic parameters as the target type. Orleans will create a concrete version of the serializer at runtime for every concrete MyGenericType<T> type which is serialized, for example, one for each of MyGenericType<int> and MyGenericType<string> . Hints for Writing Serializers and Deserializers Often the simplest way to write a serializer/deserializer pair is to serialize by constructing a byte array and writing the array length to the stream, followed by the array itself, and then deserialize by reversing the process. If the array is fixed-length, you can omit it from the stream. This works well when you have a data type that you can represent compactly and that doesn't have sub-objects that might be duplicated (so you don't have to worry about object identity). Another approach, which is the approach the Orleans runtime takes for collections such as dictionaries, works well for classes with significant and complex internal structure: use instance methods to access the semantic content of the object, serialize that content, and deserialize by setting the semantic contents rather than the complex internal state. In this approach, inner objects are written using SerializeInner and read using DeserializeInner. In this case, it is common to write a custom copier, as well. If you write a custom serializer, and it winds up looking like a sequence of calls to SerializeInner for each field in the class, you don't need a custom serializer for that class. Fallback Serialization Orleans supports transmission of arbitrary types at runtime and therefore the in-built code generator cannot determine the entire set of types which will be transmitted ahead of time. Additionally, certain types cannot have serializers generated for them because they are inaccessible (for example, private ) or have fields which are inaccessible (for example, readonly ). Therefore, there is a need for just-in-time serialization of types which were unexpected or could not have serializers generated ahead-of-time. The serializer responsible for these types is called the fallback serializer . Orleans ships with two fallback serializers: Orleans.Serialization.BinaryFormatterSerializer which uses .NET's BinaryFormatter ; and Orleans.Serialization.ILBasedSerializer which emits CIL instructions at runtime to create serializers which leverage Orleans' serialization framework to serialize each field. This means that if an inaccessible type MyPrivateType contains a field MyType which has a custom serializer, that custom serializer will be used to serialize it. The fallback serializer can be configured using the FallbackSerializationProvider property on both ClientConfiguration on the client and GlobalConfiguration on the silos. var cfg = new ClientConfiguration(); cfg.FallbackSerializationProvider = typeof(FantasticSerializer).GetTypeInfo(); var cfg = new GlobalConfiguration(); cfg.FallbackSerializationProvider = typeof(FantasticSerializer).GetTypeInfo(); Alternatively, the fallback serialization provider can be specified in XML configuration: <Messaging> <FallbackSerializationProvider type=\"GreatCompany.FantasticFallbackSerializer, GreatCompany.SerializerAssembly\"/> </Messaging> .NET Core uses the ILBasedSerializer by default, whereas .NET 4.6 uses BinaryFormatterSerializer by default. Optimize Copying Using Immutable Types Orleans has a feature that can be used to avoid some of the overhead associated with serializing messages containing immutable types. This section describes the feature and its application, starting with context on where it is relevant. Serialization in Orleans When a grain method is invoked, the Orleans runtime makes a deep copy of the method arguments and forms the request out of the copies. This protects against the calling code modifying the argument objects before the data is passed to the called grain. If the called grain is on a different silo, then the copies are eventually serialized into a byte stream and sent over the network to the target silo, where they are deserialized back into objects. If the called grain is on the same silo, then the copies are handed directly to the called method. Return values are handled the same way: first copied, then possibly serialized and deserialized. Note that all 3 processes, copying, serializing, and deserializing, respect object identity. In other words, if you pass a list that has the same object in it twice, on the receiving side you'll get a list with the same object in it twice, rather than with two objects with the same values in them. Optimizing Copying In many cases, the deep copying is unnecessary. For instance, a possible scenario is a web front-end that receives a byte array from its client and passes that request, including the byte array, on to a grain for processing. The front-end process doesn't do anything with the array once it has passed it on to the grain; in particular, it doesn't reuse the array to receive a future request. Inside the grain, the byte array is parsed to fetch the input data, but not modified. The grain returns another byte array that it has created to get passed back to the web client; it discards the array as soon as it returns it. The web front-end passes the result byte array back to its client, without modification. In such a scenario, there is no need to copy either the request or response byte arrays. Unfortunately, the Orleans runtime can't figure this out by itself, since it can't tell whether or not the arrays are modified later on by the web front-end or by the grain. In the best of all possible worlds, we'd have some sort of .NET mechanism for indicating that a value is no longer modified; lacking that, we've added Orleans-specific mechanisms for this: the Immutable<T> wrapper class and the [Immutable] attribute. Using Immutable<T> The Orleans.Concurrency.Immutable<T> wrapper class is used to indicate that a value may be considered immutable; that is, the underlying value will not be modified, so no copying is required for safe sharing. Note that using Immutable<T> implies that neither the provider of the value nor the recipient of the value will modify it in the future; it is not a one-sided commitment, but rather a mutual dual-side commitment. Using Immutable<T> is simple: in your grain interface, instead of passing T , pass Immutable<T> . For instance, in the above described scenario, the grain method that was: Task<byte[]> ProcessRequest(byte[] request); Becomes: Task<Immutable<byte[]>> ProcessRequest(Immutable<byte[]> request); To create an Immutable<T> , simply use the constructor: Immutable<byte[]> immutable = new Immutable<byte[]>(buffer); To get the value inside the immutable, use the .Value property: byte[] buffer = immutable.Value; Using [Immutable] For user-defined types, the [Orleans.Concurrency.Immutable] attribute can be added to the type. This instructs Orleans' serializer to avoid copying instances of this type. The following code snippet demonstrates using [Immutable] to denote an immutable type. This type will not be copied during transmission. [Immutable] public class MyImmutableType { public MyImmutableType(int value) { this.MyValue = value; } public int MyValue { get; } } Immutability in Orleans For Orleans' purposes, immutability is a rather strict statement: the contents of the data item will not be modified in any way that could change the item's semantic meaning, or that would interfere with another thread simultaneously accessing the item. The safest way to ensure this is to simply not modify the item at all: bitwise immutability, rather than logical immutability. In some cases it is safe to relax this to logical immutability, but care must be taken to ensure that the mutating code is properly thread-safe; because dealing with multithreading is complex, and uncommon in an Orleans context, we strongly recommend against this approach and recommend sticking to bitwise immutability. Serialization Best Practices Serialization serves two primary purposes in Orleans: As a wire format for transmitting data between grains and clients at runtime. As a storage format for persisting long-lived data for later retrieval. The serializers generated by Orleans are suitable for the first purpose due to their flexibility, performance, and versatility. They are not as suitable for the second purpose, since they are not explicitly version-tolerant. It is recommended that users configure a version-tolerant serializer such as Protocol Buffers for persistent data. Protocol Buffers is supported via Orleans.Serialization.ProtobufSerializer from the Microsoft.Orleans.OrleansGoogleUtils NuGet package. The best-practices for the particular serializer of choice should be used in order to ensure version-tolerance. Third-party serializers can be configured using the SerializationProviders configuration property as described above."
  },
  "Documentation/clusters_and_clients/configuration_guide/load_balancing.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/load_balancing.html",
    "title": "Load Balancing | Microsoft Orleans Documentation",
    "keywords": "Load Balancing Load balancing, in a broad sense, is one of the pillars of the Orleans runtime . Orleans runtime tries to make everything balanced, since balancing allows to maximize resource usage and avoid hotspots, which leads to better performance, as well as helps with elasticity. Load balancing in Orleans applies in multiple places. Below is a non-exhaustive list of places where the runtime performs balancing: Default actor placement strategy is random - new activations are placed randomly across silos. That results in a balanced placement and prevents hotspots for most scenarios. A more advanced ActivationCountPlacement tries to equalize the number of activations on all silos, which results in a more even distribution of activations across silos. This is especially important for elasticity. Grain Directory service is built on top of a Distributed Hash Table, which inherently is balanced. The directory service maps grains to activations, each silo owns part of the global mapping table, and this table is globally partitioned in a balanced way across all silos. We use consistent hashing with virtual buckets for that. Clients connect to all gateways and spread their requests across them, in a balanced way. Reminder service is a distributed partitioned runtime service. The assignment of which silo is responsible to serve which reminder is balanced across all silos via consistent hashing, just like in grain directory. Performance critical components within a silo are partitioned, and the work across them is locally balanced . That way the silo runtime can fully utilize all available CPU cores and not create in-silo bottlenecks. This applies to all local resources: allocation of work to threads, sockets, dispatch responsibilities, queues, etc. StreamQueueBalance balances the responsibility of pulling events from persistence queues across silos in the cluster. Also notice that balancing, in a broad sense, does not necessarily mean loss of locality . One can be balanced and still maintain a good locality. For example, when balancing means sharding/partitioning, you can partition responsibility for a certain logical task, while still maintaining locality within each partition. That applies both for local and distributed balancing. Refer to this presentation on Balancing Techniques in Orleans for more details."
  },
  "Documentation/clusters_and_clients/configuration_guide/list_of_options_classes.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/list_of_options_classes.html",
    "title": "List of Options Classes | Microsoft Orleans Documentation",
    "keywords": "List of Options Classes All Options classes used to configure Orleans should be in the Orleans.Configuration namespace. Many of them have helper methods in the Orleans.Hosting namespace. Common core options for IClientBuilder and ISiloHostBuilder Option type Used for ClusterOptions Setting the ClusterId and the ServiceId NetworkingOptions Setting timeout values for sockets and opened connections SerializationProviderOptions Setting the serialization providers TypeManagementOptions Setting the refresh period of the Type Map (see Heterogeneous silos and Versioning) IClientBuilder specific options Option type Used for ClientMessagingOptions Setting the number of connection to keep open, and specify what network interface to use ClientStatisticsOption Setting various setting related to statistics output GatewayOptions Setting the refresh period of the list of available gateways ISiloHostBuilder specific options Option type Used for ClusterMembershipOptions Settings for cluster membership ConsistentRingOptions Configuration options for consistent hashing algorithm, used to balance resource allocations across the cluster. EndpointOptions Setting the Silo endpoint options GrainCollectionOptions Options for grain garbage collection GrainVersioningOptions Governs grain implementation selection in heterogeneous deployments LoadSheddingOptions Settings for load shedding configuration MultiClusterOptions Options for configuring multi-cluster support PerformanceTuningOptions Performance tuning options (networking, number of threads) ProcessExitHandlingOptions Configure silo behavior on process exit SchedulingOptions Configuring scheduler behavior SiloMessagingOptions Configuring global messaging options that are silo related. SiloOptions Setting the name of the Silo SiloStatisticsOptions Setting various setting related to statistics output TelemetryOptions Setting telemetry consumer settings"
  },
  "Documentation/clusters_and_clients/configuration_guide/activation_garbage_collection.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/activation_garbage_collection.html",
    "title": "Activation Garbage Collection | Microsoft Orleans Documentation",
    "keywords": "Activation Garbage Collection As described in the Core Concepts section, a grain activation is an in-memory instance of a grain class that gets automatically created by the Orleans runtime on an as-needed basis as a temporary physical embodiment of a grain. Activation Garbage Collection (Activation GC) is the process of removal from memory of unused grain activations. It is conceptually similar to how garbage collection of memory works in .NET. However, Activation GC only takes into consideration how long a particular grain activation has been idle. Memory usage is not used as a factor. How Activation GC Works The general process of Activation GC involves Orleans runtime in a silo periodically scanning for grain activations that have not been used at all for the configured period of time (Collection Age Limit). Once a grain activation has been idle for that long, it gets deactivated. The deactivation process begins by the runtime calling the grain’s OnDeactivateAsync() method, and completes by removing references to the grain activation object from all data structures of the silo, so that the memory is reclaimed by the .NET GC. As a result, with no burden put on the application code, only recently used grain activations stay in memory while activations that aren't used anymore get automatically removed, and system resources used by them get reclaimed by the runtime. What counts as “being active” for the purpose of grain activation collection receiving a method call receiving a reminder receiving an event via streaming What does NOT count as “being active” for the purpose of grain activation collection performing a call (to another grain or to an Orleans client) timer events arbitrary IO operations or external calls not involving Orleans framework Collection Age Limit This period of time after which an idle grain activation becomes subject to Activation GC is called Collection Age Limit. The default Collection Age Limit is 2 hours, but it can be changed globally or for individual grain classes. Explicit Control of Activation Garbage Collection Delaying Activation GC A grain activation can delay its own Activation GC, by calling this.DelayDeactivation() method: protected void DelayDeactivation(TimeSpan timeSpan) This call will ensure that this activation is not deactivated for at least the specified time duration. It takes priority over Activation Garbage Collection settings specified in the config, but does not cancel them. Therefore, this call provides an additional hook to delay the deactivation beyond what is specified in the Activation Garbage Collection settings . This call can not be used to expedite Activation Garbage Collection. A positive timeSpan value means “prevent GC of this activation for that time span”. A negative timeSpan value means “cancel the previous setting of the DelayDeactivation call and make this activation behave based on the regular Activation Garbage Collection settings”. Scenarios: 1) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(20)) , it will cause this activation to not be collected for at least 20 min. 2) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(5)) , the activation will be collected after 10 min, if no extra calls were made. 3) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(5)) , and after 7 minutes there is another call on this grain, the activation will be collected after 17 min from time zero, if no extra calls were made. 4) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(20)) , and after 7 minutes there is another call on this grain, the activation will be collected after 20 min from time zero, if no extra calls were made. Note that DelayDeactivation does not 100% guarantee that the grain activation will not get deactivated before the specified period of time expires. There are certain failure cases that may cause 'premature' deactivation of grains. That means that DelayDeactivation cannot not be used as a means to 'pin' a grain activation in memory forever or to a specific silo . DelayDeactivation is merely an optimization mechanism that can help reduce the aggregate cost of a grain getting deactivated and reactivated over time, if that matters. In most cases there should be no need to use DelayDeactivation at all. Expediting Activation GC A grain activation can also instruct the runtime to deactivate it next time it becomes idle by calling this.DeactivateOnIdle() method: protected void DeactivateOnIdle() A grain activation is considered idle if it is not processing any message at the moment. If you call DeactivateOnIdle while a grain is processing a message, it will get deactivated as soon as processing of the current message is finished. If there are any requests queued for the grain, they will be forwarded to the next activation. DeactivateOnIdle take priority over any Activation Garbage Collection settings specified in the config or DelayDeactivation . Note that this setting only applies to the grain activation from which it has been called and it does not apply to other grain activation of this type. Configuration Grain garbage collection can be configured using the GrainCollectionOptions options: mySiloHostBuilder.Configure<GrainCollectionOptions>(options => { // Set the value of CollectionAge to 10 minutes for all grain options.CollectionAge = TimeSpan.FromMinutes(10); // Override the value of CollectionAge to 5 minutes for MyGrainImplementation options.ClassSpecificCollectionAge[typeof(MyGrainImplementation).FullName] = TimeSpan.FromMinutes(5); })"
  },
  "Documentation/clusters_and_clients/developing_a_client.html": {
    "href": "Documentation/clusters_and_clients/developing_a_client.html",
    "title": "Developing a Client | Microsoft Orleans Documentation",
    "keywords": "What Is Grain Client? The term \"Client\" or sometimes \"Grain Client\" is used for application code that interacts with grains but itself is not part of a grain logic. Client code runs outside of the cluster of Orleans servers called silos where grains are hosted. Hence, a client acts as a connector or conduit to the cluster and to all grains of the application. Usually, clients are used on the frontend web servers to connect to an Orleans cluster that serves as a middle tier with grains executing business logic. In a typical setup, a frontend web server: Receives a web request Performs necessary authentication and authorization validation Decides which grain(s) should process the request Uses Grain Client to make one or more method call to the grain(s) Handles successful completion or failures of the grain calls and any returned values Sends a response for the web request Initialization of Grain Client Before a grain client can be used for making calls to grains hosted in an Orleans cluster, it needs to be configured, initialized, and connected to the cluster. Configuration is provided via a ClientConfiguration object that contains a hierarchy of configuration properties for programmatically configuring a client. There is also a way to configure a client via a XML file, but that option will be deprecated in the future. More information is in the Client Configuration guide . Here we will simply use a helper method that creates a configuration object hardcoded for connecting to a local silo running as localhost . ClientConfiguration clientConfig = ClientConfiguration.LocalhostSilo(); Once we have a configuration object, we can build a client via the ClientBuilder class. IClusterClient client = new ClientBuilder().UseConfiguration(clientConfig).Build(); Lastly, we need to call Connect() method on the constructed client object to make it connect to the Orleans cluster. It's an asynchronous method that returns a Task . So we need to wait for its completion with an await or .Wait() . await client.Connect(); Making Calls to Grains Making calls to grain from a client is really no different from making such calls from within grain code . The same GetGrain<T>(key) method, where T is the target grain interface, is used in both cases to obtain grain references . The slight difference is in through what factory object we invoke GetGrain . In client code we do that through the connected client object. IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); Task t = player.JoinGame(game) await t; A call to a grain method returns a Task or a Task<T> as required by the grain interface rules . The client can use the await keyword to asynchronously await the returned Task without blocking the thread, or in some cases the Wait() method to block the current thread of execution. The major difference between making calls to grains from client code and from within another grain is the single-threaded execution model of grains. Grains are constrained to be single-threaded by the Orleans runtime, while clients may be multi-threaded. Orleans does not provide any such guarantee on the client side, and so it is up to the client to manage its own concurrency using whatever synchronization constructs are appropriate for its environment – locks, events, Tasks , etc. Receiving notifications There are situations in which a simple request-response pattern is not enough, and the client needs to receive asynchronous notifications. For example, a user might want to be notified when a new message has been published by someone that she is following. Observers is one such mechanism that enables exposing client side objects as grain-like targets to get invoked by grains. Calls to observers do not provide any indication of success or failure, as they are sent as one-way best effort message. So it is a responsibility of the application code to build a higher level reliability mechanism on top of observers where necessary. Another mechanism that can be used for delivering asynchronous messages to clients is Streams . Streams expose indications of success or failure of delivery of individual messages, and hence enable reliable communication back to the client. Example Here is an extended version of the example given above of a client application that connects to Orleans, finds the player account, subscribes for updates to the game session the player is part of with an observer, and prints out notifications until the program is manually terminated. namespace PlayerWatcher { class Program { /// <summary> /// Simulates a companion application that connects to the game /// that a particular player is currently part of, and subscribes /// to receive live notifications about its progress. /// </summary> static void Main(string[] args) { RunWatcher().Wait(); // Block main thread so that the process doesn't exit. // Updates arrive on thread pool threads. Console.ReadLine(); } static async Task RunWatcher() { try { // Connect to local silo var config = ClientConfiguration.LocalhostSilo(); var client = new ClientBuilder().UseConfiguration(config).Build(); await client.Connect(); // Hardcoded player ID Guid playerId = new Guid(\"{2349992C-860A-4EDA-9590-000000000006}\"); IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); IGameGrain game = null; while (game == null) { Console.WriteLine(\"Getting current game for player {0}...\", playerId); try { game = await player.GetCurrentGame(); if (game == null) // Wait until the player joins a game { await Task.Delay(5000); } } catch (Exception exc) { Console.WriteLine(\"Exception: \", exc.GetBaseException()); } } Console.WriteLine(\"Subscribing to updates for game {0}...\", game.GetPrimaryKey()); // Subscribe for updates var watcher = new GameObserver(); await game.SubscribeForGameUpdates( await client.CreateObjectReference<IGameObserver>(watcher)); Console.WriteLine(\"Subscribed successfully. Press <Enter> to stop.\"); } catch (Exception exc) { Console.WriteLine(\"Unexpected Error: {0}\", exc.GetBaseException()); } } } /// <summary> /// Observer class that implements the observer interface. Need to pass a grain reference to an instance of this class to subscribe for updates. /// </summary> class GameObserver : IGameObserver { // Receive updates public void UpdateGameScore(string score) { Console.WriteLine(\"New game score: {0}\", score); } } } }"
  },
  "Community/Orleans-Architecture-Principles-and-Approach-I.html": {
    "href": "Community/Orleans-Architecture-Principles-and-Approach-I.html",
    "title": "Orleans Architecture - Principles and Approach I | Microsoft Orleans Documentation",
    "keywords": "Now that Orleans is (finally) available as open source, it's important to be clear about the goals and principles that has motivated the design decisions behind Orleans so that new changes either fit within that framework or explicitly and intentionally revise those goals and principles. About the time I joined the Orleans project, we agreed that the goal was to produce a framework that would allow mainstream developers to easily build scalable distributed (cloud) applications. To break this down a bit: The target audience shouldn't exclude programmers who haven't done distributed systems development . We want to enable all developers, whether cloud experts or cloud beginners, to focus on their application logic and features -- which is to say, what actually provides business value -- rather than on generic distributed systems issues. The goal is to allow them to build cloud applications easily . Easily means that they shouldn't have to think about distribution any more than is absolutely required. Easily also means that Orleans should present as familiar a façade to the developer as possible; in a .NET context, that means C# objects and interfaces. Those applications should be \"scalable by default\" . Since our target users aren't necessarily distributed systems experts, we want to provide them a framework that will lead them to build scalable applications without explicitly thinking about it. This means that the framework has to make a lot of decisions for them in order to guarantee an acceptable degree of scalability, even if that means that the scalability isn't optimal for every application. We supplemented this goal with a set of architectural principles: We're focused on the 80% case . There are certainly applications that Orleans isn't appropriate for; that's OK. There are applications that Orleans is a reasonable fit for, but where you can get somewhat better performance by a bunch of hand-tuning that Orleans doesn't allow; that's OK too. The 80% that Orleans fits well and performs well enough on covers a lot of interesting applications, and we'd rather do a great job on 80% than a lousy job on 99%. Scalability is paramount . We'll trade off raw performance if that gets us better scaling. Availability is paramount . A cloud application should be like a utility: always there when you want it. Detect and fix problems , don't assume you can 100% prevent them. At cloud scale, bad things happen often, and even impossible bad things happen, just less often. This has led us to what is often termed \"recovery-oriented computing\", rather than trying to be fault-tolerant; our experience has shown that fault tolerance is fragile and often illusory. Even mathematically proven protocols are no protection against random bit flips in memory or disk controllers that fail while reporting success -- both real examples I've seen in production in my career. The above has led us to certain practices: API-first design : if we don't know how we're going to expose a feature to the developer, then we don't build it. Of course, the best way is for a feature have no developer exposure at all... Make it easy to do the right thing : keep things as simple as possible (but no simpler), don't provide a hammer if a screwdriver is the right tool. As one of our early adopters put it, we try to help our customers \"fall into the pit of success\". If there is a standard pattern that will work well for 80% of the applications out there, then don't worry about enabling every possible alternative. Orleans' embrace of asynchrony is a good example of this. Make it easy for developers to extend the framework without breaking it . Custom serialization and persistence providers are a couple of examples of this. Some sort of custom task scheduling extension would be an anti-example. Follow the principle of least surprise : as much as possible, things should be as familiar, but everything should behave the way it looks. The next post will start applying these principles to the current Orleans design and walk through the motivations for some specific decisions we made. Thanks for reading! Alan Geller Alan Geller, http://research.microsoft.com/en-us/people/ageller/ , works on quantum computing at Microsoft Research. He was one of the primary architects of Orleans from 2008 until 2012. Earlier, he was the platform architect for Amazon Web Services from 2004 to 2008, and before that built a wide variety of large-scale production distributed systems in telecommunications and financial services."
  },
  "1.5/Documentation/Event-Sourcing/Diagnostics.html": {
    "href": "1.5/Documentation/Event-Sourcing/Diagnostics.html",
    "title": "JournaledGrain Diagnostics | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . JournaledGrain Diagnostics Monitoring Connection Errors By design, log consistency providers are resilient under connection errors (including both connections to storage, and connections between clusters). But just tolerating errors is not enough, as applications usually need to monitor any such issues, and bring them to the attention of an operator if they are serious. JournaledGrain subclasses can override the following methods to receive notifiations when there are connection errors observed, and when those errors are resolved: protected override void OnConnectionIssue(ConnectionIssue issue) { /// handle the observed error described by issue } protected override void OnConnectionIssueResolved(ConnectionIssue issue) { /// handle the resolution of a previously reported issue } ConnectionIssue is an abstract class, with several common fields describing the issue, including how many times it has been observed since the last time connection was successful. The actual type of connection issue is defined by subclasses. Connection issues are categorized into types, such as PrimaryOperationFailed or NotificationFailed , and sometimes have extra keys (such as RemoteCluster ) that further narrow the category. If the same category of issue happens several times (for example, we keep getting a NotificationFailed that targets the same RemoteCluster ), it is reported each time by OnConnectionIssue . Once this category of issue is resolved (for example, we are finally successful with sending a notification to this RemoteCluster ), then OnConnectionIssueResolved is called once, with the same issue object that was last reported by OnConnectionIssue . Connection issues, and their resolution, for independent categories, are reported independently. Simple Statistics We currently offer a simple support for basic statistics (in the future, we will probably replace this with a more standard telemetry mechanism). Statistics collection can be enabled or disabled for a JournaledGrain by calling void EnableStatsCollection() void DisableStatsCollection() The statistics can be retrieved by calling LogConsistencyStatistics GetStats()"
  },
  "1.5/Documentation/Deployment-and-Operations/Monitoring/Runtime-Monitoring.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Monitoring/Runtime-Monitoring.html",
    "title": "Runtime Monitoring | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Runtime Monitoring [[THIS IS IN NEED OF REVIEW]] There are five ways Orleans deployment can be monitored by an external operator by utilizing the data that Orleans writes automatically to Azure storage. The tables mentioned below are desribed in more detail here . OrleansSilosTable for cluster membership - this table lists all silos in the deployment (partition key DeploymentID, row key silo id). The operator can use this table to check cluster health, watch the current set of live silos, or learn why and when a certain silo went down. Orleans' cluster membership protocol uses this table internally and updates it with significant membership events (silos goes up and down). OrleansSiloMetrics table for coarse grain performance statistics - Orleans writes a small number (about 10) of coarse-grain performance stats into this table (partition key DeplomentID, row key silo id). The table is updated automatically every X seconds (configurable) for each silo. The metrics include silo CPU, memory usage, number of grain activations on this silo, number of messages in the send/receive queue, etc. This data can be used to compare silos, check that there are no significant outliers (for example, one silo runs at much higher CPU), or simply check that in general the metrics reported by silos are in the expected range. In addition, this data can be used to decide to add new silos if the system becomes overloaded or reduce the number of silos if the system is mostly idle. OrleansSiloStatistics table - this table includes a much larger number of performance statistics (hundreds of counters) which provide a much more detailed and in-depth view of the internal silo state. This table is currently not recommended for use by external operators. It is mainly for Orleans developers to help them troubleshoot complex production problems, if they occur. The Orleans team is building tools to analyze this data automatically and provide compact recommendations to operators based on it. Such tools can also be built by anyone independently. Watching error codes in MDS - Orleans automatically writes different error messages into logger. This logger can be configured to output its data to various destinations. For example, the Halo team redirects all logs in production to MDS. They have written custom alerts in MDS to watch for specific error codes and count their occurrences, and alert them when those reach a certain threshold. The list of important error codes to watch is specified here: Silo Error Code Monitoring Client Error Code Monitoring Windows performance counters - The Orleans runtime continually updates a number of them. CounterControl.exe helps register the counters, and needs to run with elevated privileges. Obviously, the performance counters can be monitored using any of the standard monitoring tools."
  },
  "1.5/Documentation/Deployment-and-Operations/Configuration-Guide/index.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Configuration-Guide/index.html",
    "title": "Orleans Configuration Guide | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Orleans Configuration Guide This Configuration Guide explains the key configuration parameters and how they should be used for most typical usage scenarios. Orleans Configuration xsd file is located here . Orleans can be used in a variety of configurations that fit different usage scenarios, such as local single node deployment for development and testing, cluster of servers, multi-instance Azure worker role, etc. All of the different target scenarios are achieved by specifying particular values in the Orleans configuration XML files. This guide provides instructions for the key configuration parameters that are necessary to make Orleans run in one of the target scenarios. There are also other configuration parameters that primarily help fine tune Orleans for better performance. They are documented in the XSD schema and in general are not required even for running the system in production. Orleans is a framework for building and running high scale services. A typical deployment of an Orleans application spans a cluster of servers. The instances of the Orleans runtime, called silos, running on each of the servers need to be configured to connect to each other. In addition to that, there is always a client component that connects to the Orleans deployment, most typically a web frontend, that needs to be configured to connect to the silos. The Server Configuration and Client Configuration sections of the guide cover those aspects, respectively. The section on Typical Configurations provides a summary of a few common configurations. Important : Make sure you properly configure .NET Garbage Collection as detailed in Configuring .NET Garbage Collection ."
  },
  "1.5/Documentation/Deployment-and-Operations/Using-Azure-Web-Apps.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Using-Azure-Web-Apps.html",
    "title": "Getting Started using Azure Web Apps | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Getting Started using Azure Web Apps If you would like to connect to an Azure Silo from an Azure Web App rather than a Web Role hosted within the same cloud service you can. For this to work securely you will need to assign both the Azure Web App and the Worker Role hosting the Silo to an Azure Virtual Network . First we'll setup the Azure Web App, you can follow this guide which will create the virtual network and assign it to the Azure Web App. Now we can assign the cloud service to the virtual network by modifying the ServiceConfiguration file. <NetworkConfiguration> <VirtualNetworkSite name=\"virtual-network-name\" /> <AddressAssignments> <InstanceAddress roleName=\"role-name\"> <Subnets> <Subnet name=\"subnet-name\" /> </Subnets> </InstanceAddress> </AddressAssignments> </NetworkConfiguration> Also make sure the Silo endpoints are configured. <Endpoints> <InternalEndpoint name=\"OrleansSiloEndpoint\" protocol=\"tcp\" port=\"11111\" /> <InternalEndpoint name=\"OrleansProxyEndpoint\" protocol=\"tcp\" port=\"30000\" /> </Endpoints> Finally, you need to specify the same deployment id for Silos and the Web App Client. You can now use the GrainClient to make a connection from the Web App to the Silo. Potential Issues If the Web App is having difficulty connecting to the Silo: Make sure you have at least two roles , or two instances of one role in your Azure Cloud Service, or the InternalEndpoint firewall rules may not be generated. Check that both the Web App and the Silo are using the same DeploymentId . Make sure the network security group is set up to allow internal virtual network connections. If you haven't got one you can create and assign one easily using the following PowerShell : New-AzureNetworkSecurityGroup -Name \"Default\" -Location \"North Europe\" Get-AzureNetworkSecurityGroup -Name \"Default\" | Set-AzureNetworkSecurityGroupToSubnet -VirtualNetworkName \"virtual-network-name\" -SubnetName \"subnet-name\""
  },
  "1.5/Documentation/Deployment-and-Operations/Docker-Deployment.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Docker-Deployment.html",
    "title": "Docker Deployment | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Docker Deployment Note : Even if you are very familiar with Docker and/or Orleans, as any other Orleans documentation, I recommend you to read it to the end in order to avoid problems you may face that we already worked around. Note : This article and its sample are a work in progress. Any feedback, PR or suggestion is very welcome. Deploying Orleans solutions to Docker Deploying Orleans to Docker can be tricky given the way Docker orchestrators and clustering stacks was designed. The most complicated thing is to understand the concept of Overlay Network from Docker Swarm and Kubernets Networking model. Docker containers and networking model were designed to run mostly stateless and immutable containers. So, spin up a cluster running node.js or nginx applications, is pretty easy. However, if you try to use something more elaborated, like a real clustered or distributed application (like Orleans-based ones) you will eventually have troubles setting it up. It is possible, but not as simples as web-based applications. Docker clustering consist of putting together multiple hosts to work as a single pool of resources managed using a Container Orchestrator . Docker Inc. provide Swarm as their option for Container Orchestration while Google has Kubernetes (aka K8s ). There are other Orchestrators like DC/OS , Mesos , etc., but in this document we will talk about Swarm and K8s as they are more widely used. The same grain interfaces and implementation which run anywhere Orleans is already supported, will run on Docker containers as well, so no special considerations are needed in order to be able to run your application in Docker containers. The Orleans-Docker sample provides a working example of how to run two console applications. One as Orleans Client and another as Silo, and the details are described below. The concepts discussed here, can be used on both .Net Core and .Net 4.6.1 flavors of Orleans but to ilustrate the cross-platform nature of Docker and .Net Core, we are going to focus on the example considering you are using .Net Core. Platform-specific (Windows/Linux/OSX) details may be provide along this article. Pre-requisites This article assume that you have the following prerequisites installed: Docker - Docker4X has a easy-to-use installer for the major supported platforms. It contains Docker engine and also Docker Swarm. Kubernetes (K8s) - Google's offer for Container Orchestration. It contains a guidance to install Minikube (a local deployment of K8s) and kubectl along with all its dependencies. .Net Core - Cross-platform flavor of .Net Visual Studio Code (VSCode) - You can use whatever IDE you want. VSCode is cross-platform so we are using it to ensure it works on all platforms. Once you installed VSCode, install the C# extension . Note : You are not required to have Kubernetes installed if you are not going to use it. Docker4X installer already includes Swarm so no extra installation is required to use it. Note for Windows Users : On Windows, Docker installer will enable Hyper-V at installation process. As this article and its examples are using .Net Core, the container images used are based on Windows Server NanoServer . If you don't plan to use .Net Core and will target .Net 4.6.1 full framework, the image used should be Windows Server Core and the 1.4+ version of Orleans (which support only .net full framework). Creating Orleans Solution The following instructions show how to create a regular Orleans solution using the new dotnet tooling. Note : Please adapt the commands to whatever appropriate in your platform. Also, the directory structure is just a suggestion. Please adapt it whatever way you want. mkdir Orleans-Docker cd Orleans-Docker dotnet new sln mkdir -p src/OrleansSilo mkdir -p src/OrleansClient mkdir -p src/OrleansGrains mkdir -p src/OrleansGrainInterfaces dotnet new console -o src/OrleansSilo --framework netcoreapp1.1 dotnet new console -o src/OrleansClient --framework netcoreapp1.1 dotnet new classlib -o src/OrleansGrains --framework netstandard1.5 dotnet new classlib -o src/OrleansGrainInterfaces --framework netstandard1.5 dotnet sln add src/OrleansSilo/OrleansSilo.csproj dotnet sln add src/OrleansClient/OrleansClient.csproj dotnet sln add src/OrleansGrains/OrleansGrains.csproj dotnet sln add src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansClient/OrleansClient.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansSilo/OrleansSilo.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansGrains/OrleansGrains.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansSilo/OrleansSilo.csproj reference src/OrleansGrains/OrleansGrains.csproj What we did so far was just boilerplate code to create the solution structure, projects, and add references between projects. Nothing different than a regular Orleans project. By the time this article was written, Orleans 2.0 (which is the only version which support .Net Core and cross-platform) is in Technology Preview so its nugets are hosted in a MyGet feed and not published to Nuget.org official feed. In order to install the preview nugets, we will use dotnet cli forcing the source feed and version from MyGet: dotnet add src/OrleansClient/OrleansClient.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansGrains/OrleansGrains.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansSilo/OrleansSilo.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansSilo/OrleansSilo.csproj package Microsoft.Orleans.OrleansRuntime -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet restore Ok, now you have all the basic dependencies to run a simple Orleans application. Note that so far, nothing changed from your regular Orleans application. Now, lets add some code so we can do something with it. Implementing your Orleans Application Assuming that you are using VSCode , from the solution directory, run code . . That will open the directory in VSCode and load the solution. This is the solution structure we just created previously. We also added Program.cs , OrleansHostWrapper , IGreetingGrain and GreetingGrain files to the interfaces and grain projects respectively and here is the code for those files: IGreetingGrain.cs : using System; using System.Threading.Tasks; using Orleans; namespace OrleansGrainInterfaces { public interface IGreetingGrain : IGrainWithGuidKey { Task<string> SayHello(string name); } } GreetingGrain.cs : using System; using System.Threading.Tasks; using OrleansGrainInterfaces; namespace OrleansGrains { public class GreetingGrain : Grain, IGreetingGrain { public Task<string> SayHello(string name) { return Task.FromResult($\"Hello from Orleans, {name}\"); } } } OrleansHostWrapper.cs : using System; using System.Net; using Orleans.Runtime; using Orleans.Runtime.Configuration; using Orleans.Runtime.Host; namespace OrleansSilo { public class OrleansHostWrapper { private readonly SiloHost siloHost; public OrleansHostWrapper(ClusterConfiguration config) { siloHost = new SiloHost(Dns.GetHostName(), config); siloHost.LoadOrleansConfig(); } public int Run() { if (siloHost == null) { return 1; } try { siloHost.InitializeOrleansSilo(); if (siloHost.StartOrleansSilo()) { Console.WriteLine($\"Successfully started Orleans silo '{siloHost.Name}' as a {siloHost.Type} node.\"); return 0; } else { throw new OrleansException($\"Failed to start Orleans silo '{siloHost.Name}' as a {siloHost.Type} node.\"); } } catch (Exception exc) { siloHost.ReportStartupError(exc); Console.Error.WriteLine(exc); return 1; } } public int Stop() { if (siloHost != null) { try { siloHost.StopOrleansSilo(); siloHost.Dispose(); Console.WriteLine($\"Orleans silo '{siloHost.Name}' shutdown.\"); } catch (Exception exc) { siloHost.ReportStartupError(exc); Console.Error.WriteLine(exc); return 1; } } return 0; } } } Program.cs (Silo): using System; using System.Collections.Generic; using System.Linq; using System.Net; using Orleans.Runtime.Configuration; namespace OrleansSilo { public class Program { private static OrleansHostWrapper hostWrapper; static int Main(string[] args) { int exitCode = InitializeOrleans(); Console.WriteLine(\"Press Enter to terminate...\"); Console.ReadLine(); exitCode += ShutdownSilo(); return exitCode; } private static int InitializeOrleans() { var config = new ClusterConfiguration(); config.Globals.DataConnectionString = \"[AZURE STORAGE CONNECTION STRING HERE]\"; config.Globals.DeploymentId = \"Orleans-Docker\"; config.Globals.LivenessType = GlobalConfiguration.LivenessProviderType.AzureTable; config.Globals.ReminderServiceType = GlobalConfiguration.ReminderServiceProviderType.AzureTable; config.Defaults.PropagateActivityId = true; config.Defaults.ProxyGatewayEndpoint = new IPEndPoint(IPAddress.Any, 10400); config.Defaults.Port = 10300; var ips = Dns.GetHostAddressesAsync(Dns.GetHostName()).Result; config.Defaults.HostNameOrIPAddress = ips.FirstOrDefault()?.ToString(); hostWrapper = new OrleansHostWrapper(config); return hostWrapper.Run(); } private static int ShutdownSilo() { if (hostWrapper != null) { return hostWrapper.Stop(); } return 0; } } } Program.cs (client): using System; using System.Net; using System.Threading; using System.Threading.Tasks; using Orleans; using Orleans.Runtime.Configuration; using OrleansGrainInterfaces; namespace OrleansClient { class Program { private static IClusterClient client; private static bool running; static void Main(string[] args) { Task.Run(() => InitializeOrleans()); Console.ReadLine(); running = false; } static async Task InitializeOrleans() { var config = new ClientConfiguration(); config.DeploymentId = \"Orleans-Docker\"; config.PropagateActivityId = true; var hostEntry = await Dns.GetHostEntryAsync(\"orleans-silo\"); var ip = hostEntry.AddressList[0]; config.Gateways.Add(new IPEndPoint(ip, 10400)); Console.WriteLine(\"Initializing...\"); client = new ClientBuilder().UseConfiguration(config).Build(); await client.Connect(); running = true; Console.WriteLine(\"Initialized!\"); var grain = client.GetGrain<IGreetingGrain>(Guid.Empty); while(running) { var response = await grain.SayHello(\"Gutemberg\"); Console.WriteLine($\"[{DateTime.UtcNow}] - {response}\"); await Task.Delay(1000); } client.Dispose(); } } } We are not going into details about the grain implementation here since it is out of the scope of this article. Please check other documents related to it. Those files are essentially a minimal Orleans application and we will start from it to move forward with the remaining of this article. Note : In this article we are using OrleansAzureUtils membership provider but you can use any other already supported by Orleans. Dockerfile In order to create your container, Docker use images. For more details on how to create your own, you can check Docker documentation . In this article we are going to use official Microsoft images . Based on the target and development platforms, you need to pick the appropriate image. In this article, we are using microsoft/dotnet:1.1.2-sdk which is a linux-based image. You can use microsoft/dotnet:1.1.2-sdk-nanoserver for Windows for example. Pick one that suit your needs. Note for Windows users : As previously mentioned, to be cross-platform, we are using .Net Core and Orleans Technical preview 2.0 in this article. If you want to use Docker on Windows with the fully released Orleans 1.4+, you need to use the images that are based on Windows Server Core since NanoServer and Linux based images, only support .Net Core. Dockerfile.debug : FROM microsoft/dotnet:1.1.2-sdk ENV NUGET_XMLDOC_MODE skip WORKDIR /vsdbg RUN apt-get update \\ && apt-get install -y --no-install-recommends \\ unzip \\ && rm -rf /var/lib/apt/lists/* \\ && curl -sSL https://aka.ms/getvsdbgsh | bash /dev/stdin -v latest -l /vsdbg WORKDIR /app ENTRYPOINT [\"tail\", \"-f\", \"/dev/null\"] This dockerfile essentially download and install the VSdbg debugger and start an empty container and keep it alive forever so we don't need tear down/up while debugging. Now, for production, the image is smaller since it contains only the .Net Core runtime and not the whole SDK, and the dockerfile is a bit simpler: Dockerfile : FROM microsoft/dotnet:1.1.2-runtime WORKDIR /app ENTRYPOINT [\"dotnet\", \"OrleansSilo.dll\"] COPY . /app docker-compose The docker-compose.yml file, essentially pack up within a project a set of services and its dependencies at service level. Each service contains one or more instances of a given container, which is based on the images you selected on your Dockerfile. More details on the docker-compose you you can find on docker-compose documentation . For an Orleans deployment, a common use case is to have a docker-compose.yml which contains two services. One for Orleans Silo, and other for Orleans Client. The Client would have a dependency on the Silo and that means, it will only start after the Silo service is up. Another case is to add a storage/database service/container, like for example SQL Server, which should start first before the client and the silo, so both services should take a dependency on it. Note : Before you read further (and eventually get crazy with it), please note that identation matters in docker-compose files. So pay attention to it if you have any problem. Here is how we will describe our services for this article: docker-compose.override.yml (Debug): version: '3.1' services: orleans-client: image: orleans-client:debug build: context: ./src/OrleansClient/bin/PublishOutput/ dockerfile: Dockerfile.Debug volumes: - ./src/OrleansClient/bin/PublishOutput/:/app - ~/.nuget/packages:/root/.nuget/packages:ro depends_on: - orleans-silo orleans-silo: image: orleans-silo:debug build: context: ./src/OrleansSilo/bin/PublishOutput/ dockerfile: Dockerfile.Debug volumes: - ./src/OrleansSilo/bin/PublishOutput/:/app - ~/.nuget/packages:/root/.nuget/packages:ro docker-compose.yml (production): version: '3.1' services: orleans-client: image: orleans-client depends_on: - orleans-silo orleans-silo: image: orleans-silo Note that in production, we don't map the local directory and neither we have the build: action. The reason is that in production, the images should be already being built and pushed to your own Docker Registry. Put everything together Now we have all the moving parts required to run your Orleans Application, we are going to put it together so we can run our Orleans solution inside Docker (Finally!). Note : The following commands should be performed from the solution directory. First, lets make sure we restore all NuGet packages from our solution. You only need to do it once. You are only required to do it again if you change any package dependency on your project. # dotnet restore Now, let's build our solution using dotnet CLI as usual and publish it to an output directory: # dotnet publish -o ./bin/PublishOutput Note : We are using publish here instead of build, to avoid problems with our dynamicaly loaded assemblied in Orleans. We are still looking for a better solution for it. With the application built and published, you need to build your Dockerfile images. This step is only required to be performed once per project and should be only performed again if you change the Dockerfil, docker-compose, or for any reason you cleaned up your local image registry. # docker-compose build All the images used in both Dockerfile and docker-compose.yml are pulled from the registry and cached on your development machine. Your images are built, and you are all set to run. Now lets run it! # docker-compose up -d Creating network \"orleansdocker_default\" with the default driver Creating orleansdocker_orleans-silo_1 ... Creating orleansdocker_orleans-silo_1 ... done Creating orleansdocker_orleans-client_1 ... Creating orleansdocker_orleans-client_1 ... done # Now if you run a docker-compose ps , you will see 2 containers running for the orleansdocker project: # docker-compose ps Name Command State Ports ------------------------------------------------------------------ orleansdocker_orleans-client_1 tail -f /dev/null Up orleansdocker_orleans-silo_1 tail -f /dev/null Up Note for Windows users : If you are on Windows, and your container is using a Windows image as base, the Command column will show you the Powershell relative command to a tail on *NIX systems so the container will keep up the same way. Now that you have your containers up, you don't need to stop it every time you want to start your Orleans application. All you need is to integrate your IDE to debug the application inside the container which was previously mapped in your docker-compose.yml . Scaling Once you have your compose project running, you can easily scale up or down your application using docker-compose scale command: # docker-compose scale orleans-silo=15 Starting orleansdocker_orleans-silo_1 ... done Creating orleansdocker_orleans-silo_2 ... Creating orleansdocker_orleans-silo_3 ... Creating orleansdocker_orleans-silo_4 ... Creating orleansdocker_orleans-silo_5 ... Creating orleansdocker_orleans-silo_6 ... Creating orleansdocker_orleans-silo_7 ... Creating orleansdocker_orleans-silo_8 ... Creating orleansdocker_orleans-silo_9 ... Creating orleansdocker_orleans-silo_10 ... Creating orleansdocker_orleans-silo_11 ... Creating orleansdocker_orleans-silo_12 ... Creating orleansdocker_orleans-silo_13 ... Creating orleansdocker_orleans-silo_14 ... Creating orleansdocker_orleans-silo_15 ... Creating orleansdocker_orleans-silo_6 Creating orleansdocker_orleans-silo_5 Creating orleansdocker_orleans-silo_3 Creating orleansdocker_orleans-silo_2 Creating orleansdocker_orleans-silo_4 Creating orleansdocker_orleans-silo_9 Creating orleansdocker_orleans-silo_7 Creating orleansdocker_orleans-silo_8 Creating orleansdocker_orleans-silo_10 Creating orleansdocker_orleans-silo_11 Creating orleansdocker_orleans-silo_15 Creating orleansdocker_orleans-silo_12 Creating orleansdocker_orleans-silo_14 Creating orleansdocker_orleans-silo_13 Few seconds later, you will see the services scaled to the specific number of instances you requested. # docker-compose ps Name Command State Ports ------------------------------------------------------------------ orleansdocker_orleans-client_1 tail -f /dev/null Up orleansdocker_orleans-silo_1 tail -f /dev/null Up orleansdocker_orleans-silo_10 tail -f /dev/null Up orleansdocker_orleans-silo_11 tail -f /dev/null Up orleansdocker_orleans-silo_12 tail -f /dev/null Up orleansdocker_orleans-silo_13 tail -f /dev/null Up orleansdocker_orleans-silo_14 tail -f /dev/null Up orleansdocker_orleans-silo_15 tail -f /dev/null Up orleansdocker_orleans-silo_2 tail -f /dev/null Up orleansdocker_orleans-silo_3 tail -f /dev/null Up orleansdocker_orleans-silo_4 tail -f /dev/null Up orleansdocker_orleans-silo_5 tail -f /dev/null Up orleansdocker_orleans-silo_6 tail -f /dev/null Up orleansdocker_orleans-silo_7 tail -f /dev/null Up orleansdocker_orleans-silo_8 tail -f /dev/null Up orleansdocker_orleans-silo_9 tail -f /dev/null Up Note : The Command column on those examples are showing the tail command just because we are using the debugger container. If we were in production, it would be showing dotnet OrleansSilo.dll for example. Docker Swarm Docker clustering stack is called Swarm and you can find more by reading its documentation here . To run this article in a Swarm cluster, you don't have any extra work. When you run docker-compose up -d in a Swarm node, it will schedule containers based on the configured rules. The same applies to other Swarm-based services like Docker Datacenter , Azure ACS (in Swarm mode), AWS ECS Container Service and so on. All you need to do is to deploy your Swarm cluster before deploy your dockerized Orleans application. Note : If you are using a Docker engine with the Swarm mode that already have support to stack , deploy and compose v3, a better approach to deploy your solution would be docker stack deploy -c docker-compose.yml <name> . Just keep in mind that it requires v3 compose file support at your Docker engine and the majority of hosted services like Azure and AWS still use v2 and older engines. Google Kubernetes (K8s) If you plan to use Kubernetes to host Orleans, there is a community-maintained clustering provider available at OrleansContrib\\Orleans.Clustering.Kubernetes and there you can find documentation and samples on how to host Orleans in Kubernetes seamlessly using the provider. [Bonus topic] Debugging Orleans inside Containers Well, now that you know how to run Orleans in a container from scratch, would be good to leverage one of the most important principles in Docker. Containers are immutable. And they should have (almost) the same image, dependencies, and runtime in development as in production. That ensure the good old statement \"It work on my machine!\" never happen again. To make that possible, you need to have a way to develop inside the container and that includes have a debugger attached to your application inside the container. There are multiple ways to achieve that using multiple tools. After evaluate several, by the time I wrote this article, I ended up choosing one that looks more simple and is less intrusive in the application. As mentioned ealier in this article, we are using VSCode to develop the sample, so here is how to get the debugger attached to your Orleans Application inside the container. First, change two files inside your .vscode directory in your solution: tasks.json : { \"version\": \"0.1.0\", \"command\": \"dotnet\", \"isShellCommand\": true, \"args\": [], \"tasks\": [ { \"taskName\": \"publish\", \"args\": [ \"${workspaceRoot}/Orleans-Docker.sln\", \"-c\", \"Debug\", \"-o\", \"./bin/PublishOutput\" ], \"isBuildCommand\": true, \"problemMatcher\": \"$msCompile\" } ] } This file essentially tells VSCode that whenever you build the project, it will actually execute the publish command as we manually did earlier. launch.json : { \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Silo\", \"type\": \"coreclr\", \"request\": \"launch\", \"cwd\": \"/app\", \"program\": \"/app/OrleansSilo.dll\", \"sourceFileMap\": { \"/app\": \"${workspaceRoot}/src/OrleansSilo\" }, \"pipeTransport\": { \"debuggerPath\": \"/vsdbg/vsdbg\", \"pipeProgram\": \"/bin/bash\", \"pipeCwd\": \"${workspaceRoot}\", \"pipeArgs\": [ \"-c\", \"docker exec -i orleansdocker_orleans-silo_1 /vsdbg/vsdbg --interpreter=vscode\" ] } }, { \"name\": \"Client\", \"type\": \"coreclr\", \"request\": \"launch\", \"cwd\": \"/app\", \"program\": \"/app/OrleansClient.dll\", \"sourceFileMap\": { \"/app\": \"${workspaceRoot}/src/OrleansClient\" }, \"pipeTransport\": { \"debuggerPath\": \"/vsdbg/vsdbg\", \"pipeProgram\": \"/bin/bash\", \"pipeCwd\": \"${workspaceRoot}\", \"pipeArgs\": [ \"-c\", \"docker exec -i orleansdocker_orleans-client_1 /vsdbg/vsdbg --interpreter=vscode\" ] } } ] } Now you can just build the solution from VSCode (which will publish) and start both the Silo and the Client. It will send a docker exec command to the running docker-compose service instance/container to start the debugger to the application and thats it. You have the debugger attached to the container and use it as if it was a locally running Orleans application. The difference now is that it is inside the container, and once you are done, you can just publish the container to your registry and pull it on your Docker hosts in production."
  },
  "1.5/Documentation/Advanced-Concepts/Reentrant-Grains.html": {
    "href": "1.5/Documentation/Advanced-Concepts/Reentrant-Grains.html",
    "title": "Reentrant Grains | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Reentrant Grains By default, the Orleans scheduler requires an activation to completely finish processing one request before invoking the next request. An activation cannot receive a new request until all of the Task s created (directly or indirectly) in the processing of the current request have been resolved and all of their associated closures executed. Grain implementation classes may be marked with the [Reentrant] attribute to indicate that turns belonging to different requests may be freely interleaved. In other words, a reentrant activation may start executing another request while a previous request has not finished processing and has pending closures. Execution of turns of both requests are still limited to a single thread. So the activation is still executing one turn at a time, and each turn is executing on behalf of only one of the activation’s requests. Reentrant grain code will never run multiple pieces of grain code in parallel (execution of grain code will always be single-threaded), but reentrant grains may see the execution of code for different requests interleaving. That is, the continuation turns from different requests may interleave. For example, with the below pseudo-code, when Foo and Bar are 2 methods of the same grain class: Task Foo() { await task1; // line 1 return Do2(); // line 2 } Task Bar() { await task2; // line 3 return Do2(); // line 4 } If this grain is marked [Reentrant] , the execution of Foo and Bar may interleave. For example, the following order of execution is possible: Line 1, line 3, line 2 and line 4. That is, the turns from different requests interleave. If the grain was not reentrant, the only possible executions would be: line 1, line 2, line 3, line 4 OR: line 3, line 4, line 1, line 2 (new request cannot start before the previous one finished). Reentrant grains should have slightly less overhead because of fewer activations, scheduling queues, smaller directory, and resources proportional to the number of activations. How small or large the “slightly” depends on what order of numbers we are talking about here, and on the potential overhead of handling interleaving requests (extra copies of state, etc.). The main tradeoff in choosing between reentrant and non-reentrant grains is the code complexity to make interleaving work correctly and the difficulty to reason about it. In a trivial case when the grains are stateless and the logic is simple, fewer (but not too few, so that all the hardware threads are used) reentrant grains should be in general slightly more efficient. If the code is more complex, then a larger number of non-reentrant grains, even if slightly less efficient overall, should save you a lot of grief of figuring out non-obvious interleaving issues. In the end answer will depend on the specifics of the application."
  },
  "1.5/Documentation/Introduction.html": {
    "href": "1.5/Documentation/Introduction.html",
    "title": "Introduction | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Introduction Orleans is a framework that provides a straightforward approach to building distributed high-scale computing applications, without the need to learn and apply complex concurrency or other scaling patterns. Background Cloud applications and services are inherently parallel and distributed. They are also interactive and dynamic; often requiring near real time direct interactions between cloud entities. Such applications are very difficult to build today. The development process demands expert level programmers and typically requires expensive iterations of the design and the architecture, as the workload grows. Most of today’s high scale properties are built as a composition of stateless n-tier services with most of application logic residing in the middle tier. While the model allows to scale out by adding more servers to the middle tier, it is constrained by the performance and scalability of the storage layer because most requests coming to the middle tier from the frontend web servers require one or more reads from storage, and updates are even more complicated and prone to concurrency issues and conflicts due to lack of coordination between the middle tier servers. It often requires caching in the stateless layer to get acceptable performance, adding complexity and introducing cache consistency issues. The other problem with the stateless n-tier model is that it doesn't support well horizontal communications between individual application entities exposed by the middle tier, which makes it hard to implement complex business logic with multiple entities performing individual operations as part of processing a request. Orleans as a Stateful Middle Tier Orleans provides an intuitive way of building a stateful middle tier, where various business logic entities appear as sea of isolated globally addressable .NET objects (grains) of different application defined types distributed across a cluster of servers (silos). A grain type is a simple .NET class that implements one or more application defined grain interfaces. Individual grains are instances of application defined grain classes that get automatically created by the Orleans runtime on servers on an as-needed basis to handle requests for those grains. Grains naturally map to most application entities, such as users, devices, sessions, inventories, orders, etc., which makes it very easy to build business logic that is object-oriented but scales transparently across a cluster of servers. Each grain has a stable logical identity (key) within its grain type chosen by the application logic, for example, user email or device ID or inventory SKU code. Orleans guarantees single-threaded execution of each individual grain, hence protecting the application logic from perils of concurrency and races. In the world of microservices, Orleans is used as a framework for implementing a microservice that can be deployed and managed by a microservices deployment/management solution of developer's choice. Grain Lifecycle Grain can have persistent state in storage or in-memory state or a combination of both. Any grain can be called by any other grain or by a frontend (client) by using the target grain's logical identity without the need to ever create or instantiate the target grain. The Orleans programming model makes grains appear as if they are in memory the whole time. In reality, a grain goes through the lifecycle from existing only as its persisted state in storage to being instantiated in memory to being removed from memory. The Orleans runtime behind the scene instantiates (activates) grains when there's work for them to do, and removes them from memory (deactivates) to reclaim hardware resources when they are idle for too long. This grain lifecycle management work of the runtime is transparent to the application code, and liberates it from the complicated task of distributed resource management. Application logic can be written with the whole \"address space\" of grains available to it without the need to have hardware resources to keep all grains in memory at the same time, conceptually similar to how virtual memory works in operating systems. In addition, the virtual nature of grains allows Orleans to handle server failures mostly transparently to the application logic because grains that were executing on a failed server get automatically re-instantiated on other servers in the cluster once the failure is detected. Virtual Actors Implementation of Orleans is based on the Actor Model that's been around since 1970s. However, unlike actors in more traditional actor systems such as Erlang or Akka, Orleans Grains are virtual actors. The biggest difference is that physical instantiations of grains are completely abstracted away and are automatically managed by the Orleans runtime. The Virtual Actor Model is much more suitable for high-scale dynamic workloads like cloud services and is the major innovation of Orleans. You can read more details in the Technical Report on Orleans. Origin of Orleans Orleans was created at Microsoft Research and designed for use in the cloud . Since 2011, it has been used extensively in the cloud and on premises by several Microsoft product groups, most notably by game studios, such as 343 Industries and The Coalition as a platform for cloud services behind Halo 4/5 and Gears of War 4, as well as by a number of other companies. Orleans was open-sourced in January 2015, and attracted many developers that formed one of the most vibrant open source communities in the .NET ecosystem . In an active collaboration between the developer community and the Orleans team at Microsoft, features are added and improved on a daily basis. Microsoft Research continues to partner with the Orleans team to bring new major features, such as geo-distribution , indexing , and distributed transactions , that are pushing the state of the art. Orleans has become the framework of choice for building distributed systems and cloud services for many .NET developers."
  },
  "Documentation/deployment/grain_versioning/version_selector_strategy.html": {
    "href": "Documentation/deployment/grain_versioning/version_selector_strategy.html",
    "title": "Version selector strategy | Microsoft Orleans Documentation",
    "keywords": "Version selector strategy When several versions of the same grain interface exist in the cluster, and a new activation has to be created, a compatible version will be chosen according to the strategy defined in GrainVersioningOptions.DefaultVersionSelectorStrategy . Orleans out of the box supports the following strategies: All compatible versions (default) Using this strategy, the version of the new activation will be chosen randomly across all compatible versions. For example if we have 2 versions of a given grain interface, V1 and V2: V2 is backward compatible with V1 In the cluster there are 2 silos that support V2, 8 support V1 The request was made from a V1 client/silo In this case, there is a 20% chance that the new activation will be a V2 and 80% chance that it will be a V1. Latest version Using this strategy, the version of the new activation will always be the latest compatible version. For example if we have 2 versions of a given grain interface, V1 and V2 (V2 is backward or fully compatible with V1) then all new activations will be V2. Minimum version Using this strategy, the version of the new activation will always be the requested or the minimum compatible version. For example if we have 2 versions of a given grain interface, V2, V3, all fully compatibles: If the request was made from a V1 client/silo, the new activation will be a V2 If the request was made from a V3 client/silo, the new activation will be a V2 too"
  },
  "1.5/Documentation/Orleans-Streams/Streams-Why.html": {
    "href": "1.5/Documentation/Orleans-Streams/Streams-Why.html",
    "title": "Why Orleans Streams? | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Why Orleans Streams? There are already a wide range of technologies that allow you to build stream processing systems. Those include systems to durably store stream data (e.g., Event Hubs and Kafka ) and systems to express compute operations over stream data (e.g., Azure Stream Analytics , Apache Storm , and Apache Spark Streaming ). Those are great systems that allow you to build efficient data stream processing pipelines. Limitations of Existing Systems However, those systems are not suitable for fine-grained free-form compute over stream data . The Streaming Compute systems mentioned above all allow you to specify a unified data-flow graph of operations that are applied in the same way to all stream items . This is a powerful model when data is uniform and you want to express the same set of transformation, filtering, or aggregation operations over this data. But there are other use cases where you need to express fundamentally different operations over different data items. And in some of them as part of this processing you occasionally need to make an external call, such as invoke some arbitrary REST API. The unified data-flow stream processing engines either do not support those scenarios, support them in a limited and constrained way, or are inefficient in supporting them. This is because they are inherently optimized for a large volume of similar items, and usually limited in terms of expressiveness, processing . Orleans Streams target those other scenarios. Motivation It all started with requests from Orleans users to support returning a sequence of items from a grain method call. As you can imagine, that was only the tip of the iceberg. They actually needed much more than that. A typical scenario for Orleans Streams is when you have per user streams and you want to perform different processing for each user , within the context of an individual user. We may have millions of users but some of them are interested in weather and can subscribe to weather alerts for a particular location, while some are interested in sports events; somebody is tracking status of a particular flight. Processing those events requires different logic, but you don't want to run two independent instances of stream processing. Some users are interested in only a particular stock and only if certain external condition applies, condition that may not necessarily be part of the stream data (thus needs to be checked dynamically at runtime as part of processing). Users change their interests all the time, hence their subscriptions to specific streams of events come and go dynamically, thus the streaming topology changes dynamically and rapidly . On top of that, the processing logic per user evolves and changes dynamically as well, based on user state and external events . External events may modify the processing logic for a particular user. For example, in a game cheating detection system, when a new way to cheat is discovered the processing logic needs to be updated with the new rule to detect this new violation. This needs to be done of course without disrupting the ongoing processing pipeline . Bulk data-flow stream processing engines were not build to support such scenarios. It goes almost without saying that such a system has to run on a number of network-connected machines, not on a single node. Hence, the processing logic has to be distributed in a scalable and elastic manner across a cluster of servers. New Requirements We identified 4 basic requirements for our Stream Processing system that will allow it to target the above scenarios. Flexible stream processing logic Support for highly dynamic topologies Fine-grained stream granularity Distribution Flexible stream processing logic We want the system to support different ways of expressing the stream processing logic. The existing systems we mentioned above require the developer to write a declarative data-flow computation graph, usually by following a functional programming style. This limits the expressiveness and flexibility of the processing logic. Orleans streams are indifferent to the way processing logic is expressed. It can be expressed as a data-flow (e.g., by using Reactive Extensions (Rx) in .NET ); as a functional program; as a declarative query; or in a general imperative logic. The logic can be stateful or stateless, may or may not have side effects, and can trigger external actions. All power goes to the developer. Support for dynamic topologies We want the system to allow for dynamically evolving topologies. The existing systems we mentioned above are usually limited to only static topologies that are fixed at deployment time and cannot evolve at runtime. In the following example of a dataflow expression everything is nice and simple until you need to change it. Stream.GroupBy(x=> x.key).Extract(x=>x.field).Select(x=>x+2).AverageWindow(x, 5sec).Where(x=>x > 0.8) * Change the threshold condition in the Where filter, add an additional Select statement or add another branch in the data-flow graph and produce a new output stream. In existing systems this is not possible without tearing down the entire topology and restarting the data-flow from scratch. Practically, those systems will checkpoint the existing computation and will be able to restart from the latest checkpoint. Still, such a restart is disruptive and costly to an online service that produces results in real time. Such a restart becomes especially impractical when we are talking about a large number of such expressions being executed with similar but different (per-user, per-deveice, et.) parameters and that keep constantly changing. We want the system to allow for evolving the stream processing graph at runtime, by adding new links or nodes to the computation graph, or by changing the processing logic within the computation nodes. Fine grained stream granularity In the existing systems, the smallest unit of abstraction is usually the whole flow (topology). However, many of our target scenarios require individual node/link in the topology to be a logical entity by itself. That way each entity can be potentially managed independently. For example, in the big stream topology comprising of multiple links, different links can have different characteristics and can be implemented over different physical transports. Some links can go over TCP sockets, while others over reliable queues. Different links can have different delivery guarantees. Different nodes can have different checkpointing strategies, and their processing logic can be expressed in different models or even different languages. Such flexibility is usually not possible in existing systems. The unit of abstraction and flexibility argument is similar to comparison of SoA (Service Oriented Architectures) vs. Actors. Actor systems allow more flexibility, since each is essentially an independently managed ''tiny service''. Similarly, we want the system to allow for such a fine grained control. Distribution And of course, our system should have all the properties of a \"good distributed system\" . That includes: Scalability - supports large number of streams and compute elements. Elasticity - allows to add/remove resources to grow/shrink based on load. Reliability - be resilient to failures Efficiency - use the underlying resources efficiently Responsiveness - enable near real time scenarios. These were the requirements we had in mind for building Orleans Streaming . Clarificaton : Orleans currently does not directly support writing declarative dataflow expressions like in the example above. The current Orleans Streaming APIs are more low level building blocks, as described here . Providing declarative dataflow expressions is our future goal. Next Orleans Streams Programming APIs"
  },
  "1.5/Documentation/Orleans-Streams/Streams-Quick-Start.html": {
    "href": "1.5/Documentation/Orleans-Streams/Streams-Quick-Start.html",
    "title": "Orleans Streams Quick Start | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Orleans Streams Quick Start This guide will show you a quick way to setup and use Orleans Streams. To learn more about the details of the streaming features, read other parts of this documentation. Required Configurations In this guide we'll use a Simple Message based Stream which uses grain messaging to send stream data to subscribers. We will use the in-memory storage provider to store lists of subscriptions so it is not a wise choise for real production applications. <Globals> <StorageProviders> <Provider Type=\"Orleans.Storage.MemoryStorage\" Name=\"Default\" /> <Provider Type=\"Orleans.Storage.MemoryStorage\" Name=\"PubSubStore\" /> </StorageProviders> <StreamProviders> <Provider Type=\"Orleans.Providers.Streams.SimpleMessageStream.SimpleMessageStreamProvider\" Name=\"SMSProvider\"/> </StreamProviders> Now we can create streams, send data using them as producers and also receive data as subscribers. Producing Events Producing events for streams is relatively easy. You should first get access to the stream provider which you defined in the config above ( SMSProvider ) and then choose a stream and push data to it. //Pick a guid for a chat room grain and chat room stream var guid = some guid identifying the chat room //Get one of the providers which we defined in config var streamProvider = GetStreamProvider(\"SMSProvider\"); //Get the reference to a stream var stream = streamProvider.GetStream<int>(guid, \"RANDOMDATA\"); As you can see our stream has a GUID and a namespace. This will make it easy to identify unique streams. For example, in a chat room namespace can \"Rooms\" and GUID be the owning RoomGrain's GUID. Here we use the GUID of some known chat room. Now using the OnNext method of the stream we can push data to it. Let's do it inside a timer and using random numbers. You could use any other data type for the stream as well. RegisterTimer(s => { return stream.OnNextAsync(new System.Random().Next()); }, null, TimeSpan.FromMilliseconds(1000), TimeSpan.FromMilliseconds(1000)); Subscribing and receiving streaming data For receiving data we can use implicit/explicit subscriptions, which are fully described in other pages of the manual. Here we use implicit subscriptions which are easier. When a grain type wants to implicitly subscribe to a stream it uses the attribute ImplicitStreamSubscription (namespace)] . For our case we'll define a ReceiverGrain like this: [ImplicitStreamSubscription(\"RANDOMDATA\")] public class ReceiverGrain : Grain, IRandomReceiver Now whenever some data is pushed to the streams of namespace RANDOMDATA as we have in the timer, a grain of type ReceiverGrain with the same guid of the stream will receive the message. Even if no activations of the grain currently exist, the runtime will automatically create a new one and send the message to it. In order for this to work however, we need to complete the subscription process by setting our OnNext method for receiving data. So our ReceiverGrain should call in its OnActivateAsync something like this //Create a GUID based on our GUID as a grain var guid = this.GetPrimaryKey(); //Get one of the providers which we defined in config var streamProvider = GetStreamProvider(\"SMSProvider\"); //Get the reference to a stream var stream = streamProvider.GetStream<int>(guid, \"RANDOMDATA\"); //Set our OnNext method to the lambda which simply prints the data, this doesn't make new subscriptions await stream.SubscribeAsync<int>(async (data, token) => Console.WriteLine(data)); We are all set now. The only requirement is that something triggers our producer grain's creation and then it will registers the timer and starts sending random ints to all interested parties. Again, this guide skips lots of details and is only good for showing the big picture. Read other parts of this manual and other resources on RX to gain a good understanding on what is available and how. Reactive programming can be a very powerful approach to solve many problems. You could for example use LINQ in the subscriber to filter numbers and do all sorts of interesting stuff. Next Orleans Streams Programming APIs"
  },
  "1.5/Documentation/Orleans-Streams/Streams-Programming-APIs.html": {
    "href": "1.5/Documentation/Orleans-Streams/Streams-Programming-APIs.html",
    "title": "Orleans Streams Programming APIs | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Orleans Streams Programming APIs Applications interact with streams via APIs that are very similar to the well known Reactive Extensions (Rx) in .NET . The main difference is that Orleans stream extensions are asynchronous , to make processing more efficient in Orleans' distributed and scalable compute fabric. Async Stream An application starts by using a stream provider to get a handle to a stream. You can read more about stream providers here , but for now you can think of it as stream factory that allows implementers to customize streams behavior and semantics: IStreamProvider streamProvider = base.GetStreamProvider(\"SimpleStreamProvider\"); IAsyncStream<T> stream = streamProvider.GetStream<T>(Guid, \"MyStreamNamespace\"); Application can get a reference to the stream provider either by calling the GetStreamProvider method on the Grain class when inside a grain, or by calling GrainClient.GetStreamProvider() method when on the client. Orleans.Streams.IAsyncStream<T> is a logical, strongly-typed handle to a virtual stream . It is similar in spirit to Orleans Grain Reference. Calls to GetStreamProvider and GetStream are purely local. The arguments to GetStream are a GUID and an additional string that we call a stream namespace (which can be null). Together the GUID and the namespace string comprise the stream identity (similar in sprit to the arguments to GrainFactory.GetGrain ). The combination of GUID and namespace string provide extra flexibility in determining stream identities. Just like grain 7 may exist within the Grain type PlayerGrain and a different grain 7 may exist within the grain type ChatRoomGrain , Stream 123 may exist with the stream namespace PlayerEventsStream and a different stream 123 may exist within the stream namespace ChatRoomMessagesStream . Producing and Consuming IAsyncStream<T> implements both Orleans.Streams.IAsyncObserver<T> and Orleans.Streams.IAsyncObservable<T> interfaces. That way an application can use the stream either to produce new events into the stream by using Orleans.Streams.IAsyncObserver<T> or to subscribe to and consume events from a stream by using Orleans.Streams.IAsyncObservable<T> . public interface IAsyncObserver<in T> { Task OnNextAsync(T item, StreamSequenceToken token = null); Task OnCompletedAsync(); Task OnErrorAsync(Exception ex); } public interface IAsyncObservable<T> { Task<StreamSubscriptionHandle<T>> SubscribeAsync(IAsyncObserver<T> observer); } To produce events into the stream, an application just calls await stream.OnNextAsync<T>(event) To subscribe to a stream, an application calls StreamSubscriptionHandle<T> subscriptionHandle = await stream.SubscribeAsync(IAsyncObserver) The argument to SubscribeAsync can either be an object that implements the IAsyncObserver interface or a combination of lambda functions to process incoming events. More options for SubscribeAsync are available via AsyncObservableExtensions class. SubscribeAsync returns a StreamSubscriptionHandle<T> , which is an opaque handle that can be used to unsubscribe from the stream (similar in spirit to an asynchronous version of IDisposable ). await subscriptionHandle.UnsubscribeAsync() It is important to note that the subscription is for a grain, not for an activation . Once the grain code subscribed to the stream, this subscription surpasses the life of this activation and stays durable forever, until the grain code (potentially in a different activation) explicitly unsubscribes. This is the heart of a virtual stream abstraction : not only all the streams always exists, logically, but also that a stream subscription is durable and lives beyond a particular physical activation that issued this subscription. Multiplicity An Orleans stream may have multiple producers and multiple consumers. A message published by a producer will be delivered to all consumers that were subscribed to the stream before the message was published. In addition, the consumer can subscribe to the same stream multiple times. Each time it subscribes it gets back a unique StreamSubscriptionHandle<T> . If a grain (or client) is subscribed X times to the same stream, it will receive the same event X times, once for each subscription. The consumer can also unsubscribe from an individual subscription or find out all its current subscriptions, by calling: IList<StreamSubscriptionHandle<T>> allMyHandles = await IAsyncStream<T>.GetAllSubscriptionHandles() Recovering From Failures If the producer of a stream dies (or its grain is deactivated), there is nothing it needs to do. Next time this grain wants to produce more events it can get the stream handle again and produce new events in the same way. Consumer logic is a little bit more involved. As we said before, once consumer grain subscribed to a stream, this subscription is valid until it explicitly unsubscribes. If the consumer of the stream dies (or its grain is deactivated) and new event is generated on the stream, the consumer grain will be automatically re-activated (just like any regular Orleans grain is automatically activated upon message to it). The only thing that the grain code needs to do now is to provide a IAsyncObserver<T> to process the data. The consumer basically need to re-attach processing logic as part of OnActivateAsync method. To do that it can call: StreamSubscriptionHandle<int> newHandle = await subscriptionHandle.ResumeAsync(IAsyncObserver) The consumer uses the previous handle it got when it first subscribed in order to \"resume processing\". Notice that ResumeAsync merely updates an existing subscription with the new instance of IAsyncObserver logic and does not change the fact that this consumer is already subscribed to this stream. How the consumer has an old subscriptionHandle? There are 2 options. The consumer may have persisted the handle it was given back from the original SubscribeAsync operation and can use it now. Alternatively, if the consumer does not have the handle, it can ask the IAsyncStream<T> for all its active subscription handles, by calling: IList<StreamSubscriptionHandle<T>> allMyHandles = await IAsyncStream<T>.GetAllSubscriptionHandles() The consumer can now resume all of them, or unsubscribe from some if he wishes to. COMMENT: If the consumer grain implements the the IAsyncObserver interface directly ( public class MyGrain<T> : Grain, IAsyncObserver<T> ), it should in theory not be required to re-attach the IAsyncObserver and thus will not need to call ResumeAsync . The streaming runtime should be able to automatically figure out that the grain already implements IAsyncObserver and will just invoke those IAsyncObserver methods. However, the streaming runtime currently does not support this and the grain code still needs to explicitly call ResumeAsync , even if the grain implements IAsyncObserver directly. Supporting this is on our TODO list. Explicit and Implicit Subscriptions By default, stream consumer has to explicitly subscribe to the stream. This subscription would usually be triggered by some external message that the grain (or client) receive that instructs them to subscribe. For example, in a chat service when user joins a chat room his grain receives a JoinChatGroup message with the chat name and it will cause the user grain to subscribe to this chat stream. In addition, Orleans Streams also support \"Implicit Subscriptions\" . In this model the grain does not explicitely subscribe to the stream. This grain is subscribed automatically, implicitly, just based on its grain identity and an ImplicitStreamSubscription attribute. Implicit subscriptions main value is allowing the stream activity to trigger the grain activation (hence triggering the subscription) automaticaly. For example, using SMS streams, if one grain wanted to produce a stream and another grain process this stream, the producer would need to know the identity of the consumer grain and make a grain call to it telling it to subscribe to the stream. Only after that it can start sending events. Instead, using implicit subscriptions, the producer can just start producing events onto a stream, and the consumer grain will automatically be activated and subscribe to the stream. In that case, the producer doesn't care at all who is reading the events Grain implementation class of type MyGrainType can declare an attribute [ImplicitStreamSubscription(\"MyStreamNamespace\")] . This tells the streaming runtime that when an event is generated on a stream whose identity is GUID XXX and \"MyStreamNamespace\" namespace, it should be delivered to grain whose identity is XXX of type MyGrainType . That is, the runtime maps stream <XXX, MyStreamNamespace> to consumer grain <XXX, MyGrainType> . The presence of ImplicitStreamSubscription causes the streaming runtime to automatically subscribe this grain to a stream and deliver the stream events to it. However, the grain code still needs to tell the runtime how it wants events to be processed. Essentially, it need to attach the IAsyncObserver . Therefore, when the grain is activated, the grain code inside OnActivateAsync needs to call: IStreamProvider streamProvider = base.GetStreamProvider(\"SimpleStreamProvider\"); IAsyncStream<T> stream = streamProvider.GetStream<T>(this.GetPrimaryKey(), \"MyStreamNamespace\"); StreamSubscriptionHandle<T> subscription = await stream.SubscribeAsync(IAsyncObserver<T>); Writing Subscription Logic Below are the guidelines on how to write the subscription logic for various cases: explicit and implicit subscriptions, rewindable and non-rewindable streams. The main difference between explicit and implicit subscriptions is that for implicit the grain always has exactly one implicit subscription for every stream namespace, there is no way to create multiple subscriptions (there is no subscription multiplicity), there is no way to unsubscribe, and the grain logic always only needs to attach the processing logic. That also means that for implicit subscriptions there is never a need to Resume a subscription. On the other hand, for explicit subscriptions, one needs to Resume the subscription, otherwise if the grain subscribes again it will result in the grain being subscribed multiple times. Implicit Subscriptions: For implicit subscriptions the grain needs to subscribe to attach the processing logic. This should be done in the grain's OnActivateAsync method. The grain should simply execute await stream.SubscribeAsync(OnNext ...) in its OnActivateAsync method. That will cause this particular activation to attach the OnNext function to process that stream. The grain can optionally specify the StreamSequenceToken as an argument to SubscribeAsync , which will cause this implicit subscription to start consuming from that token. There is never a need for implicit subscription to call ResumeAsync . public async override Task OnActivateAsync() { var streamProvider = GetStreamProvider(PROVIDER_NAME); var stream = streamProvider.GetStream<string>(this.GetPrimaryKey(), \"MyStreamNamespace\"); await stream.SubscribeAsync(OnNextAsync) } Explicit Subscriptions: For explicit subscriptions, a grain must call SubscribeAsync to subscribe to the stream. This creates a subscription, as well as attaches the processing logic. The explicit subscription will exist until the grain unsubscribes, so if a grain gets deactivated and reactivated, the grain is still explicitly subscribed, but no processing logic will be attached. In this case the grain needs to re-attach the processing logic. To do that, in its OnActivateAsync , the grain first needs to find out what subscriptions it has, by calling stream.GetAllSubscriptionHandles() . The grain must execute ResumeAsync on each handle it wishes to continue processing or UnsubscribeAsync on any handles it is done with. The grain can also optionally specify the StreamSequenceToken as an argument to the ResumeAsync calls, which will cause this explicit subscription to start consuming from that token. public async override Task OnActivateAsync() { var streamProvider = GetStreamProvider(PROVIDER_NAME); var stream = streamProvider.GetStream<string>(this.GetPrimaryKey(), \"MyStreamNamespace\"); var subscriptionHandles = await stream.GetAllSubscriptionHandles(); if (!subscriptionHandles.IsNullOrEmpty()) subscriptionHandles.ForEach(async x => await x.ResumeAsync(OnNextAsync)); } Stream Order and Sequence Tokens The order of events delivery between an individual producer and an individual consumer depends on a stream provider. With SMS the producer explicitly controls the order of events seen by the consumer by controlling the way he publishes them. By default (if the FireAndForget options for SMS provider is set to false) and if the producer awaits every OnNextAsync call, the events arrive in FIFO order. In SMS it is up to the producer to decide how to handle delivery failures that will be indicated by a broken Task returned by the OnNextAsync call. Azure Queue streams do not guarantee FIFO order, since the underlying Azure Queues do not guarantee order in failure cases (they do guarantee FIFO order in failure free executions). When a producer produces the event into Azure Queue, if the enqueue operation failed, it is up to the producer to attempt another enqueue and later on deal with potential duplicates messages. On the delivery side, Orleans Streaming runtime dequeues the event from the Azure Queue and attempts to deliver it for processing to consumers. Orleans Streaming runtime deletes the event from the queue only upon successful processing. If the delivery or processing failed, the event is not delete from the queue and will automatically re-appear in the queue much later. The Streaming runtime will try to deliver it again, thus potentially breaking the FIFO order. The described behaivour matches the regular semantics of Azure Queues. Application Defined Order : To deal with the above ordering issues, application can optionally specify its own ordering. This is achived via a notion of StreamSequenceToken . StreamSequenceToken is an opaque IComparable object that can be used to order events. A producer can pass an optional StreamSequenceToken to the OnNext call. This StreamSequenceToken will be passed all the way to the consumer and will be delivered together with the event. That way, application can reason and reconstruct it's order independently from the streaming runtime. Rewindable Streams Some streams only allow application to subscribe to them starting at the latest point in time, while other streams allow \"going back in time\". The latter capability is dependent on the underlying queuing technology and the particular stream provider. For example, Azure Queues only allow consuming the latest enqueued events, while EventHub allows replaying events from an arbitrary point in time (up to some expiration time). Streams that support going back in time are called Rewindable Streams . The consumer of a rewindable stream can pass a StreamSequenceToken to the SubscribeAsync call and the runtime will deliver events to it starting from that StreamSequenceToken (a null token means the consumer wants to receive events starting from the latest). The ability to rewind a stream is very useful in recovery scenarios. For example, consider a grain that subscribes to a stream and periodically checkpoints its state together with the latest sequence token. When recovering from a failure, the grain can re-subscribe to the same stream from the latest checkpointed sequence token, thereby recovering without losing any events that were generated since the last checkpoint. Current Status of Rewindable Streams: Both SMS and Azure Queue providers are not-rewindable and Orleans currently does not include an implementation of rewindable streams. We are actively working on this. Stateless Automatically Scaled-Out Processing By default Orleans Streaming is targeted to support a large number of relatively small streams, each is processed by one or more statefull grains. Collectively, the processing of all the streams together is sharded among a large number of regular (statefull) grains. The application code controls this sharding by assigning stream ids, grain ids and explicitly subscribing. The goal is sharded statefull processing . However, there is also an interesting scenario of automatically scaled-out stateless processing . In this scenario application has a small number of streams (or even one large stream) and the goal is stateless processing. For example, a global stream of all messages for all events and the processing involving some kind of decoding/deciphering and potentially forwarding them for further statefull processing into another set of streams. The stateless scaled-out stream processing can be supported in Orleans via StatelessWorker grains. Current Status of Stateless Automatically Scaled-Out Processing: This is currently not implemented (due to priority constrains). An attempt to subscribe to a stream from a StatelessWorker grain will result in undefined behavior. We are currently considering to support this option . Grains and Orleans Clients Orleans streams work uniformly across grains and Orleans clients . That is, exactly the same APIs can be used inside a grain and in an Orleans client to produce and consume events. This greatly simplifies the application logic, making special client-side APIs, such as Grain Observers, redundant. Fully Managed and Reliable Streaming Pub-Sub To track stream subscriptions, Orleans uses a runtime component called Streaming Pub-Sub which serves as a rendezvous point for stream consumers and stream producers. Pub Sub tracks all stream subscriptions, persists them, and matches stream consumers with stream producers. Applications can choose where and how the Pub-Sub data is stored. The Pub-Sub component itself is implemented as grains (called PubSubRendezvousGrain ) and it is using Orleans Declarative Persistence for those grain. PubSubRendezvousGrain uses storage provider named PubSubStore . As with any grain, you can designate an implementation for a storage provider. For Streaming Pub-Sub you can change the implementation of the PubSubStore in the config file: <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <StorageProviders> <Provider Type=\"Orleans.Storage.AzureTableStorage\" Name=\"PubSubStore\" /> </StorageProviders> </Globals> </OrleansConfiguration> That way Pub-Sub data will be durably stored in Azure Table. For initial development you can use the memory storage as well. In addition to the Pub-Sub, Orleans Streaming Runtime delivers events from producers to consumers, manages all runtime resources allocated to actively used streams, and transparently garbage collects runtime resources from unused streams. Configuration In order to use streams you need to enable stream providers via configuration. You can read more about stream providers here . Sample stream providers configuration: <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <StreamProviders> <Provider Type=\"Orleans.Providers.Streams.SimpleMessageStream.SimpleMessageStreamProvider\" Name=\"SMSProvider\"/> <Provider Type=\"Orleans.Providers.Streams.AzureQueue.AzureQueueStreamProvider\" Name=\"AzureQueueProvider\"/> </StreamProviders> </Globals> </OrleansConfiguration> It is also possible to register a stream provider programmatically, via calling one of the RegisterStreamProvider methods on the Orleans.Runtime.Configuration.GlobalConfiguration or Orleans.Runtime.Configuration.ClientConfiguration classes. public void RegisterStreamProvider(string providerTypeFullName, string providerName, IDictionary<string, string> properties = null) public void RegisterStreamProvider<T>(string providerName, IDictionary<string, string> properties = null) where T : IStreamProvider Next Orleans Stream Providers"
  },
  "1.5/Documentation/Orleans-Streams/Streams-Implementation.html": {
    "href": "1.5/Documentation/Orleans-Streams/Streams-Implementation.html",
    "title": "Orleans Streams Implementation Details | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Orleans Streams Implementation Details This section provides a high level overview of Orleans Stream implementation. It describes concepts and details that are not visible on the application level. If you only plan to use streams, you do not have to read this section. However, if you plan to extend streams, please read this section before reading Streams Extensibility section . Terminology : We refer by the word \"queue\" to any durable storage technology that can ingest stream events and allows either to pull events or provides a push-based mechanism to consume events. Usually, to provide scalability, those technologies provide sharded/partitions queues. For example, Azure Queues allow to create multiple queues, Event Hubs have multiple hubs, Kafka topics, ... Persistent Streams All Orleans Persistent Stream Providers share a common implementation PersistentStreamProvider . This generic stream provider is parametrized with a technology specific IQueueAdapter . When stream producer generates a new stream item and calls stream.OnNext() , Orleans Streaming Runtime invokes the appropriate method on the IQueueAdapter of that stream provider that enqueues the item directly into an appropriate queue. Pulling Agents At the heart of the Persistent Stream Provider are the pulling agents. Pulling agents pull events from a set of durable queues and deliver them to the application code in grains that consumes them. One can think of the pulling agents as a distributed \"micro-service\" -- a partitioned, highly available, and elastic distributed component. The pulling agents run inside the same silos that host application grains and are fully managed by the Orleans Streaming Runtime. StreamQueueMapper and StreamQueueBalancer Pulling agents are parametrized with IStreamQueueMapper and StreamQueueBalancerType . IStreamQueueMapper provides a list of all queues and is also responsible for mapping streams to queues. That way, the producer side of the Persistent Stream Provider know which queue to enqueue the message into. StreamQueueBalancerType expresses the way queues are balanced across Orleans silos and agents. The goal is to assign queues to agents in a balanced way, to prevent bottlenecks and support elasticity. When new silo is added to the Orleans cluster, queues are automatically rebalanced across the old and new silos. StreamQueueBalancer allows to customize that process. Orleans has a number of built in StreamQueueBalancers, to support different balancing scenarios (large and small number of queues) and different environments (Azure, on prem, static). Pulling Protocol Every silo runs a set of pulling agents, every agent is pulling from one queue. Pulling agents themselves are implemented by the internal runtime component, called SystemTarget . SystemTargets are essentially runtime grains, are subject to single threaded concurrency, can use regular grain messaging and are as lightweight as grains. As opposite to grain, SystemTargets are not virtual: they are explicitly created (by the runtime) and are also not location transparent. By implementing pulling agents as SystemTargets Orleans Streaming Runtime can rely on a lot of built-in Orleans features and can also scale to a very large number of queues, since creating a new pulling agent is as cheap as creating a new grain. Every pulling agent runs periodic timer that pulls from the queue (by invoking IQueueAdapterReceiver ) GetQueueMessagesAsync() method. The returned messages are put in the internal per-agent data structure called IQueueCache . Every message is inspected to find out its destination stream. The agent uses the Pub Sub to find out the list of stream consumers that subscribed to this stream. Once the consumer list if retrieved, the agent stores it locally (in its pub-sub cache) so it does not need to consult with Pub Sub on every message. The agent also subscribes with the pub-sub to receive notification of any new consumers that subscribe to that stream. This handshake between the agent and the pub-sub guarantees strong streaming subscription semantics : once the consumer has subscribed to the stream it will see all events that were generated after it has subscribed (in addition, using StreamSequenceToken allows to subscribe in the past). Queue Cache IQueueCache is an internal per-agent data structure that allows to decouple bringing new events from the queue from delivering them to consumers. It also allows to decouple delivery to different streams and to different consumers. Imagine a situation when one stream has 3 stream consumers and one of them is slow. If care not taken, it is possible that this slow consumer will impact agent's progress, slowing the consumption of other consumers of that stream, and even potentially slowing the de-queuing and delivering of events for other stream. To prevent that and allow maximum parallelism in the agent, we use IQueueCache . IQueueCache buffers stream events and provides a way to the agent to deliver events to each consumer at its pace. The per-consumer delivery is implemented by the internal component called IQueueCacheCursor , which tracks per consumer progress. That way each consumer receives events at its own pace :fast consumers receive events as quickly as they are dequeued from the queue, while slow consumers receive them later on. Once the message was delivered to all consumers, it can be deleted from the cache. Backpressure Backpressure in Orleans Streaming Runtime applies in two places: bringing stream events from the queue to the agent and delivering the events from the agent to stream consumers . The latter is provided by the built-in Orleans messaging delivery mechanism. Every stream event is delivered from the agent to consumers via the standard Orleans grain messaging, one at a time. That is, the agents sends one event (or a limited size batch of events) to each individual stream consumer and awaits this call. The next event will not start being delivered until the Task for the previous event was resolved or broken. That way we naturally limit the per-consumer delivery rate to one message at a time. With regard to bringing stream events from the queue to the agent Orleans Streaming provides a new special Backpressure mechanism. Since the agent decouples de-queuing of events from the queue and delivering them to consumers, it is possible that a single slow consumer will fall behind so much that the IQueueCache will fill up. To prevent IQueueCache from growing indefinitely, we limit its size (the size limit is configurable). However, the agent never throws away undelivered events. Instead, when the cache starts to fill up, the agents slows the rate of dequeing events from the queue. That way, we can \"ride\" the slow delivery periods by adjusting the rate at which we consume from the queue (\"backpressure\") and get back into fast consumption rate later on. To detect the \"slow delivery\" valleys the IQueueCache uses an internal data structure of cache buckets that track the progress of delivery of events to individual stream consumer. This results in a very responsive and self-adjusting systems. Next Orleans Streams Extensibility"
  },
  "1.5/Documentation/Orleans-Streams/Streams-Extensibility.html": {
    "href": "1.5/Documentation/Orleans-Streams/Streams-Extensibility.html",
    "title": "Orleans Streams Extensibility | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Orleans Streams Extensibility There are three ways developers can extend the currently implemented behaviour of Orleans Streaming: Utilize or extend Stream Provider Configuration. Write a Custom Queue Adapter. Writ a New Stream Provider We will describe those below. Please read the Orleans Streams Implementation before reading this section to have a high level view of the internal implementation. Stream Provider Configuration Currently implemented stream providers support a number of configuration options. Simple Message Stream Provider Configuration . SMS Stream Provider currently supports only a single configuration option: FireAndForgetDelivery : this option specifies if the messages sent by SMS stream producer are sent as fire and forget without the way to know if they were delivered or not. When FireAndForgetDelivery is set to false (messages are sent not as FireAndForget), the stream producer's call stream.OnNext() returns a Task that represents the processing status of the stream consumer. If this Task succeeds, the producer knows for sure that the message was delivered and processed successfully. If FireAndForgetDelivery is set to true, the returned Task only expresses that the Orleans runtime has accepted the message and queued it for further delivery. The default value for FireAndForgetDelivery is false. Persistent Stream Provider Configuration . All persistent stream providers support the following configuration options: GetQueueMessagesTimerPeriod - how much time the pulling agents wait after the last attempt to pull from the queue that did not return any items before the agent attempts to pull again. Default is 100 milliseconds. InitQueueTimeout - how much time the pulling agents waits for the adapter to initialize the connection with the queue. Default is 5 seconds. QueueBalancerType - the type of balancing algorithm to be used to balance queues to silos and agents. Default is ConsistentRingBalancer. Azure Queue Stream Provider Configuration . Azure Queue stream provider supports the following configuration options, in addition to what is supported by Persistent Stream Provider: DataConnectionString - the Azure Queue storage connection string. DeploymentId - the deployment id of this Orleans cluster (usually similar to Azure Deployment Id). CacheSize - the size of the persistent provider cache that is used to store stream message for further delivery. Default is 4096. It would be totally possible and a lot of times easy to provide additional configuration options. For example, in some scenarios developers might want more control over queue names used by the Queue Adapter. This is currently abstracted away with IStreamQueueMapper , but there is currently no way to configure which IStreamQueueMapper to use without writing a new code. We would be happy to provide such an option, if needed. So please consider adding more configuration options to existing stream providers before writing a completely new provider. Writing a Custom Queue Adapter If you want to use a different queueing technology, you need to write a queue adapter that abstracts away the access to that queue. Below we provide details on how this should be done. Please refer to AzureQueueAdapterFactory for an example. Start by defining a MyQueueFactory class that implements IQueueAdapterFactory . You need to: a. Initialize the factory: read the passed config values, potentially allocate some data structures if you need to, etc. b. Implement a method that returns your IQueueAdapter . c. Implement a method that returns IQueueAdapterCache . Theoretically, you can build your own IQueueAdapterCache , but you don't have to. It is a good idea just to allocate and return an Orleans SimpleQueueAdapterCache . d. Implement a method that returns IStreamQueueMapper . Again, it is theoretically possible to build your own IStreamQueueMapper , but you don't have to. It is a good idea just to allocate and return an Orleans HashRingBasedStreamQueueMapper . Implement MyQueueAdapter class that implements the IQueueAdapter interface, which is an interfaces that manages access to a sharded queue . IQueueAdapter manages access to a set of queues/queue partitions (those are the queues that were returned by IStreamQueueMapper ). It provides an ability to enqueue a message in a specified the queue and create an IQueueAdapterReceiver for a particular queue. Implement MyQueueAdapterReceiver class that implements the IQueueAdapterReceiver , which is an interfaces that manages access to one queue (one queue partition) . In addition to initialization and shutdown, it basically provides one method: retrieve up to maxCount messages from the queue. Declare public class MyQueueStreamProvider : PersistentStreamProvider<MyQueueFactory> . This is your new Stream Provider. Configuration : in order to load and use you new stream provider you need to configure it properly via silo config file. If you need to use it on the client, you need to add a similar config element to the client config file. It is also possible to configure the stream provider programmatically. Below is an example of silo configuration: <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <StreamProviders> <Provider Type=\"My.App.MyQueueStreamProvider\" Name=\"MyStreamProvider\" GetQueueMessagesTimerPeriod=\"100ms\" AdditionalProperty=\"MyProperty\"/> </StreamProviders> </Globals> </OrleansConfiguration> Writing a Completely New Stream Provider It is also possible to write a completely new Stream Provider. In such a case there is very little integration that needs to be done from Orleans perspective. You just need to implement the IStreamProviderImpl interface, which is a thin interface that allows application code to get a handle to the stream. Beyond that, it is totally up to you how to implement it. Implementing a completely new Stream Provider might turn to be a rather complicated task, since you might need access to various internal runtime components, some of which may have internal access. We currently do not envision scenarios where one would need to implement a completely new Stream Provider and could not instead achieve his goals through the two options outlined above: either via extended configuration or by writing a Queue Adapter. However, if you think you have such a scenario, we would like to hear about it and work together on simplifying writing new Stream Providers."
  },
  "1.5/Documentation/Orleans-Streams/Stream-Providers.html": {
    "href": "1.5/Documentation/Orleans-Streams/Stream-Providers.html",
    "title": "Orleans Stream Providers | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Stream Providers Streams can come in different shapes and forms. Some streams may deliver events over direct TCP links, while others deliver events via durable queues. Different stream types may use different batching strategies, different caching algorithms, or different back pressure procedures. We did not want to constrain streaming applications to only a small subset of those behavioral choices. Instead, Stream Providers are extensibility points to Orleans Streaming Runtime that allow users to implement any type of stream. This extensibility point is similar in spirit to Orleans Storage Providers . Orleans currently ships with two default stream providers: Simple Message Stream Provider and Azure Queue Stream Provider . Simple Message Stream Provider Simple Message Stream Provider, also known as the SMS provider, delivers events over TCP by utilizing regular Orleans grain messaging. Since events in SMS are delivered over unreliable TCP links, SMS does not guarantee reliable event delivery and does not automaticaly resend failed messages for SMS streams. The producer of the SMS stream has a way to know if his event was successfully received and processed or not: by default the call to stream.OnNextAsync returns a Task that represents the processing status of the stream consumer. If this Task fails, the producer can decide to send the same event again, thus achieving reliability on ther application level. Although individual stream messages delivery is best effort, SMS streams themselves are reliable. That is, the subscriber-to-producer binding performed by Pub Sub is fully reliable. Azure Queue (AQ) Stream Provider Azure Queue (AQ) Stream Provider delivers events over Azure Queues. On the producer side, AQ Stream Provider enqueues events directly into Azure Queue. On the consumer side, AQ Stream Provider manages a set of pulling agents that pull events from a set of Azure Queues and deliver them to application code that consumes them. One can think of the pulling agents as a distributed \"micro-service\" -- a partitioned, highly available, and elastic distributed component. The pulling agents run inside the same silos that host application grains. Thus, there is no need to run separate Azure worker roles to pull from the queues. The existence of pulling agents, their management, backpresure, balancing the queues between them, and handing off queues from a failed agent to another agent are fully managed by Orleans Streaming Runtime and are transparent to application code that uses streams. Queue Adapters Different stream providers that deliver events over durable queues exhibit similar behavior and are subject to a similar implementation. Therefore, we provide a generic extensible PersistentStreamProvider that allows developers to plug in different types of queues without writing a completely new stream provider from scratch. PersistentStreamProvider is parameterized with an IQueueAdapter , which abstracts specific queue implementation details and provides means to enqueue and dequeue events. All the rest is handled by the logic inside the PersistentStreamProvider . Azure Queue Provider mentioned above is also implemented this way: it is an instance of PersistentStreamProvider with AzureQueueAdapter . Next Orleans Streams Implementation Details"
  },
  "1.5/Documentation/Orleans-Streams/index.html": {
    "href": "1.5/Documentation/Orleans-Streams/index.html",
    "title": "Orleans Streams | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Orleans Streams Orleans v.1.0.0 added support for streaming extensions to the programing model. Streaming extensions provide a set of abstractions and APIs that make thinking about and working with streams simpler and more robust. Streaming extensions allow developers to write reactive applications that operate on a sequence of events in a structured way. The extensibility model of stream providers makes the programming model compatible with and portable across a wide range of existing queuing technologies, such as Event Hubs , ServiceBus , Azure Queues , and Apache Kafka . There is no need to write special code or run dedicated processes to interact with such queues. Why should I care? If you already know all about Stream Processing and are familiar with technologies like Event Hubs , Kafka , Azure Stream Analytics , Apache Storm , Apache Spark Streaming , and Reactive Extensions (Rx) in .NET , you may be asking why should you care. Why do we need yet another Stream Processing System and how Actors are related to Streams? \"Why Orleans Streams?\" is meant to answer that question. Programming Model There is a number of principles behind Orleans Streams Programming Model. Following the philosophy of Orleans virtual actors , Orleans streams are virtual . That is, a stream always exists. It is not explicitly created or destroyed, and it can never fail. Streams are identified by stream IDs, which are just logical names comprised of GUIDs and strings. Orleans Streams allow to decouple generation of data from its processing both in time and space . That means that stream producer and stream consumer may be on different servers, in different times and will withstand failures. Orleans streams are lightweight and dynamic . Orleans Streaming Runtime is designed to handle a large number of streams that come and go at a high rate. Orleans stream bindings are dynamic . Orleans Streaming Runtime is designed to handle cases where grains connect to and disconnect from streams at a high rate. Orleans Streaming Runtime transparently manages the lifecycle of stream consumption . After an application subscribes to a stream, from then on it will receive the stream's events, even in presence of failures. Orleans streams work uniformly across grains and Orleans clients . Programming APIs Applications interact with streams via APIs that are very similar to the well known Reactive Extensions (Rx) in .NET , by using Orleans.Streams.IAsyncStream<T> that implements Orleans.Streams.IAsyncObserver<T> and Orleans.Streams.IAsyncObservable<T> interfaces. In a typical example below a device generates some data, which is sent as an HTTP request to the service running in the Cloud. Orleans client running in the front end server receives this HTTP call and publishes the data into a matching device stream: public async Task OnHttpCall(DeviceEvent deviceEvent) { // Post data directly into device's stream. IStreamProvider streamProvider = GrainClient.GetStreamProvider(\"myStreamProvider\"); IAsyncStream<DeviceEventData> deviceStream = streamProvider.GetStream<DeviceEventData>(deviceEvent.DeviceId); await deviceStream.OnNextAsync(deviceEvent.Data); } In another example below a chat user (implemented as Orleans Grain) joins a chat room, gets a handle to a stream of chat messages generated by all others users in this room and subscribes to it. Notice that the chat user neither does not need to know about the chat room grain itself (there might not be such a grain in our system) nor about other user in that group that produce messages. Needless to say, to produce to the chat stream, users don't need to know who is currently subscribed to the stream. This demonstrates how chat users can be completely decoupled in time and space. public class ChatUser: Grain { public async Task JoinChat(string chatGroupName) { IStreamProvider streamProvider = base.GetStreamProvider(\"myStreamProvider\"); IAsyncStream<string> chatStream = streamProvider.GetStream<string>(chatGroupName); await chatStream.SubscribeAsync((string chatEvent) => Console.Out.Write(chatEvent)); } } Quick Start Sample The Quick Start Sample is a good quick overview of the overall workflow of using streams in the application. After reading it you should read the Streams Programming APIs to get a deeper understanding of the concepts. Streams Programming APIs A Streams Programming APIs provides detailed description of the programming APIs. Stream Providers Streams can come via physical channels of various shapes and forms and can have different semantics. Orleans Streaming is designed to support this diversity via the concept of Stream Providers , which is an extensibility point in the system. Orleans currently has implementation of two stream providers: TCP based Simple Message Stream Provider and Azure Queue based Azure Queue Stream Provider . More details on Steam Providers can be found at Stream Providers . Stream Semantics Stream Subsription Semantics : Orleans Streams guarantee Sequential Consistency for Stream Subsription operations. Specificaly, when consumer subscribes to a stream, once the Task representing the subsription operation was successfuly resolved, the consumer will see all events that were generated after it has subscribed. In addition, Rewindable streams allow to subscribe from an arbitrary point in time in the past by using StreamSequenceToken (more details can be found here ). Individual Stream Events Delivery Guarantees : Individual event delivery guarantees depend on individual stream providers. Some provide only best-effort at-most-once delivery (such as Simple Message Streams), while others provide at-least-once delivery (such as Azure Queue Streams). It is even possible to build a stream provider that will guarantee exactly-once delivery (we don't have such a provider yet, but it is possible to build one with the extensability model ). Events Delivery Order : Event order also depends on a particular stream provider. In SMS streams, the producer explicitelly controls the order of events seen by the consumer by controlling the way it publishes them. Azure Queue streams do not guarantee FIFO order, since the underlaying Azure Queues do not guarantee order in failure cases. Applications can also control their own stream delivery ordering, by using StreamSequenceToken . Streams Implementation The Orleans Streams Implementation provides a high level overview of the internal implementation. Streams Extensibility The Orleans Streams Extensibility describes how to extend streams with new functionality. Code Samples More examples of how to use streaming APIs within a grain can be found here . We plan to create more samples in the future. More Material Orleans Virtual Meetup about Streams Orleans Streaming Presentation from Virtual Meetup"
  },
  "1.5/Tutorials/Concurrency.html": {
    "href": "1.5/Tutorials/Concurrency.html",
    "title": "Concurrency | Microsoft Orleans Documentation",
    "keywords": "Concurrency Please read about Grains before following this tutorial. Let's go back to the code that was established in the tutorial on collections of actors and modify it to demonstrate how things can go bad by creating a trivial cycle in the messaging graph: when an employee receives a greeting, he sends another greeting back to the sender and waits for the acknowledgment. This will send a back-and-forth series of messages, until we get to 3. First create a class in the interface project which we'll use to send the greetings around: public class GreetingData { public Guid From { get; set; } public string Message { get; set; } public int Count { get; set; } } From will be the sender of the message (the ID of the grain), Message will be the message text, and Count will be the number of times the message has been sent back and forth. This stops us from getting a stack overflow. We need to modify the arguments of Greeting on the IEmployee interface to : Task Greeting(GreetingData data); We need to update the implementation accordingly: public async Task Greeting(GreetingData data) { Console.WriteLine(\"{0} said: {1}\", data.From, data.Message); // stop this from repeating endlessly if (data.Count >= 3) return; // send a message back to the sender var fromGrain = GrainFactory.GetGrain<IEmployee>(data.From); await fromGrain.Greeting(new GreetingData { From = this.GetPrimaryKey(), Message = \"Thanks!\", Count = data.Count + 1 }); } We'll also update the Manager class, so it send the new message object: public async Task AddDirectReport(IEmployee employee) { _reports.Add(employee); await employee.SetManager(this); await employee.Greeting(new GreetingData { From = this.GetPrimaryKey(), Message = \"Welcome to my team!\" }); } Now the Employee sends a message back to the manager, saying \"Thanks!\". Let's add some simple client code to add a direct report to a manager: var e0 = GrainClient.GrainFactory.GetGrain<IEmployee>(Guid.NewGuid()); var m1 = GrainClient.GrainFactory.GetGrain<IManager>(Guid.NewGuid()); m1.AddDirectReport(e0).Wait(); When we run this code, the first \"Thanks!\" greeting is received. However, when this message is responded to this we get a 30 second pause (or 10 minutes when the debugger is attached), then warnings appear in the log and we're told the grain is about to break it's promise. 7b66f830-8d81-49fc-b8fc-279af6924bd3 said: Welcome to my team! ce14310a-8500-4b2f-a21b-b4b23eb48d0d said: Thanks! [2014-03-12 15:25:37.398 GMT 31 WARNING 100157 CallbackData 127.0.0.1:11111] Response did not arrive on time in 00:00:30 for message: Request S127.0.0.1:11111:132333898*grn/906ECA4C/00000001@68e2b3ab->S127.0.0.1:11111:132333898*grn/D9BB797F/00000000@c24c4187 #13: MyGrainInterfaces1.IEmployee:Greeting(). Target History is: <S127.0.0.1:11111:132333898:*grn/D9BB797F/00000000:@c24c4187>. About to break its promise. [2014-03-12 15:25:37.398 GMT 27 WARNING 100157 CallbackData 127.0.0.1:11111] Response did not arrive on time in 00:00:30 for message: Request S127.0.0.1:11111:132333898*grn/D9BB797F/00000000@c24c4187->S127.0.0.1:11111:132333898*grn/D9BB797F/00000001@afc70cb4 #14: MyGrainInterfaces1.IEmployee:Greeting(). Target History is: <S127.0.0.1:11111:132333898:*grn/D9BB797F/00000001:@afc70cb4>. About to break its promise. [2014-03-12 15:25:37.407 GMT 28 WARNING 100157 CallbackData 127.0.0.1:11111] Response did not arrive on time in 00:00:30 for message: Request S127.0.0.1:11111:132333898*grn/D9BB797F/00000001@afc70cb4->S127.0.0.1:11111:132333898*grn/D9BB797F/00000000@c24c4187 #15: MyGrainInterfaces1.IEmployee:Greeting(). Target History is: <S127.0.0.1:11111:132333898:*grn/D9BB797F/00000000:@c24c4187>. About to break its promise. An exception is then thrown in the client code. We've created a deadlock. Grain 0 sends a message to grain 1. In that call grain 1 sends a message back to grain 0. However, grain 0 can't process it because it's awaiting the first message, so it gets queued. The await can't complete until the second message is returned, so we've entered a state that we can't escape from. Orleans waits for 30 seconds (10 minutes with the debugger), then kills the request. Orleans offers us a way to deal with this, by marking the grain [Reentrant] , which means that additional calls may be made while the grain is waiting for a task to complete, resulting in interleaved execution. [Reentrant] public class Employee : Grain, IEmployee { ... } We see that the sample works, and Orleans is able to interleave the grain calls: aaadb551-7dde-4dbe-82ce-1a5f2547babe said: Welcome to my team! 63e4d07c-ac50-4012-ba50-5b5cf54e4e45 said: Thanks! aaadb551-7dde-4dbe-82ce-1a5f2547babe said: Thanks! 63e4d07c-ac50-4012-ba50-5b5cf54e4e45 said: Thanks! Messages Messages are simply data passed from one actor to another, we just created the GreetingData class to do just this. In .NET, most objects are created from a class of some sort and are passed around by reference, something that doesn't work well with concurrency, and definitely not with distribution. When Orleans sends a message from one grain to another, it creates a deep copy of the object, and provides the copy to the second grain, and not the object stored in the first grain. This prohibits the mutation of state from one grain to another, one of the main tenets in the actor model is that state shouldn't be shared, and message passing is the only mechanism for exchanging data. When the grains are in different silos, the object model is serialized to a binary format, and sent over the wire. However, this deep copy process is expensive, and if you promise not to modify the message, then for communication with grains within a silo, it's unnecessary. If you indicate to Orleans that you are not going to modify the object (i.e. it's immutable) then it can skip the deep copy step, and it will pass the object by reference. There's no way Orleans or C# can stop you from modifying the state, you have to be disciplined. Immutability is indicated with a the [Immutable] attribute on the class: [Immutable] public class GreetingData { public Guid From { get; set; } public string Message { get; set; } public int Count { get; set; } } No other code change is required, this is just a signal to give to Orleans to tell it your not going to modify this object. Next Next, we'll see how we can interact with external services from inside our grain. Interaction with Libraries and Services"
  },
  "1.5/Documentation/Samples-Overview/index.html": {
    "href": "1.5/Documentation/Samples-Overview/index.html",
    "title": "Samples Overview | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Samples Overview What do I need? To productively use the Orleans samples, please follow the Prerequisites section for the supported versions of the .NET framework, Visual Studio and Azure SDK. An Azure subscription will help with some of the samples, but is not required. For the Azure-based samples, you will need to install the SDK. The samples themselves can be downloaded from GitHub . Hello World This is the Orleans version of an old classic. It demonstrates that while there is no such thing as \"trivial\" when you are dealing with distributed computing, Orleans makes it pretty straight-forward. Azure Web Sample An Azure-hosted version of Hello World. Adventure Before there was graphical user interfaces, before the era of game consoles and massive-multiplayer games, there were VT100 terminals and there was Colossal Cave Adventure . Possibly lame by today's standards, back then it was a magical world of monsters, chirping birds, and things you could pick up. It's the inspiration for this sample. Presence Service This sample shows the principles behind a typical (though much simplified) presence service, such as you would find in online games and other social applications. Tic Tac Toe This is a simple online version of the classic board game. Chirper A simple social network pub/sub system, with chirp messages being sent from publishers to followers. Twitter Sentiment This sample uses Orleans to aggregate and analyze twitter data for a simple sentiment dashboard. Twitter Sentiment relies on a Node.js project for some of its functionality, as well as Twitter developer credentials. To use this sample, you will need to: Get the Node.js Tools for Visual Studio Get a Twitter account Sign up as a Twitter Developer. GPS Tracker A combination of Orleans and SignalR is used to simulate GPS devices tracked as they move around San Francisco, updating their locations as they change. Storage Providers This sample contains sample code for two Orleans storage providers: one that stores data in a regular file system, one that connects to MongoDB."
  },
  "Documentation/resources/Ideas-for-Contributions.html": {
    "href": "Documentation/resources/Ideas-for-Contributions.html",
    "title": "Ideas for Contributions | Microsoft Orleans Documentation",
    "keywords": "Ideas for Contributions These are some of the ideas for contributing to Orleans. Just an initial list for consideration, meant to be a live document. If you are interested in any of these or one that is not listed, create an issue to discuss it. We roughly put them into 3 size categories based on our gut feel, which may be wrong: Small - hours of work Medium - couple of days of work Large - big projects, multiple days up to weeks of work Project template/wizard for Azure deployment [Medium/Large] Worker role for silos (in our experience it is better to star a silo as a standalone process and wait on the process handle in the worker roles code) Worker/web role for frontend clients Configuration of diagnostics, ETW tracing, etc. Try Azure SDK plug-in as suggested here by @richorama. Cluster monitoring dashboard [Medium] https://github.com/OrleansContrib/OrleansMonitor may be a good start Proper support for F# [Medium/Large] See Issue #38 Orleans backplane for SignalR [Medium] See Issue #73 Port Orleans to coreclr [Medium] See Issue #368 Some APIs from the full .NET got deprecated in coreclr, mainly around files and reflection, but at large the porting effort shouldn't be too big. This will allow to run Orleans efficiently cross platform. Secure communication between silos and clients Add support for secure communication mode with certificates used for encryption of messages."
  },
  "Documentation/resources/Documentation-Guidelines.html": {
    "href": "Documentation/resources/Documentation-Guidelines.html",
    "title": "Documentation Guidelines | Microsoft Orleans Documentation",
    "keywords": "Documentation Guidelines The Orleans documentation is built in Markdown . We use a few simple conventions to ensure a homogeneous style throughout the full set of documents. These standards are being introduced. If you have issues with these guidelines then raise an issue or a Pull Request. If you find documentation that fails to meet the guidelines, then make a fix and submit a pull request. Also if you are using windows 10 you can go to the store and find free MarkDown editors like this Structure Language The documentation will follow US-English spelling. Desktop tools like http://markdownpad.com have spell checking features. Paragraph structure Each sentence should be written on a single line, and only one sentence per line. This makes merging changes easier and also helps identify verbose language. Paragraphs in Markdown are just one or more lines of consecutive text followed by one or more blank lines. Headings Heading should be used to structure a document. Avoid using other emphasis features like ALLCAPS, Italics or bold to identify a new topic. Using a header is not only more consistent, but also allows linking to the header. Footers At the end of a page, it is helpful to link to the next logical page in the documentation. If the page is the last in a sub-section then linking back to the index page is useful. Styles Code formatting Blocks of example code should be formatted with the triple back tick format followed by the language ``` csharp [StorageProvider(ProviderName=\"store1\")] public class MyGrain<IMyGrainState> ... { ... } ``` Which will render as [StorageProvider(ProviderName=\"store1\")] public class MyGrain<IMyGrainState> ... { ... } Inline code should be marked with a single backtick (`). This include references to: type names e.g. Task<T> variable names e.g. game namespaces e.g. Orleans.Storage.AzureTableStorage If showing text that is an output (e.g. text file content or console output) you can either use the triple back tick without specifying a language or you can indent the content. For example: 1 said: Welcome to my team! 0 said: Thanks! 1 said: Thanks! 0 said: Thanks! File names and paths When referencing a filename, directory/folder or URI then use standard italics to format. This can be done by surrounding the string with either with a single asterisk ( * ) or a single underscore ( _ ) Examples: OrleansRuntimeInterfaces.dll C:\\Binaries ../src/Grain.cs Tables Markdown supports tabular data . Tables could be used to structure data so that is is easily consumable for the reader. Suffix Unit ms millisecond(s) s second(s) m minute(s) Links When referencing another concept, the concept should be linked to. Forward and backward references with in a page can be linked to via the header. e.g. link back to Structure Links to other documents can either link to the page, or a sub-section/header within the page. External links should be exposed as a the full link e.g. https://github.com/dotnet/roslyn Contribution The Orleans documentation is managed as Markdown files in a Git repository hosted on GitHub in the gh-pages branch . See the GitHub Pages documentation on how to use the gh-pages branch convention for \"Project site\" documents."
  },
  "Documentation/resources/Contributing.html": {
    "href": "Documentation/resources/Contributing.html",
    "title": "Contributing to Orleans | Microsoft Orleans Documentation",
    "keywords": "Contributing to Orleans Some notes and guidelines for developers wanting to contribute to Orleans. Contributing To This Project Here are some pointers for anyone looking for mini-features and work items that would make a positive contribution to Orleans. These are just a few ideas, so if you think of something else that would be useful, then spin up a discussion thread on GitHub to discuss the proposal, and go for it! Orleans GitHub Repository Pull requests are always welcome! Ideas for Contributions Intern and Student Projects Some suggestions for possible intern / student projects. Documentation Guidelines A style guide for writing documentation for this site. Code Contributions: This project uses the same contribution process as the other DotNet projects on GitHub. DotNet Project Contribution Guidelines Guidelines and workflow for contributing to DotNet projects on GitHub. DotNet CLA Contribution License Agreement for DotNet projects on GitHub. .NET Framework Design Guidelines Some basic API design rules, coding standards, and style guide for .NET Framework APIs. Coding Standards and Conventions We try not to be too OCD about coding style wars, but in case of disputes we do fall back to the core principles in the two \".NET Coding Standards\" books used by the other DotNet OSS projects on GitHub: C# Coding Style Guide .NET Framework Design Guidelines There are lots of other useful documents on the .NET CoreCLR and .NET Core Framework documentation sites which are worth reading, although most experienced C# developers will probably have picked up many of those best-practices by osmosis, particularly around performance and memory management. Source Code Organization Orleans has not religiously followed a \"One Class Per File\" rule, but instead we have tried to use pragmatic judgment to maximize the change of \"code understand-ability\" for developers on the team. If lots of small-ish classes share a \"common theme\" and/or are always dealt with together, then it is OK to place those into one source code file in most cases. See for example the various \"log consumer\" classes were originally placed in single source file, as they represented a single unit of code comprehension. As a corollary, it is much easier to find the source code for a class if it is in a file with the same name as the class [similar to Java file naming rules], so there is a tension and value judgment here between code find-ability and minimizing / constraining the number of projects in a solution and files within a project [which both have direct impact on the Visual Studio \"Opening\" and \"Building\" times for large projects]. Code search tools in VS and ReSharper definitely help here. Dependencies and Inter-Project References One topic that we are very strict about is around dependency references between components and sub-systems. Component / Project References References between projects in a solution must always use \" Project References \" rather than \" DLL References \" to ensure that component build relationships are known to the build tools. Right : <ProjectReference Include=\"..\\Orleans\\Orleans.csproj\"> <Project>{BC1BD60C-E7D8-4452-A21C-290AEC8E2E74}</Project> <Name>Orleans</Name> </ProjectReference> Wrong : <Reference Include=\"Orleans\" > <HintPath>..\\Orleans\\bin\\Debug\\Orleans.dll</HintPath> </Reference> In order to help ensure we keep inter-project references clean, then on the build servers [and local Build.cmd script] we deliberately use side-by-side input .\\src and output .\\Binaries directories rather than the more normal in-place build directory structure (eg. [PROJ]\\bin\\Release ) used by VS on local dev machines. Unified Component Versions We use the same unified versions of external component throughout the Orleans code base, and so should never need to add bindingRedirect entries in App.config files. Also, in general it should almost never be necessary to have Private=True elements in Orleans project files, except to override a conflict with a Windows / VS \"system\" component. Some package management tools can occasionally get confused when making version changes, and sometimes think that we are using multiple versions of the same assembly within a solution, which of course we never do. We long for the day when package management tools for .NET can make version changes transactionally! Until then, it is occasionally necessary to \"fix\" the misguided actions of some .NET package management tools by hand-editing the .csproj files (they are just XML text files) back to sanity and/or using the \"Discard Edited Line\" functions that most good Git tools such as Atlassian SourceTree provide. Using \"sort\" references and unified component versions avoids creating brittle links between Orleans run-time and/or external components, and has proved highly effective in the last several years at reducing stress levels for the Orleans Team during important deployment milestones. :)"
  },
  "Documentation/grains/event_sourcing/journaledgrain_diagnostics.html": {
    "href": "Documentation/grains/event_sourcing/journaledgrain_diagnostics.html",
    "title": "JournaledGrain Diagnostics | Microsoft Orleans Documentation",
    "keywords": "JournaledGrain Diagnostics Monitoring Connection Errors By design, log consistency providers are resilient under connection errors (including both connections to storage, and connections between clusters). But just tolerating errors is not enough, as applications usually need to monitor any such issues, and bring them to the attention of an operator if they are serious. JournaledGrain subclasses can override the following methods to receive notifiations when there are connection errors observed, and when those errors are resolved: protected override void OnConnectionIssue(ConnectionIssue issue) { /// handle the observed error described by issue } protected override void OnConnectionIssueResolved(ConnectionIssue issue) { /// handle the resolution of a previously reported issue } ConnectionIssue is an abstract class, with several common fields describing the issue, including how many times it has been observed since the last time connection was successful. The actual type of connection issue is defined by subclasses. Connection issues are categorized into types, such as PrimaryOperationFailed or NotificationFailed , and sometimes have extra keys (such as RemoteCluster ) that further narrow the category. If the same category of issue happens several times (for example, we keep getting a NotificationFailed that targets the same RemoteCluster ), it is reported each time by OnConnectionIssue . Once this category of issue is resolved (for example, we are finally successful with sending a notification to this RemoteCluster ), then OnConnectionIssueResolved is called once, with the same issue object that was last reported by OnConnectionIssue . Connection issues, and their resolution, for independent categories, are reported independently. Simple Statistics We currently offer a simple support for basic statistics (in the future, we will probably replace this with a more standard telemetry mechanism). Statistics collection can be enabled or disabled for a JournaledGrain by calling void EnableStatsCollection() void DisableStatsCollection() The statistics can be retrieved by calling LogConsistencyStatistics GetStats()"
  },
  "Documentation/grains/event_sourcing/journaledgrain_basics.html": {
    "href": "Documentation/grains/event_sourcing/journaledgrain_basics.html",
    "title": "JournaledGrain API | Microsoft Orleans Documentation",
    "keywords": "JournaledGrain Basics Journaled grains derive from <JournaledGrain<StateType,EventType> , with the following type parameters: The StateType represents the state of the grain. It must be a class with a public default constructor. EventType is a common supertype for all the events that can be raised for this grain, and can be any class or interface. All state and event objects should be serializable (because the log-consistency providers may need to persist them, and/or send them in notification messages). For grains whose events are POCOs (plain old C# objects), JournaledGrain<StateType> can be used as a shorthand for JournaledGrain<StateType,Object> . Reading the Grain State To read the current grain state, and determine its version number, the JournaledGrain has properties GrainState State { get; } int Version { get; } The version number is always equal to the total number of confirmed events, and the state is the result of applying all the confirmed events to the initial state. The initial state, which has version 0 (because no events have been applied to it), is determined by the default constructor of the GrainState class. Important: The application should never directly modify the object returned by State . It is meant for reading only. Rather, when the application wants to modify the state, it must do so indirectly by raising events. Raising Events Raising events is accomplished by calling the RaiseEvent function. For example, a grain representing a chat can raise a PostedEvent to indicate that a user submitted a post: RaiseEvent(new PostedEvent() { Guid = guid, User = user, Text = text, Timestamp = DateTime.UtcNow }); Note that RaiseEvent kicks off a write to storage access, but does not wait for the write to complete. For many applications, it is important to wait until we have confirmation that the event has been persisted. In that case, we always follow up by waiting for ConfirmEvents : RaiseEvent(new DepositTransaction() { DepositAmount = amount, Description = description }); await ConfirmEvents(); Note that even if you don't explicitly call ConfirmEvents , the events will eventually be confirmed - it happens automatically in the background. State Transition Methods The runtime updates the grain state automatically whenever events are raised. There is no need for the application to explicitly update the state after raising an event. However, the application still has to provide the code that specifies how to update the state in response to an event. This can be done in two ways. (a) The GrainState class can implement one or more Apply methods on the StateType . Typically, one would create multiple overloads, and the closest match is chosen for the runtime type of the event: class GrainState { Apply(E1 @event) { // code that updates the state } Apply(E2 @event) { // code that updates the state } } (b) The grain can override the TransitionState function: protected override void TransitionState(State state, EventType @event) { // code that updates the state } The transition methods are assumed to have no side effects other than modifying the state object, and should be deterministic (otherwise, the effects are unpredictable). If the transition code throws an exception, that exception is caught and included in a warning in the Orleans log, issued by the log-consistency provider. When, exactly, the runtime calls the transition methods depends on the chosen log consistency provider and its configuration. It is best for applications not to rely on a particular timing, except when specifically guaranteed by the log consistency provider. Some providers, such as the LogStorage log-consistency provider, replay the event sequence every time the grain is loaded. Therefore, as long as the event objects can still be properly deserialized from storage, it is possibly to radically modify the GrainState class and the transition methods. But for other providers, such as the StateStorage log-consistency provider, only the GrainState object is persisted, so developers must ensure that it can be deserialized correctly when read from storage. Raising Multiple Events It is possible to make multiple calls to RaiseEvent before calling ConfirmEvents: RaiseEvent(e1); RaiseEvent(e2); await ConfirmEvents(); However, this is likely to cause two successive storage accesses, and it incurs a risk that the grain fails after writing only the first event. Thus, it is usually better to raise multiple events at once, using RaiseEvents(IEnumerable<EventType> events) This guarantees that the given sequence of events is written to storage atomically. Note that since the version number always matches the length of the event sequence, raising multiple events increases the version number by more than one at a time. Retrieving the Event Sequence The following method from the base JournaledGrain class allows the application to retrieve a specified segment of the sequence of all confirmed events: Task<IReadOnlyList<EventType>> RetrieveConfirmedEvents(int fromVersion, int toVersion) However, it is not supported by all log consistency providers. If not supported, or if the specified segment of the sequence is no longer available, a NotSupportedException is thrown. To retrieve all events up to the latest confirmed version, one would call await RetrieveConfirmedEvents(0, Version); Only confirmed events can be retrieved: an exception is thrown if toVersion is larger than the current value of the property Version . Since confirmed events never change, there are no races to worry about, even in the presence of multiple instances or delayed confirmation. However, in such situations, it is possible that the value of the property Version is larger by the time the await resumes than at the time RetrieveConfirmedEvents is called, so it may be advisable to save its value in a variable. See also the section on Concurrency Guarantees."
  },
  "Documentation/grains/event_sourcing/index.html": {
    "href": "Documentation/grains/event_sourcing/index.html",
    "title": "Event Sourcing Overview | Microsoft Orleans Documentation",
    "keywords": "Event Sourcing Event sourcing provides a flexible way to manage and persist grain state. An event-sourced grain has many potential advantages over a standard grain. For one, it can be used with many different storage provider configurations, and supports geo-replication across multiple clusters. Moreover, it cleanly separates the grain class from definitions of the grain state (represented by a grain state object) and grain updates (represented by event objects). The documentation is structured as follows: JournaledGrain Basics explains how to define an event-sourced grains by deriving from JournaledGrain , how to access the current state, and how to raise events that update the state. Replicated Instances explains how the event-sourcing mechanism handles replicated grain instances and ensures consistency. It discusses the possibility of racing events and conflicts, and how to address them. Immediate/Delayed Confirmation explains how delayed confirmation of events, and reentrancy, can improve availability and throughput. Notifications explains how to subscribe to notifications, allowing grains to react to new events. Event Sourcing Configuration explains how to configure projects, clusters, and log-consistency providers. Built-In Log-Consistency Providers explains how the three currently included log-consistency providers work. JournaledGrain Diagnostics explains how to monitor for connection errors, and get simple statistics. The behavior documented above is reasonably stable, as far as the JournaledGrain API is concerned. However, we expect to extend or change the list of log consistency providers soon, to more easily allow developers to plug in standard event storage systems."
  },
  "Documentation/grains/event_sourcing/immediate_vs_delayed_confirmation.html": {
    "href": "Documentation/grains/event_sourcing/immediate_vs_delayed_confirmation.html",
    "title": "Immediate vs. Delayed Confirmation | Microsoft Orleans Documentation",
    "keywords": "Immediate Confirmation For many applications, we want to ensure that events are confirmed immediately, so that the persisted version does not lag behind the current version in memory, and we do not risk losing the latest state if the grain should fail. We can guarantee this by following these rules: Confirm all RaiseEvent calls using ConfirmEvents before the grain method returns. Make sure tasks returned by RaiseConditionalEvent complete before the grain method returns. Avoid [Reentrant] or [AlwaysInterleave] attributes, so only one grain call can be processed at a time. If we follow these rules, it means that after an event is raised, no other grain code can execute until the event has been written to storage. Therefore, it is impossible to observe inconsistencies between the version in memory and the version in storage. While this is often exactly what we want, it also has some potential disadvantages. Potential Disadvantages if the connection to a remote cluster or to storage is temporarily interrupted , then the grain becomes unavailable: effectively, the grain cannot execute any code while it is stuck waiting to confirm the events, which can take an indefinite amount of time (the log-consistency protocol keeps retrying until storage connectivity is restored). when handling a lot of of updates to a single grain instance , confirming them one at a time can become very inefficient, i.e. have poor throughput. Delayed Confirmation To improve availability and throughput in the situations mentioned above, grains can choose to do one or both of the following: allow grain methods to raise events without waiting for confirmation. allow reentrancy, so the grain can keep processing new calls even if previous calls get stuck waiting for confirmation. This means it is possible for grain code to execute while some events are still in the process of being confirmed. The JournaledGrain API has some specific provisions to give developers precise control over how to deal with unconfirmed events that are currently \"in flight\". The following property can be examined to find out what events are currently unconfirmed: IEnumerable<EventType> UnconfirmedEvents { get; } Also, since the state returned by the State property does not include the effect of unconfirmed events, there is an alternative property StateType TentativeState { get; } which returns a \"tentative\" state, obtained from \"State\" by applying all the unconfirmed events. The tentative state is essentially a \"best guess\" at what will likely become the next confirmed state, after all unconfirmed events are confirmed. However, there is no guarantee that it actually will, because the grain may fail, or because the events may race against other events and lose, causing them to be canceled (if they are conditional) or appear at a later position in the sequence than anticipated (if they are unconditional). Concurrency Guarantees Note that Orleans turn-based scheduling (cooperative concurrency) guarantees always apply, even when using reentrancy or delayed confirmation. This means that even though several methods may be in progress, only one can be actively executing --- all others are stuck at an await, so there are never any true races caused by parallel threads. In particular, note that: The properties State , TentativeState , Version , and UnconfirmedEvents can change during the execution of a method. But such changes can only happen while stuck at an await. These guarantees assume that the user code stays within the recommended practice with respect to tasks and async/await (in particular, does not use thread pool tasks, or only uses them for code that does not call grain functionality and that are properly awaited)."
  },
  "Documentation/grains/timers_and_reminders.html": {
    "href": "Documentation/grains/timers_and_reminders.html",
    "title": "Timers and Reminders | Microsoft Orleans Documentation",
    "keywords": "Timers and Reminders The Orleans runtime provides two mechanisms, called timers and reminders, that enable the developer to specify periodic behavior for grains. Timers Description Timers are used to create periodic grain behavior that isn't required to span multiple activations (instantiations of the grain). It is essentially identical to the standard . NET System.Threading.Timer class. In addition, it is subject to single threaded execution guarantees within the grain activation that it operates. Each activation may have zero or more timers associated with it. The runtime executes each timer routine within the runtime context of the activation that it is associated with. Usage To start a timer, use the Grain.RegisterTimer method, which returns an IDisposable reference: public IDisposable RegisterTimer( Func<object, Task> asyncCallback, // function invoked when the timer ticks object state, // object tp pass to asyncCallback TimeSpan dueTime, // time to wait before the first timer tick TimeSpan period) // the period of the timer Cancel the timer by disposing it. A timer will cease to trigger if the activation is deactivated or when a fault occurs and its silo crashes. Important Considerations When activation collection is enabled, the execution of a timer callback does not change the activation's state from idle to in use. This means that a timer cannot be used to postpone deactivation of otherwise idle activations. The period passed to Grain.RegisterTimer is the amount of time that passes from the moment the Task returned by asyncCallback is resolved to the moment that the next invocation of asyncCallback should occur. This not only makes it impossible for successive calls to asyncCallback to overlap but also makes it so that the length of time asyncCallback takes to complete affects the frequency at which asyncCallback is invoked. This is an important deviation from the semantics of System.Threading.Timer . Each invocation of asyncCallback is delivered to an activation on a separate turn and will never run concurrently with other turns on the same activation. Note however, asyncCallback invocations are not delivered as messages and are thus not subject to message interleaving semantics. This means that invocations of asyncCallback should be considered to behave as if running on a reentrant grain with respect to other messages to that grain. Reminders Description Reminders are similar to timers with a few important differences: Reminders are persistent and will continue to trigger in all situations (including partial or full cluster restarts) unless explicitly cancelled. Reminders are associated with a grain, not any specific activation. If a grain has no activation associated with it and a reminder ticks, one will be created. e.g.: If an activation becomes idle and is deactivated, a reminder associated with the same grain will reactivate the grain when it ticks next. Reminders are delivered by message and are subject to the same interleaving semantics as all other grain methods. Reminders should not be used for high-frequency timers-- their period should be measured in minutes, hours, or days. Configuration Reminders, being persistent, rely upon storage to function. You must specify which storage backing to use before the reminder subsystem will function. The reminder functionality is controlled by the SystemStore element in the server-side configuration. It works with either Azure Table or SQL Server as the store. Azure Table configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var silo = new SiloHostBuilder() [...] .UseAzureTableReminderService(options => options.ConnectionString = connectionString) [...] SQL: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; const string invariant = \"YOUR_INVARIANT\"; var silo = new SiloHostBuilder() [...] .UseAdoNetReminderService(options => { options.ConnectionString = connectionString; options.Invariant = invariant; }) [...] If you just want a placeholder implementation of reminders to work with without needing to set up an Azure account or SQL database, then this will give you a development-only implementation of the reminder system: var silo = new SiloHostBuilder() [...] .UseInMemoryReminderService() [...] Usage A grain that uses reminders must implement the IRemindable.RecieveReminder method. Task IRemindable.ReceiveReminder(string reminderName, TickStatus status) { Console.WriteLine(\"Thanks for reminding me-- I almost forgot!\"); return TaskDone.Done; } To start a reminder, use the Grain.RegisterOrUpdateReminder method, which returns an IOrleansReminder object: protected Task<IOrleansReminder> RegisterOrUpdateReminder(string reminderName, TimeSpan dueTime, TimeSpan period) reminderName is a string that must uniquely identify the reminder within the scope of the contextual grain. dueTime specifies a quantity of time to wait before issuing the first timer tick. period specifies the period of the timer. Since reminders survive the lifetime of any single activation, they must be explicitly cancelled (as opposed to being disposed). You cancel a reminder by calling Grain.UnregisterReminder : protected Task UnregisterReminder(IOrleansReminder reminder) reminder is the handle object returned by Grain.RegisterOrUpdateReminder . Instances of IOrleansReminder aren't guaranteed to be valid beyond the lifespan of an activation. If you wish to identify a reminder in a way that persists, use a string containing the reminder's name. If you only have the reminder's name and need the corresponding instance of IOrleansReminder , call the Grain.GetReminder method: protected Task<IOrleansReminder> GetReminder(string reminderName) Which Should I Use? We recommend that you use timers in the following circumstances: It doesn't matter (or is desirable) that the timer ceases to function if the activation is deactivated or failures occur. If the resolution of the timer is small (e.g. reasonably expressible in seconds or minutes). The timer callback can be started from Grain.OnActivateAsync or when a grain method is invoked. We recommend that you use reminders in the following circumstances: When the periodic behavior needs to survive the activation and any failures. To perform infrequent tasks (e.g. reasonably expressible in minutes, hours, or days). Combining Timers and Reminders You might consider using a combination of reminders and timers to accomplish your goal. For example, if you need a timer with a small resolution that needs to survive across activations, you can use a reminder that runs every five minutes, whose purpose is to wake up a grain that restarts a local timer that may have been lost due to a deactivation."
  },
  "1.5/Documentation/Advanced-Concepts/Codegen.html": {
    "href": "1.5/Documentation/Advanced-Concepts/Codegen.html",
    "title": "Code Generation | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Code Generation Efficient code generation is one of the pillars of the Orleans Runtime . The Orleans Runtime makes use of generated code in order to ensure proper serialization of types that are used across the cluster as well as for generating boilerplate which abstracts away the implementation details of method shipping, exception propagation, and other internal runtime concepts. There are two modes of OrleansCodeGenerator : Build-time Codegen - in this mode, codegen will run every time your project is compiled. A build task is injected into your project's build pipeline and the code is generated in the project's intermediate output directory. To activate this mode, add the package Microsoft.Orleans.OrleansCodeGenerator.Build to your Grain Interface project. If you edit your .csproj file, you will see that an extra build target was added. This mode allows a user to step-into the generated code while debugging since the file is physically on the disk. However, your build time will be slower than usual if you have big projects. This is the default mode selected when you create a Grain Interface project by using the Visual Studio templates. Runtime Codegen - This mode makes OrleansCodeGenerator to generate code when the Silo is starting. As such, no code is generated during the build. Users can therefore not step-into the generated code while debugging and it will increase silo initialization time. To enable this mode, if you were using the build-time codegen, remove the the Microsoft.Orleans.OrleansCodeGenerator.Build package and install Microsoft.Orleans.OrleansCodeGenerator in your Silo Host and Client projects. If the project was created via the Visual Studio templates then it will already be installed. Otherwise, just install Microsoft.Orleans.OrleansCodeGenerator on your silo & client projects. Both modes generate the same code with the exception that run-time code generation can only generate code for publicly accessible types."
  },
  "Documentation/tutorials_and_samples/Hello-World.html": {
    "href": "Documentation/tutorials_and_samples/Hello-World.html",
    "title": "Hello World | Microsoft Orleans Documentation",
    "keywords": "Hello World Run the Hello World sample One way to run this sample is to download a local copy of HelloWorld from the Samples/2.0/HelloWorld/ folder . Open two Command Prompt windows and navigate to the HelloWorld folder in each one. Build the project. Start the silo in one window with the command: dotnet run --project src\\SiloHost After the silo is running, start the client in the other window with this: dotnet run --project src\\OrleansClient The silo and client windows will display greetings to each other. How Orleans says Hello In this sample, a client connects with a grain, sends it a greeting and receives a greeting back. The client then prints that greeting and that's that. Simple enough in theory, but since there's distribution involved, there's a bit more to it. There are four projects involved -- one for declaring the grain interfaces, one for the grain implementations, and one for the client, one for the silo host There's one grain interface, in IHello.cs: public interface IHello : Orleans.IGrainWithIntegerKey { Task<string> SayHello(string greeting); } This is simple enough, and we can see that all replies must be represented as a Task or Task in communication interfaces. The implementation, found in HelloGrain.cs, is similarly trivial: public class HelloGrain : Orleans.Grain, HelloWorldInterfaces.IHello { Task<string> HelloWorldInterfaces.IHello.SayHello(string greeting) { return Task.FromResult($\"You said: '{greeting}', I say: Hello!\"); } } The class inherits from the base class Grain , and implements the communication interface defined earlier. Since there is nothing that the grain needs to wait on, the method is not declared async and instead returns its value using Task.FromResult() . The client, which orchestrates the grain code and is found in OrleansClient project, looks like this: //configure the client with proper cluster options, logging and clustering client = new ClientBuilder() .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"HelloWorldApp\"; }) .ConfigureLogging(logging => logging.AddConsole()) .Build(); //connect the client to the cluster, in this case, which only contains one silo await client.Connect(); ... // example of calling grains from the initialized client var friend = client.GetGrain<IHello>(0); var response = await friend.SayHello(\"Good morning, my friend!\"); Console.WriteLine(\"\\n\\n{0}\\n\\n\", response); The silo host, which configures and starts the silo, in SiloHost project looks like this: //define the cluster configuration var builder = new SiloHostBuilder() //configure the cluster with local host clustering .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"HelloWorldApp\"; }) .Configure<EndpointOptions>(options => options.AdvertisedIPAddress = IPAddress.Loopback) .ConfigureLogging(logging => logging.AddConsole()); //build the silo var host = builder.Build(); //start the silo await host.StartAsync();"
  },
  "Documentation/tutorials_and_samples/Adventure.html": {
    "href": "Documentation/tutorials_and_samples/Adventure.html",
    "title": "Adventure | Microsoft Orleans Documentation",
    "keywords": "Adventure A simple multiplayer text adventure game inspired by old-fashioned, text-based adventure games. Instructions Open OrleansAdventure.sln in Visual Studio. Start the 'AdventureSetup' project. Once AdventureSetup is running, start the 'AdventureClient' project. You will then be prompted to enter your name on the command line. Enter it and begin the game. Overview The AdventureSetup program reads a game description (\"map\") from AdventureConfig.txt. It sets up a series of \"rooms\" e.g. forest, beach, caves, a clearing etc . These locations are connected to other rooms to model the places and layout of the game. The sample configuration describes only a handful of locations. Rooms can contain \"things\" such as keys, swords etc. The AdventureClient program sets up your player and provides a simple text based user interface to allow you to play the game. You can move around rooms and interact with things using a simple command language, saying things such as \"go north\" or \"take brass key\". Why Orleans? Orleans allows the game to be described via very simple C# code while allowing it to scale to a massive multiplayer game. For this motivation to be meaningful, the labyrinth of rooms needs to be very large and need to support a large number of simultaneous players. One value of Orleans is that the service can be designed for growth, the overhead of running it at a small scale is not significant, and you can remain confident that it will scale if the need arises. How is it modeled? Player and Rooms are modeled as grains. These grains allow us to distribute the game with each grain modelling state and functionality. Things such as keys are modeled as plain old objects - they are really just simple immutable data structures that move around rooms and among players; they don't need to be grains. Possible improvements Make the map much, much, bigger Make the brass key unlock something Allow players to message each other Make eating food and drinking water possible and meaningful"
  },
  "Documentation/streaming/stream_providers.html": {
    "href": "Documentation/streaming/stream_providers.html",
    "title": "Orleans Stream Providers | Microsoft Orleans Documentation",
    "keywords": "Stream Providers Streams can come in different shapes and forms. Some streams may deliver events over direct TCP links, while others deliver events via durable queues. Different stream types may use different batching strategies, different caching algorithms, or different back pressure procedures. We did not want to constrain streaming applications to only a small subset of those behavioral choices. Instead, Stream Providers are extensibility points to Orleans Streaming Runtime that allow users to implement any type of stream. This extensibility point is similar in spirit to Orleans Storage Providers . Orleans currently ships with many stream providers, including : Simple Message Stream Provider and Azure Queue Stream Provider . Simple Message Stream Provider Simple Message Stream Provider, also known as the SMS provider, delivers events over TCP by utilizing regular Orleans grain messaging. Since events in SMS are delivered over unreliable TCP links, SMS does not guarantee reliable event delivery and does not automatically resend failed messages for SMS streams. The producer of the SMS stream has a way to know if its event was successfully received and processed or not: by default the call to stream.OnNextAsync returns a Task that represents the processing status of the stream consumer. If this Task fails, the producer can decide to send the same event again, thus achieving reliability on the application level. Although individual stream messages delivery is best effort, SMS streams themselves are reliable. That is, the subscriber-to-producer binding performed by Pub Sub is fully reliable. Azure Queue (AQ) Stream Provider Azure Queue (AQ) Stream Provider delivers events over Azure Queues. On the producer side, AQ Stream Provider enqueues events directly into Azure Queue. On the consumer side, AQ Stream Provider manages a set of pulling agents that pull events from a set of Azure Queues and deliver them to application code that consumes them. One can think of the pulling agents as a distributed \"micro-service\" -- a partitioned, highly available, and elastic distributed component. The pulling agents run inside the same silos that host application grains. Thus, there is no need to run separate Azure worker roles to pull from the queues. The existence of pulling agents, their management, backpressure, balancing the queues between them, and handing off queues from a failed agent to another agent are fully managed by Orleans Streaming Runtime and are transparent to application code that uses streams. Queue Adapters Different stream providers that deliver events over durable queues exhibit similar behavior and are subject to a similar implementation. Therefore, we provide a generic extensible PersistentStreamProvider that allows developers to plug in different types of queues without writing a completely new stream provider from scratch. PersistentStreamProvider uses an IQueueAdapter component, which abstracts specific queue implementation details and provides means to enqueue and dequeue events. All the rest is handled by the logic inside the PersistentStreamProvider . Azure Queue Provider mentioned above is also implemented this way: it is an instance of PersistentStreamProvider that uses an AzureQueueAdapter . Next Orleans Streams Implementation Details"
  },
  "Documentation/clusters_and_clients/monitoring/index.html": {
    "href": "Documentation/clusters_and_clients/monitoring/index.html",
    "title": "Runtime Monitoring | Microsoft Orleans Documentation",
    "keywords": "Runtime Monitoring Orleans output its runtime statistics and metrics through the ITelemetryConsumer interface. Application can register one or more telemetry consumers with for their silos and clients, to receives statistics and metrics that Orleans runtime periotically publishes. These can be consumers for popular telemetry analytics solutions or custom ones for any other destination and purpose. Three telemetry consumer are currently included in the Orleans codebase. They are released as separate NuGet packages: Microsoft.Orleans.OrleansTelemetryConsumers.AI for publishing to Application Insights . Microsoft.Orleans.OrleansTelemetryConsumers.Counters for publishing to Windows performance counters. The Orleans runtime continually updates a number of them. CounterControl.exe tool, included in the Microsoft.Orleans.CounterControl NuGet package, helps register necessary performance counter categories. It has to run with elevated privileges. The performance counters can be monitored using any of the standard monitoring tools. Microsoft.Orleans.OrleansTelemetryConsumers.NewRelic , for publishing to New Relic . To configure your silo and client to use telemetry consumers, silo configuration code looks like this: var siloHostBuilder = new SiloHostBuilder(); //configure the silo with AITelemetryConsumer siloHostBuilder.Configure<TelemetryOptions>(options => options.AddConsumer<AITelemetryConsumer>); client configuration code look like this: var clientBuilder = new ClientBuilder(); //configure the clientBuilder with AITelemetryConsumer clientBuilder.Configure<TelemetryOptions>(options => options.AddConsumer<AITelemetryConsumer>);"
  },
  "Documentation/deployment/multi-cluster_support/MultiClusterConfiguration.html": {
    "href": "Documentation/deployment/multi-cluster_support/MultiClusterConfiguration.html",
    "title": "Multi-Cluster Configuration | Microsoft Orleans Documentation",
    "keywords": "Multi-Cluster Configuration The multi-cluster configuration determines which clusters are currently part of the multi-cluster. It does not change automatically, but is controlled by the operator. Thus, it is quite different from the membership mechanism used within a cluster, which automatically determines the set of silos that are part of the cluster. We use the following terminology for the clusters in a service: A cluster is active if it has at least one active silo, and inactive otherwise A cluster is joined if it is part of the current multi-cluster configuration, and non-joined otherwise Being active/inactive is independent from being joined/non-joined: all four combinations are possible. All the clusters for a particular service are connected by a gossip network . The gossip network propagates configuration and status information. Injecting a configuration An operator issues configuration changes by injecting them into the multi-cluster network. The configurations can be injected into any cluster, and spread from there to all active clusters. Each new configuration consists of a list of cluster ids that form the multi-cluster. It also has a UTC timestamp that is used to track its propagation through the gossip network. Initially, the multi-cluster configuration is null, which means the multi-cluster list is empty (contains no clusters). Thus, the operator must initially inject a multi-cluster configuration. Once injected, this configuration persists in all connected silos (while running) and in all specified gossip channels (if those channels are persistent). We pose some restrictions on the injection of new configurations that an operator must follow: Each new configuration may add a number of clusters, or remove a number of clusters (but not both at the same time). An operator should not issue a new configuration while a previous configuration change is still being processed. These restrictions ensure that protocols such as the single-instance-protocol can correctly maintain mutual exclusion of activations even under configuration changes. Via Management Grain Multi-cluster configurations can be injected on any node in any cluster, using the Orleans Management Grain. For example, to inject a multi-cluster configuration that consists of the three clusters { us1, eu1, us2 }, we can pass a string enumerable to the management grain: var clusterlist = \"us1,eu1,us2\".Split(','); var mgtGrain = client.GetGrain<IManagementGrain>(0); mgtGrain.InjectMultiClusterConfiguration(clusterlist, \"my comment here\")); The first argument to InjectMultiClusterConfiguration is an enumerable of cluster ids, which is going to define the new multi-cluster configuration. The second argument is an (optional) comment string that can be used to tag configurations with arbitrary information, such as who injected them why. There is an optional third argument, a boolean called checkForLaggingSilosFirst , which defaults to true. It means that the system performs a best-effort check to see if there are any silos anywhere that have not caught up to the current configuration yet, and rejects the change if it finds such a silo. This helps to detect violations of the restriction that only one configuration change should be pending at a time (though it cannot guarantee it under all circumstances). Via Default Configuration In situations where the multi-cluster configuration is known in advance and the deployment is fresh every time (e.g. for testing), we may want to supply a default configuration. The global configuration supports an optional attribute DefaultMultiCluster which takes a comma-separated list of cluster ids: var silo = new SiloHostBuilder() [...] .Configure<MultiClusterOptions>(options => { [...] options.DefaultMultiCluster = new[] { \"us1\", \"eu1\", \"us2\" }; [...] }) [...] After a silo is started with this setting, it checks to see if the current multi-cluster configuration is null, and if so, injects the given configuration with the current UTC timestamp. WARNING. Persistent multi-cluster gossip channels (e.g. based on AzureTable) retain the last injected configuration unless they are deleted explicitly. In that case, specifying a DefaultMulticluster has no effect when re-deploying a cluster because the configuration stored in the gossip channels is not null.> Via Gossip Channel An operator can also inject the configuration directly into the gossip channel. Changes in the channel are picked up and propagated automatically by the periodic background gossip, though possibly very slowly (using the management grain is much faster). A rough estimate on the propagation time is 30 seconds (or whatever gossip interval is specified in the global configuration) times the binary logarithm of the total number of silos in all clusters. But since the gossip pairs are selected randomly, it can be both much quicker or much slower. If using the Azure Table-Based Gossip Channel, operators can inject a new configuration simply by editing the configuration record in the OrleansGossipTable , e.g. using some tool for editing data in Azure tables. The configuration record has the following format: Name Type Value PartitionKey String the ServiceId RowKey String \"CONFIG\" Clusters String comma-separated list of cluster IDs, e.g. \"us1,eu1,us2\" Comment String optional comment GossipTimestamp DateTime UTC timestamp for the configuration NOTE . When editing this record in storage, the GossipTimestamp must also be set to a newer value than it has currently (otherwise the change is ignored). The most convenient and recommended way to do this is to delete the GossipTimestamp field - our gossip channel implementation then automatically replaces it with a correct, current Timestamp (it uses the Azure Table Timestamp). Cluster Addition/Removal Procedures Adding or removing a cluster from the multi-cluster often needs to be coordinated within some larger context. We recommend to always follow the procedures described below when adding/removing clusters from the multi-cluster. Procedure for adding a cluster Start a new Orleans cluster and wait till all silos are up and running. Inject a configuration that contains the new cluster. Start routing user requests to the new cluster. Procedure for removing a cluster Stop routing new user requests to the cluster. Inject a configuration that no longer contains the cluster. Stop all silos of the cluster. Once a cluster has been removed in this way, it can be re-added by following the procedure for adding a new cluster. Activity on Non-Joined Clusters There can be brief, temporary periods of time where a cluster is both active and non-joined: A freshly started cluster may start executing code before it is in the multicluster configuration (between steps 1 and 2 of the procedure for adding a cluster) A cluster that is being decommissioned may still execute code before the silos are shut down (between steps 2 and 3 of the procedure for removing a cluster). During those intermediate situations, the following are possible: For global-single-instance grains: A grain may have a duplicate activation on a non-joined cluster. For versioned grains: activations on non-joined clusters do not receive notifications when the grain state changes."
  },
  "Documentation/deployment/multi-cluster_support/GlobalSingleInstance.html": {
    "href": "Documentation/deployment/multi-cluster_support/GlobalSingleInstance.html",
    "title": "Global-Single-Instance Grains | Microsoft Orleans Documentation",
    "keywords": "Grain Coordination Attributes Developers can indicate when and how clusters should coordinate their grain directories with respect to a particular grain class. The [GlobalSingleInstance] attribute means we want the same behavior as when running Orleans in a single global cluster: that is, route all calls to a single activation of the grain. Conversely, the [OneInstancePerCluster] attribute indicates that each cluster can have its own independent activation. This is appropriate if communication between clusters is undesired. The attributes are placed on grain implementations. For example: using Orleans.MultiCluster; [GlobalSingleInstance] public class MyGlobalGrain : Orleans.Grain, IMyGrain { ... } [OneInstancePerCluster] public class MyLocalGrain : Orleans.Grain, IMyGrain { ... } If a grain class does not specify either one of those attributes, it defaults to [OneInstancePerCluster] , or [GlobalSingleInstance] if the configuration parameter UseGlobalSingleInstanceByDefault is set to true. Protocol for Global-Single-Instance Grains When a global-single-instance (GSI) grain is accessed, and no activation is known to exist, a special GSI activation protocol is executed before activating a new instance. Specifically, a request is sent to all other clusters in the current multi-cluster configuration to check if they already have an activation for this grain. If all responses are negative, a new activation is created in this cluster. Otherwise, the remote activation is used (and a reference to it is cached in the local directory). Protocol for One-Instance-Per-Cluster Grains There is no inter-cluster communication for One-Instance-Per-Cluster grains. They simply use the standard Orleans mechanism independently within each cluster. Inside the Orleans framework itself, the following grain classes are marked with the [OneInstancePerCluster] attribute: ManagementGrain , GrainBasedMembershipTable , and GrainBasedReminderTable . Doubtful Activations If the GSI protocol does not receive conclusive responses from all clusters after 3 retries (or whatever number is specified by the configuration parameter GlobalSingleInstanceNumberRetries ), it creates a new local \"doubtful\" activation optimistically, favoring availability over consistency. Doubtful activations may be duplicates (because some remote cluster that did not respond during the GSI protocol activation may nevertheless have an activation of this grain). Therefore, periodically every 30 seconds (or whatever interval is specified by the configuration parameter GlobalSingleInstanceRetryInterval ) the GSI protocol is run again for all doubtful activations. This ensures that once communication between clusters is restored, duplicate activations can be detected and removed."
  },
  "Documentation/index.html": {
    "href": "Documentation/index.html",
    "title": "Introduction | Microsoft Orleans Documentation",
    "keywords": "This is the overview page about Orleans ///TODO: create an INDEX section with every document in this project listed alphabetically and/or arranged by subject. This documentation is for the 2.0 release Orleans 2.0 is a significant overhaul from the 1.x versions. The 2.0 release is cross-platform via .NET Standard 2.0 and .NET Core . It has a more modular and flexible structure due to heavy use of Dependency Injection, a modern configuration API, and a revamped provider model. Orleans 2.0 still supports most of the 1.x API via optional legacy packages. Orleans 1.5 will continue to be supported for some time, but 2.0 is where all the investments are going. For 1.5 Documentation and Tutorials, refer to the respective sections that are snapshots of the documentation as of the 2.0 release. Introduction Orleans is a framework that provides a straightforward approach to building distributed high-scale computing applications, without the need to learn and apply complex concurrency or other scaling patterns. Background Cloud applications and services are inherently parallel and distributed. They are also interactive and dynamic; often requiring near real time direct interactions between cloud entities. Such applications are very difficult to build today. The development process demands expert level programmers and typically requires expensive iterations of the design and the architecture, as the workload grows. Most of today’s high scale properties are built as a composition of stateless n-tier services with most of application logic residing in the middle tier. While the model allows to scale out by adding more servers to the middle tier, it is constrained by the performance and scalability of the storage layer because most requests coming to the middle tier from the frontend web servers require one or more reads from storage, and updates are even more complicated and prone to concurrency issues and conflicts due to lack of coordination between the middle tier servers. It often requires caching in the stateless layer to get acceptable performance, adding complexity and introducing cache consistency issues. The other problem with the stateless n-tier model is that it doesn't support well horizontal communications between individual application entities exposed by the middle tier, which makes it hard to implement complex business logic with multiple entities performing individual operations as part of processing a request. Orleans as a Stateful Middle Tier Orleans provides an intuitive way of building a stateful middle tier, where various business logic entities appear as sea of isolated globally addressable .NET objects (grains) of different application defined types distributed across a cluster of servers (silos). A grain type is a simple .NET class that implements one or more application defined grain interfaces. Individual grains are instances of application defined grain classes that get automatically created by the Orleans runtime on servers on an as-needed basis to handle requests for those grains. Grains naturally map to most application entities, such as users, devices, sessions, inventories, orders, etc., which makes it very easy to build business logic that is object-oriented but scales transparently across a cluster of servers. Each grain has a stable logical identity (key) within its grain type chosen by the application logic, for example, user email or device ID or inventory SKU code. Orleans guarantees single-threaded execution of each individual grain, hence protecting the application logic from perils of concurrency and races. In the world of microservices, Orleans is used as a framework for implementing a microservice that can be deployed and managed by a microservices deployment/management solution of developer's choice. Grain Lifecycle Grain can have persistent state in storage or in-memory state or a combination of both. Any grain can be called by any other grain or by a frontend (client) by using the target grain's logical identity without the need to ever create or instantiate the target grain. The Orleans programming model makes grains appear as if they are in memory the whole time. In reality, a grain goes through the lifecycle from existing only as its persisted state in storage to being instantiated in memory to being removed from memory. The Orleans runtime behind the scene instantiates (activates) grains when there's work for them to do, and removes them from memory (deactivates) to reclaim hardware resources when they are idle for too long. This grain lifecycle management work of the runtime is transparent to the application code, and liberates it from the complicated task of distributed resource management. Application logic can be written with the whole \"address space\" of grains available to it without the need to have hardware resources to keep all grains in memory at the same time, conceptually similar to how virtual memory works in operating systems. In addition, the virtual nature of grains allows Orleans to handle server failures mostly transparently to the application logic because grains that were executing on a failed server get automatically re-instantiated on other servers in the cluster once the failure is detected. Virtual Actors Implementation of Orleans is based on the Actor Model that's been around since 1970s. However, unlike actors in more traditional actor systems such as Erlang or Akka, Orleans Grains are virtual actors. The biggest difference is that physical instantiations of grains are completely abstracted away and are automatically managed by the Orleans runtime. The Virtual Actor Model is much more suitable for high-scale dynamic workloads like cloud services and is the major innovation of Orleans. You can read more details in the Technical Report on Orleans. Origin of Orleans Orleans was created at Microsoft Research and designed for use in the cloud . Since 2011, it has been used extensively in the cloud and on premises by several Microsoft product groups, most notably by game studios, such as 343 Industries and The Coalition as a platform for cloud services behind Halo 4/5 and Gears of War 4, as well as by a number of other companies. Orleans was open-sourced in January 2015, and attracted many developers that formed one of the most vibrant open source communities in the .NET ecosystem . In an active collaboration between the developer community and the Orleans team at Microsoft, features are added and improved on a daily basis. Microsoft Research continues to partner with the Orleans team to bring new major features, such as geo-distribution , indexing , and distributed transactions , that are pushing the state of the art. Orleans has become the framework of choice for building distributed systems and cloud services for many .NET developers."
  },
  "Documentation/frequently_asked_questions.html": {
    "href": "Documentation/frequently_asked_questions.html",
    "title": "Frequently Asked Questions | Microsoft Orleans Documentation",
    "keywords": "///TODO: after files are rearranged and checked for accuracy, put links back Frequently Asked Questions Availability Can I freely use Orleans in my project? Absolutely. The source code has been released under the MIT license . NuGet packages are published on nuget.org . Is Orleans production ready? I heard it's a research project. Orleans, indeed, initially started as a research project within Microsoft Research. It later grew into a product and has been used in production within Microsoft since 2011, and by other companies after it was publicly released in 2015. Orleans is definitely production ready, and powers many highly available systems and cloud services. Does Microsoft support Orleans? Source code of Orleans has been released under an MIT license on GitHub . Microsoft continues to invest in Orleans and accepts community contributions to the codebase. Positioning Is Orleans a server product? How do I run Orleans? Orleans is a framework, a set of libraries, that helps you build an application. Orleans-based applications can be run in various hosting environments, in the Cloud or on on-premises clusters or even on a single machine. It is the responsibility of application developer to build, deploy, and run an Orleans-based application in their target hosting environment. Where can I run Orleans? Orleans can run in any environment where .NET application can run. Prior to Orleans 2.0, it required full .NET Framework. Starting with 2.0, Orleans conforms to .NET Standard 2.0, and hence can run on .NET Core in Windows and non-Windows environments that support .NET Core. Is Orleans built for Azure? No. We believe that you should be able to run Orleans anywhere you need, the way you need. Orleans is very flexible, and has a number of optional providers that help host it in cloud environment, such as Azure, AWS or GCP, or on on-premises clusters, with a choice of technologies to support Orleans' clustering protocol. What is the difference between Orleans and other actor languages and frameworks, such as Erlang or Akka? While based on the same base principles of the Actor Model, Orleans took a step forward, and introduced a notion of Virtual Actors that greatly simplifies developer's experience and is much more suitable for cloud services and high-scale systems. Microsoft has another actor model implementation - Azure Service Fabric Reliable Actors. How do I choose between the two? Reliable Actors are tightly integrated with Service Fabric to leverage its core features, such as replicated in-cluster storage. Orleans has a reacher feature set, is not tied to any particular hosting platform, and can run in almost any environment. Orleans provides an optional integration package for hosting Orleans applications in Service Fabric. In the end, it's the application developer's decision of how much they would benefit from the tight integration of Reliable Actors with the underlying platform of Service Fabric versus the flexibility to run anywhere and the feature set of Orleans. Design How big or how small should a grain be in my application? The grain isolation model makes them very good at representing independent isolated contexts of state and computation. In most cases, grains naturally map to such application entities as users, sessions, accounts. Those entities are generally isolated from each other, can be accessed and updated independently, and expose a well defined set of supported operations. This works well with the intuitive \"one entity - one grain\" modeling. An application entity may be too big to be efficiently represented by a single grain if it encapsulates too much state, and as a result has to handle a high rate of requests to it. Even though a single grain can generally handle up to a few thousand trivial calls per second, the rule of thumb is to be wary of individual grain receiving hundreds of requests per second. That may be a sign of the grain being too large, and decomposing it into a set of smaller grains may lead to a more stable and balanced system. An application entity may be too small to be a grain if that would cause constant interaction of other grains with it, and as a result, cause too much of a messaging overhead. In such cases, it may make more sense to make those closely interacting entities part of a single grain, so that they would invoke each other directly. How should you avoid grain hot spots? The throughput of a grain is limited by a single thread that its activation can execute on. Therefore, it is advisable to avoid designs where a single grain receives a disproportionate share of requests or is involved in processing requests to other grains. There are various patterns that help prevent overloading of a single grain even when logically it is a central point of communication. For example, if a grain is an aggregator of some counters or statistics that are reported by a large number of grains on a regular basis, one proven approach is to add a controlled number of intermediate aggregator grains and assign each of the reporting grains (using a modulo on a key or a hash) to an intermediate aggregator, so that the load is more or less evenly distributed across all intermediate aggregator grains that in their turn periodically report partial aggregates to the central aggregator grain. Can a single Orleans cluster run across multiple datacenters? Orleans clusters are currently limited to a single data center per cluster. Instead, since 1.3.0, you can consider a multi-cluster deployment where clusters deployed to different datacenters form a single multi-cluster. In what cases can a split brain (same grain activated in multiple silos at the same time) happen? During normal operations the Orleans runtime guarantees that each grain will have at most one instance in the cluster. The only time this guarantee can be violated is when a silo crashes or gets killed without a proper shutdown. In that case, there is a ~30 second (based on configuration) window where a grain can potentially get temporarily instantiated in more than one silo. Convergence to a single instance per grain is guaranteed, and duplicate activations will be deactivated when this window closes. Also you can take a look at Orleans' paper for a more detailed information, however you don't need to understand it fully to be able to write your application code. You just need to consider the rare possibility of having two instances of an actor while writing your application. The persistence model guarantees that no writes to storage are blindly overwritten in such a case. How To How do I tear down a grain? In general there is no need for application logic to force deactivation of a grain, as the Orleans runtime automatically detects and deactivates idle activations of a grain to reclaim system resources. Letting Orleans do that is more efficient because it batches deactivation operations instead of executing them one by one. In the rare cases when you think you do need to expedite deactivation of a grain, the grain can do that by calling the base.DeactivateOnIdle() method. Can I tell Orleans where to activate a grain? It is possible to do so using restrictive placement strategies, but we generally consider this a rather advanced pattern that requires careful consideration. By doing what the question suggests, the application would take on the burden of resource management without necessarily having enough information about the global state of the system to do so well. This is especially counter-productive in cases of silo restarts, which in cloud environments may happen on a regular basis for OS patching. Thus, specific placement may have a negative impact on your application's scalability as well as resilience to system failure. That being said, for the rare cases where the application indeed knows where a particular grain should be activated, for example, if it has a knowledge of the locality of grain's persistent state, in 1.5.0 we introduced custom placement policies and directors. How do you version grains or add new grain classes and interfaces? You can add silos with new grain classes or new versions of existing grain classes to a running cluster. Can I Connect to Orleans silos from the public Internet? Orleans is designed to be hosted as the back-end part of a service, and you are expected to create a front-end tier to which external clients will connect. It can be an HTTP based Web API project, a socket server, a SignalR server or anything else fits the needs of the application. You can connect to Orleans from the Internet if you expose TCP endpoints of silos to it, but it is not a good practice from the security point of view. What happens if a silo fails before my grain call returns a response for my call? In case of a silo failure in the middle of a grain call, you'll receive an exception that you can catch in your code and retry or do something else to handle the error according to your application logic. The grain that failed with the silo will get automatically re-instantiated upon a next call to it. The Orleans runtime does not eagerly recreate grains from a failed silo because many of them may not be needed immediately or at all. Instead, the runtime recreates such grains individually and only when a new request arrives for a particular grain. For each grain it picks one of the available silos as a new host. The benefit of this approach is that the recovery process is performed only for grains that are actually being used and it is spread in time and across all available silos, which improves the responsiveness of the system and the speed of recovery. Note also that there is a delay between the time when a silo fails and when the Orleans cluster detects the failure. The delay is a configurable tradeoff between the speed of detection and the probability of false positives. During this transition period all calls to the grain will fail, but after the detection of the failure the grain will be created, upon a new call to it, on another silo, so it will be eventually available. What happens if a grain call takes too long to execute? Since Orleans uses a cooperative multi-tasking model, it will not preempt the execution of a grain automatically but Orleans generates warnings for long executing grain calls so you can detect them. Cooperative multi-tasking has a much better throughput compared to preemptive multi-tasking. Keep in mind that grain calls should not execute any long running tasks like IO operations synchronously and should not block on other tasks to complete. All waiting should be done asynchronously using the await keyword or other asynchronous waiting mechanisms. Grains should return as soon as possible to let other grains execute for maximum throughput."
  },
  "Community/Contributing.html": {
    "href": "Community/Contributing.html",
    "title": "Contributing to Orleans | Microsoft Orleans Documentation",
    "keywords": "Contributing to Orleans Some notes and guidelines for developers wanting to contribute to Orleans. Contributing To This Project Here are some pointers for anyone looking for mini-features and work items that would make a positive contribution to Orleans. These are just a few ideas, so if you think of something else that would be useful, then spin up a discussion thread on GitHub to discuss the proposal, and go for it! Orleans GitHub Repository Pull requests are always welcome! Ideas for Contributions Intern and Student Projects Some suggestions for possible intern / student projects. Documentation Guidelines A style guide for writing documentation for this site. Code Contributions: This project uses the same contribution process as the other DotNet projects on GitHub. DotNet Project Contribution Guidelines Guidelines and workflow for contributing to DotNet projects on GitHub. DotNet CLA Contribution License Agreement for DotNet projects on GitHub. .NET Framework Design Guidelines Some basic API design rules, coding standards, and style guide for .NET Framework APIs. Coding Standards and Conventions We try not to be too OCD about coding style wars, but in case of disputes we do fall back to the core principles in the two \".NET Coding Standards\" books used by the other DotNet OSS projects on GitHub: C# Coding Style Guide .NET Framework Design Guidelines There are lots of other useful documents on the .NET CoreCLR and .NET Core Framework documentation sites which are worth reading, although most experienced C# developers will probably have picked up many of those best-practices by osmosis, particularly around performance and memory management. Source Code Organization Orleans has not religiously followed a \"One Class Per File\" rule, but instead we have tried to use pragmatic judgment to maximize the change of \"code understand-ability\" for developers on the team. If lots of small-ish classes share a \"common theme\" and/or are always dealt with together, then it is OK to place those into one source code file in most cases. See for example the various \"log consumer\" classes were originally placed in single source file, as they represented a single unit of code comprehension. As a corollary, it is much easier to find the source code for a class if it is in a file with the same name as the class [similar to Java file naming rules], so there is a tension and value judgment here between code find-ability and minimizing / constraining the number of projects in a solution and files within a project [which both have direct impact on the Visual Studio \"Opening\" and \"Building\" times for large projects]. Code search tools in VS and ReSharper definitely help here. Dependencies and Inter-Project References One topic that we are very strict about is around dependency references between components and sub-systems. Component / Project References References between projects in a solution must always use \" Project References \" rather than \" DLL References \" to ensure that component build relationships are known to the build tools. Right : <ProjectReference Include=\"..\\Orleans\\Orleans.csproj\"> <Project>{BC1BD60C-E7D8-4452-A21C-290AEC8E2E74}</Project> <Name>Orleans</Name> </ProjectReference> Wrong : <Reference Include=\"Orleans\" > <HintPath>..\\Orleans\\bin\\Debug\\Orleans.dll</HintPath> </Reference> In order to help ensure we keep inter-project references clean, then on the build servers [and local Build.cmd script] we deliberately use side-by-side input .\\src and output .\\Binaries directories rather than the more normal in-place build directory structure (eg. [PROJ]\\bin\\Release ) used by VS on local dev machines. Unified Component Versions We use the same unified versions of external component throughout the Orleans code base, and so should never need to add bindingRedirect entries in App.config files. Also, in general it should almost never be necessary to have Private=True elements in Orleans project files, except to override a conflict with a Windows / VS \"system\" component. Some package management tools can occasionally get confused when making version changes, and sometimes think that we are using multiple versions of the same assembly within a solution, which of course we never do. We long for the day when package management tools for .NET can make version changes transactionally! Until then, it is occasionally necessary to \"fix\" the misguided actions of some .NET package management tools by hand-editing the .csproj files (they are just XML text files) back to sanity and/or using the \"Discard Edited Line\" functions that most good Git tools such as Atlassian SourceTree provide. Using \"sort\" references and unified component versions avoids creating brittle links between Orleans run-time and/or external components, and has proved highly effective in the last several years at reducing stress levels for the Orleans Team during important deployment milestones. :)"
  },
  "1.5/Tutorials/Unit-Testing-Grains.html": {
    "href": "1.5/Tutorials/Unit-Testing-Grains.html",
    "title": "Unit Testing Grains | Microsoft Orleans Documentation",
    "keywords": "Unit Testing Grains This tutorial shows how to unit test your grains to make sure they behave correctly. There are two main ways to unit test your grains, and the method you choose will depend on the type of functionality you are testing. The Microsoft.Orleans.TestingHost NuGet package can be used to create test silos for your grains, or you can use a mocking framework like Moq to mock parts of the Orleans runtime that your grain interacts with. Using TestCluster The Microsoft.Orleans.TestingHost NuGet package contains TestCluster which can be used to create an in-memory cluster, comprised of two silos by default, which can be used to test grains. using System; using System.Threading.Tasks; using Orleans; using Orleans.TestingHost; using Xunit; namespace Tests { public class HelloGrainTests { [Fact] public async Task SaysHelloCorrectly() { var cluster = new TestCluster(); cluster.Deploy(); var hello = cluster.GrainFactory.GetGrain<IHelloGrain>(Guid.NewGuid()); var greeting = await hello.SayHello(); cluster.StopAllSilos(); Assert.Equal(\"Hello, World\", greeting); } } } Due to the overhead of starting an in-memory cluster you may wish to create a TestCluster and reuse it among multiple test cases. For example this can be done using xUnit's class or collection fixtures (see https://xunit.github.io/docs/shared-context.html for more details). In order to share a TestCluster between multiple test cases, first create a fixture type: public class ClusterFixture : IDisposable { public ClusterFixture() { this.Cluster = new TestCluster(); this.Cluster.Deploy(); } public void Dispose() { this.Cluster.StopAllSilos(); } public TestCluster Cluster { get; private set; } } Next create a collection fixture: [CollectionDefinition(ClusterCollection.Name)] public class ClusterCollection : ICollectionFixture<ClusterFixture> { public const string Name = \"ClusterCollection\"; } You can now reuse a TestCluster in your test cases: using System; using System.Threading.Tasks; using Orleans; using Xunit; namespace Tests { [Collection(ClusterCollection.Name)] public class HelloGrainTests { private readonly TestCluster _cluster; public HelloGrainTests(ClusterFixture fixture) { _cluster = fixture.Cluster; } [Fact] public async Task SaysHelloCorrectly() { var hello = _cluster.GrainFactory.GetGrain<IHelloGrain>(Guid.NewGuid()); var greeting = await hello.SayHell(); Assert.Equal(\"Hello, World\", greeting); } } } xUnit will call the Dispose method of the ClusterFixture type when all tests have been completed and the in-memory cluster silos will be stopped. TestCluster also has a constructor which accepts TestClusterOptions that can be used to configure the silos in the cluster. Using Mocks Orleans also makes it possible to mock many parts of system, and for many of scenarios this is the easiest way to unit test grains. This approach does have limitations (e.g. around scheduling reentrancy and serialization), and may require that grains include code used only by your unit tests. The Orleans TestKit provides an alternative approach which side-steps many of these limitations. For example, let us imagine that the grain we are testing interacts with other grains. In order to be able to mock those other grains we also need to mock the GrainFactory member of the grain under test. By default GrainFactory is a normal protected property, but most mocking frameworks require properties to be public and virtual to be able to mock them. So the first thing we need to do is make GrainFactory both public and virtual property: public new virtual IGrainFactory GrainFactory { get { return base.GrainFactory; } } Now we can create our grain outside of the Orleans runtime and use mocking to control the behaviour of GrainFactory : using System; using System.Threading.Tasks; using Orleans; using Xunit; using Moq; namespace Tests { public class WorkerGrainTests { [Fact] public async Task RecordsMessageInJournal() { var data = \"Hello, World\"; var journal = new Mock<IJournalGrain>(); var worker = new Mock<WorkerGrain>(); myGrain.Setup(x => x.GrainFactory.GetGrain<IJournalGrain>(It.IsAny<Guid>())).Returns(journal.Object); await worker.DoWork(data) journal.Verfiy(x => x.Record(data), Times.Once()); } } } Here we create our grain under test, WorkerGrain , using Moq which means we can then override the behaviour of the GrainFactory so that it returns a mocked IJournalGrain . We can then verify that our WorkerGrain interacts with the IJournalGrain as we expect."
  },
  "1.5/Documentation/Core-Features/Timers-and-Reminders.html": {
    "href": "1.5/Documentation/Core-Features/Timers-and-Reminders.html",
    "title": "Timers and Reminders | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Timers and Reminders The Orleans runtime provides two mechanisms, called timers and reminders, that enable the developer to specify periodic behavior for grains. Timers Description Timers are used to create periodic grain behavior that isn't required to span multiple activations (instantiations of the grain). It is essentially identical to the standard . NET System.Threading.Timer class. In addition, it is subject to single threaded execution guarantees within the grain activation that it operates. Each activation may have zero or more timers associated with it. The runtime executes each timer routine within the runtime context of the activation that it is associated with. Usage To start a timer, use the Grain.RegisterTimer method, which returns an IDisposable reference: protected IDisposable RegisterTimer(Func<object, Task> asyncCallback, object state, TimeSpan dueTime, TimeSpan period) asyncCallback is the function to be invoked when the timer ticks. state is an object that will be passed to asyncCallback when the timer ticks. dueTime specifies a quantity of time to wait before issuing the first timer tick. period specifies the period of the timer. Cancel the timer by disposing it. A timer will cease to trigger if the activation is deactivated or when a fault occurs and its silo crashes. Important Considerations When activation collection is enabled, the execution of a timer callback does not change the activation's state from idle to in use. This means that a timer cannot be used to postpone deactivation of otherwise idle activations. The period passed to Grain.RegisterTimer is the amount of time that passes from the moment the Task returned by asyncCallback is resolved to the moment that the next invocation of asyncCallback should occur. This not only makes it impossible for successive calls to asyncCallback to overlap but also makes it so that the length of time asyncCallback takes to complete affects the frequency at which asyncCallback is invoked. This is an important deviation from the semantics of System.Threading.Timer . Each invocation of asyncCallback is delivered to an activation on a separate turn and will never run concurrently with other turns on the same activation. Note however, asyncCallback invocations are not delivered as messages and are thus not subject to message interleaving semantics. This means that invocations of asyncCallback should be considered to behave as if running on a reentrant grain with respect to other messages to that grain. Reminders Description Reminders are similar to timers with a few important differences: Reminders are persistent and will continue to trigger in all situations (including partial or full cluster restarts) unless explicitly cancelled. Reminders are associated with a grain, not any specific activation. If a grain has no activation associated with it and a reminder ticks, one will be created. e.g.: If an activation becomes idle and is deactivated, a reminder associated with the same grain will reactivate the grain when it ticks next. Reminders are delivered by message and are subject to the same interleaving semantics as all other grain methods. Reminders should not be used for high-frequency timers-- their period should be measured in minutes, hours, or days. Configuration Reminders, being persistent, rely upon storage to function. You must specify which storage backing to use before the reminder subsystem will function. The reminder functionality is controlled by the SystemStore element in the server-side configuration. It works with either Azure Table or SQL Server as the store. <SystemStore SystemStoreType=\"AzureTable\" /> OR <SystemStore SystemStoreType=\"SqlServer\" /> If you just want a placeholder implementation of reminders to work with without needing to set up an Azure account or SQL database, then adding this element to the configuration file (under 'Globals') will give you a development-only implementation of the reminder system: <ReminderService ReminderServiceType=\"ReminderTableGrain\"/> Usage A grain that uses reminders must implement the IRemindable.RecieveReminder method. Task IRemindable.ReceiveReminder(string reminderName, TickStatus status) { Console.WriteLine(\"Thanks for reminding me-- I almost forgot!\"); return TaskDone.Done; } To start a reminder, use the Grain.RegisterOrUpdateReminder method, which returns an IOrleansReminder object: protected Task<IOrleansReminder> RegisterOrUpdateReminder(string reminderName, TimeSpan dueTime, TimeSpan period) reminderName is a string that must uniquely identify the reminder within the scope of the contextual grain. dueTime specifies a quantity of time to wait before issuing the first timer tick. period specifies the period of the timer. Since reminders survive the lifetime of any single activation, they must be explicitly cancelled (as opposed to being disposed). You cancel a reminder by calling Grain.UnregisterReminder : protected Task UnregisterReminder(IOrleansReminder reminder) reminder is the handle object returned by Grain.RegisterOrUpdateReminder . Instances of IOrleansReminder aren't guaranteed to be valid beyond the lifespan of an activation. If you wish to identify a reminder in a way that persists, use a string containing the reminder's name. If you only have the reminder's name and need the corresponding instance of IOrleansReminder , call the Grain.GetReminder method: protected Task<IOrleansReminder> GetReminder(string reminderName) Which Should I Use? We recommend that you use timers in the following circumstances: It doesn't matter (or is desirable) that the timer ceases to function if the activation is deactivated or failures occur. If the resolution of the timer is small (e.g. reasonably expressible in seconds or minutes). The timer callback can be started from Grain.OnActivateAsync or when a grain method is invoked. We recommend that you use reminders in the following circumstances: When the periodic behavior needs to survive the activation and any failures. To perform infrequent tasks (e.g. reasonably expressible in minutes, hours, or days). Combining Timers and Reminders You might consider using a combination of reminders and timers to accomplish your goal. For example, if you need a timer with a small resolution that needs to survive across activations, you can use a reminder that runs every five minutes, whose purpose is to wake up a grain that restarts a local timer that may have been lost due to a deactivation."
  },
  "1.5/Documentation/Advanced-Concepts/Request-Context.html": {
    "href": "1.5/Documentation/Advanced-Concepts/Request-Context.html",
    "title": "Request Context | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Request Context RequestContext is an Orleans feature that allows application metadata, such as a trace ID, to flow with requests. Application metadata may be added on the client; it will flow with Orleans requests to the receiving grain. The feature is implemented by a public static class, RequestContext, in the Orleans namespace. This class exposes two simple methods: void Set(string key, object value) is used to store a value in the request context. The value can be any Serializable type. Object Get(string key) is used to retrieve a value from the current request context. The backing storage for RequestContext is thread-static. When a thread (whether client-side or within Orleans) sends a request, the contents of the sending thread’s RequestContext is included with the Orleans message for the request; when the grain code receives the request, that metadata is accessible from the local RequestContext. If the grain code does not modify the RequestContext, then any grain it makes a request of will receive the same metadata, and so on. Application metadata also is maintained when you schedule a future computation using StartNew or ContinueWith; in both cases, the continuation will execute with the same metadata as the scheduling code had at the moment the computation was scheduled (that is, the system makes a copy of the current metadata and passes that to the continuation, so changes after the call to StartNew or ContinueWith will not be seen by the continuation). Note that application metadata does not flow back with responses; that is, code that runs as a result of a response being received, either within a ContinueWith continuation or after a call to Wait or GetValue, will still run within the current context that was set by the original request. For example, to set a trace ID in the client to a new GUID, one would simply call: RequestContext.Set(\"TraceId\", new Guid()); Within grain code (or other code that runs within Orleans on a scheduler thread), the trace ID of the original client request could be used, for instance, when writing a log: Logger.Info(\"Currently processing external request {0}\", RequestContext.Get(\"TraceId\")); While any serializable object may be sent as application metadata, it’s worth mentioning that large or complex objects may add noticeable overhead to message serialization time. For this reason, the use of simple types (strings, GUIDs, or numeric types) is recommended."
  },
  "Documentation/deployment/troubleshooting_azure_cloud_services_deployments.html": {
    "href": "Documentation/deployment/troubleshooting_azure_cloud_services_deployments.html",
    "title": "Troubleshooting Deployments | Microsoft Orleans Documentation",
    "keywords": "Troubleshooting Deployments This page gives some general guidelines for troubleshooting any issues that occur while deploying to Azure Cloud Services. These are very common issues to watch out for. Be sure to check the logs for more information. Getting a SiloUnavailableException First check to make sure that you are actually starting the silos before attempting to initialize the client. Sometimes the silos take a long time to start so it can be beneficial to try to initialize the client multiple times. If it still throws an exception, then there might be another issue with the silos. Check the silo configuration and make sure that the silos are starting up properly. Common Connection String Issues Using the local connection string when deploying to Azure – the website will fail to connect Using different connection strings for the silos and the front end (web and worker roles) – the website will fail to initialize the client because it cannot connect to the silos The connection string configuration can be checked in the Azure Portal. The logs may not display properly if the connection strings are not set up correctly. Modifying the Configuration Files Improperly Make sure that the proper endpoints are configured in the ServiceDefinition.csdef file or else the deployment will not work. It will give errors saying that it cannot get the endpoint information. Missing Logs Make sure that the connection strings are set up properly. It is likely that the Web.config file in the web role or the app.config file in the worker role were modified improperly. Incorrect versions in these files can cause issues with the deployment. Be careful when dealing with updates. Version Issues Make sure that the same version of Orleans is used in every project in the solution. Not doing this can lead to the worker role recycling. Check the logs for more information. Visual Studio provides some silo startup error messages in the deployment history. Role Keeps Recycling Check that all the appropriate Orleans assemblies are in the solution and have Copy Local set to True. Check the logs to see if there is an unhandled exception while initializing. Make sure that the connection strings are correct. Check the Azure Cloud Services troubleshooting pages for more information. How to Check Logs Use the cloud explorer in Visual Studio to navigate to the appropriate storage table or blob in the storage account. The WADLogsTable is a good starting point for looking at the logs. You might only be logging errors. If you want informational logs as well, you will need to modify the configuration to set the logging severity level. Programmatic configuration: When creating a ClusterConfiguration object, set config.Defaults.DefaultTraceLevel = Severity.Info . When creating a ClientConfiguration object, set config.DefaultTraceLevel = Severity.Info . Declarative configuration: Add <Tracing DefaultTraceLevel=\"Info\" /> to the OrleansConfiguration.xml and/or the ClientConfiguration.xml files. In the diagnostics.wadcfgx file for the web and worker roles, make sure to set the scheduledTransferLogLevelFilter attribute in the Logs element to Information , as this is an additional layer of trace filtering that defines which traces are sent to the WADLogsTable in Azure Storage. You can find more information about this in the Configuration Guide. Compatibility with ASP.NET The razor view engine included in ASP.NET uses the same code generation assemblies as Orleans ( Microsoft.CodeAnalysis and Microsoft.CodeAnalysis.CSharp ). This can present a version compatibility problem at runtime. To resolve this, try upgrading Microsoft.CodeDom.Providers.DotNetCompilerPlatform (this is the NuGet package ASP.NET uses to include the above assemblies) to the latest version, and setting binding redirects like this: <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis.CSharp\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly> <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly>"
  },
  "Documentation/deployment/index.html": {
    "href": "Documentation/deployment/index.html",
    "title": "Running the Application | Microsoft Orleans Documentation",
    "keywords": "Orleans Application A typical Orleans application consists of a cluster of server processes (silos) where grains live, and a set of client processes, usually web servers, that receive external requests, turn them into grain method calls, and return results back. Hence, the first thing one needs to do to run an Orleans application is to start a cluster of silos. For testing purposes, a cluster can consist of a single silo. For a reliable production deployment, we obviously want more than one silos in a cluster for fault tolerance and scale. Once the cluster is running, we can start one or more client processes that connect to the cluster and can send requests to the grains. Clients connect to a special TCP endpoint on silos - gateway. By default, every silo in a cluster has a client gateway enabled. So clients can connect to all silos in parallel for better performance and resilience. Configuring and Starting a Silo A silo is configured programmatically via a ClusterConfiguration object. It can be instantiated and populated directly, load settings from a file, or created with several available helper methods for different deployment environments. For local testing, the easiest way to go is to use ClusterConfiguration.LocalhostPrimarySilo() helper method. The configuration object is then passed to a new instance of SiloHost class, that can be initialized and started after that. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for hosting a silo. Add the Microsoft.Orleans.Server NuGet meta-package to the project. PM> Install-Package Microsoft.Orleans.Server Here is an example of how a local silo can be started: var siloConfig = ClusterConfiguration.LocalhostPrimarySilo(); var silo = new SiloHost(\"Test Silo\", siloConfig); silo.InitializeOrleansSilo(); silo.StartOrleansSilo(); Console.WriteLine(\"Press Enter to close.\"); // wait here Console.ReadLine(); // shut the silo down after we are done. silo.ShutdownOrleansSilo(); Configuring and Connecting a Client Client for connecting to a cluster of silos and sending requests to grains is configured programmatically via a ClientConfiguration object and a ClientBuilder . ClientConfiguration object can be instantiated and populated directly, load settings from a file, or created with several available helper methods for different deployment environments. For local testing, the easiest way to go is to use ClientConfiguration.LocalhostSilo() helper method. The configuration object is then passed to a new instance of ClientBuilder class. ClientBuilder exposes more methods for configuring additional client features. After that Build method of the ClientBuilder object is called to get an implementation of IClusterClient interface. Finally, we call Connect() method on the returned object to connect to the cluster. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for running a client or reuse the console application project you created for hosting a silo. Add the Microsoft.Orleans.Client NuGet meta-package to the project. PM> Install-Package Microsoft.Orleans.Client Here is an example of how a client can connect to a local silo: var config = ClientConfiguration.LocalhostSilo(); var builder = new ClientBuilder().UseConfiguration(config). var client = builder.Build(); await client.Connect(); Production Configurations The configuration examples we used here are for testing silos and clients running on the same machine as localhost . In production, silos and clients usually run on different servers and are configured with one of the reliable cluster configuration options. You can find more about that in the Configuration Guide](../clusters_and_clients/configuration_guide/index.md) and in the description of Cluster Management ."
  },
  "Documentation/deployment/docker_deployment.html": {
    "href": "Documentation/deployment/docker_deployment.html",
    "title": "Docker Deployment | Microsoft Orleans Documentation",
    "keywords": "Docker Deployment Note : Even if you are very familiar with Docker and/or Orleans, as any other Orleans documentation, I recommend you to read it to the end in order to avoid problems you may face that we already worked around. Note : This article and its sample are a work in progress. Any feedback, PR or suggestion is very welcome. Deploying Orleans solutions to Docker Deploying Orleans to Docker can be tricky given the way Docker orchestrators and clustering stacks was designed. The most complicated thing is to understand the concept of Overlay Network from Docker Swarm and Kubernets Networking model. Docker containers and networking model were designed to run mostly stateless and immutable containers. So, spinning up a cluster running node.js or nginx applications, is pretty easy. However, if you try to use something more elaborate, like a real clustered or distributed application (like Orleans-based ones) you will eventually have trouble setting it up. It is possible, but not as simple as web-based applications. Docker clustering consists of putting together multiple hosts to work as a single pool of resources, managed using a Container Orchestrator . Docker Inc. provide Swarm as their option for Container Orchestration while Google has Kubernetes (aka K8s ). There are other Orchestrators like DC/OS , Mesos , etc., but in this document we will talk about Swarm and K8s as they are more widely used. The same grain interfaces and implementation which run anywhere Orleans is already supported, will run on Docker containers as well, so no special considerations are needed in order to be able to run your application in Docker containers. The Orleans-Docker sample provides a working example of how to run two console applications. One as Orleans Client and another as Silo, and the details are described below. The concepts discussed here, can be used on both .Net Core and .Net 4.6.1 flavors of Orleans but to ilustrate the cross-platform nature of Docker and .Net Core, we are going to focus on the example considering you are using .Net Core. Platform-specific (Windows/Linux/OSX) details may be provide along this article. Pre-requisites This article assume that you have the following prerequisites installed: Docker - Docker4X has a easy-to-use installer for the major supported platforms. It contains Docker engine and also Docker Swarm. Kubernetes (K8s) - Google's offer for Container Orchestration. It contains a guidance to install Minikube (a local deployment of K8s) and kubectl along with all its dependencies. .Net Core - Cross-platform flavor of .Net Visual Studio Code (VSCode) - You can use whatever IDE you want. VSCode is cross-platform so we are using it to ensure it works on all platforms. Once you installed VSCode, install the C# extension . Note : You are not required to have Kubernetes installed if you are not going to use it. Docker4X installer already includes Swarm so no extra installation is required to use it. Note for Windows Users : On Windows, Docker installer will enable Hyper-V at installation process. As this article and its examples are using .Net Core, the container images used are based on Windows Server NanoServer . If you don't plan to use .Net Core and will target .Net 4.6.1 full framework, the image used should be Windows Server Core and the 1.4+ version of Orleans (which supports only .net full framework). Creating Orleans Solution The following instructions show how to create a regular Orleans solution using the new dotnet tooling. Note : Please adapt the commands to whatever is appropriate in your platform. Also, the directory structure is just a suggestion. Please adapt it to your needs. mkdir Orleans-Docker cd Orleans-Docker dotnet new sln mkdir -p src/OrleansSilo mkdir -p src/OrleansClient mkdir -p src/OrleansGrains mkdir -p src/OrleansGrainInterfaces dotnet new console -o src/OrleansSilo --framework netcoreapp1.1 dotnet new console -o src/OrleansClient --framework netcoreapp1.1 dotnet new classlib -o src/OrleansGrains --framework netstandard1.5 dotnet new classlib -o src/OrleansGrainInterfaces --framework netstandard1.5 dotnet sln add src/OrleansSilo/OrleansSilo.csproj dotnet sln add src/OrleansClient/OrleansClient.csproj dotnet sln add src/OrleansGrains/OrleansGrains.csproj dotnet sln add src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansClient/OrleansClient.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansSilo/OrleansSilo.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansGrains/OrleansGrains.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansSilo/OrleansSilo.csproj reference src/OrleansGrains/OrleansGrains.csproj What we did so far was just boilerplate code to create the solution structure, projects, and add references between projects. Nothing different than a regular Orleans project. By the time this article was written, Orleans 2.0 (which is the only version which support .Net Core and cross-platform) is in Technology Preview so its nugets are hosted in a MyGet feed and not published to Nuget.org official feed. In order to install the preview nugets, we will use dotnet cli forcing the source feed and version from MyGet: dotnet add src/OrleansClient/OrleansClient.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansGrains/OrleansGrains.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansSilo/OrleansSilo.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansSilo/OrleansSilo.csproj package Microsoft.Orleans.OrleansRuntime -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet restore Ok, now you have all the basic dependencies to run a simple Orleans application. Note that so far, nothing changed from your regular Orleans application. Now, lets add some code so we can do something with it. Implementing your Orleans Application Assuming that you are using VSCode , from the solution directory, run code . . That will open the directory in VSCode and load the solution. This is the solution structure we just created previously. We also added Program.cs , OrleansHostWrapper , IGreetingGrain and GreetingGrain files to the interfaces and grain projects respectively and here is the code for those files: IGreetingGrain.cs : using System; using System.Threading.Tasks; using Orleans; namespace OrleansGrainInterfaces { public interface IGreetingGrain : IGrainWithGuidKey { Task<string> SayHello(string name); } } GreetingGrain.cs : using System; using System.Threading.Tasks; using OrleansGrainInterfaces; namespace OrleansGrains { public class GreetingGrain : Grain, IGreetingGrain { public Task<string> SayHello(string name) { return Task.FromResult($\"Hello from Orleans, {name}\"); } } } OrleansHostWrapper.cs : using System; using System.Net; using Orleans.Runtime; using Orleans.Runtime.Configuration; using Orleans.Runtime.Host; namespace OrleansSilo { public class OrleansHostWrapper { private readonly SiloHost siloHost; public OrleansHostWrapper(ClusterConfiguration config) { siloHost = new SiloHost(Dns.GetHostName(), config); siloHost.LoadOrleansConfig(); } public int Run() { if (siloHost == null) { return 1; } try { siloHost.InitializeOrleansSilo(); if (siloHost.StartOrleansSilo()) { Console.WriteLine($\"Successfully started Orleans silo '{siloHost.Name}' as a {siloHost.Type} node.\"); return 0; } else { throw new OrleansException($\"Failed to start Orleans silo '{siloHost.Name}' as a {siloHost.Type} node.\"); } } catch (Exception exc) { siloHost.ReportStartupError(exc); Console.Error.WriteLine(exc); return 1; } } public int Stop() { if (siloHost != null) { try { siloHost.StopOrleansSilo(); siloHost.Dispose(); Console.WriteLine($\"Orleans silo '{siloHost.Name}' shutdown.\"); } catch (Exception exc) { siloHost.ReportStartupError(exc); Console.Error.WriteLine(exc); return 1; } } return 0; } } } Program.cs (Silo): using System; using System.Collections.Generic; using System.Linq; using System.Net; using Orleans.Runtime.Configuration; namespace OrleansSilo { public class Program { private static OrleansHostWrapper hostWrapper; static int Main(string[] args) { int exitCode = InitializeOrleans(); Console.WriteLine(\"Press Enter to terminate...\"); Console.ReadLine(); exitCode += ShutdownSilo(); return exitCode; } private static int InitializeOrleans() { var config = new ClusterConfiguration(); config.Globals.DataConnectionString = \"[AZURE STORAGE CONNECTION STRING HERE]\"; config.Globals.DeploymentId = \"Orleans-Docker\"; config.Globals.LivenessType = GlobalConfiguration.LivenessProviderType.AzureTable; config.Globals.ReminderServiceType = GlobalConfiguration.ReminderServiceProviderType.AzureTable; config.Defaults.PropagateActivityId = true; config.Defaults.ProxyGatewayEndpoint = new IPEndPoint(IPAddress.Any, 10400); config.Defaults.Port = 10300; var ips = Dns.GetHostAddressesAsync(Dns.GetHostName()).Result; config.Defaults.HostNameOrIPAddress = ips.FirstOrDefault()?.ToString(); hostWrapper = new OrleansHostWrapper(config); return hostWrapper.Run(); } private static int ShutdownSilo() { if (hostWrapper != null) { return hostWrapper.Stop(); } return 0; } } } Program.cs (client): using System; using System.Net; using System.Threading; using System.Threading.Tasks; using Orleans; using Orleans.Runtime.Configuration; using OrleansGrainInterfaces; namespace OrleansClient { class Program { private static IClusterClient client; private static bool running; static void Main(string[] args) { Task.Run(() => InitializeOrleans()); Console.ReadLine(); running = false; } static async Task InitializeOrleans() { var config = new ClientConfiguration(); config.DeploymentId = \"Orleans-Docker\"; config.PropagateActivityId = true; var hostEntry = await Dns.GetHostEntryAsync(\"orleans-silo\"); var ip = hostEntry.AddressList[0]; config.Gateways.Add(new IPEndPoint(ip, 10400)); Console.WriteLine(\"Initializing...\"); client = new ClientBuilder().UseConfiguration(config).Build(); await client.Connect(); running = true; Console.WriteLine(\"Initialized!\"); var grain = client.GetGrain<IGreetingGrain>(Guid.Empty); while(running) { var response = await grain.SayHello(\"Gutemberg\"); Console.WriteLine($\"[{DateTime.UtcNow}] - {response}\"); await Task.Delay(1000); } client.Dispose(); } } } We are not going into details about the grain implementation here since it is out of the scope of this article. Please check other documents related to it. Those files are essentially a minimal Orleans application and we will start from it to move forward with the remaining of this article. Note : In this article we are using OrleansAzureUtils membership provider but you can use any other already supported by Orleans. Dockerfile In order to create your container, Docker uses images. For more details on how to create your own, you can check Docker documentation . In this article we are going to use official Microsoft images . Based on the target and development platforms, you need to pick the appropriate image. In this article, we are using microsoft/dotnet:1.1.2-sdk which is a linux-based image. You can use microsoft/dotnet:1.1.2-sdk-nanoserver for Windows for example. Pick one that suit your needs. Note for Windows users : As previously mentioned, to be cross-platform, we are using .Net Core and Orleans Technical preview 2.0 in this article. If you want to use Docker on Windows with the fully released Orleans 1.4+, you need to use the images that are based on Windows Server Core since NanoServer and Linux based images, only support .Net Core. Dockerfile.debug : FROM microsoft/dotnet:1.1.2-sdk ENV NUGET_XMLDOC_MODE skip WORKDIR /vsdbg RUN apt-get update \\ && apt-get install -y --no-install-recommends \\ unzip \\ && rm -rf /var/lib/apt/lists/* \\ && curl -sSL https://aka.ms/getvsdbgsh | bash /dev/stdin -v latest -l /vsdbg WORKDIR /app ENTRYPOINT [\"tail\", \"-f\", \"/dev/null\"] This dockerfile essentially downloads and installs the VSdbg debugger and starts an empty container, keeping it alive forever so we don't need tear down/up while debugging. Now, for production, the image is smaller since it contains only the .Net Core runtime and not the whole SDK, and the dockerfile is a bit simpler: Dockerfile : FROM microsoft/dotnet:1.1.2-runtime WORKDIR /app ENTRYPOINT [\"dotnet\", \"OrleansSilo.dll\"] COPY . /app docker-compose The docker-compose.yml file, essentially defines (within a project) a set of services and its dependencies at service level. Each service contains one or more instances of a given container, which is based on the images you selected on your Dockerfile. More details on the docker-compose can be found on docker-compose documentation . For an Orleans deployment, a common use case is to have a docker-compose.yml which contains two services. One for Orleans Silo, and other for Orleans Client. The Client would have a dependency on the Silo and that means, it will only start after the Silo service is up. Another case is to add a storage/database service/container, like for example SQL Server, which should start first before the client and the silo, so both services should take a dependency on it. Note : Before you read further (and eventually get crazy with it), please note that identation matters in docker-compose files. So pay attention to it if you have any problem. Here is how we will describe our services for this article: docker-compose.override.yml (Debug): version: '3.1' services: orleans-client: image: orleans-client:debug build: context: ./src/OrleansClient/bin/PublishOutput/ dockerfile: Dockerfile.Debug volumes: - ./src/OrleansClient/bin/PublishOutput/:/app - ~/.nuget/packages:/root/.nuget/packages:ro depends_on: - orleans-silo orleans-silo: image: orleans-silo:debug build: context: ./src/OrleansSilo/bin/PublishOutput/ dockerfile: Dockerfile.Debug volumes: - ./src/OrleansSilo/bin/PublishOutput/:/app - ~/.nuget/packages:/root/.nuget/packages:ro docker-compose.yml (production): version: '3.1' services: orleans-client: image: orleans-client depends_on: - orleans-silo orleans-silo: image: orleans-silo Note that in production, we don't map the local directory and neither we have the build: action. The reason is that in production, the images should be built and pushed to your own Docker Registry. Put everything together Now we have all the moving parts required to run your Orleans Application, we are going to put it together so we can run our Orleans solution inside Docker (Finally!). Note : The following commands should be performed from the solution directory. First, lets make sure we restore all NuGet packages from our solution. You only need to do it once. You are only required to do it again if you change any package dependency on your project. # dotnet restore Now, let's build our solution using dotnet CLI as usual and publish it to an output directory: # dotnet publish -o ./bin/PublishOutput Note : We are using publish here instead of build, to avoid problems with our dynamicaly loaded assemblied in Orleans. We are still looking for a better solution for it. With the application built and published, you need to build your Dockerfile images. This step is only required to be performed once per project and should be only performed again if you change the Dockerfile, docker-compose, or for any reason you cleaned up your local image registry. # docker-compose build All the images used in both Dockerfile and docker-compose.yml are pulled from the registry and cached on your development machine. Your images are built, and you are all set to run. Now lets run it! # docker-compose up -d Creating network \"orleansdocker_default\" with the default driver Creating orleansdocker_orleans-silo_1 ... Creating orleansdocker_orleans-silo_1 ... done Creating orleansdocker_orleans-client_1 ... Creating orleansdocker_orleans-client_1 ... done # Now if you run a docker-compose ps , you will see 2 containers running for the orleansdocker project: # docker-compose ps Name Command State Ports ------------------------------------------------------------------ orleansdocker_orleans-client_1 tail -f /dev/null Up orleansdocker_orleans-silo_1 tail -f /dev/null Up Note for Windows users : If you are on Windows, and your container is using a Windows image as base, the Command column will show you the Powershell relative command to a tail on *NIX systems so the container will keep up the same way. Now that you have your containers up, you don't need to stop it every time you want to start your Orleans application. All you need is to integrate your IDE to debug the application inside the container which was previously mapped in your docker-compose.yml . Scaling Once you have your compose project running, you can easily scale up or down your application using docker-compose scale command: # docker-compose scale orleans-silo=15 Starting orleansdocker_orleans-silo_1 ... done Creating orleansdocker_orleans-silo_2 ... Creating orleansdocker_orleans-silo_3 ... Creating orleansdocker_orleans-silo_4 ... Creating orleansdocker_orleans-silo_5 ... Creating orleansdocker_orleans-silo_6 ... Creating orleansdocker_orleans-silo_7 ... Creating orleansdocker_orleans-silo_8 ... Creating orleansdocker_orleans-silo_9 ... Creating orleansdocker_orleans-silo_10 ... Creating orleansdocker_orleans-silo_11 ... Creating orleansdocker_orleans-silo_12 ... Creating orleansdocker_orleans-silo_13 ... Creating orleansdocker_orleans-silo_14 ... Creating orleansdocker_orleans-silo_15 ... Creating orleansdocker_orleans-silo_6 Creating orleansdocker_orleans-silo_5 Creating orleansdocker_orleans-silo_3 Creating orleansdocker_orleans-silo_2 Creating orleansdocker_orleans-silo_4 Creating orleansdocker_orleans-silo_9 Creating orleansdocker_orleans-silo_7 Creating orleansdocker_orleans-silo_8 Creating orleansdocker_orleans-silo_10 Creating orleansdocker_orleans-silo_11 Creating orleansdocker_orleans-silo_15 Creating orleansdocker_orleans-silo_12 Creating orleansdocker_orleans-silo_14 Creating orleansdocker_orleans-silo_13 Few seconds later, you will see the services scaled to the specific number of instances you requested. # docker-compose ps Name Command State Ports ------------------------------------------------------------------ orleansdocker_orleans-client_1 tail -f /dev/null Up orleansdocker_orleans-silo_1 tail -f /dev/null Up orleansdocker_orleans-silo_10 tail -f /dev/null Up orleansdocker_orleans-silo_11 tail -f /dev/null Up orleansdocker_orleans-silo_12 tail -f /dev/null Up orleansdocker_orleans-silo_13 tail -f /dev/null Up orleansdocker_orleans-silo_14 tail -f /dev/null Up orleansdocker_orleans-silo_15 tail -f /dev/null Up orleansdocker_orleans-silo_2 tail -f /dev/null Up orleansdocker_orleans-silo_3 tail -f /dev/null Up orleansdocker_orleans-silo_4 tail -f /dev/null Up orleansdocker_orleans-silo_5 tail -f /dev/null Up orleansdocker_orleans-silo_6 tail -f /dev/null Up orleansdocker_orleans-silo_7 tail -f /dev/null Up orleansdocker_orleans-silo_8 tail -f /dev/null Up orleansdocker_orleans-silo_9 tail -f /dev/null Up Note : The Command column on those examples are showing the tail command just because we are using the debugger container. If we were in production, it would be showing dotnet OrleansSilo.dll for example. Docker Swarm Docker clustering stack is called Swarm and you can find more by reading its documentation here . To run this article in a Swarm cluster, you don't have any extra work. When you run docker-compose up -d in a Swarm node, it will schedule containers based on the configured rules. The same applies to other Swarm-based services like Docker Datacenter , Azure ACS (in Swarm mode), AWS ECS Container Service and so on. All you need to do is to deploy your Swarm cluster before deploy your dockerized Orleans application. Note : If you are using a Docker engine with the Swarm mode that already have support to stack , deploy and compose v3, a better approach to deploy your solution would be docker stack deploy -c docker-compose.yml <name> . Just keep in mind that it requires v3 compose file support at your Docker engine and the majority of hosted services like Azure and AWS still use v2 and older engines. Google Kubernetes (K8s) If you plan to use Kubernetes to host Orleans, there is a community-maintained clustering provider available at OrleansContrib\\Orleans.Clustering.Kubernetes and there you can find documentation and samples on how to host Orleans in Kubernetes seamlessly using the provider. [Bonus topic] Debugging Orleans inside Containers Well, now that you know how to run Orleans in a container from scratch, would be good to leverage one of the most important principles in Docker. Containers are immutable. And they should have (almost) the same image, dependencies, and runtime in development as in production. This ensures the good old statement \"It works on my machine!\" never happens again. To make that possible, you need to have a way to develop inside the container and that includes have a debugger attached to your application inside the container. There are multiple ways to achieve that using multiple tools. After evaluating several, by the time I wrote this article, I ended up choosing one that looks more simple and is less intrusive in the application. As mentioned ealier in this article, we are using VSCode to develop the sample, so here is how to get the debugger attached to your Orleans Application inside the container. First, change two files inside your .vscode directory in your solution: tasks.json : { \"version\": \"0.1.0\", \"command\": \"dotnet\", \"isShellCommand\": true, \"args\": [], \"tasks\": [ { \"taskName\": \"publish\", \"args\": [ \"${workspaceRoot}/Orleans-Docker.sln\", \"-c\", \"Debug\", \"-o\", \"./bin/PublishOutput\" ], \"isBuildCommand\": true, \"problemMatcher\": \"$msCompile\" } ] } This file essentially tells VSCode that whenever you build the project, it will actually execute the publish command as we manually did earlier. launch.json : { \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Silo\", \"type\": \"coreclr\", \"request\": \"launch\", \"cwd\": \"/app\", \"program\": \"/app/OrleansSilo.dll\", \"sourceFileMap\": { \"/app\": \"${workspaceRoot}/src/OrleansSilo\" }, \"pipeTransport\": { \"debuggerPath\": \"/vsdbg/vsdbg\", \"pipeProgram\": \"/bin/bash\", \"pipeCwd\": \"${workspaceRoot}\", \"pipeArgs\": [ \"-c\", \"docker exec -i orleansdocker_orleans-silo_1 /vsdbg/vsdbg --interpreter=vscode\" ] } }, { \"name\": \"Client\", \"type\": \"coreclr\", \"request\": \"launch\", \"cwd\": \"/app\", \"program\": \"/app/OrleansClient.dll\", \"sourceFileMap\": { \"/app\": \"${workspaceRoot}/src/OrleansClient\" }, \"pipeTransport\": { \"debuggerPath\": \"/vsdbg/vsdbg\", \"pipeProgram\": \"/bin/bash\", \"pipeCwd\": \"${workspaceRoot}\", \"pipeArgs\": [ \"-c\", \"docker exec -i orleansdocker_orleans-client_1 /vsdbg/vsdbg --interpreter=vscode\" ] } } ] } Now you can just build the solution from VSCode (which will publish) and start both the Silo and the Client. It will send a docker exec command to the running docker-compose service instance/container to start the debugger to the application and thats it. You have the debugger attached to the container and use it as if it was a locally running Orleans application. The difference now is that it is inside the container, and once you are done, you can just publish the container to your registry and pull it on your Docker hosts in production."
  },
  "1.5/Documentation/Multi-Cluster/SiloConfiguration.html": {
    "href": "1.5/Documentation/Multi-Cluster/SiloConfiguration.html",
    "title": "Multi-Cluster Silo Configuration | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Orleans Silo Configuration To get a quick overview, we show all relevant configuration parameters (including optional ones) in XML syntax below: <?xml version=\"1.0\" encoding=\"utf-8\"?> <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <MultiClusterNetwork ClusterId=\"clusterid\" DefaultMultiCluster=\"uswest,europewest,useast\" BackgroundGossipInterval=\"30s\" UseGlobalSingleInstanceByDefault=\"false\" GlobalSingleInstanceRetryInterval=\"30s\" GlobalSingleInstanceNumberRetries=\"3\" MaxMultiClusterGateways=\"10\"> <GossipChannel Type=\"...\" ConnectionString=\"...\"/> <GossipChannel Type=\"...\" ConnectionString=\"...\"/> </MultiClusterNetwork> <SystemStore ... ServiceId=\"some-guid\" .../> </Globals> </OrleansConfiguration> As usual, all configuration settings can also be read and written programmatically, via the respective members of the GlobalConfiguration class. The Service Id is an arbitrary Guid for identifying this service. It must be the same for all clusters and all silos. If not specified, the default Guid (containing all zeroes) is used. The MultiClusterNetwork section is optional - if not present, all multi-cluster support is disabled for this silo. The required parameters ClusterId and GossipChannel are explained in the section on Multi-Cluster Communication . The optional parameters MaxMultiClusterGateways and BackgroundGossipInterval are explained in the section on Multi-Cluster Communication . The optional parameter DefaultMultiCluster is explained in the section on Multi-Cluster Configuration . The optional parameters UseGlobalSingleInstanceByDefault , GlobalSingleInstanceRetryInterval and GlobalSingleInstanceNumberRetries are explained in the section on Global-Single-Instance Grains . Orleans Client Configuration No extra configuration is required for Orleans client. The same client may not connect to silos in different clusters (the silo refuses the connection in that situation)."
  },
  "1.5/Documentation/Multi-Cluster/MultiClusterConfiguration.html": {
    "href": "1.5/Documentation/Multi-Cluster/MultiClusterConfiguration.html",
    "title": "Multi-Cluster Configuration | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Multi-Cluster Configuration The multi-cluster configuration determines which clusters are currently part of the multi-cluster. It does not change automatically, but is controlled by the operator. Thus, it is quite different from the membership mechanism used within a cluster, which automatically determines the set of silos that are part of the cluster. We use the following terminology for the clusters in a service: A cluster is active if it has at least one active silo, and inactive otherwise A cluster is joined if it is part of the current multi-cluster configuration, and non-joined otherwise Being active/inactive is independent from being joined/non-joined: all four combinations are possible. All the clusters for a particular service are connected by a gossip network . The gossip network propagates configuration and status information. Injecting a configuration An operator issues configuration changes by injecting them into the multi-cluster network. The configurations can be injected into any cluster, and spread from there to all active clusters. Each new configuration consists of a list of cluster ids that form the multi-cluster. It also has a UTC timestamp that is used to track its propagation through the gossip network. Initially, the multi-cluster configuration is null, which means the multi-cluster list is empty (contains no clusters). Thus, the operator must initially inject a multi-cluster configuration. Once injected, this configuration persists in all connected silos (while running) and in all specified gossip channels (if those channels are persistent). We pose some restrictions on the injection of new configurations that an operator must follow: Each new configuration may add a number of clusters, or remove a number of clusters (but not both at the same time). An operator should not issue a new configuration while a previous configuration change is still being processed. These restrictions ensure that protocols such as the single-instance-protocol can correctly maintain mutual exclusion of activations even under configuration changes. Via Management Grain Multi-cluster configurations can be injected on any node in any cluster, using the Orleans Management Grain. For example, to inject a multi-cluster configuration that consists of the three clusters { us1, eu1, us2 }, we can pass a string enumerable to the management grain: var clusterlist = \"us1,eu1,us2\".Split(','); var mgtGrain = GrainClient.GrainFactory.GetGrain<IManagementGrain>(0); mgtGrain.InjectMultiClusterConfiguration(clusterlist, \"my comment here\")); The first argument to InjectMultiClusterConfiguration is an enumerable of cluster ids, which is going to define the new multi-cluster configuration. The second argument is an (optional) comment string that can be used to tag configurations with arbitrary information, such as who injected them why. There is an optional third argument, a boolean called checkForLaggingSilosFirst , which defaults to true. It means that the system performs a best-effort check to see if there are any silos anywhere that have not caught up to the current configuration yet, and rejects the change if it finds such a silo. This helps to detect violations of the restriction that only one configuration change should be pending at a time (though it cannot guarantee it under all circumstances). Via Default Configuration In situations where the multi-cluster configuration is known in advance and the deployment is fresh every time (e.g. for testing), we may want to supply a default configuration. The global configuration supports an optional attribute DefaultMultiCluster which takes a comma-separated list of cluster ids: <MultiClusterNetwork ... DefaultMulticluster=\"us1,eu1,us2\" ...> After a silo is started with this setting, it checks to see if the current multi-cluster configuration is null, and if so, injects the given configuration with the current UTC timestamp. WARNING. Persistent multi-cluster gossip channels (e.g. based on AzureTable) retain the last injected configuration unless they are deleted explicitly. In that case, specifying a DefaultMulticluster has no effect when re-deploying a cluster because the configuration stored in the gossip channels is not null.> Via Gossip Channel An operator can also inject the configuration directly into the gossip channel. Changes in the channel are picked up and propagated automatically by the periodic background gossip, though possibly very slowly (using the management grain is much faster). A rough estimate on the propagation time is 30 seconds (or whatever gossip interval is specified in the global configuration) times the binary logarithm of the total number of silos in all clusters. But since the gossip pairs are selected randomly, it can be both much quicker or much slower. If using the Azure Table-Based Gossip Channel, operators can inject a new configuration simply by editing the configuration record in the OrleansGossipTable , e.g. using some tool for editing data in Azure tables. The configuration record has the following format: Name Type Value PartitionKey String the ServiceId GUID RowKey String \"CONFIG\" Clusters String comma-separated list of cluster IDs, e.g. \"us1,eu1,us2\" Comment String optional comment GossipTimestamp DateTime UTC timestamp for the configuration NOTE . When editing this record in storage, the GossipTimestamp must also be set to a newer value than it has currently (otherwise the change is ignored). The most convenient and recommended way to do this is to delete the GossipTimestamp field - our gossip channel implementation then automatically replaces it with a correct, current Timestamp (it uses the Azure Table Timestamp). Cluster Addition/Removal Procedures Adding or removing a cluster from the multi-cluster often needs to be coordinated within some larger context. We recommend to always follow the procedures described below when adding/removing clusters from the multi-cluster. Procedure for adding a cluster Start a new Orleans cluster and wait till all silos are up and running. Inject a configuration that contains the new cluster. Start routing user requests to the new cluster. Procedure for removing a cluster Stop routing new user requests to the cluster. Inject a configuration that no longer contains the cluster. Stop all silos of the cluster. Once a cluster has been removed in this way, it can be re-added by following the procedure for adding a new cluster. Activity on Non-Joined Clusters There can be brief, temporary periods of time where a cluster is both active and non-joined: A freshly started cluster may start executing code before it is in the multicluster configuration (between steps 1 and 2 of the procedure for adding a cluster) A cluster that is being decommissioned may still execute code before the silos are shut down (between steps 2 and 3 of the procedure for removing a cluster). During those intermediate situations, the following are possible: For global-single-instance grains: A grain may have a duplicate activation on a non-joined cluster. For versioned grains: activations on non-joined clusters do not receive notifications when the grain state changes."
  },
  "1.5/Documentation/Multi-Cluster/GossipChannels.html": {
    "href": "1.5/Documentation/Multi-Cluster/GossipChannels.html",
    "title": "Multi-Cluster Communication | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Multi-Cluster Communication The network must be configured in such a way that any Orleans silo can connect to any other Orleans silo via TCP/IP, regardless of where in the world it is located. Exactly how this is achieved is outside of the scope of Orleans, as it depends on how and where silos are deployed. For example, on Windows Azure, we can use VNETs to connect muliple deployments within a region, and gateways to connect VNETs across different regions. Cluster Id Each cluster has its own unique cluster id. The cluster id must be specified in the global configuration. Cluster ids may not be empty, nor may they contain commas. Also, if using Azure Table Storage, cluster ids may not contain the characters forbidden for row keys (/, , #, ?). We recommend using very short strings for the cluster ids, because cluster ids are transmitted frequently and may be stored in storage by some log-view providers. Cluster Gateways Each cluster automatically designates a subset of its active silos to serve as cluster gateways . Cluster gateways directly advertise their IP addresses to other clusters, and can thus serve as \"points of first contact\". By default, at most 10 silos (or whatever number is configured as MaxMultiClusterGateways ) are designated as cluster gateways. Communication between silos in different clusters does not always pass through a gateway. Once a silo has learned and cached the location of a grain activation (no matter in what cluster), it sends messages to that silo directly, even if the silo is not a cluster gateway. Gossip Gossip is a mechanism for clusters to share configuration and status information. As the name suggests, gossip is decentralized and bidirectional: each silo communicates directly with other silos, both in the same cluster and in other clusters, to exchange information in both directions. Content . Gossip contains some or all of the following information: The current time-stamped multi-cluster configuration . A dictionary that contains information about cluster gateways. The key is the silo address, and the value contains (1) a timestamp, (2) the cluster id, and (3) a status, which is either active or inactive. Fast & Slow Propagation . When a gateway changes its status, or when an operator injects a new configuration, this gossip information is immediately sent to all silos, clusters, and gossip channels. This happens fast, but is not reliable. Should the message be lost due to any reasons (e.g. races, broken sockets, silo failures), our periodic background gossip ensures that the information eventually spreads, albeit more slowly. All information is eventually propagated everywhere, and is highly resilient to occasional message loss and failures. All gossip data is timestamped, which ensures that newer information replaces older information regardless of the relative timing of messages. For example, newer multi-cluster configurations replace older ones, and newer information about a gateway replaces older information about that gateway. For more details on the representation of gossip data, see the MultiClusterData class. It has a Merge method that combines gossip data, resolving conflicts using timestamps. Gossip Channels When a silo is first started, or when it is restarted after a failure, it needs to have a way to bootstrap the gossip . This is the role of the gossip channel , which can be configured in the Silo Configuration . On startup, a silo fetches all the information from the gossip channels. After startup, a silo keeps gossiping periodically, every 30 seconds or whatever is configured as BackgroundGossipInterval . Each time it synchronizes its gossip information with a partner randomly selected from all cluster gateways and gossip channels. Notes: Though not strictly required, we recommend to always configure at least two gossip channels, in distinct regions, for better availability. Latency of communication with gossip channels is not critical. Multiple different services can use the same gossip channel without interference, as long as the ServiceId Guid (as specified by their respective configuration) is distinct. There is no strict requirement that all silos use the same gossip channels, as long as the channels are sufficient to let a silo initially connect with the \"gossiping community\" when it starts up. But if a gossip channel is not part of a silo's configuration, and that silo is a gateway, it does not push its status updates to the channel (fast propagation), so it may take longer before those reach the channel via periodic background gossip (slow propagation). Azure-Table-Based Gossip Channel We have already implemented a gossip channel based on Azure Tables. The configuration specifies standard connection strings used for Azure accounts. For example, a configuration could specify two gossip channels with separate Azure storage accounts usa and europe as follows: <MultiClusterNetwork ClusterId=\"...\"> <GossipChannel Type=\"AzureTable\" ConnectionString=\"DefaultEndpointsProtocol=https;AccountName=usa;AccountKey=...\"/> <GossipChannel Type=\"AzureTable\" ConnectionString=\"DefaultEndpointsProtocol=https;AccountName=europe;AccountKey=...\"/> </MultiClusterNetwork> Multiple different services can use the same gossip channel without interference, as long as the ServiceId guid specified by their respective configuration is distinct. Other Gossip Channel Implementations We are working on other gossip channel providers, similar to how membership and reminders are packaged for many different storage back-ends."
  },
  "1.5/Documentation/Samples-Overview/Adventure.html": {
    "href": "1.5/Documentation/Samples-Overview/Adventure.html",
    "title": "Adventure | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Adventure A simple multiplayer text adventure game inspired by old-fashioned, text-based adventure games. Instructions: Build Adventure.sln Start your local Silo from a command window using command file #1. The game map initialization script, #2 Start the client #3 Reminisce about the good old days before graphical user interfaces Overview The AdventureSetup program reads a game description (\"map\") from AdventureConfig.txt. It sets up a series of \"rooms\" e.g. forest, beach, caves, a clearing etc . These locations are connected to other rooms to model the places and layout of the game. The sample configuration describes only a handful of locations. Rooms can contain \"things\" such as keys, swords etc. The AdventureClient program sets up your player and provides a simple text based user interface to allow you to play the game. You can move around rooms and interact with things using a simple command language, saying things such as \"go north\" or \"take brass key\". Why Orleans? Orleans allows the game to be described via very simple C# code while allowing it to scale to a massive multiplayer game. For this motivation to be meaningful, the labyrinth of rooms needs to be very large and need to support a large number of simultaneous players. One value of Orleans is that the service can be designed for growth, the overhead of running it at a small scale is not significant, and you can remain confident that it will scale if the need arises. How is it modeled? Player and Rooms are modeled as grains. These grains allow us to distribute the game with each grain modelling state and functionality. Things such as keys are modeled as plain old objects - they are really just simple immutable data structures that move around rooms and among players; they don't need to be grains. Things for you to do if you are so inclined Make the map much, much, bigger Make the brass key unlock something Allow players to message each other Make eating food and drinking water possible and meaningful"
  },
  "Documentation/streaming/streams_why.html": {
    "href": "Documentation/streaming/streams_why.html",
    "title": "Why Orleans Streams? | Microsoft Orleans Documentation",
    "keywords": "Why Orleans Streams? There are already a wide range of technologies that allow you to build stream processing systems. Those include systems to durably store stream data (e.g., Event Hubs and Kafka ) and systems to express compute operations over stream data (e.g., Azure Stream Analytics , Apache Storm , and Apache Spark Streaming ). Those are great systems that allow you to build efficient data stream processing pipelines. Limitations of Existing Systems However, those systems are not suitable for fine-grained free-form compute over stream data . The Streaming Compute systems mentioned above all allow you to specify a unified data-flow graph of operations that are applied in the same way to all stream items . This is a powerful model when data is uniform and you want to express the same set of transformation, filtering, or aggregation operations over this data. But there are other use cases where you need to express fundamentally different operations over different data items. And in some of them as part of this processing you occasionally need to make an external call, such as invoke some arbitrary REST API. The unified data-flow stream processing engines either do not support those scenarios, support them in a limited and constrained way, or are inefficient in supporting them. This is because they are inherently optimized for a large volume of similar items, and usually limited in terms of expressiveness, processing . Orleans Streams target those other scenarios. Motivation It all started with requests from Orleans users to support returning a sequence of items from a grain method call. As you can imagine, that was only the tip of the iceberg. They actually needed much more than that. A typical scenario for Orleans Streams is when you have per user streams and you want to perform different processing for each user , within the context of an individual user. We may have millions of users but some of them are interested in weather and can subscribe to weather alerts for a particular location, while some are interested in sports events; somebody is tracking status of a particular flight. Processing those events requires different logic, but you don't want to run two independent instances of stream processing. Some users are interested in only a particular stock and only if certain external condition applies, condition that may not necessarily be part of the stream data (thus needs to be checked dynamically at runtime as part of processing). Users change their interests all the time, hence their subscriptions to specific streams of events come and go dynamically, thus the streaming topology changes dynamically and rapidly . On top of that, the processing logic per user evolves and changes dynamically as well, based on user state and external events . External events may modify the processing logic for a particular user. For example, in a game cheating detection system, when a new way to cheat is discovered the processing logic needs to be updated with the new rule to detect this new violation. This needs to be done of course without disrupting the ongoing processing pipeline . Bulk data-flow stream processing engines were not build to support such scenarios. It goes almost without saying that such a system has to run on a number of network-connected machines, not on a single node. Hence, the processing logic has to be distributed in a scalable and elastic manner across a cluster of servers. New Requirements We identified 4 basic requirements for our Stream Processing system that will allow it to target the above scenarios. Flexible stream processing logic Support for highly dynamic topologies Fine-grained stream granularity Distribution Flexible stream processing logic We want the system to support different ways of expressing the stream processing logic. The existing systems we mentioned above require the developer to write a declarative data-flow computation graph, usually by following a functional programming style. This limits the expressiveness and flexibility of the processing logic. Orleans streams are indifferent to the way processing logic is expressed. It can be expressed as a data-flow (e.g., by using Reactive Extensions (Rx) in .NET ); as a functional program; as a declarative query; or in a general imperative logic. The logic can be stateful or stateless, may or may not have side effects, and can trigger external actions. All power goes to the developer. Support for dynamic topologies We want the system to allow for dynamically evolving topologies. The existing systems we mentioned above are usually limited to only static topologies that are fixed at deployment time and cannot evolve at runtime. In the following example of a dataflow expression everything is nice and simple until you need to change it. Stream.GroupBy(x=> x.key).Extract(x=>x.field).Select(x=>x+2).AverageWindow(x, 5sec).Where(x=>x > 0.8) * Change the threshold condition in the Where filter, add an additional Select statement or add another branch in the data-flow graph and produce a new output stream. In existing systems this is not possible without tearing down the entire topology and restarting the data-flow from scratch. Practically, those systems will checkpoint the existing computation and will be able to restart from the latest checkpoint. Still, such a restart is disruptive and costly to an online service that produces results in real time. Such a restart becomes especially impractical when we are talking about a large number of such expressions being executed with similar but different (per-user, per-deveice, et.) parameters and that keep constantly changing. We want the system to allow for evolving the stream processing graph at runtime, by adding new links or nodes to the computation graph, or by changing the processing logic within the computation nodes. Fine grained stream granularity In the existing systems, the smallest unit of abstraction is usually the whole flow (topology). However, many of our target scenarios require individual node/link in the topology to be a logical entity by itself. That way each entity can be potentially managed independently. For example, in the big stream topology comprising of multiple links, different links can have different characteristics and can be implemented over different physical transports. Some links can go over TCP sockets, while others over reliable queues. Different links can have different delivery guarantees. Different nodes can have different checkpointing strategies, and their processing logic can be expressed in different models or even different languages. Such flexibility is usually not possible in existing systems. The unit of abstraction and flexibility argument is similar to comparison of SoA (Service Oriented Architectures) vs. Actors. Actor systems allow more flexibility, since each is essentially an independently managed ''tiny service''. Similarly, we want the system to allow for such a fine grained control. Distribution And of course, our system should have all the properties of a \"good distributed system\" . That includes: Scalability - supports large number of streams and compute elements. Elasticity - allows to add/remove resources to grow/shrink based on load. Reliability - be resilient to failures Efficiency - use the underlying resources efficiently Responsiveness - enable near real time scenarios. These were the requirements we had in mind for building Orleans Streaming . Clarificaton : Orleans currently does not directly support writing declarative dataflow expressions like in the example above. The current Orleans Streaming APIs are more low level building blocks, as described here . Providing declarative dataflow expressions is our future goal. Next Orleans Streams Programming APIs"
  },
  "Documentation/streaming/streams_quick_start.html": {
    "href": "Documentation/streaming/streams_quick_start.html",
    "title": "Orleans Streams Quick Start | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Quick Start This guide will show you a quick way to setup and use Orleans Streams. To learn more about the details of the streaming features, read other parts of this documentation. Required Configurations In this guide we'll use a Simple Message based Stream which uses grain messaging to send stream data to subscribers. We will use the in-memory storage provider to store lists of subscriptions so it is not a wise choice for real production applications. On silo, where hostBuilder is an ISiloHostBuilder hostBuilder.AddSimpleMessageStreamProvider(\"SMSProvider\") .AddMemoryGrainStorage(\"PubSubStore\"); On cluster client, where clientBuilder is an IClientBuilder clientBuilder.AddSimpleMessageStreamProvider(\"SMSProvider\"); Now we can create streams, send data using them as producers and also receive data as subscribers. Producing Events Producing events for streams is relatively easy. You should first get access to the stream provider which you defined in the config above ( SMSProvider ) and then choose a stream and push data to it. //Pick a guid for a chat room grain and chat room stream var guid = some guid identifying the chat room //Get one of the providers which we defined in config var streamProvider = GetStreamProvider(\"SMSProvider\"); //Get the reference to a stream var stream = streamProvider.GetStream<int>(guid, \"RANDOMDATA\"); As you can see our stream has a GUID and a namespace. This will make it easy to identify unique streams. For example, in a chat room namespace can \"Rooms\" and GUID be the owning RoomGrain's GUID. Here we use the GUID of some known chat room. Now using the OnNext method of the stream we can push data to it. Let's do it inside a timer and using random numbers. You could use any other data type for the stream as well. RegisterTimer(s => { return stream.OnNextAsync(new System.Random().Next()); }, null, TimeSpan.FromMilliseconds(1000), TimeSpan.FromMilliseconds(1000)); Subscribing and receiving streaming data For receiving data we can use implicit/explicit subscriptions, which are fully described in other pages of the manual. Here we use implicit subscriptions which are easier. When a grain type wants to implicitly subscribe to a stream it uses the attribute ImplicitStreamSubscription (namespace)] . For our case we'll define a ReceiverGrain like this: [ImplicitStreamSubscription(\"RANDOMDATA\")] public class ReceiverGrain : Grain, IRandomReceiver Now whenever some data is pushed to the streams of namespace RANDOMDATA as we have in the timer, a grain of type ReceiverGrain with the same guid of the stream will receive the message. Even if no activations of the grain currently exist, the runtime will automatically create a new one and send the message to it. In order for this to work however, we need to complete the subscription process by setting our OnNext method for receiving data. So our ReceiverGrain should call in its OnActivateAsync something like this //Create a GUID based on our GUID as a grain var guid = this.GetPrimaryKey(); //Get one of the providers which we defined in config var streamProvider = GetStreamProvider(\"SMSProvider\"); //Get the reference to a stream var stream = streamProvider.GetStream<int>(guid, \"RANDOMDATA\"); //Set our OnNext method to the lambda which simply prints the data, this doesn't make new subscriptions await stream.SubscribeAsync<int>(async (data, token) => Console.WriteLine(data)); We are all set now. The only requirement is that something triggers our producer grain's creation and then it will registers the timer and starts sending random ints to all interested parties. Again, this guide skips lots of details and is only good for showing the big picture. Read other parts of this manual and other resources on RX to gain a good understanding on what is available and how. Reactive programming can be a very powerful approach to solve many problems. You could for example use LINQ in the subscriber to filter numbers and do all sorts of interesting stuff. Next Orleans Streams Programming APIs"
  },
  "1.5/Documentation/Runtime-Implementation-Details/Messaging-Delivery-Guarantees.html": {
    "href": "1.5/Documentation/Runtime-Implementation-Details/Messaging-Delivery-Guarantees.html",
    "title": "Messaging Delivery Guarantees | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Messaging Delivery Guarantees Orleans messaging delivery guarantees are at-most-once , by default. Optionally, if configured to do retries upon timeout, Orleans provides at-least-once deliv­ery instead. In more details: Every message in Orleans has automatic timeout (the exact timeout can be configured). If the reply does not arrive on time the return Task is broken with timeout exception. Orleans can be configured to do automatic retries upon timeout. By default we do NOT do automatic retries. Application code of course can also pick to do retries upon timeout. If the Orleans system is configured not to do automatic retries (default setting) and application is not resending – Orleans provides at most once message delivery . A message will either be delivered once or not at all. It will never be delivered twice. In the system with retries (either by the runtime or by the application) the message may arrive multiple times. Orleans currently does nothing to durably store which messages already arrived and suppress the second delivery (we believe this would be pretty costly). So in the system with retries Orleans does NOT guarantee at most once delivery. If you keep retrying potentially indefinitely , the message will eventually arrive , thus providing at least once delivery guarantee. Notice that “will eventually arrive” is something that the runtime needs to guarantee. It does not come for free just by itself even if you keep retrying. Orleans provides eventually delivery since grains never go into any permanent failure state and a failed grain will for sure eventually be re-activated on another silo. So to summarize : in the system without retries Orleans guarantees at most once message delivery. In the system with infinite retries Orleans guarantee at least once (and does NOT guarantee at most once). Note : In the Orleans technical report we accidentally only mentioned the 2nd option with automatic retries and forgot to mention that by default with no retries, Orleans provides at most once delivery."
  },
  "1.5/Documentation/Samples-Overview/Tic-Tac-Toe.html": {
    "href": "1.5/Documentation/Samples-Overview/Tic-Tac-Toe.html",
    "title": "Tic Tac Toe | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Tic Tac Toe TicTacToe is based on the classic board game, also known as \"noughts and crosses.\" Its game logic is simple, which makes it an excellent sample for showing how a turn-based game could be easily implemented in Orleans. A game like this may not at first sight seem a natural fit for Orleans, if you only think about it in terms of a single player game. However, within a social game context, such as a Facebook game, where thousands of players could be playing dozens of games at any one time - some games waiting for the opponent to join, others mid game, waiting for the next move to play out, then it is a much more natural fit. Orleans enables the developer to concentrate on expressing game logic as grains, letting the runtime handle the scale. This sample also demonstrates how an Orleans application can be deployed to Windows Azure. Running the Sample The sample comes complete with a Windows Azure project, so it can be run locally in the Windows Azure local emulator, or deployed as a real cloud service. If running locally, you will need to create multiple \"private\" browsing sessions, to ensure each browser session is recognized as a new player. To run locally without the emulator: Open the TicTacToe.sln file in Visual Studio and build the solution. Set the TicTacToe.Grains project as the startup project. Press F5 to start the application. Start the TicTacToe.Web project manually using the Project context menu -> Debug -> Start new instance Your browser should open, asking you to enter your name. To run locally using the Azure emulator: Open the TicTacToe.sln file in Visual Studio and build the solution. Set the TicTacToe.Azure project as the startup project. Start the Azure Compute Emulator if necessary. Press F5 to start the application. Your browser should open, asking you to enter your name. To run in Windows Azure: Open the TicTacToe.sln file in Visual Studio and build the solution. Expand the TicTacToe.Azure project, and in the Roles folder, open the properties for TicTacToe.Web and TicTacToe.WorkerRole . Set the value for the DataConnectionString setting for both roles to a Windows Azure Storage Account. Right click on the TicTacToe.Azure project, and click Publish . Follow the instructions in the wizard to deploy the application on Azure. The application will deploy, and you will be able to access on http://YOURCLOUDSERVICE.cloudapp.net/ How it works There are two main grain types in OrleansXO, one represents a player, the other representing a game. User Grain A PlayerGrain is activated for each player logging in to the system. A GUID is used to uniquely identify the user, which is stored in a cookie by the MVC web application. The IPlayer interface defines the operations a player can perform: public interface IPlayer : IGrain { Task<List<GameSummary>> GetGameSummaries(); Task<Guid> CreateGame(); Task<GameState> JoinGame(Guid gameId); Task LeaveGame(Guid gameId, GameOutcome outcome); Task SetUsername(string username); Task<string> GetUsername(); } The player grain handles the creating of new games (so another player can then join), leaving a game (once it is over), and tracking the progress of all active games. Game Grain Each game is also represented by a GameGrain . They are also uniquely identify using a GUID. public interface IGame : Orleans.IGrain { Task<GameState> AddPlayerToGame(Guid player); Task<GameState> GetState(); Task<List<GameMove>> GetMoves(); Task<GameState> MakeMove(GameMove move); Task<GameSummary> GetSummary(Guid player); Task SetName(string name); } Once a user grain creates a game, that user is automatically added as one of the players. Once a game is joined by a second player, the game can start. The players make their turns until the game ends with either a draw or a winner. The GameGrain maintains the state of the game, the players in the game, whose turn it is next, and whether the game is in play or finished. The MakeMove method handles the game logic, checking the validity of a move and, once played, checks if that move ends the game. In the case of the game ending, the player grains are informed of the outcome via the LeaveGame call. The game was designed with social gaming in mind, so the main mechanism for inviting other players is an \"out of band\" from the game, and would probably be an invite to a friend, sending the GUID that represents the game. As an optimization purely for testing, a pairing grain was created that uses MemoryCache to hold a the list of games that are available to join, with an expiry of one hour, to stop \"stale\" games appearing on the list. An ASP.NET MVC application serves an HTML page. JavaScript running in the browser polls the web server, and retrieve JSON data, which it renders using Handlebars templates ."
  },
  "1.5/Documentation/Samples-Overview/Chirper.html": {
    "href": "1.5/Documentation/Samples-Overview/Chirper.html",
    "title": "Chirper | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Chirper A simple social network pub/sub system, with short text messages being sent between users. Publishers send out short \"Chirp\" messages (not to be confused with \"Tweets\", for a variety of legal reasons! ;) to any other users that are following them. Instructions Build Chirper.sln Start your local Silo from a command window using command file #1. The loader script, #2 Start the Chirper client #3 Start a second Chirper client as a publisher #4 Type a comment into the publisher client window, and see it displayed on the other client console window. Overview The NetworkLoader program reads a graphml data file containing a description of a network of Users and Followers. The NetworkLoader program sets up a network of ChirperAccount (aka \"users\") grains based on the input data file, one grain for each user defined in the network. It then creates the follower links between those users by calling the FollowUserId method on the appropriate user grain. For this demo, we use a simplified network of 1,000 Users with a total of 27,000 Follower links connecting those Users, but other network data files can be created with the NetworkGenerator program, or with a normal text / XML editor. The ChirperClient program connects to the Chirper network as a user specified on the cmd line. It then listens for any new Chirps that might be sent out by the other users they follow. When you type a comment into the publisher window, the text is sent as a Chirp message to all followers of that user, including the first client console window, as well as being echo'ed on the publisher's window. Why Orleans? Orleans allows the network of Chirper users to be described via very simple C# code whilst allowing it to easily scale out to handle increasing number of users and volume of chirp messages. How is it modeled? Chirper users are modeled as grains, which provides a very natural mapping of concepts. These grains allow to distribute the load for handling the message throughput, with each grain handling the forwarding of messages generated by that user to any other users that are following them. The grains implement three different grain interfaces to represent the three functional facets of those entities -- IChirperPublisher , IChirperSubscriber and IChirperAccount There is also an IChirperViewer observer interface for applications to subscribe for status changes from a particular Chirper user without becoming a Follower. This observer interface is typically used when writing client UI applications such as ChirperClient . Things for you to do if you are so inclined: Connect more clients to see the Chirper broadcast behavior. Make the network of users much bigger. Make the rate of generating messages higher."
  },
  "1.5/Tutorials/Interaction-with-Libraries-and-Services.html": {
    "href": "1.5/Tutorials/Interaction-with-Libraries-and-Services.html",
    "title": "Interaction with Libraries and Services | Microsoft Orleans Documentation",
    "keywords": "Interaction with Libraries and Services Code running in a grain is not prohibited from calling external systems or services, but the rule for always using asynchronous code must be maintained. In this sample we'll see how a grain can call out to an external service. Creating a Stock Grain For this sample, let's create a grain which maintains the current price for a stock. Create a grain interface project, and add an interface for an IStockGrain : public interface IStockGrain : Orleans.IGrainWithStringKey { Task<string> GetPrice(); } Note, we've opted for an string-based key for our grain, which is useful since the ticker symbol makes a natural key. The IGrainWithStringKey interface is new in the September refresh. Now add a grain implementation project, and add a reference to the interface project. Add a reference to System.Net.Http . We'll implement the grain so it retrieves the price of the stock when it is activated: public class StockGrain : Orleans.Grain, IStockGrain { string price; public override async Task OnActivateAsync() { string stock; this.GetPrimaryKey(out stock); await UpdatePrice(stock); await base.OnActivateAsync(); } async Task UpdatePrice(string stock) { price = await GetPriceFromYahoo(stock); } async Task<string> GetPriceFromYahoo(string stock) { var uri = \"http://download.finance.yahoo.com/d/quotes.csv?f=snl1c1p2&e=.csv&s=\" + stock; using (var http = new HttpClient()) using (var resp = await http.GetAsync(uri)) { return await resp.Content.ReadAsStringAsync(); } } public Task<string> GetPrice() { return Task.FromResult(price); } } Next create some client code to connect to the Orleans Silo, and retrieve the grain state: Console.WriteLine(\"Waiting for Orleans Silo to start. Press Enter to proceed...\"); Console.ReadLine(); var config = Orleans.Runtime.Configuration.ClientConfiguration.LocalhostSilo(30000); GrainClient.Initialize(config); // retrieve the MSFT stock var grain = GrainClient.GrainFactory.GetGrain<IStockGrain>(\"MSFT\"); var price = grain.GetPrice().Result; Console.WriteLine(price); Console.ReadLine(); When we start the local silo, and run the application, we should see the stock value written out \"MSFT\",\"Microsoft Corpora\",37.70,-0.19,\"-0.50%\" Note that the extra text in the stock price is just the formatting that Yahoo! returned. Refreshing the value with a timer The problem with the grain as it stands is that the value of the stock will change, but the grain will maintain the same value for it's lifetime (an indefinite period of time). One way to fix this is to periodically refresh the price. A traditional .NET timer is not suitable for running in a grain. Instead, Orleans provides it's own timer. Let's re-factor the OnActivateAsync() method to introduce a timer which will call the UpdatePrice method in 1 minute, and then repeatedly every minute from then on, until the grain is deactivated: public override async Task OnActivateAsync() { string stock; this.GetPrimaryKey(out stock); await UpdatePrice(stock); var timer = RegisterTimer( UpdatePrice, stock, TimeSpan.FromMinutes(1), TimeSpan.FromMinutes(1)); await base.OnActivateAsync(); } We'll also have to slightly adjust the UpdatePrice method, as the stock argument must be an object rather than a string. We'll also add some logging so we can see what's happening: async Task UpdatePrice(object stock) { price = await GetPriceFromYahoo(stock as string); Console.WriteLine(price); } The RegisterTimer method takes four arguments: callback - A function to call. state - An object to pass as the first argument of the callback function (this can be null). dueTime - The period to wait before starting the first call to callback . period - The period between subsequent calls to callback . Note: In our sample we're passing the stock name as the state argument when we register the timer. This means the stock name is presented to the UpdatePrice method as the argument. Alternative we could set state to be null , and read the stock name from inside UpdatePrice using GetPrimaryKey . The method returns an IOrleansTimer which is disposable and can be used to stop the timer. It's a good idea to hold on to a reference to this in case you need to stop the timer. Now when we run the sample, the grain is activated, the timer gets registered and every minute the price is updated for us: \"MSFT\",\"Microsoft Corpora\",37.70,-0.19,\"-0.50%\" \"MSFT\",\"Microsoft Corpora\",37.70,-0.19,\"-0.50%\" \"MSFT\",\"Microsoft Corpora\",37.70,-0.19,\"-0.50%\" \"MSFT\",\"Microsoft Corpora\",37.70,-0.19,\"-0.50%\" Orleans is acting as an automatically refreshing cache. Whenever a stock grain is queried Orleans will provide the latest price it has, without having to make a call to the stock web service. Parallelization Running code in a single threaded execution model, does not prohibit you from awaiting several tasks at once (or in parallel). Let's add a new function to retrieve the graph data for a stock: async Task<string> GetYahooGraphData(string stock) { // retrieve the graph data from Yahoo finance var uri = string.Format( \"http://chartapi.finance.yahoo.com/instrument/1.0/{0}/chartdata;type=quote;range=1d/csv/\",stock); using (var http = new HttpClient()) using (var resp = await http.GetAsync(uri)) { return await resp.Content.ReadAsStringAsync(); } } We'll also add a new field to the grain to store this information: string graphData; Now we can retrieve the graph data and current price like this: async Task UpdatePrice(object stock) { price = await GetPriceFromYahoo(stock as string); graphData = await GetYahooGraphData(stock as string); Console.WriteLine(price); } However, by doing this we're waiting for the price from Yahoo, and after that's complete we request the graph data. This is inefficient, as we could be doing these at the same time. Fortunately, Task has a convenient WhenAll method which allows us to await multiple tasks at once, allowing these tasks to complete in parallel. async Task UpdatePrice(object stock) { // collect the task variables without awaiting var priceTask = GetPriceFromYahoo(stock as string); var graphDataTask = GetYahooGraphData(stock as string); // await both tasks await Task.WhenAll(priceTask, graphDataTask); // read the results price = priceTask.Result; graphData = graphDataTask.Result; Console.WriteLine(price); } Note: The Result of a Task will block execution if the task hasn't completed. This should be avoided in Orleans, tasks should always be awaited before Result is read. Note: When a large number of asynchronous actions need to happen simultaneously you can collect the tasks in a List<Task<T>> and present this to Task.WhenAll . External Tasks It's tempting to use the Task Parallel Library \"TPL\" for executing parallel tasks in Orleans, but TPL uses the .NET thread pool to dispatch tasks. This is prohibited within grain code. Orleans has its own task scheduler which provides the single threaded execution model used within grains. It's important that when running tasks the Orleans scheduler is used, and not the .NET thread pool. Should your grain code require a sub-task to be created, you should use Task.Factory.StartNew : await Task.Factory.StartNew(() =>{ /* logic */ }); This technique will use the current task scheduler, which will be the Orleans scheduler. You should avoid using Task.Run , which always uses the .NET thread pool, and therefore will not run in the single-threaded execution model. Next Let's look at how Orleans can persist grain state for us: Declarative Persistence"
  },
  "Tutorials/Custom-Grain-Storage.html": {
    "href": "Tutorials/Custom-Grain-Storage.html",
    "title": "Custom Grain Storage | Microsoft Orleans Documentation",
    "keywords": "Custom Grain Storage Writing a Custom Grain Storage In the tutorial on declarative actor storage, we looked at allowing grains to store their state in an Azure table using one of the built-in storage providers. While Azure is a great place to squirrel away your data, there are many alternatives. In fact, there are so many that there was no way to support them all. Instead, Orleans is designed to let you easily add support for your own form of storage by writing a grain storage. In this tutorial, we'll walk through how to write a simple file-based grain storage. A file system is not the best place to store grains states as it is local, there can be issues with file locks and the last update date is not sufficient to prevent inconsistency. But it's an easy example to help us illustrate the implementation of a Grain Storage . Getting Started An Orleans grain storage is a class that implements IGrainStorage which is included in Microsoft.Orleans.Core NuGet package . We also inherit from ILifecycleParticipant<ISiloLifecycle> which will allow us to subscribe to a particular event in the lifecycle of the silo. We start by creating a class named FileGrainStorage . using Orleans; using System; using Orleans.Storage; using Orleans.Runtime; using System.Threading.Tasks; namespace GrainStorage { public class FileGrainStorage : IGrainStorage, ILifecycleParticipant<ISiloLifecycle> { private readonly string _storageName; private readonly FileGrainStorageOptions _options; private readonly ClusterOptions _clusterOptions; private readonly IGrainFactory _grainFactory; private readonly ITypeResolver _typeResolver; private JsonSerializerSettings _jsonSettings; public FileGrainStorage(string storageName, FileGrainStorageOptions options, IOptions<ClusterOptions> clusterOptions, IGrainFactory grainFactory, ITypeResolver typeResolver) { _storageName = storageName; _options = options; _clusterOptions = clusterOptions.Value; _grainFactory = grainFactory; _typeResolver = typeResolver; } public Task ClearStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { throw new NotImplementedException(); } public Task ReadStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { throw new NotImplementedException(); } public Task WriteStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { throw new NotImplementedException(); } public void Participate(ISiloLifecycle lifecycle) { throw new NotImplementedException(); } public void Participate(ISiloLifecycle lifecycle) { throw new NotImplementedException(); } } } Prior starting the implementation, we create an option class containing the root directory where the grains states files will be stored under. For that we will create an options file FileGrainStorageOptions : public class FileGrainStorageOptions { public string RootDirectory { get; set; } } The create a constructor containing two fields, storageName to specify which grains should write using this storage [StorageProvider(ProviderName = \"File\")] and directory which would be the directory where the grain states will be saved. IGrainFactory , ITypeResolver will be used in the next section where we will initilize the storage. We also take two options as argument, our own FileGrainStorageOptions and the ClusterOptions . Those will be needed for the implementation of the storage functionalities. We also need JsonSerializerSettings as we are serializing and deserializing in Json format. Json is an implementation detail, it is up to the developer to decide what serialization/deserialization protocol would fit the application. Another common format is binary format. Initializing the storage To initialize the storage, we register an Init function on the ApplicationServices lifecycle. public void Participate(ISiloLifecycle lifecycle) { lifecycle.Subscribe(OptionFormattingUtilities.Name<FileGrainStorage>(_storageName), ServiceLifecycleStage.ApplicationServices, Init); } The Init function is used to set the _jsonSettings which will be used to configure the Json serializer. At the same time we create the folder to store the grains states if it does not exist yet. private Task Init(CancellationToken ct) { // Settings could be made configurable from Options. _jsonSettings = OrleansJsonSerializer.UpdateSerializerSettings(OrleansJsonSerializer.GetDefaultSerializerSettings(_typeResolver, _grainFactory), false, false, null); var directory = new System.IO.DirectoryInfo(_rootDirectory); if (!directory.Exists) directory.Create(); return Task.CompletedTask; } We also provide a common function to construct the filename ensuring uniqueness per service, grain Id and grain type. private string GetKeyString(string grainType, GrainReference grainReference) { return $\"{_clusterOptions.ServiceId}.{grainReference.ToKeyString()}.{grainType}\"; } Reading State To read a grain state, we get the filename using the function we previously defined and combine it to the root directory coming from the options. public async Task ReadStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { var fName = GetKeyString(grainType, grainReference); var path = Path.Combine(_options.RootDirectory, fName); var fileInfo = new FileInfo(path); if (!fileInfo.Exists) { grainState.State = Activator.CreateInstance(grainState.State.GetType()); return; } using (var stream = fileInfo.OpenText()) { var storedData = await stream.ReadToEndAsync(); grainState.State = JsonConvert.DeserializeObject(storedData, _jsonSettings); } grainState.ETag = fileInfo.LastWriteTimeUtc.ToString(); } We use the fileInfo.LastWriteTimeUtc as a ETag which will be used by other functions for inconsistency checks to prevent data loss. Note that for the deserialization, we use the _jsonSettings which was set on the Init function. This is important to be able to serialize/deserialize properly the state. Writing State Writing the state is similar to reading the state. public async Task WriteStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { var storedData = JsonConvert.SerializeObject(grainState.State, _jsonSettings); var fName = GetKeyString(grainType, grainReference); var path = Path.Combine(_options.RootDirectory, fName); var fileInfo = new FileInfo(path); if (fileInfo.Exists && fileInfo.LastWriteTimeUtc.ToString() != grainState.ETag) { throw new InconsistentStateException($\"Version conflict (WriteState): ServiceId={_clusterOptions.ServiceId} ProviderName={_storageName} GrainType={grainType} GrainReference={grainReference.ToKeyString()}.\"); } using (var stream = new StreamWriter(fileInfo.Open(FileMode.Create, FileAccess.Write))) { await stream.WriteAsync(storedData); } fileInfo.Refresh(); grainState.ETag = fileInfo.LastWriteTimeUtc.ToString(); } Similarly as reading, we use _jsonSettings to write the state. The current ETag is used to check against the last updated time in UTC of the file. If the date is different, it means that another activation of the same grain changed the state concurrently. In this situation, we throw an InconsistentStateException which will result in the current activation being killed to prevent overwritting the state previously saved by the other activated grain. Clearing State Clearing the state would be deleting the file if the file exists. public Task ClearStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { var fName = GetKeyString(grainType, grainReference); var path = Path.Combine(_options.RootDirectory, fName); var fileInfo = new FileInfo(path); if (fileInfo.Exists) { if (fileInfo.LastWriteTimeUtc.ToString() != grainState.ETag) { throw new InconsistentStateException($\"Version conflict (ClearState): ServiceId={_clusterOptions.ServiceId} ProviderName={_storageName} GrainType={grainType} GrainReference={grainReference.ToKeyString()}.\"); } grainState.ETag = null; grainState.State = Activator.CreateInstance(grainState.State.GetType()); fileInfo.Delete(); } return Task.CompletedTask; } For the same reason as WriteState , we check for inconsistency before proceeding to delete the file and reset the ETag, we check if the current ETag is the same as the last write time UTC. Putting it Together After that we will create a factory which will allow us to scope the options setting to the provider name and at the same time create an instance of the FileGrainStorage to ease the registration to the service collection. public static class FileGrainStorageFactory { internal static IGrainStorage Create(IServiceProvider services, string name) { IOptionsSnapshot<FileGrainStorageOptions> optionsSnapshot = services.GetRequiredService<IOptionsSnapshot<FileGrainStorageOptions>>(); return ActivatorUtilities.CreateInstance<FileGrainStorage>(services, name, optionsSnapshot.Get(name), services.GetProviderClusterOptions(name)); } } Lastly to register the grain storage, we create an extension on the ISiloHostBuilder which internally register the grain storage as a named service using .AddSingletonNamedService(...) , an extension provided by Orleans.Core . public static class FileSiloBuilderExtensions { public static ISiloHostBuilder AddFileGrainStorage(this ISiloHostBuilder builder, string providerName, Action<FileGrainStorageOptions> options) { return builder.ConfigureServices(services => services.AddFileGrainStorage(providerName, options)); } public static IServiceCollection AddFileGrainStorage(this IServiceCollection services, string providerName, Action<FileGrainStorageOptions> options) { services.AddOptions<FileGrainStorageOptions>(providerName).Configure(options); return services .AddSingletonNamedService(providerName, FileGrainStorageFactory.Create) .AddSingletonNamedService(providerName, (s, n) => (ILifecycleParticipant<ISiloLifecycle>)s.GetRequiredServiceByName<IGrainStorage>(n)); } } Our FileGrainStorage implements two interfaces, IGrainStorage and ILifecycleParticipant<ISiloLifecycle> therefore we need to register two named services for each interfaces: return services .AddSingletonNamedService(providerName, FileGrainStorageFactory.Create) .AddSingletonNamedService(providerName, (s, n) => (ILifecycleParticipant<ISiloLifecycle>)s.GetRequiredServiceByName<IGrainStorage>(n)); This enables us to add the file storage using the extension on the ISiloHostBuilder : var silo = new SiloHostBuilder() .UseLocalhostClustering() .AddFileGrainStorage(\"File\", opts => { opts.RootDirectory = \"C:/TestFiles\"; }) .Build(); Now we will be able to decorate our grains with the provider [StorageProvider(ProviderName = \"File\")] and it will store in the grain state in the root directory set in the options."
  },
  "1.5/Documentation/Advanced-Concepts/Application-Bootstrap-within-a-Silo.html": {
    "href": "1.5/Documentation/Advanced-Concepts/Application-Bootstrap-within-a-Silo.html",
    "title": "Application Bootstrapping within a Silo | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Application Bootstrapping within a Silo There are several scenarios where application want to run some \"auto-exec\" functions when a silo comes online. Some examples include, but are not limited to: Starting background timers to perform periodic housekeeping tasks Pre-loading some cache grains with data downloaded from external backing storage. We have now added support for this auto-run functionality through configuring \"bootstrap providers\" for Orleans silos. For example: <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <BootstrapProviders> <Provider Type=\"My.App.BootstrapClass1\" Name=\"bootstrap1\" /> <Provider Type=\"My.App.BootstrapClass2\" Name=\"bootstrap2\" /> </BootstrapProviders> </Globals> </OrleansConfiguration> It is also possible to register Bootstrap provider programaticaly, via calling one of the: public void RegisterBootstrapProvider(string providerTypeFullName, string providerName, IDictionary<string, string> properties = null) public void RegisterBootstrapProvider<T>(string providerName, IDictionary<string, string> properties = null) where T : IBootstrapProvider on the Orleans.Runtime.Configuration.GlobalConfiguration class. These bootstrap providers are C# classes that implement the Orleans.Providers.IBootstrapProvider interface. When each silo starts up, the Orleans runtime will instantiate each of the listed app bootstrap classes, and then call their Init method in an appropriate runtime execution context that allows those classes to act as a client and send messages to grains. There should be no blocking calls made inside the Init method. Task Init( string name, IProviderRuntime providerRuntime, IProviderConfiguration config) Any Exceptions that are thrown from an Init method of a bootstrap provider will be reported by the Orleans runtime in the silo log, then the silo startup will be halted. This fail-fast approach is the standard way that Orleans handles silo start-up issues, and is intended to allow any problems with silo configuration and/or bootstrap logic to be easily detected during testing phases rather than being silently ignored and causing unexpected problems later in the silo lifecycle."
  },
  "1.5/Documentation/Deployment-and-Operations/Service-Fabric.html": {
    "href": "1.5/Documentation/Deployment-and-Operations/Service-Fabric.html",
    "title": "Service Fabric Hosting | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Service Fabric Hosting Overview Orleans can be hosted on Service Fabric. There are currently two points of integration with Service Fabric: Hosting : Silos can be hosted on Service Fabric inside of a Service Fabric Reliable Service. Silos should be hosted as unpartitioned, stateless services since Orleans manages distribution of grains itself using fine-grained, dynamic distribution. Other hosting options (partitioned, stateful) are currently untested and unsupported. Clustering (beta): Silos and clients can leverage Service Fabric's Service Discovery mechanisms to form clusters. This option requires Service Fabric Hosting, however Service Fabric Hosting does not require Service Fabric Clustering. A sample which demonstrates hosting and clustering is present at Samples/ServiceFabric . Hosting Hosting support is available in the Microsoft.Orleans.Hosting.ServiceFabric package. It allows an Orleans Silo to run as a Service Fabric ICommunicationListener . The Silo lifecycle follows the typical communication listener lifecycle: it is initialized via the ICommunicationListener.OpenAsync method and is gracefully terminated via the ICommunicationListener.CloseAsync method or abruptly terminated via the ICommunicationListener.Abort method. OrleansCommunicationListener provides the ICommunicationListener implementation. The recommended approach is to create the communication listener using OrleansServiceListener.CreateStateless(Action<StatelessServiceContext, ISiloHostBuilder> configure) in the Orleans.Hosting.ServiceFabric namespace. This ensures that the listener has the endpoint name required by Clustering (described below). Each time the communication listener is opened, the configure delegate passed to CreateStateless is invoked to configure the new Silo. Hosting can be used in conjunction with the Service Fabric Clustering provider, however other clustering providers can be used instead. Example: Configuring Service Fabric hosting. The following example demonstrates a Service Fabric StatelessService class which hosts an Orleans silo. The full sample can be found in the Samples/ServiceFabric directory of the Orleans repository. internal sealed class StatelessCalculatorService : StatelessService { public StatelessCalculatorService(StatelessServiceContext context) : base(context) { } protected override IEnumerable<ServiceInstanceListener> CreateServiceInstanceListeners() { // Listeners can be opened and closed multiple times over the lifetime of a service // instance. A new Orleans silo will be both created and initialized each time the // listener is opened and will be shutdown when the listener is closed. var listener = OrleansServiceListener.CreateStateless( (serviceContext, builder) => { // Optional: use Service Fabric for cluster membership. builder.UseServiceFabricClustering(serviceContext); // Alternative: use Azure Storage for cluster membership. builder.UseAzureTableMembership(options => { /* Configure connection string*/ }); // Optional: configure logging. builder.ConfigureLogging(logging => logging.AddDebug()); var config = new ClusterConfiguration(); config.Globals.RegisterBootstrapProvider<BootstrapProvider>(\"poke_grains\"); config.Globals.ReminderServiceType = GlobalConfiguration.ReminderServiceProviderType.ReminderTableGrain; // Service Fabric manages port allocations, so update the configuration using // those ports. config.Defaults.ConfigureServiceFabricSiloEndpoints(serviceContext); // Tell Orleans to use this configuration. builder.UseConfiguration(config); // Add your application assemblies. builder.ConfigureApplicationParts(parts => { parts.AddApplicationPart(typeof(CalculatorGrain).Assembly).WithReferences(); // Alternative: add all loadable assemblies in the current base path // (see AppDomain.BaseDirectory). parts.AddFromApplicationBaseDirectory(); }); }); return new[] { listener }; } protected override async Task RunAsync(CancellationToken cancellationToken) { while (true) { cancellationToken.ThrowIfCancellationRequested(); await Task.Delay(TimeSpan.FromSeconds(10), cancellationToken); } } } Clustering (beta) Note: it is currently recommended to use a storage-backed clustering provider such as SQL, ZooKeeper, Consul, or Azure Tables in production while this feature is in beta. Support to use Service Fabric's Service Discovery (Naming Service) mechanism for cluster membership is available in the Microsoft.Orleans.Clustering.ServiceFabric package. The implementation requires that the Service Fabric Hosting support is also used and that the Silo endpoint is named \"Orleans\" in the value returned from StatelessService.CreateServiceInstanceListeners() . The simplest way to ensure this is to use the OrleansServiceListener.CreateStateless(...) method as described in the previous section. Service Fabric Clustering is enabled with the ISiloHostBuilder.UseServiceFabricClustering(ServiceContext) extension method on the silo and the IClientBuilder.UseServiceFabricClustering(Uri) extension method on the client. The current recommendation is to use a storage-backed clustering provider for production services, such as SQL, ZooKeeper, Consul, or Azure Storage. These providers (particularly SQL and Azure Storage) are sufficiently well tested for production use."
  },
  "1.5/Documentation/Core-Features/Grain-Persistence.html": {
    "href": "1.5/Documentation/Core-Features/Grain-Persistence.html",
    "title": "Grain Persistence | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Grain Persistence Goals Allow different grain types to use different types of storage providers (e.g., one uses Azure table, and one uses an ADO.NET one) or the same type of storage provider but with different configurations (e.g., both use Azure table, but one uses storage account #1 and one uses storage account #2) Allow configuration of a storage provider instance to be swapped (e.g., Dev-Test-Prod) with just config file changes, and no code changes required. Provide a framework to allow additional storage providers to be written later, either by the Orleans team or others. Provide a minimal set of production-grade storage providers Storage providers have complete control over how they store grain state data in persistent backing store. Corollary: Orleans is not providing a comprehensive ORM storage solution, but allows custom storage providers to support specific ORM requirements as and when required. Grain Persistence API Grain types can be declared in one of two ways: Extend Grain if they do not have any persistent state, or if they will handle all persistent state themselves, or Extend Grain<T> if they have some persistent state that they want the Orleans runtime to handle. Stated another way, by extending Grain<T> a grain type is automatically opted-in to the Orleans system managed persistence framework. For the remainder of this section, we will only be considering Option #2 / Grain<T> because Option #1 grains will continue to run as now without any behavior changes. Grain State Stores Grain classes that inherit from Grain<T> (where T is an application-specific state data type that needs to be persisted) will have their state loaded automatically from a specified storage. Grains will be marked with a [StorageProvider] attribute that specifies a named instance of a storage provider to use for reading / writing the state data for this grain. [StorageProvider(ProviderName=\"store1\")] public class MyGrain<MyGrainState> ... { ... } The Orleans Provider Manager framework provides a mechanism to specify & register different storage providers and storage options in the silo config file. <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <StorageProviders> <Provider Type=\"Orleans.Storage.MemoryStorage\" Name=\"DevStore\" /> <Provider Type=\"Orleans.Storage.AzureTableStorage\" Name=\"store1\" DataConnectionString=\"DefaultEndpointsProtocol=https;AccountName=data1;AccountKey=SOMETHING1\" /> <Provider Type=\"Orleans.Storage.AzureBlobStorage\" Name=\"store2\" DataConnectionString=\"DefaultEndpointsProtocol=https;AccountName=data2;AccountKey=SOMETHING2\" /> </StorageProviders> Configuring Storage Providers AzureTableStorage <Provider Type=\"Orleans.Storage.AzureTableStorage\" Name=\"TableStore\" DataConnectionString=\"UseDevelopmentStorage=true\" /> The following attributes can be added to the <Provider /> element to configure the provider: DataConnectionString=\"...\" (mandatory) - The Azure storage connection string to use TableName=\"OrleansGrainState\" (optional) - The table name to use in table storage, defaults to OrleansGrainState DeleteStateOnClear=\"false\" (optional) - If true, the record will be deleted when grain state is cleared, otherwise an null record will be written, defaults to false UseJsonFormat=\"false\" (optional) - If true, the json serializer will be used, otherwise the Orleans binary serializer will be used, defaults to false UseFullAssemblyNames=\"false\" (optional) - (if UseJsonFormat=\"true\" ) Serializes types with full assembly names (true) or simple (false), defaults to false IndentJSON=\"false\" (optional) - (if UseJsonFormat=\"true\" ) Indents the serialized json, defaults to false Note: state should not exceed 64KB, a limit imposed by Table Storage. AzureBlobStorage <Provider Type=\"Orleans.Storage.AzureTableStorage\" Name=\"BlobStore\" DataConnectionString=\"UseDevelopmentStorage=true\" /> The following attributes can be added to the <Provider /> element to configure the provider: DataConnectionString=\"...\" (mandatory) - The Azure storage connection string to use ContainerName=\"grainstate\" (optional) - The blob storage container to use, defaults to grainstate UseFullAssemblyNames=\"false\" (optional) - Serializes types with full assembly names (true) or simple (false), defaults to false IndentJSON=\"false\" (optional) - Indents the serialized json, defaults to false DynamoDBStorageProvider <Provider Type=\"Orleans.Storage.DynamoDBStorageProvider\" Name=\"DDBStore\" DataConnectionString=\"Service=us-wes-1;AccessKey=MY_ACCESS_KEY;SecretKey=MY_SECRET_KEY;\" /> DataConnectionString=\"...\" (mandatory) - The DynamoDB storage connection string to use. You can set Service , AccessKey , SecretKey , ReadCapacityUnits and WriteCapacityUnits in it. TableName=\"OrleansGrainState\" (optional) - The table name to use in table storage, defaults to OrleansGrainState DeleteStateOnClear=\"false\" (optional) - If true, the record will be deleted when grain state is cleared, otherwise an null record will be written, defaults to false UseJsonFormat=\"false\" (optional) - If true, the json serializer will be used, otherwise the Orleans binary serializer will be used, defaults to false UseFullAssemblyNames=\"false\" (optional) - (if UseJsonFormat=\"true\" ) Serializes types with full assembly names (true) or simple (false), defaults to false IndentJSON=\"false\" (optional) - (if UseJsonFormat=\"true\" ) Indents the serialized json, defaults to false ADO.NET Storage Provider (SQL Storage Provider) The ADO .NET Storage Provider allows you to store grain state in relational databases. Currently following databases are supported: SQL Server MySQL/MariaDB PostgreSQL Oracle First, install the base package: Install-Package Microsoft.Orleans.OrleansSqlUtils Under the folder where the package gets installed alongside your project, you will find different SQL scripts for the supported database vendors. You can also get them from the OrleansSQLUtils repository . Create a database, and then run the appropriate script to create the tables. The next steps are to install a second NuGet package (see table below) specific to the database vendor you want, and to configure the storage provider either programmatically or via XML configuration. Database Script NuGet Package AdoInvariant Remarks SQL Server CreateOrleansTables_SQLServer.sql System.Data.SqlClient System.Data.SqlClient MySQL / MariaDB CreateOrleansTables_MySQL.sql MySql.Data MySql.Data.MySqlClient PostgreSQL CreateOrleansTables_PostgreSQL.sql Npgsql Npgsql Oracle CreateOrleansTables_Oracle.sql ODP.net Oracle.DataAccess.Client No .net Core support The following is an example of how to configure an ADO .NET Storage Provider using XML configuration: <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <StorageProviders> <Provider Type=\"Orleans.Storage.AdoNetStorageProvider\" Name=\"OrleansStorage\" AdoInvariant=\"<AdoInvariant>\" DataConnectionString=\"<ConnectionString>\" UseJsonFormat=\"true\" /> </StorageProviders> </Globals> </OrleansConfiguration> In code, you would need something like the following: var properties = new Dictionary<string, string>() { [\"AdoInvariant\"] = \"<AdoInvariant>\", [\"DataConnectionString\"] = \"<ConnectionString>\", [\"UseJsonFormat\"] = \"true\" }; config.Globals.RegisterStorageProvider<AdoNetStorageProvider>(\"OrleansStorage\", properties); Essentially, you only need to set the database-vendor-specific connection string and an AdoInvariant (see table above) that identifies the vendor. You may also choose the format in which the data is saved, which may be either binary (default), JSON, or XML. While binary is the most compact option, it is opaque and you will not be able to read or work with the data. JSON is the recommended option. You can set the following properties: Name Type Description Name String Arbitrary name that persistent grains will use to refer to this storage provider Type String Set to Orleans.Storage.AdoNetStorageProvider AdoInvariant String Identifies the database vendor (see above table for values; default is System.Data.SqlClient ) DataConnectionString String Vendor-specific database connection string (required) UseJsonFormat Boolean Use JSON format (recommended) UseXmlFormat Boolean Use XML format UseBinaryFormat Boolean Use compact binary format (default) The StorageProviders sample provides some code you can use to quickly test the above, and also showcases some custom storage providers. Use the following command in the Package Manager Console to update all Orleans packages to the latest version: Get-Package | where Id -like 'Microsoft.Orleans.*' | foreach { update-package $_.Id } The ADO.NET persistence has functionality to version data and define arbitrary (de)serializers with arbitrary application rules and streaming, but currently there is no method to expose them to application code. More information in ADO.NET Persistence Rationale . MemoryStorage MemoryStorage is a simple storage provider that does not really use a persistent data store underneath. It is convenient to learn to work with Storage Providers quickly, but is not intended to be used in real scenarios. Note: This provider persists state to volatile memory which is erased at silo shut down. Use only for testing. To set up the memory storage provider using XML configuration: <?xml version=\"1.0\" encoding=\"utf-8\"?> <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <StorageProviders> <Provider Type=\"Orleans.Storage.MemoryStorage\" Name=\"OrleansStorage\" NumStorageGrains=\"10\" /> </StorageProviders> </Globals> </OrleansConfiguration> To set it up in code: siloHost.Config.Globals.RegisterStorageProvider<MemoryStorage>(\"OrleansStorage\"); You can set the following properties: Name Type Description Name String Arbitrary name that persistent grains will use to refer to this storage provider Type String Set to Orleans.Storage.MemoryStorage NumStorageGrains Integer The number of grains to use to store the state, defaults to 10 ShardedStorageProvider <Provider Type=\"Orleans.Storage.ShardedStorageProvider\" Name=\"ShardedStorage\"> <Provider /> <Provider /> <Provider /> </Provider> Simple storage provider for writing grain state data shared across a number of other storage providers. A consistent hash function (default is Jenkins Hash) is used to decide which shard (in the order they are defined in the config file) is responsible for storing state data for a specified grain, then the Read / Write / Clear request is bridged over to the appropriate underlying provider for execution. Notes on Storage Providers If there is no [StorageProvider] attribute specified for a Grain<T> grain class, then a provider named Default will be searched for instead. If not found then this is treated as a missing storage provider. If there is only one provider in the silo config file, it will be considered to be the Default provider for this silo. A grain that uses a storage provider which is not present and defined in the silo configuration when the silo loads will fail to load, but the rest of the grains in that silo can still load and run. Any later calls to that grain type will fail with an Orleans.Storage.BadProviderConfigException error specifying that the grain type is not loaded. The storage provider instance to use for a given grain type is determined by the combination of the storage provider name defined in the [StorageProvider] attribute on that grain type, plus the provider type and configuration options for that provider defined in the silo config. Different grain types can use different configured storage providers, even if both are the same type: for example, two different Azure table storage provider instances, connected to different Azure storage accounts (see config file example above). All configuration details for storage providers is defined statically in the silo configuration that is read at silo startup. There are no mechanisms provided at this time to dynamically update or change the list of storage providers used by a silo. However, this is a prioritization / workload constraint rather than a fundamental design constraint. State Storage APIs There are two main parts to the grain state / persistence APIs: Grain-to-Runtime and Runtime-to-Storage-Provider. Grain State Storage API The grain state storage functionality in the Orleans Runtime will provide read and write operations to automatically populate / save the GrainState data object for that grain. Under the covers, these functions will be connected (within the code generated by Orleans client-gen tool) through to the appropriate persistence provider configured for that grain. Grain State Read / Write Functions Grain state will automatically be read when the grain is activated, but grains are responsible for explicitly triggering the write for any changed grain state as and when necessary. See the Failure Modes section below for details of error handling mechanisms. GrainState will be read automatically (using the equivalent of base.ReadStateAsync() ) before the OnActivateAsync() method is called for that activation. GrainState will not be refreshed before any method calls to that grain, unless the grain was activated for this call. During any grain method call, a grain can request the Orleans runtime to write the current grain state data for that activation to the designated storage provider by calling base.WriteStateAsync() . The grain is responsible for explicitly performing write operations when they make significant updates to their state data. Most commonly, the grain method will return the base.WriteStateAsync() Task as the final result Task returned from that grain method, but it is not required to follow this pattern. The runtime will not automatically update stored grain state after any grain methods. During any grain method or timer callback handler in the grain, the grain can request the Orleans runtime to re-read the current grain state data for that activation from the designated storage provider by calling base.ReadStateAsync() . This will completely overwrite any current state data currently stored in the grain state object with the latest values read from persistent store. An opaque provider-specific Etag value ( string ) may be set by a storage provider as part of the grain state metadata populated when state was read. Some providers may choose to leave this as null if they do not use Etag s. Conceptually, the Orleans Runtime will take a deep copy of the grain state data object for its own use during any write operations. Under the covers, the runtime may use optimization rules and heuristics to avoid performing some or all of the deep copy in some circumstances, provided that the expected logical isolation semantics are preserved. Sample Code for Grain State Read / Write Operations Grains must extend the Grain<T> class in order to participate in the Orleans grain state persistence mechanisms. The T in the above definition will be replaced by an application-specific grain state class for this grain; see the example below. The grain class should also be annotated with a [StorageProvider] attribute that tells the runtime which storage provider (instance) to use with grains of this type. public class MyGrainState { public int Field1 { get; set; } public string Field2 { get; set; } } [StorageProvider(ProviderName=\"store1\")] public class MyPersistenceGrain : Grain<MyGrainState>, IMyPersistenceGrain { ... } Grain State Read The initial read of the grain state will occur automatically by the Orleans runtime before the grain’s OnActivateAsync() method is called; no application code is required to make this happen. From that point forward, the grain’s state will be available through the Grain<T>.State property inside the grain class. Grain State Write After making any appropriate changes to the grain’s in-memory state, the grain should call the base.WriteStateAsync() method to write the changes to the persistent store via the defined storage provider for this grain type. This method is asynchronous and returns a Task that will typically be returned by the grain method as its own completion Task. public Task DoWrite(int val) { State.Field1 = val; return base.WriteStateAsync(); } Grain State Refresh If a grain wishes to explicitly re-read the latest state for this grain from backing store, the grain should call the base.ReadStateAsync() method. This will reload the grain state from persistent store, via the defined storage provider for this grain type, and any previous in-memory copy of the grain state will be overwritten and replaced when the ReadStateAsync() Task completes. public async Task<int> DoRead() { await base.ReadStateAsync(); return State.Field1; } Failure Modes for Grain State Persistence Operations Failure Modes for Grain State Read Operations Failures returned by the storage provider during the initial read of state data for that particular grain will result in the activate operation for that grain to be failed; in this case, there will not be any call to that grain’s OnActivateAsync() life cycle callback method. The original request to that grain which caused the activation will be faulted back to the caller the same way as any other failure during grain activation. Failures encountered by the storage provider to read state data for a particular grain will result in the ReadStateAsync() Task to be faulted. The grain can choose to handle or ignore that faulted Task , just like any other Task in Orleans. Any attempt to send a message to a grain which failed to load at silo startup time due to a missing / bad storage provider config will return the permanent error Orleans.BadProviderConfigException . Failure Modes for Grain State Write Operations Failures encountered by the storage provider to write state data for a particular grain will result in the WriteStateAsync() Task to be faulted. Usually, this will mean the grain call will be faulted back to the client caller provided the WriteStateAsync() Task is correctly chained in to the final return Task for this grain method. However, it will be possible for certain advanced scenarios to write grain code to specifically handle such write errors, just like they can handle any other faulted Task . Grains that execute error-handling / recovery code must catch exceptions / faulted WriteStateAsync() Task s and not re-throw to signify that they have successfully handled the write error. Storage Provider Framework There is a service provider API for writing additional persistence providers – IStorageProvider . The Persistence Provider API covers read and write operations for GrainState data. public interface IStorageProvider { Logger Log { get; } Task Init(); Task Close(); Task ReadStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); Task WriteStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); } Storage Provider Semantics Any attempt to perform a write operation when the storage provider detects an Etag constraint violation should cause the write Task to be faulted with transient error Orleans.InconsistentStateException and wrapping the underlying storage exception. public class InconsistentStateException : AggregateException { /// <summary>The Etag value currently held in persistent storage.</summary> public string StoredEtag { get; private set; } /// <summary>The Etag value currently held in memory, and attempting to be updated.</summary> public string CurrentEtag { get; private set; } public InconsistentStateException( string errorMsg, string storedEtag, string currentEtag, Exception storageException ) : base(errorMsg, storageException) { this.StoredEtag = storedEtag; this.CurrentEtag = currentEtag; } public InconsistentStateException(string storedEtag, string currentEtag, Exception storageException) : this(storageException.Message, storedEtag, currentEtag, storageException) { } } Any other failure conditions from a write operation should cause the write Task to be broken with an exception containing the underlying storage exception. Data Mapping Individual storage providers should decide how best to store grain state – blob (various formats / serialized forms) or column-per-field are obvious choices. The basic storage provider for Azure Table encodes state data fields into a single table column using Orleans binary serialization. ADO.NET Persistence Rationale The principles for ADO.NET backed persistence storage are: Keep business critical data safe an accessible while data, the format of data and code evolve. Take advantenge of vendor and storage specific functionality. In practice this means adhering to ADO.NET implementation goals and some added implementation logic in ADO.NET specific storage provider that allow evolving the shape of the data in the storage. In addition to the usual storage provider capabilities, the ADO.NET provider has built-in capability to Change storage data format from one format to another format (e.g. from JSON to binary) when roundtripping state. Shape the type to be saved or read from the storage in arbitrary ways. This helps to evolve the version state. Stream data out of the database. Both 1. and 2. can be applied on arbitrary decision parameters, such as grain ID , grain type , payload data . This happen so that one chooses a format, e.g. Simple Binary Encoding (SBE) and implements IStorageDeserializer and IStorageSerializer . The built-in (de)serializers have been built using this method. The OrleansStorageDefault (De)Serializer can be used as examples on how to implement other formats. When the (de)serializers have been implemented, they need to ba added to the StorageSerializationPicker property in AdoNetStorageProvider . This is an implementation of IStorageSerializationPicker . By default StorageSerializationPicker will be used. And example of changing data storage format or using (de)serializers can be seen at RelationalStorageTests . Currently there is no method to expose this to Orleans application consumption as there is no method to access the framework created AdoNetStorageProvider instance."
  },
  "Documentation/clusters_and_clients/configuration_guide/client_configuration.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/client_configuration.html",
    "title": "Client Configuration | Microsoft Orleans Documentation",
    "keywords": "Note If you just want to start a local silo and a local client for development purpose, look at the Local Development Configuration page. Client Configuration A client for connecting to a cluster of silos and sending requests to grains is configured programmatically via a ClientBuilder and a number of supplemental option classes. Like silo options, client option classes follow the ASP.NET Options . There are several key aspects of client configuration: Orleans clustering information Clustering provider Application parts Example of a client configuration: var client = new ClientBuilder() // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"MyAwesomeOrleansService\"; }) // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) // Application parts: just reference one of the grain interfaces that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IValueGrain).Assembly)) .Build(); Let's breakdown the steps used in this sample: Orleans clustering information [...] // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"orleans-docker\"; options.ServiceId = \"AspNetSampleApp\"; }) [...] Here we set two things: the ClusterId to \"my-first-cluster\" : this is a unique ID for the Orleans cluster. All clients and silo that uses this ID will be able to directly talk to each other. Some will choose to use a different ClusterId for each deployments for example. the ServiceId to \"AspNetSampleApp\" : this is a unique ID for your application, that will be used by some provider (for example for persistence providers). This ID should be stable (not change) accross deployments . Clustering provider [...] // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) [...] The client will discover all gateway available in the cluster using this provider. Several providers are available, here in this sample we use the Azure Table provider. To get more detail, look in the matching section in the Server Configuration page. Application parts [...] // Application parts: just reference one of the grain interfaces that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IValueGrain).Assembly)).WithReferences()) [...]; To get more detail, look in the matching section in the Server Configuration page."
  },
  "Documentation/who_is_using_orleans.html": {
    "href": "Documentation/who_is_using_orleans.html",
    "title": "Who Is Using Orleans? | Microsoft Orleans Documentation",
    "keywords": "Who Is Using Orleans? Orleans has been used extensively by several Microsoft projects and product groups, most notably by 343 Industries as a platform for all of Halo 4 and Halo 5 cloud services. There are various other internal projects at Microsoft which are using Orleans, but we are not able to talk publicly about many of those yet. There are many more companies and projects which are also using Orleans, and this page provides a partial list of some that we know about.... Feel free to send us a pull request on GitHub to add your company / project to this list. Companies Companies currently using Orleans in production: Gassumo Microsoft Skype , Azure , others Microsoft Studios 343 Studios ( Halo ), Age of Empires , BigPark , Black Tusk , others Microsoft Research NašeÚkoly.CZ Trustev Mailcloud Limited Gigya Honeywell Mesh Systems MESHVista Smart Cloud IoT Platform leverages Orleans for back-end services monitoring device state and business logic Applicita Limited A number of client projects where extreme scale and performance is required Drawboard Cloud collaboration and synchronisation platform YouScan Social media monitoring & analytics provider. Orleans is used for stateful stream processing at scale, reliable execution of long running jobs and as a main application server. Visa PagoLivre Mobile and Social Payment platform invertirOnline.com Argentinian-based electronic brokerage firm Lebara Nomnio Nomnio IoT Platform and industry projects where reliability and performance is required Real Artists Ship 2.0 Fast, native, comprehensive issue tracking for GitHub Manufacturing Resources International MRI designs, engineers, and fabricates BoldVu® LCD displays used in out of home advertising networks. Orleans powers our IOT infrastructure to help monitor and maintain our displays Projects and Applications Projects, websites and applications powered by Orleans, or provide extensions to Orleans. Claw (Clash Of Animal Warriors) is a real-time multiplayer mobile game which uses Orleans for its MatchMaker software which should handle many players at the same time and respond to them as fast as possible. Halo 4 - 343 Industries Microsoft BigPark Studio Orleans-Contrib Community contribution projects, including Orleans Monitoring, Design Patterns, Storage Provider, etc. Pegasus Mission More Info here and here Sync.Today 2015 .NET Business Processes Automation Platform. More info here Microdot A microservices framework by Gigya, for writing Orleans based microservices"
  },
  "Documentation/whats_new_in_orleans.html": {
    "href": "Documentation/whats_new_in_orleans.html",
    "title": "What's new in Orleans | Microsoft Orleans Documentation",
    "keywords": "What's new in Orleans? v2.0.0 March 28th 2018 Major changes (since 2.0.0-rc2) All included providers obtain ServiceId and ClusterId from the global ClusterOptions and do not have those properties on their own options classes (#4235, #4277, 4290) Use string for ServiceId instead of Guid (#4262) v2.0.0-rc2 March 12th 2018 Major changes (since 2.0.0-rc1) A new \"facade\" API for easier configuration of various aspects of stream providers: Persistent stream configurators v2.0.0-rc1 February 27th 2018 Major changes (since 2.0.0-beta3) New provider lifecycle model to replace the old one Builder pattern and options-based configuration of components and extension v2.0.0-beta3 December 21st 2017 Community Virtual Meetup #15 Orleans 2.0 with the core team December 13th 2017 Presentation v2.0.0-beta2 December 12th 2017 v1.5.3 December 8th 2017 v2.0.0-beta1 October 26th 2017 Major new features Most packages are now targetting .NET Standard 2.0 (which mean they can be used from either .NET Framework or .NET Core 2.0) and on non-Windows platforms. v1.5.2 October 17th 2017 v1.5.1 August 28th 2017 v1.5.0 July 6th 2017 Major new features Non-static grain client via ClientBuilder enables connecting to multiple Orleans cluster from the same app domain and connecting to other clusters from within a silo. Support for versioning of grain interfaces for non-downtime upgrades. Support for custom grain placement strategies and directors. Support for hash-based grain placement. v1.4.2 June 9th 2017 v1.4.1 March 27th 2017 Community Virtual Meetup #14 Orleans FSM with John Azariah March 22nd 2017 v1.4.0 February 21st 2017 Major new features Revamped JournaledGrain for event sourcing with support for geo-distributed log-based consistency providers. Abstraction of Grain Services with fixed-placed per-silo application components with their workload partitioned via cluster consistency ring. Support for heterogeneous silos with non-uniform distribution of available grain classes. Cluster membership provider for Service Fabric. Community Virtual Meetup #13 Upgrading Orleans Applications with Sergey Bykov and team February 8th 2017 Presentation v1.4.0-beta February 1st 2017 Major new features Revamped JournaledGrain for event sourcing with support for geo-distributed log-based consistency providers. Abstraction of Grain Services with fixed-placed per-silo application components with their workload partitioned via cluster consistency ring. Support for heterogeneous silos with non-uniform distribution of available grain classes. Cluster membership provider for Service Fabric. Community Virtual Meetup #12 Deploying Orleans with Jakub Konecki December 8th 2016 Presentation v1.3.1 November 15th 2016 Community Virtual Meetup #11 A monitoring and visualisation show with Richard Astbury , Dan Vanderboom and Roger Creyke October 13th 2016 v1.3.0 October 11th 2016 v1.2.4 October 5th 2016 v1.3.0-beta2 September 27th 2016 Notable new features Support for geo-distributed multi-cluster deployments #1108 #1109 #1800 Added new Amazon AWS basic Orleans providers #2006 Support distributed cancellation tokens in grain methods #1599 Community Virtual Meetup #10 The roadmap to Orleans 2.0 with the core team August 25th 2016 v1.2.3 July 11th 2016 v1.2.2 June 15th 2016 v1.2.1 May 19th 2016 v1.2.0 May 4th 2016 v1.2.0-beta April 18th 2016 Major improvements Added an EventHub stream provider based on the same code that is used in Halo 5. Increased throughput by between 5% and 26% depending on the scenario. Migrated all but 30 functional tests to GitHub. Grain state doesn't have to extend GrainState anymore (marked as [Obsolete] ) and can be a simple POCO class. Added support for per-grain-class and global server-side interceptors. Added support for using Consul 0.6.0 as a Membership Provider. Support C# 6. Switched to xUnit for testing as a step towards CoreCLR compatibility. v1.1.3 March 9th 2016 Community Virtual Meetup #9 Nehme Bilal and Reuben Bond talk about deploying Orleans with YAMS and Service Fabric Fabruary 26st 2016 Community Virtual Meetup #8.5 Networking discussion hosted by Jason Bragg February 11th 2016 Community Virtual Meetup #8 Orleans core team present the roadmap January 21st 2016 v1.1.2 January 20th 2016 v1.1.1 January 11th 2016 Community Virtual Meetup #7 Christmas Special - Yevhen Bobrov on Orleankka December 17th 2015 v1.1.0 December 14nd 2015 Community Virtual Meetup #6 MSR PhDs on Geo Distributed Orleansp October 23rd 2015 v1.0.10 September 22nd 2015 v1.0.9 July 15th 2015 v1.0.8 May 26th 2015 Community Virtual Meetup #5 Gabriel Kliot on the new Orleans Streaming API May 22nd 2015 v1.0.7 May 15th 2015 Community Virtual Meetup #4 Reuben Bond on using Orleans at FreeBay April 15th 2015 v1.0.5 March 30th 2015 Community Virtual Meetup #3 Yevhen Bobrov on a Uniform API for Orleans March 6th 2015 Community Virtual Meetup #2 Orleans team live Q&A and roadmap January 12th 2015 Orleans Open Source v1.0 Update (January 2015) Community Virtual Meetup #1 Jakub Konecki on Event Sourced Grains December 18th 2014"
  },
  "Community/Links.html": {
    "href": "Community/Links.html",
    "title": "Links | Microsoft Orleans Documentation",
    "keywords": "Links By Orleans team Orleans Architecture: Principles and Approach I Episode 142: Microsoft Research project Orleans simplify development of scalable cloud services Orleans: Thinking Big and Small Available Now: Preview of Project “Orleans” – Cloud Services at Scale Orleans: Distributed Virtual Actors for Programmability and Scalability By others Introducing Orleans Microsoft Orleans v2.0 - A comprehensive guide for beginners and experts alike (PowerPoint) A First Look at Project Orleans A Second Look at Project Orleans Project Orleans: An Introduction Introduction To Project Orleans Introduction to Orleans Project Orleans: Different Than Erlang, Designed for a Broad Group of Developers Two Reasons You May Want to Use Microsoft’s Project Orleans Hatay Tuna & Christian Martinez - Applied Actor Model with Orleans Actor Programming with Orleans: What’s Different? Orleans – a “cloud native” runtime built for #azure Project Orleans - Actor Model framework A look at Microsoft Orleans through Erlang-tinted glasses Using Codename “Orleans” in Enterprise Applications Beyond the introduction Grains, Grains and more Grains Fine-graining your Orleans Grains inside the IoT universe Monitorable Grains Aggregating Results in Orleans Creating RESTful Services using Orleans Tackle Distribution, High Throughput and Low-Latency with Orleans – A “cloud native” Runtime Built for #Azure Saving state only once in a while in #ProjectOrleans Using Orleans for building scalable cloud applications Orleans in an IoT universe Orleans Preview & Halo 4 Using Project “Orleans” in Halo Orleans & Thinking Outside the Box John Azariah & Mahesh Krishnan - Immutability, State and Scale - Functional, Distributed Applications in Azure last edited: 5 June 2018"
  },
  "Community/Ideas-for-Contributions.html": {
    "href": "Community/Ideas-for-Contributions.html",
    "title": "Ideas for Contributions | Microsoft Orleans Documentation",
    "keywords": "Ideas for Contributions These are some of the ideas for contributing to Orleans. Just an initial list for consideration, meant to be a live document. If you are interested in any of these or one that is not listed, create an issue to discuss it. We roughly put them into 3 size categories based on our gut feel, which may be wrong: Small - hours of work Medium - couple of days of work Large - big projects, multiple days up to weeks of work Project template/wizard for Azure deployment [Medium/Large] Worker role for silos (in our experience it is better to star a silo as a standalone process and wait on the process handle in the worker roles code) Worker/web role for frontend clients Configuration of diagnostics, ETW tracing, etc. Try Azure SDK plug-in as suggested here by @richorama. Cluster monitoring dashboard [Medium] https://github.com/OrleansContrib/OrleansMonitor may be a good start Proper support for F# [Medium/Large] See Issue #38 Orleans backplane for SignalR [Medium] See Issue #73 Port Orleans to coreclr [Medium] See Issue #368 Some APIs from the full .NET got deprecated in coreclr, mainly around files and reflection, but at large the porting effort shouldn't be too big. This will allow to run Orleans efficiently cross platform. Secure communication between silos and clients Add support for secure communication mode with certificates used for encryption of messages."
  },
  "1.5/Documentation/Multi-Cluster/GlobalSingleInstance.html": {
    "href": "1.5/Documentation/Multi-Cluster/GlobalSingleInstance.html",
    "title": "Global-Single-Instance Grains | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Grain Coordination Attributes Developers can indicate when and how clusters should coordinate their grain directories with respect to a particular grain class. The [GlobalSingleInstance] attribute means we want the same behavior as as when running Orleans in a single global cluster: that is, route all calls to a single activation of the grain. Conversely, the [OneInstancePerCluster] attribute indicates that each cluster can have its own independent activation. This is appropriate if communication between clusters is undesired. The attributes are placed on grain implementations. For example: using Orleans.MultiCluster; [GlobalSingleInstance] public class MyGlobalGrain : Orleans.Grain, IMyGrain { ... } [OneInstancePerCluster] public class MyLocalGrain : Orleans.Grain, IMyGrain { ... } If a grain class does not specify either one of those attributes, it defaults to [OneInstancePerCluster] , or [GlobalSingleInstance] if the configuration parameter UseGlobalSingleInstanceByDefault is set to true. Protocol for Global-Single-Instance Grains When a global-single-instance (GSI) grain is accessed, and no activation is known to exist, a special GSI activation protocol is executed before activating a new instance. Specifically, a request is sent to all other clusters in the current multi-cluster configuration to check if they already have an activation for this grain. If all responses are negative, a new activation is created in this cluster. Otherwise, the remote activation is used (and a reference to it is cached in the local directory). Protocol for One-Instance-Per-Cluster Grains There is no inter-cluster communication for One-Instance-Per-Cluster grains. They simply use the standard Orleans mechanism independently within each cluster. Inside the Orleans framework itself, the following grain classes are marked with the [OneInstancePerCluster] attribute: ManagementGrain , GrainBasedMembershipTable , and GrainBasedReminderTable . Doubtful Activations If the GSI protocol does not receive conclusive responses from all clusters after 3 retries (or whatever number is specified by the configuration parameter GlobalSingleInstanceNumberRetries ), it creates a new local \"doubtful\" activation optimistically, favoring availability over consistency. Doubtful activations may be duplicates (because some remote cluster that did not respond during the GSI protocol activation may nevertheless have an activation of this grain). Therefore, periodically every 30 seconds (or whatever interval is specified by the configuration parameter GlobalSingleInstanceRetryInterval ) the GSI protocol is run again for all doubtful activations. This ensures that once communication between clusters is restored, duplicate activations can be detected and removed."
  },
  "1.5/Documentation/Installation/NuGets.html": {
    "href": "1.5/Documentation/Installation/NuGets.html",
    "title": "Orleans NuGet Packages | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Nuget Packages Orleans NuGet packages as of v1.5.0 There are 4 key NuGet packages you will need to use in most scenarios: Microsoft Orleans Build-time Code Generation PM> Install-Package Microsoft.Orleans.OrleansCodeGenerator.Build Build support for grain interfaces and implementation projects. Add it to your grain interfaces and implementation projects to enable code generation of grain references and serializers. Microsoft.Orleans.Templates.Interfaces and Microsoft.Orleans.Templates.Grains packages are obsolete and provided only for backward compatibility and migration. Microsoft Orleans Core Library PM> Install-Package Microsoft.Orleans.Core Contains Orleans.dll, which defines most of Orleans public types and Orleans Client. Reference it for building libraries and client applications that use Orleans types but don't need any of the included providers. Microsoft Orleans Server Libraries PM> Install-Package Microsoft.Orleans.Server Includes everything you need to run a silo. Microsoft Orleans Client Libraries PM> Install-Package Microsoft.Orleans.Client Includes everything you need for an Orleans client (frontend). Additional Packages The below packages provide additional functionality. Microsoft Orleans Providers PM> Install-Package Microsoft.Orleans.OrleansProviders Contains a set of built-in persistence and stream providers, primarily for testing, as well as some abstractions and utility types for building persistence and stream providers. Included in Microsoft.Orleans.Client and Microsoft.Orleans.Server. Microsoft Orleans Event-Sourcing PM> Install-Package Microsoft.Orleans.EventSourcing Contains a set of base types for creating grain classes with event-sourced state. Providers and extensions Microsoft Orleans Azure Utilities PM> Install-Package Microsoft.Orleans.OrleansAzureUtils Contains Azure Table based cluster membership provider, wrapper classes that simplify instantiation of silos and clients in Azure Worker/Web roles, persistence providers for Azure Tables and Azure Blobs, and a stream provider for Azure Queues. Microsoft Orleans Sql Utilities PM> Install-Package Microsoft.Orleans.OrleansSqlUtils Contains SQL based cluster membership and persistence providers for use with SQL Server, MySQL, PostgreSQL, and other SQL databases. Microsoft Orleans ServiceBus Utilities PM> Install-Package Microsoft.Orleans.OrleansServiceBus Includes the stream provider for Azure Event Hubs. Microsoft Orleans Consul Utilities PM> Install-Package Microsoft.Orleans.OrleansConsulUtils Includes the plugin for using Consul for storing cluster membership data. Microsoft Orleans ZooKeeper Utilities PM> Install-Package Microsoft.Orleans.OrleansZooKeeperUtils Includes the plugin for using ZooKeeper for storing cluster membership data. Microsoft Orleans AWS Utilities PM> Install-Package Microsoft.Orleans.OrleansAWSUtils Includes DynamoDB based cluster membership provider, DynamoDB persistence provider, and SQS based stream provider. Microsoft Orleans Telemetry Consumer - Performance Counters PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.Counters Windows Performance Counters implementation of Orleans Telemetry API. Microsoft Orleans Telemetry Consumer - Azure Application Insights PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.AI Includes the telemetry consumer for Azure Application Insights. Microsoft Orleans Telemetry Consumer - NewRelic PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.NewRelic Includes the telemetry consumer for NewRelic. Microsoft Orleans Bond Serializer PM> Install-Package Microsoft.Orleans.Serialization.Bond Includes support for Bond serializer . Microsoft Orleans Google Utilities PM> Install-Package Microsoft.Orleans.OrleansGoogleUtils Includes Google Protocol Buffers serializer. Hosting and testing Microsoft Orleans Runtime PM> Install-Package Microsoft.Orleans.OrleansRuntime Core runtime library of Microsoft Orleans that hosts and executes grains within a silo. Microsoft Orleans Silo Host PM> Install-Package Microsoft.Orleans.OrleansHost Includes the default silo host - OrleansHost.exe. Can be used for on-premises deployments or as an out-of-process silo host in Azure Worker Role. Included in Microsoft.Orleans.Server. We are planning to deprecate this package in favor of customers building their custom silo host processes in order to simplify dependency management and programmatic configuration. Microsoft Orleans Service Fabric Support PM> Install-Package Microsoft.Orleans.ServiceFabric Support for hosting Microsoft Orleans on Service Fabric. Microsoft Orleans Testing Host Library PM> Install-Package Microsoft.Orleans.TestingHost Includes the library for hosting silos in a testing project. Microsoft Orleans Code Generation PM> Install-Package Microsoft.Orleans.OrleansCodeGenerator Includes the run time code generator. Included in Microsoft.Orleans.Server and Microsoft.Orleans.Client. Tools Microsoft Orleans Performance Counter Tool PM> Install-Package Microsoft.Orleans.CounterControl Includes OrleansCounterControl.exe, which registers Windows performance counter categories for Orleans statistics and for deployed grain classes. Requires elevation. Can be executed in Azure as part of a role startup task. Included in Microsoft.Orleans.Server. Microsoft Orleans Management Tool PM> Install-Package Microsoft.Orleans.OrleansManager Includes Orleans management tool - OrleansManager.exe. We are planning to deprecate this package in favor of customers building their custom management tools in order to simplify dependency management and programmatic configuration."
  },
  "Documentation/grains/transactions.html": {
    "href": "Documentation/grains/transactions.html",
    "title": "Transactions in Orleans 2.0 | Microsoft Orleans Documentation",
    "keywords": "Orleans Transactions (Beta) Orleans transactions are in a beta state and should not be used in production systems. Orleans supports distributed transactions against persistent grain state. Setup Orleans transactions are opt-in. A silo must be configured to use transactions. If it is not, any calls to transactional grains will receive an OrleansTransactionsDisabledException. Transaction Manager Orleans transactions requires a transaction manager which is authoritative on the state of a transaction. Currently, the transaction manager is run within the cluster and must be configured. This can be programmatically configured on the silo host builder using UseInClusterTransactionManager and TransactionsConfiguration. The TransactionsConfiguration contains the following configurable values: TransactionIdAllocationBatchSize - To avoid a storage call on every transaction start, transaction Ids are allocated in batches. This is the number of new transaction Ids allocated per transaction Id generation request (storage call). AvailableTransactionIdThreshold - A new batch of transaction Ids will be automatically allocated if the available ids drop below this threshold. TransactionRecordPreservationDuration - How long to preserve a transaction record in the TM memory after the transaction has completed. This is used to answer queries about the outcome of the transaction. It is suggested that you use the defaults for these values unless they demonstrate themselves as insufficient. Transaction Log The transaction manager must persist transaction results for recoverability purposes. To support a range of backend storage solutions an abstraction has been provided for log storage. We currently support an azure storage version of the log storage, and an in-memory version for development and test purposes. This can be programmatically configured on the silo host builder using UseAzureTransactionLog or UseInMemoryTransactionLog. Transactional State To support various transactional storage patterns the grain facing interface and supporting logic is pluggable. We currently only support ITransactionalState. This can be programmatically enabled on the silo host builder using UseTransactionalState. To use a transactional state, a storage provider needs also be configured. Example: var builder = new SiloHostBuilder() [...] .AddAzureTableGrainStorageAsDefault(options => options.ConnectionString = ”YOUR_STORAGE_CONNECTION_STRING”) .UseInClusterTransactionManager() .UseAzureTransactionLog(options => options.ConnectionString = ”YOUR_STORAGE_CONNECTION_STRING”) .UseTransactionalState(); var host = builder.Build(); await host.StartAsync(); Programming Model For a grain to support transactions, transactional operations on a grain must be marked as being part of a transaction using the “Transaction” attribute. Calls can be marked as “Required”, meaning the call can take part in a transaction among multiple other grains or as “RequiresNew” indicating that it will already start its own transaction. Example: public interface IATMGrain : IGrainWithIntegerKey { [Transaction(TransactionOption.RequiresNew)] Task Transfer(Guid fromAccount, Guid toAccount, uint amountToTransfer); } The Transfer operation in the above atm grain will always start a new transaction which involves the two referenced accounts. public interface IAccountGrain : IGrainWithGuidKey { [Transaction(TransactionOption.Required)] Task Withdraw(uint amount); [Transaction(TransactionOption.Required)] Task Deposit(uint amount); [Transaction(TransactionOption.Required)] Task<uint> GetBalance(); } The Withdraw and Deposit operations in the above account grain can take part in transactional operations, like the Transfer operation in the ATM grain, with other transactional grains. To use a transactional state within a grain, one needs only define a serializable state class to be persisted and declare the state in the grains constructor. Example: public class AccountGrain : Grain, IAccountGrain { private readonly ITransactionalState<Balance> balance; public AccountGrain( [TransactionalState(\"balance\")] ITransactionalState<Balance> balance) { this.balance = balance ?? throw new ArgumentNullException(nameof(balance)); } Task IAccountGrain.Deposit(uint ammount) { this.balance.State.Value += ammount; this.balance.Save(); return Task.CompletedTask; } Task IAccountGrain.Withdrawal(uint ammount) { this.balance.State.Value -= ammount; this.balance.Save(); return Task.CompletedTask; } Task<uint> IAccountGrain.GetBalance() { return Task.FromResult(this.balance.State.Value); } } In the above example the attribute TransactionalState is used to declare that the ‘balance’ construction argument should be associated with a transactional state named “balance”. With this declaration Orleans will wire up an ITransactionalState instance with a state loaded from the default storage provider for the grain to use. The state can be accessed and modified via the State property. Any changes to the state need be recorded by calling ‘Save()’. The transaction infrastructure will ensure that any such changes performed as part of a transaction, even among multiple grains distributed over an Orleans cluster, will either all be committed or reverted together."
  },
  "Documentation/clusters_and_clients/monitoring/client_error_code_monitoring.html": {
    "href": "Documentation/clusters_and_clients/monitoring/client_error_code_monitoring.html",
    "title": "Client Error Code Monitoring | Microsoft Orleans Documentation",
    "keywords": "Client Error Code Monitoring Group Log Type Log Code Values Threshold Description Azure Problems Warning or Error 100800 - 100899 Any Error or Warning Transient problems reading or writing to Azure table store will be logged as Warning. Transient read errors will automatically be retried. A final Error log message means there is a real problem connecting to Azure table storage. Gateway connectivity problems Warning or Error 100901 - 100904, 100912, 100913, 100921, 100923, 100158, 100161, 100178, , 101313 Any Error or Warning Problems connecting to gateways. No active gateways in the Azure table. Connection to active gateway lost. Grain call timeouts Warning 100157 Multiple Warnings logged in short space of time Grain-call timeout problems are generally caused by temporary network connectivity issues or silo restart / reboot problems. System should recover after a short time (depending on Liveness config settings) at which point Timeouts should clear. Ideally, monitoring for just the bulk log code 600157 variety of these warnings should be sufficient. Network Socket Problems Warning or Error 101000 to 101999, 100307, 100015, 100016 Any Error or Warning Socket disconnects are logged as Warning messages. Problems opening sockets or during message transmission are logged as Errors. Bulk log message compaction Any 500000 or higher Message summary based on bulk message threshold settings If multiple logs of the same log code occur within a designated time interval (the default is >5 within 1 minute) then additional log messages with that log code are suppressed and output as a \"bulk\" entry with log code equal to the original log code + 500000. So for example, multiple 100157 entries will show in the logs as 5 x 100157 + 1 x 600157 log entry per minute."
  },
  "Documentation/clusters_and_clients/configuration_guide/typical_configurations.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/typical_configurations.html",
    "title": "Typical Configurations | Microsoft Orleans Documentation",
    "keywords": "Typical Configurations Below are examples of typical configurations that can be used for development and production deployments. Local Development See Local Development Configuration Reliable Production Deployment Using Azure For a reliable production deployment using Azure, you need to use the Azure Table option for cluster membership. This configuration is typical of deployments to either on-premise servers, containers, or Azure virtual machine instances. The format of the DataConnection string is \"DefaultEndpointsProtocol=https;AccountName=<Azure storage account>;AccountKey=<Azure table storage account key>\" Silo configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var silo = new SiloHostBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAzureStorageClustering(options => options.ConnectionString = connectionString) .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Client configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var client = new ClientBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAzureStorageClustering(options => options.ConnectionString = connectionString) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Reliable Production Deployment Using SQL Server For a reliable production deployment using SQL server, a SQL server connection string needs to be supplied. Silo configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var silo = new SiloHostBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAdoNetClustering(options => { options.ConnectionString = connectionString; options.Invariant = \"System.Data.SqlClient\"; }) .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Client configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var client = new ClientBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAdoNetClustering(options => { options.ConnectionString = connectionString; options.Invariant = \"System.Data.SqlClient\"; }) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Unreliable Deployment on a Cluster of Dedicated Servers For testing on a cluster of dedicated servers when reliability isn’t a concern you can leverage MembershipTableGrain and avoid dependency on Azure Table. You just need to designate one of the nodes as a Primary. On the silos: var primarySiloEndpoint = new IPEndpoint(PRIMARY_SILO_IP_ADDRESS, 11111); var silo = new SiloHostBuilder() .UseDevelopmentClustering(primarySiloEndpoint) .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) .ConfigureLogging(logging => logging.AddConsole()) .Build(); On the clients: var gateways = new IPEndPoint[] { new IPEndPoint(PRIMARY_SILO_IP_ADDRESS, 11111), new IPEndPoint(OTHER_SILO__IP_ADDRESS_1, 11111), [...] new IPEndPoint(OTHER_SILO__IP_ADDRESS_N, 11111), }; var client = new ClientBuilder() .UseStaticClustering(gateways) .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"AdventureApp\"; }) .ConfigureLogging(logging => logging.AddConsole()) .Build();"
  },
  "Documentation/clusters_and_clients/configuration_guide/messaging_delivery_guarantees.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/messaging_delivery_guarantees.html",
    "title": "Messaging Delivery Guarantees | Microsoft Orleans Documentation",
    "keywords": "Messaging Delivery Guarantees Orleans messaging delivery guarantees are at-most-once , by default. Optionally, if configured to do retries upon timeout, Orleans provides at-least-once deliv­ery instead. In more details: Every message in Orleans has automatic timeout (the exact timeout can be configured). If the reply does not arrive on time the return Task is broken with timeout exception. Orleans can be configured to do automatic retries upon timeout. By default we do NOT do automatic retries. Application code of course can also pick to do retries upon timeout. If the Orleans system is configured not to do automatic retries (default setting) and application is not resending – Orleans provides at most once message delivery . A message will either be delivered once or not at all. It will never be delivered twice. In the system with retries (either by the runtime or by the application) the message may arrive multiple times. Orleans currently does nothing to durably store which messages already arrived and suppress the second delivery (we believe this would be pretty costly). So in the system with retries Orleans does NOT guarantee at most once delivery. If you keep retrying potentially indefinitely , the message will eventually arrive , thus providing at least once delivery guarantee. Notice that “will eventually arrive” is something that the runtime needs to guarantee. It does not come for free just by itself even if you keep retrying. Orleans provides eventually delivery since grains never go into any permanent failure state and a failed grain will for sure eventually be re-activated on another silo. So to summarize : in the system without retries Orleans guarantees at most once message delivery. In the system with infinite retries Orleans guarantee at least once (and does NOT guarantee at most once). Note : In the Orleans technical report we accidentally only mentioned the 2nd option with automatic retries and forgot to mention that by default with no retries, Orleans provides at most once delivery."
  },
  "1.5/Documentation/Getting-Started-With-Orleans/Developing-a-Grain.html": {
    "href": "1.5/Documentation/Getting-Started-With-Orleans/Developing-a-Grain.html",
    "title": "Developing a Grain | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Please read about Grains before reading this article. Setup Before you write code to implement a grain class, create a new Class Library project targeting .NET 4.6.1 or higher in Visual Studio and add the Microsoft.Orleans.OrleansCodeGenerator.Build NuGet package to it. PM> Install-Package Microsoft.Orleans.OrleansCodeGenerator.Build Grain Interfaces and Classes Grains interact with each other and get called from outside by invoking methods declared as part of the respective grain interfaces. A grain class implements one or more previously declared grain interfaces. All methods of a grain interface must return a Task (for void methods) or a Task<T> (for methods returning values of type T ). The following is an excerpt from the Presence Service sample: //an example of a Grain Interface public interface IPlayerGrain : IGrainWithGuidKey { Task<IGameGrain> GetCurrentGame(); Task JoinGame(IGameGrain game); Task LeaveGame(IGameGrain game); } //an example of a Grain class implementing a Grain Interface public class PlayerGrain : Grain, IPlayerGrain { private IGameGrain currentGame; // Game the player is currently in. May be null. public Task<IGameGrain> GetCurrentGame() { return Task.FromResult(currentGame); } // Game grain calls this method to notify that the player has joined the game. public Task JoinGame(IGameGrain game) { currentGame = game; Console.WriteLine( \"Player {0} joined game {1}\", this.GetPrimaryKey(), game.GetPrimaryKey()); return Task.CompletedTask; } // Game grain calls this method to notify that the player has left the game. public Task LeaveGame(IGameGrain game) { currentGame = null; Console.WriteLine( \"Player {0} left game {1}\", this.GetPrimaryKey(), game.GetPrimaryKey()); return Task.CompletedTask; } } Returning Values from Grain Methods A grain method that returns a value of type T is defined in a grain interface as returning a Task<T> . For grain methods not marked with the async keyword, when the return value is available, it is usually returned via the following statement: public Task<SomeType> GrainMethod1() { ... return Task.FromResult(<variable or constant with result>); } A grain method that returns no value, effectively a void method, is defined in a grain interface as returning a Task . The returned Task indicates asynchronous execution and completion of the method. For grain methods not marked with the async keyword, when a \"void\" method completes its execution, it needs to return the special value of Task.CompletedTask : public Task GrainMethod2() { ... return Task.CompletedTask; } A grain method marked as async returns the value directly: public async Task<SomeType> GrainMethod3() { ... return <variable or constant with result>; } A \"void\" grain methods marked as async that returns no value simply returns at the end of their execution: public async Task GrainMethod4() { ... return; } If a grain method receives the return value from another asynchronous method call, to a grain or not, and doesn't need to perform error handling of that call, it can simply return the Task it receives from that asynchronous call as its return value: public Task<SomeType> GrainMethod5() { ... Task<SomeType> task = CallToAnotherGrain(); return task; } Similarly, a \"void\" grain method can return a Task returned to it by another call instead of awaiting it. public Task GrainMethod6() { ... Task task = CallToAsyncAPI(); return task; } Grain Reference A Grain Reference is a proxy object that implements the same grain interface as the corresponding grain class. It encapsulates a logical identity (type and unique key) of the target grain. A grain reference is what is used for making calls to the target grain. Each grain reference is for a single grain (a single instance of the grain class), but one can create multiple independent references for the same grain. Since a grain reference represents a logical identity of the target grain, it is independent from the physical location of the grain, and stays valid even after a complete restart of the system. Developers can use grain references like any other .NET object. It can be passed to a method, used as a method return value, etc., and even saved to persistent storage. A grain reference can be obtained by passing the identity of a grain to the GrainFactory.GetGrain<T>(key) method, where T is the grain interface and key is the unique key of the grain within the type. The following are examples of how to obtain a grain reference of the IPlayerGrain interface defined above. From inside a grain class: //construct the grain reference of a specific player IPlayerGrain player = GrainFactory.GetGrain<IPlayerGrain>(playerId); From Orleans Client code. Prior to 1.5.0: IPlayerGrain player = GrainClient.GrainFactory.GetGrain<IPlayerGrain>(playerId); Since 1.5.0: IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); Grain Method Invocation The Orleans programming model is based on the Asynchronous Programming with Async and Await . Using the grain reference from the previous example, here's how one performs a grain method invocation: //Invoking a grain method asynchronously Task joinGameTask = player.JoinGame(this); //The await keyword effectively makes the remainder of the method execute asynchronously at a later point (upon completion of the Task being awaited) without blocking the thread. await joinGameTask; //The next line will execute later, after joinGameTask is completed. players.Add(playerId); It is possible to join two or more Tasks ; the join operation creates a new Task that is resolved when all of its constituent Task s are completed. This is a useful pattern when a grain needs to start multiple computations and wait for all of them to complete before proceeding. For example, a front-end grain that generates a web page made of many parts might make multiple back-end calls, one for each part, and receive a Task for each result. The grain would then await the join of all of these Tasks ; when the join Task is resolved, the individual Task s have been completed, and all the data required to format the web page has been received. Example: List<Task> tasks = new List<Task>(); Message notification = CreateNewMessage(text); foreach (ISubscriber subscriber in subscribers) { tasks.Add(subscriber.Notify(notification)); } // WhenAll joins a collection of tasks, and returns a joined Task that will be resolved when all of the individual notification Tasks are resolved. Task joinedTask = Task.WhenAll(tasks); await joinedTask; // Execution of the rest of the method will continue asynchronously after joinedTask is resolve. Virtual methods A grain class can optionally override OnActivateAsync and OnDeactivateAsync virtual methods that get invoked by the Orleans runtime upon activation and deactivation of each grain of the class. This gives the grain code a chance to perform additional initialization and cleanup operations. An exception thrown by OnActivateAsync fails the activation process. While OnActivateAsync , if overridden, is always called as part of the grain activation process, OnDeactivateAsync is not guaranteed to get called in all situations, for example, in case of a server failure or other abnormal events. Because of that, applications should not rely on OnDeactivateAsync for performing critical operations, such as persistence of state changes, and only use it for best effort operations. Next Developing a Client"
  },
  "1.5/Documentation/Getting-Started-With-Orleans/Developing-a-Client.html": {
    "href": "1.5/Documentation/Getting-Started-With-Orleans/Developing-a-Client.html",
    "title": "Developing a Client | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . What Is Grain Client? The term \"Client\" or sometimes \"Grain Client\" is used for application code that interacts with grains but itself is not part of a grain logic. Client code runs outside of the cluster of Orleans servers called silos where grains are hosted. Hence, a client acts as a connector or conduit to the cluster and to all grains of the application. Usually, clients are used on the frontend web servers to connect to an Orleans cluster that serves as a middle tier with grains executing business logic. In a typical setup, a frontend web server: Receives a web request Performs necessary authentication and authorization validation Decides which grain(s) should process the request Uses Grain Client to make one or more method call to the grain(s) Handles successful completion or failures of the grain calls and any returned values Sends a response for the web request Initialization of Grain Client Before a grain client can be used for making calls to grains hosted in an Orleans cluster, it needs to be configured, initialized, and connected to the cluster. Configuration is provided via a ClientConfiguration object that contains a hierarchy of configuration properties for programmatically configuring a client. There is also a way to configure a client via a XML file, but that option will be deprecated in the future. More information is in the Client Configuration guide . Here we will simply use a helper method that creates a configuration object hardcoded for connecting to a local silo running as localhost . ClientConfiguration clientConfig = ClientConfiguration.LocalhostSilo(); Once we have a configuration object, we can build a client via the ClientBuilder class. IClusterClient client = new ClientBuilder().UseConfiguration(clientConfig).Build(); Lastly, we need to call Connect() method on the constructed client object to make it connect to the Orleans cluster. It's an asynchronous method that returns a Task . So we need to wait for its completion with an await or .Wait() . await client.Connect(); Making Calls to Grains Making calls to grain from a client is really no different from making such calls from within grain code . The same GetGrain<T>(key) method, where T is the target grain interface, is used in both cases to obtain grain references . The slight difference is in through what factory object we invoke GetGrain . In client code we do that through the connected client object. IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); Task t = player.JoinGame(game) await t; A call to a grain method returns a Task or a Task<T> as required by the grain interface rules . The client can use the await keyword to asynchronously await the returned Task without blocking the thread, or in some cases the Wait() method to block the current thread of execution. The major difference between making calls to grains from client code and from within another grain is the single-threaded execution model of grains. Grains are constrained to be single-threaded by the Orleans runtime, while clients may be multi-threaded. Orleans does not provide any such guarantee on the client side, and so it is up to the client to manage its own concurrency using whatever synchronization constructs are appropriate for its environment – locks, events, Tasks , etc. Receiving notifications There are situations in which a simple request-response pattern is not enough, and the client needs to receive asynchronous notifications. For example, a user might want to be notified when a new message has been published by someone that she is following. Observers is one such mechanism that enables exposing client side objects as grain-like targets to get invoked by grains. Calls to observers do not provide any indication of success or failure, as they are sent as one-way best effort message. So it is a responsibility of the application code to build a higher level reliability mechanism on top of observers where necessary. Another mechanism that can be used for delivering asynchronous messages to clients is Streams . Streams expose indications of success or failure of delivery of individual messages, and hence enable reliable communication back to the client. Example Here is an extended version of the example given above of a client application that connects to Orleans, finds the player account, subscribes for updates to the game session the player is part of with an observer, and prints out notifications until the program is manually terminated. namespace PlayerWatcher { class Program { /// <summary> /// Simulates a companion application that connects to the game /// that a particular player is currently part of, and subscribes /// to receive live notifications about its progress. /// </summary> static void Main(string[] args) { RunWatcher().Wait(); // Block main thread so that the process doesn't exit. // Updates arrive on thread pool threads. Console.ReadLine(); } static async Task RunWatcher() { try { // Connect to local silo var config = ClientConfiguration.LocalhostSilo(); var client = new ClientBuilder().UseConfiguration(config).Build(); await client.Connect(); // Hardcoded player ID Guid playerId = new Guid(\"{2349992C-860A-4EDA-9590-000000000006}\"); IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); IGameGrain game = null; while (game == null) { Console.WriteLine(\"Getting current game for player {0}...\", playerId); try { game = await player.GetCurrentGame(); if (game == null) // Wait until the player joins a game { await Task.Delay(5000); } } catch (Exception exc) { Console.WriteLine(\"Exception: \", exc.GetBaseException()); } } Console.WriteLine(\"Subscribing to updates for game {0}...\", game.GetPrimaryKey()); // Subscribe for updates var watcher = new GameObserver(); await game.SubscribeForGameUpdates( await client.CreateObjectReference<IGameObserver>(watcher)); Console.WriteLine(\"Subscribed successfully. Press <Enter> to stop.\"); } catch (Exception exc) { Console.WriteLine(\"Unexpected Error: {0}\", exc.GetBaseException()); } } } /// <summary> /// Observer class that implements the observer interface. Need to pass a grain reference to an instance of this class to subscribe for updates. /// </summary> class GameObserver : IGameObserver { // Receive updates public void UpdateGameScore(string score) { Console.WriteLine(\"New game score: {0}\", score); } } } } Next Running the Application"
  },
  "1.5/Documentation/Event-Sourcing/Subscribe.html": {
    "href": "1.5/Documentation/Event-Sourcing/Subscribe.html",
    "title": "Notifications | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Notifications It is often convenient to have the ability to react to state changes. All callbacks are subject to Orleans' turn-based guarantees; see also the section on Concurrency Guarantees . Tracking Confirmed State To be notified of any changes to the confirmed state, JournaledGrain subclasses can override this method: protected override void OnStateChanged() { // read state and/or event log and take appropriate action } OnStateChanged is called whenever the confirmed state is updated, i.e. the version number increases. This can happen when A newer version of the state was loaded from storage. An event that was raised by this instance has been successfully written to storage. A notification message was received from some other instance. Note that since all grains initially have version zero, until the initial load from storage completes, this means that OnStateChanged is called whenever the initial load completes with a version larger than zero. Tracking Tentative State To be notified of any changes to the tentative state, JournaledGrain subclasses can override this method: protected override void OnTentativeStateChanged() { // read state and/or events and take appropriate action } OnTentativeStateChanged is called whenever the tentative state changes, i.e. if the combined sequence (ConfirmedEvents + UnconfirmedEvents) changes. In particular, a callback to OnTentativeStateChanged() always happens during RaiseEvent ."
  },
  "1.5/Documentation/Event-Sourcing/GrainStateAPI.html": {
    "href": "1.5/Documentation/Event-Sourcing/GrainStateAPI.html",
    "title": "JournaledGrain API | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . JournaledGrain Basics Journaled grains derive from <JournaledGrain<StateType,EventType> , with the following type parameters: The StateType represents the state of the grain. It must be a class with a public default constructor. EventType is a common supertype for all the events that can be raised for this grain, and can be any class or interface. All state and event objects should be serializable (because the log-consistency providers may need to persist them, and/or send them in notification messages). For grains whose events are POCOs (plain old C# objects), JournaledGrain<StateType> can be used as a shorthand for JournaledGrain<StateType,Object> . Reading the Grain State To read the current grain state, and determine its version number, the JournaledGrain has properties GrainState State { get; } int Version { get; } The version number is always equal to the total number of confirmed events, and the state is the result of applying all the confirmed events to the initial state. The initial state, which has version 0 (because no events have been applied to it), is determined by the default constructor of the GrainState class. Important: The application should never directly modify the object returned by State . It is meant for reading only. Rather, when the application wants to modify the state, it must do so indirectly by raising events. Raising Events Raising events is accomplished by calling the RaiseEvent function. For example, a grain representing a chat can raise a PostedEvent to indicate that a user submitted a post: RaiseEvent(new PostedEvent() { Guid = guid, User = user, Text = text, Timestamp = DateTime.UtcNow }); Note that RaiseEvent kicks off a write to storage access, but does not wait for the write to complete. For many applications, it is important to wait until we have confirmation that the event has been persisted. In that case, we always follow up by waiting for ConfirmEvents : RaiseEvent(new DepositTransaction() { DepositAmount = amount, Description = description }); await ConfirmEvents(); Note that even if you don't explicitly call ConfirmEvents , the events will eventually be confirmed - it happens automatically in the background. For more discussion on this topic, see Immediate vs. Delayed Confirmation . State Transition Methods The runtime updates the grain state automatically whenever events are raised. There is no need for the application to explicitly update the state after raising an event. However, the application still has to provide the code that specifies how to update the state in response to an event. This can be done in two ways. (a) The GrainState class can implement one or more Apply methods on the StateType . Typically, one would create multiple overloads, and the closest match is chosen for the runtime type of the event: class GrainState { Apply(E1 @event) { // code that updates the state } Apply(E2 @event) { // code that updates the state } } (b) The grain can override the TransitionState function: protected override void TransitionState(State state, EventType @event) { // code that updates the state } The transition methods are assumed to have no side effects other than modifying the state object, and should be deterministic (otherwise, the effects are unpredictable). If the transition code throws an exception, that exception is caught and included in a warning in the Orleans log, issued by the log-consistency provider. When, exactly, the runtime calls the transition methods depends on the chosen log consistency provider and its configuration. It is best for applications not to rely on a particular timing, except when specifically guaranteed by the log consistency provider. Some providers, such as the LogStorage log-consistency provider, replay the event sequence every time the grain is loaded. Therefore, as long as the event objects can still be properly deserialized from storage, it is possibly to radically modify the GrainState class and the transition methods. But for other providers, such as the StateStorage log-consistency provider, only the GrainState object is persisted, so developers must ensure that it can be deserialized correctly when read from storage. Raising Multiple Events It is possible to make multiple calls to RaiseEvent before calling ConfirmEvents: RaiseEvent(e1); RaiseEvent(e2); await ConfirmEvents(); However, this is likely to cause two successive storage accesses, and it incurs a risk that the grain fails after writing only the first event. Thus, it is usually better to raise multiple events at once, using RaiseEvents(IEnumerable<EventType> events) This guarantees that the given sequence of events is written to storage atomically. Note that since the version number always matches the length of the event sequence, raising multiple events increases the version number by more than one at a time. Retrieving the Event Sequence The following method from the base JournaledGrain class allows the application to retrieve a specified segment of the sequence of all confirmed events: Task<IReadOnlyList<EventType>> RetrieveConfirmedEvents(int fromVersion, int toVersion) However, it is not supported by all log consistency providers. If not supported, or if the specified segment of the sequence is no longer available, a NotSupportedException is thrown. To retrieve all events up to the latest confirmed version, one would call await RetrieveConfirmedEvents(0, Version); Only confirmed events can be retrieved: an exception is thrown if toVersion is larger than the current value of the property Version . Since confirmed events never change, there are no races to worry about, even in the presence of multiple instances or delayed confirmation . However, in such situations, it is possible that the value of the property Version is larger by the time the await resumes than at the time RetrieveConfirmedEvents is called, so it may be advisable to save its value in a variable. See also the section on Concurrency Guarantees ."
  },
  "1.5/Documentation/Core-Features/Observers.html": {
    "href": "1.5/Documentation/Core-Features/Observers.html",
    "title": "Client Observers | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . There are situations in which a simple message/response pattern is not enough, and the client needs to receive asynchronous notifications. For example, a user might want to be notified when a new instant message has been published by a friend. Client observers is a mechanism that allows notifying clients asynchronously. An observer is a one-way asynchronous interface that inherits from IGrainObserver , and all its methods must be void. The grain sends a notification to the observer by invoking it like a grain interface method, except that it has no return value, and so the grain need not depend on the result. The Orleans runtime will ensure one-way delivery of the notifications. A grain that publishes such notifications should provide an API to add or remove observers. In addition, it is usually convenient to expose a method that allows an existing subscription to be cancelled. Grain developers may use the Orleans ObserverSubscriptionManager<T> generic class to simplify development of observed grain types. To subscribe to a notification, the client must first create a local C# object that implements the observer interface. It then calls a static method on the observer factory, CreateObjectReference() , to turn the C# object into a grain reference, which can then be passed to the subscription method on the notifying grain. This model can also be used by other grains to receive asynchronous notifications. Unlike in the client subscription case, the subscribing grain simply implements the observer interface as a facet, and passes in a reference to itself (e.g. this.AsReference<IMyGrainObserverInterface> ). Code Example Let's assume that we have a grain that periodicaly sends messages to clients. For simplicity, the message in our example will be a string. We first define the interface on the client that will receive the message. the interface will look like this public interface IChat : IGrainObserver { void ReceiveMessage(string message); } The only special thing is that the interface should inherit from IGrainObserver . Now any client that wants to observe those messages should implement a class which implements IChat . The simplest case would be something like this: public class Chat : IChat { public void ReceiveMessage(string message) { Console.WriteLine(message); } } Now on the server we should have a Grain which sends these chat messages to clients. The Grain also should have a mechanism for clients to subscribe and unsubscribe themselves to receive notifications. For subscription the Grain can use the utility class ObserverSubscriptionManager : class HelloGrain : Grain, IHello { private ObserverSubscriptionManager<IChat> _subsManager; public override async Task OnActivateAsync() { // We created the utility at activation time. _subsManager = new ObserverSubscriptionManager<IChat>(); await base.OnActivateAsync(); } // Clients call this to subscribe. public Task Subscribe(IChat observer) { _subsManager.Subscribe(observer); return TaskDone.Done; } //Also clients use this to unsubscribe themselves to no longer receive the messages. public Task UnSubscribe(IChat observer) { _subsManager.Unsubscribe(observer); return TaskDone.Done; } } To send the message to clients the Notify method of the ObserverSubscriptionManager<IChat> instance can be used. The method takes an Action<T> method or lambda expression (where T is of type IChat here). You can call any method on the interface to send it to clients. In our case we only have one method ReceiveMessage and our sending code on the server would look like this: public Task SendUpdateMessage(string message) { _subsManager.Notify(s => s.ReceiveMessage(message)); return TaskDone.Done; } Now our server has a method to send messages to observer clients, two methods for subscribing/unsubscribing and the client implemented a class to be able to observe the grain messages. The last step is to create an observer reference on the client using our previously implemented Chat class and let it receive the messages after subscribing it. The code would look like this: //First create the grain reference var friend = GrainClient.GrainFactory.GetGrain<IHello>(0); Chat c = new Chat(); //Create a reference for chat usable for subscribing to the observable grain. var obj = await GrainClient.GrainFactory.CreateObjectReference<IChat>(c); //Subscribe the instance to receive messages. await friend.Subscribe(obj); Now whenever our grain on the server calls the SendUpdateMessage method, all subscribed clients will receive the message. In our client code, the Chat instance in variable c will receive the message and output it to the console. Note: Objects passed to CreateObjectReference are held via a WeakReference<T> and will therefore be garbage collected if no other references exist. Users should maintain a reference for each observer which they do not want to be collected. Note: Observers are inherently unreliable since you don't get any response back to know if the message is received and processed or simply failed due to any condition which might arise in a distributed system. Because of that your observers should poll the grain periodically or use any other mechanism to ensure that they received all messages which they should have received. In some situations you can afford to lose some messages and you don't need any additional mechanism but if you need to make sure that all observers are always receiving the messages and are receiving all of them, both periodic resubscriptions and polling the observer grain, can help to ensure eventual processing of all messages."
  },
  "1.5/Documentation/Advanced-Concepts/Powershell-Client.html": {
    "href": "1.5/Documentation/Advanced-Concepts/Powershell-Client.html",
    "title": "PowerShell Client Module | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . PowerShell Client Module The Orleans PowerShell Client Module is a set of PowerShell Cmdlets that wraps GrainClient in a set of convenient commands making possible to interact with not just ManagementGrain but any IGrain just as a regular Orleans application can by using Powershell scripts. These Cmdlets enable a series of scenarios from start maintenance tasks, tests, monitoring or any other kind of automation by leveraging Powershell scripts. Here is how to use it: Installing the module From Source You can build from source the OrleansPSUtils project and just import it with: PS> Import-Module .\\projectOutputDir\\Orleans.psd1 Althought you can do that, there is a much easier and interesting way for doing that by installing it from PowerShell Gallery . From PowerShell Gallery Powershell modules today are easily shared just as Nuget packages but instead of nuget.org, they are hosted on PowerShell Gallery . To install it on a specific folder just run: PS> Save-Module -Name OrleansPSUtils -Path <path> To install it on your PowerShell modules path ( the recommended way ), just run: PS> Install-Module -Name OrleansPSUtils If you plan to use this module on an Azure Automation , just click on the button bellow: Using the module Regardless of the way you decide to install it, the first thing you need to do in order to actually use it is import the module on the current PowerShell session so the Cmdlets get available by running this: PS> Import-Module OrleansPSUtils Note : In case of building from source, you must import it as suggested on the Install section by using the path to the .psd1 instead of using the module name since it will not be on the $env:PSModulePath PowerShell runtime variable. Again, it is highly recommended that you install from PowerShell Gallery instead. After the module is imported (which means it is loaded on PowerShell session), you will have the following Cmdlets available: Start-GrainClient Stop-GrainClient Get-Grain Start-GrainClient This module is a wrapper around GrainClient.Initialize() and its overloads. Usage : Start-GrainClient The same as call GrainClient.Initialize() which will look for the known Orleans Client configuration file names Start-GrainClient [-ConfigFilePath] <string> [[-Timeout] <timespan>] Will use the provided file path as in GrainClient.Initialize(filePath) Start-GrainClient [-ConfigFile] <FileInfo> [[-Timeout] <timespan>] Use an instance of the System.FileInfo class representing the config file just as GrainClient.Initialize(fileInfo) Start-GrainClient [-Config] <ClientConfiguration> [[-Timeout] <timespan>] Use an instance of a Orleans.Runtime.Configuration.ClientConfiguration like in GrainClient.Initialize(config) Start-GrainClient [-GatewayAddress] <IPEndPoint> [[-OverrideConfig] <bool>] [[-Timeout] <timespan>] Takes a Orleans Cluster Gateway Address Endpoint Note : The Timeout parameter is optional and if it is informed and greater than System.TimeSpan.Zero , it will call Orleans.GrainClient.SetResponseTimeout(Timeout) internally. Stop-GrainClient Takes no parameters and when called, if the GrainClient is initialized will gracefuly uninitialize. Get-Grain Wrapper around GrainClient.GrainFactory.GetGrain<T>() and its overloads. The mandatory parameter is -GrainType and the -XXXKey for the current Grain key types supported by Orleans ( string , Guid , long ) and also the -KeyExtension that can be used on Grains with compound keys. This Cmdlet return a grain reference of the type passed by as parameter on -GrainType . Example: A simple example on calling MyInterfacesNamespace.IMyGrain.SayHeloTo grain method: PS> Import-Module OrleansPSUtils PS> $configFilePath = Resolve-Path(\".\\ClientConfig.xml\").Path PS> Start-GrainClient -ConfigFilePath $configFilePath PS> Add-Type -Path .\\MyGrainInterfaceAssembly.dll PS> $grainInterfaceType = [MyInterfacesNamespace.IMyGrain] PS> $grainId = [System.Guid]::Parse(\"A4CF7B5D-9606-446D-ACE9-C900AC6BA3AD\") PS> $grain = Get-Grain -GrainType $grainInterfaceType -GuidKey $grainId PS> $message = $grain.SayHelloTo(\"Gutemberg\").Result PS> Write-Output $message Hello Gutemberg! PS> Stop-GrainClient We plan to update this page as we introduce more Cmdlets like use Observers, Streams and other Orleans core features more natively on Powershell. We hope that this help people as a starting point for automation. As always, this is a work-in-progress and we love contributions! :) Please note that the intent is not to reimplement the whole client on PowerShell but instead, give IT and DevOps teams a way to interact with the Grains without need to implement a .Net application."
  },
  "Documentation/grains/grain_persistence/relational_storage.html": {
    "href": "Documentation/grains/grain_persistence/relational_storage.html",
    "title": "Relational Storage | Microsoft Orleans Documentation",
    "keywords": "Relational Storage Relational storage backend code in Orleans is built on generic ADO.NET functionality and is consequently database vendor agnostic. The Orleans data storage layout has been explained already in Runtime Tables. Setting up the connection strings are done as explained in Orleans Configuration Guide and SQL Tables . To make Orleans code function with a given relational database backend, the following is required: Appropriate ADO.NET library must be loaded to the process (multiple can exist in GAC or otherwise). This should be defined as usual, e.g. via DbProviderFactories element in application configuration. Configure the ADO.NET invariant via AdoInvariant attribute in the element defining the connection string, by default it is System.Data.SqlClient The database needs to exist and be compatible with the code. This is done by running a vendor specific database creation script. The scripts are found in the OrleansSqlUtils NuGet package and are published with every Orleans release. Currently there are two database scripts: SQL Server - CreateOrleansTables_SqlServer.sql . AdoInvariant is System.Data.SqlClient . MySQL - CreateOrleansTables_MySql.sql . AdoInvariant is MySql.Data.MySqlClient . If you need setup scripts for other ADO.NET supported databases, open an issue or please, stop by at Orleans Gitter . Goals of the design 1. Allow use of any backend that has a ADO.NET provider This should cover the broadest possible set of backends available for .NET, which is a factor in on-premises installations. Some providers are listed at ADO.NET Data Providers MSDN page , but for the sake of a remark, not all are listed, such as Teradata . 2. Maintain the potential to tune queries and database structure as appropriate, even while a deployment is running In many cases, the servers and databases are hosted by a third party in contractual relation with the client. It is not an unusual situation the hosting environment is virtualized and performance fluctuates due to unforeseen factors, such as noisy neighbors or faulty hardware. It may not be possible to alter and re-deploy either Orleans binaries (contractual reasons) or even application binaries, but usually it is possible to tweak the database deployment. Altering standard components , such as Orleans binaries, requires a lenghtier procedure as to what is afforded in a given situation. 3. Allow one to make use of vendor and version specific abilities Vendors have implemented different extensions and features within their products. It is sensible to make use of these features when they are available. These features are such as native UPSERT or PipelineDB in PostgreSQL, PolyBase or natively compiled tables and stored procedures in SQL Server – and myriads of other features. 4. Make it possible to optimize hardware resources When designing an application, it is often possible to anticipate which data needs to be inserted faster than other data and which data could be more likely put into cold storage which is cheaper (e.g. splitting data between SSD and HDD). As for an example, further considerations are that the physical location of some data could be more expensive (e.g. SSD RAID viz HDD RAID), more secured or some other decision attribute used. Related to point 3. Some databases offer special partitioning schemes, such as SQL Server Partitioned Tables and Indexes . This principle applies also throughout the application life-cycle. Considering one of the principles of Orleans itself is a high-availability system, it should be possible to adjust storage system without interruption to Orleans deployment or that it should be possible to adjust the queries according to data and other application parameters. One example of changes is in Brian Harry's blog post When a table is small, it almost doesn’t matter what the query plan is. When it’s medium an OK query plan is fine. When it's huge (millions upon millions or billions of rows) a tiny, slight variation in query plan can kill you. So, we hint our sensitive queries heavily. This is true in general. 5. No assumptions on what tools, libraries or deployment processes are used in organizations Many organizations have familiarity with a certain set of database tools, examples being Dacpac or Red Gate . It may be so that deploying a database requires either a permission or a person, such as someone in a DBA role, to do it. Usually this means also having the target database layout and a rough sketch of the queries the application will produce to the database to be used estimate the load. There might be processes, perhaps influenced by industry standards, which mandate script based deployment. Having the queries and database structures in an external script makes this possible. 6. Use the minimum set needed of interface functionality to load the ADO.NET libraries and functionality This is both fast and has less surface to be exposed to ADO.NET library implementation discrepancies. 7. Make the design shardable When it makes sense, for instance in relational storage provider, make the design readily shardable. This means for instance no database dependent data (e.g. IDENTITY ) and basically it means the information that distinguishes row data should build on only data from the actual parameters. 8. Make the design easy to test Creating a new backend should be ideally as easy as translating one of the deployment scripts and adding a new connection string to tests assuming default parameters, check if a given database is installed and then run the tests against it. 9. Taking into account the previous points, make both porting scripts for new backends and modifying already deployed backend scripts as transparent as possible Realization of the goals Orleans framework does not have knowledge of deployment specific hardware (which may change during active deployment), the change of data during the deployment life-cycle and some vendor specific features are usable in only some situations. For this reason, the interface between relational database and Orleans should adhere a minimum set of abstractions and rules to meet the goals but to make it also robust against misuse and easy to test if needed. Runtime Tables, Cluster Management and the concrete membership protocol implementation . Also, the SQL Server implementation contains SQL Server edition specific tuning. The interface contract between the database and Orleans is defined as follows: The general idea is that data is read and written through Orleans specific queries. Orleans operates on column names and types when reading and on parameter names and types when writing. The implementations must preserve input and output names and types. Orleans uses these parameters to reads query results by name and type. Vendor and deployment specific tuning is allowed and contributions are encouraged as long as the interface contract is maintained. The implementation across vendor specific scripts should preserve the constraint names. This simplifies troubleshooting by virtue of uniform naming across concrete implementations. Version – or ETag in application code – for Orleans represents a unique version. The type of its actual implementation is not important as long as it represents a unique version. In the implementation Orleans code excepts a signed 32-bit integer. For the sake of being explicit and removing ambiguity, Orleans expects some queries to return either TRUE as > 0 value or FALSE as = 0 value. That is, affected rows or such does not matter. If an error is raised or an exception is thrown the query must ensure the entire transaction is rolled back and may either return FALSE or propagate the exception. Currently all but one query are single row inserts or updates (note, one could replace UPDATE queries with INSERT ones provided the associated SELECT queries would provide the last write) except for statistic inserts. Statistic insert, as defined by InsertOrleansStatisticsKey writes the statistics in batches of predefined maximum size using UNION ALL for all databases except for Oracle, for which a UNION ALL FROM DUAL construct is used. InsertOrleansStatisticsKey is the only query that defines a kind of a template parameters of which Orleans multiplies as many times as there are parameters with differing values. Database engines support in-database programming, this is is similar to an idea of loading an executable script and invoke it to execute database operations. In pseudocode it could be depicted as const int Param1 = 1; const DateTime Param2 = DateTime.UtcNow; const string queryFromOrleansQueryTableWithSomeKey = \"SELECT column1, column2 FROM <some Orleans table> where column1 = @param1 AND column2 = @param2;\"; TExpected queryResult = SpecificQuery12InOrleans<TExpected>(query, Param1, Param2); These principles are also included in the database scripts . Some ideas on applying customized scripts Alter scripts in OrleansQuery for grain persistence with IF ELSE so that some state is saved using the default INSERT while some grain state uses, for instance, memory optimized tables . The SELECT queries need to be altered accordingly. The idea in 1. can be used to take advantage of other deployment or vendor specific aspects. Such as splitting data between SSD or HDD , putting some data on encrypted tables, or perhaps inserting statistics data via SQL Server to Hadoop or even linked servers . The altered scripts can be tested running the Orleans test suite or straight in the database using, for instance, SQL Server Unit Test Project . Guidelines for adding new ADO.NET providers Add a new database setup script according to the Realization of the goals section above. Add the vendor ADO invariant name to AdoNetInvariants and ADO.NET provider specific data to DbConstantsStore . These are (potentially) used in some query operations. e.g. to select the correct statistics insert mode (i.e. the UNION ALL with or without FROM DUAL ). Orleans has comprehensive tests for all system stores: membership, reminders and statistics. Adding tests for the new database script is done by copy-pasting existing test classes and changing the ADO invariant name. Also, derive from RelationalStorageForTesting in order to define test functionality for the ADO invariant."
  },
  "Documentation/grains/grain_persistence/index.html": {
    "href": "Documentation/grains/grain_persistence/index.html",
    "title": "Grain Persistence | Microsoft Orleans Documentation",
    "keywords": "Grain Persistence Goals Allow different grain types to use different types of storage providers (e.g., one uses Azure table, and one uses an ADO.NET one) or the same type of storage provider but with different configurations (e.g., both use Azure table, but one uses storage account #1 and one uses storage account #2) Allow configuration of a storage provider instance to be swapped (e.g., Dev-Test-Prod) with just config file changes, and no code changes required. Provide a framework to allow additional storage providers to be written later, either by the Orleans team or others. Provide a minimal set of production-grade storage providers Storage providers have complete control over how they store grain state data in persistent backing store. Corollary: Orleans is not providing a comprehensive ORM storage solution, but allows custom storage providers to support specific ORM requirements as and when required. Grain Persistence API Grain types can be declared in one of two ways: Extend Grain if they do not have any persistent state, or if they will handle all persistent state themselves, or Extend Grain<T> if they have some persistent state that they want the Orleans runtime to handle. Stated another way, by extending Grain<T> a grain type is automatically opted-in to the Orleans system managed persistence framework. For the remainder of this section, we will only be considering Option #2 / Grain<T> because Option #1 grains will continue to run as now without any behavior changes. Grain State Storage Grain classes that inherit from Grain<T> (where T is an application-specific state data type that needs to be persisted) will have their state loaded automatically from a specified storage. Grains will be marked with a [StorageProvider] attribute that specifies a named instance of a storage provider to use for reading / writing the state data for this grain. [StorageProvider(ProviderName=\"store1\")] public class MyGrain<MyGrainState> ... { ... } The Orleans framework provides a mechanism to specify & register different storage providers and configure them using ISiloHostBuilder , var silo = new SiloHostBuilder() .AddMemoryGrainStorage(\"DevStore\") .AddAzureTableGrainStorage(\"store1\", options => options.ConnectionString = \"DefaultEndpointsProtocol=https;AccountName=data1;AccountKey=SOMETHING1\") .AddAzureBlobGrainStorage(\"store2\", options => options.ConnectionString = \"DefaultEndpointsProtocol=https;AccountName=data2;AccountKey=SOMETHING2\") .Build(); Configuring IGrainStorage Providers Orleans natively supports a range of IGrainStorage implementations, which you can use for your application to store grain state. In this section, we will go over how to configure AzureTableGrainStorage , AzureBlobGrainStorage , DynamoDBGrainStorage , MemoryGrainStorage , and AdoNetGrainStorage in a silo. Configuration of other IGrainStorage providers is similar. AzureTableGrainStorage Provider var silo = new SiloHostBuilder() .AddAzureTableGrainStorage(\"TableStore\", options => options.ConnectionString = \"UseDevelopmentStorage=true\") ... .Build(); The following settings are available for configuring AzureTableGrainStorage providers, through AzureTableGrainStorageOptions : /// <summary> /// Configuration for AzureTableGrainStorage /// </summary> public class AzureTableStorageOptions { /// <summary> /// Azure table connection string /// </summary> [RedactConnectionString] public string ConnectionString { get; set; } /// <summary> /// Table name where grain stage is stored /// </summary> public string TableName { get; set; } = DEFAULT_TABLE_NAME; public const string DEFAULT_TABLE_NAME = \"OrleansGrainState\"; /// <summary> /// Indicates if grain data should be deleted or reset to defaults when a grain clears it's state. /// </summary> public bool DeleteStateOnClear { get; set; } = false; /// <summary> /// Stage of silo lifecycle where storage should be initialized. Storage must be initialzed prior to use. /// </summary> public int InitStage { get; set; } = DEFAULT_INIT_STAGE; public const int DEFAULT_INIT_STAGE = ServiceLifecycleStage.ApplicationServices; #region json serialization public bool UseJson { get; set; } public bool UseFullAssemblyNames { get; set; } public bool IndentJson { get; set; } public TypeNameHandling? TypeNameHandling { get; set; } #endregion json serialization } Note: State size should not exceed 64KB, a limit imposed by Azure Table Storage. AzureBlobGrainStorage Provider var silo = new SiloHostBuilder() .AddAzureBlobGrainStorage(\"BlobStore\", options => options.ConnectionString = \"UseDevelopmentStorage=true\") ... .Build(); The following settings are available for configuring AzureBlobGrainStorage providers, through AzureBlobStorageOptions : public class AzureBlobStorageOptions { /// <summary> /// Azure connection string /// </summary> [RedactConnectionString] public string ConnectionString { get; set; } /// <summary> /// Container name where grain stage is stored /// </summary> public string ContainerName { get; set; } = DEFAULT_CONTAINER_NAME; public const string DEFAULT_CONTAINER_NAME = \"grainstate\"; /// <summary> /// Stage of silo lifecycle where storage should be initialized. Storage must be initialzed prior to use. /// </summary> public int InitStage { get; set; } = DEFAULT_INIT_STAGE; public const int DEFAULT_INIT_STAGE = ServiceLifecycleStage.ApplicationServices; #region json serialization public bool UseJson { get; set; } public bool UseFullAssemblyNames { get; set; } public bool IndentJson { get; set; } public TypeNameHandling? TypeNameHandling { get; set; } #endregion json serialization } DynamoDBGrainStorage Provider var silo = new SiloHostBuilder() .AddDynamoDBGrainStorage(\"DDBStore\", options => { options.AccessKey = \"MY_ACCESS_KEY\"; options.SecretKey = \"MY_SECRET_KEY\"; options.Service = \"us-wes-1\"; }) ... .Build(); The following settings are available for configuring DynamoDBGrainStorage providers, through DynamoDBStorageOptions : public class DynamoDBStorageOptions { /// <summary> /// Gets or sets a unique identifier for this service, which should survive deployment and redeployment. /// </summary> public string ServiceId { get; set; } = string.Empty; /// <summary> /// AccessKey string for DynamoDB Storage /// </summary> [Redact] public string AccessKey { get; set; } /// <summary> /// Secret key for DynamoDB storage /// </summary> [Redact] public string SecretKey { get; set; } /// <summary> /// DynamoDB Service name /// </summary> public string Service { get; set; } /// <summary> /// Read capacity unit for DynamoDB storage /// </summary> public int ReadCapacityUnits { get; set; } = DynamoDBStorage.DefaultReadCapacityUnits; /// <summary> /// Write capacity unit for DynamoDB storage /// </summary> public int WriteCapacityUnits { get; set; } = DynamoDBStorage.DefaultWriteCapacityUnits; /// <summary> /// DynamoDB table name. /// Defaults to 'OrleansGrainState'. /// </summary> public string TableName { get; set; } = \"OrleansGrainState\"; /// <summary> /// Indicates if grain data should be deleted or reset to defaults when a grain clears it's state. /// </summary> public bool DeleteStateOnClear { get; set; } = false; /// <summary> /// Stage of silo lifecycle where storage should be initialized. Storage must be initialzed prior to use. /// </summary> public int InitStage { get; set; } = DEFAULT_INIT_STAGE; public const int DEFAULT_INIT_STAGE = ServiceLifecycleStage.ApplicationServices; #region JSON Serialization public bool UseJson { get; set; } public bool UseFullAssemblyNames { get; set; } public bool IndentJson { get; set; } public TypeNameHandling? TypeNameHandling { get; set; } #endregion } ADO.NET Grain Storage Provider The ADO .NET Grain Storage provider allows you to store grain state in relational databases. Currently following databases are supported: SQL Server MySQL/MariaDB PostgreSQL Oracle First, install the base package: Install-Package Microsoft.Orleans.Persistence.AdoNet After you restore on the nuget package for your project, you will find different SQL scripts for the supported database vendors, which are copied to project directory \\OrleansAdoNetContent where each of supported ADO.NET extensions has its own directory.You can also get them from the Orleans.Persistence.AdoNet repository . Create a database, and then run the appropriate script to create the tables. The next steps are to install a second NuGet package (see table below) specific to the database vendor you want, and to configure the storage provider either programmatically or via XML configuration. Database Script NuGet Package AdoInvariant Remarks SQL Server SQLServer-Persistence.sql System.Data.SqlClient System.Data.SqlClient MySQL / MariaDB MySQL-Persistence.sql MySql.Data MySql.Data.MySqlClient PostgreSQL PostgreSQL-Persistence.sql Npgsql Npgsql Oracle Oracle-Persistence.sql ODP.net Oracle.DataAccess.Client No .net Core support The following is an example of how to configure an ADO.NET storage provider via ISiloHostBuilder : var siloHostBuilder = new SiloHostBuilder() .AddAdoNetGrainStorage(\"OrleansStorage\", options=> { options.Invariant = \"<Invariant>\"; options.ConnectionString = \"<ConnectionString>\"; options.UseJsonFormat = true; }); Essentially, you only need to set the database-vendor-specific connection string and an Invariant (see table above) that identifies the vendor. You may also choose the format in which the data is saved, which may be either binary (default), JSON, or XML. While binary is the most compact option, it is opaque and you will not be able to read or work with the data. JSON is the recommended option. You can set the following properties via AdoNetGrainStorageOptions : /// <summary> /// Options for AdonetGrainStorage /// </summary> public class AdoNetGrainStorageOptions { /// <summary> /// Connection string for AdoNet storage. /// </summary> [Redact] public string ConnectionString { get; set; } /// <summary> /// Stage of silo lifecycle where storage should be initialized. Storage must be initialzed prior to use. /// </summary> public int InitStage { get; set; } = DEFAULT_INIT_STAGE; /// <summary> /// Default init stage in silo lifecycle. /// </summary> public const int DEFAULT_INIT_STAGE = ServiceLifecycleStage.ApplicationServices; /// <summary> /// The default ADO.NET invariant used for storage if none is given. /// </summary> public const string DEFAULT_ADONET_INVARIANT = AdoNetInvariants.InvariantNameSqlServer; /// <summary> /// The invariant name for storage. /// </summary> public string Invariant { get; set; } = DEFAULT_ADONET_INVARIANT; #region json serialization related settings /// <summary> /// Whether storage string payload should be formatted in JSON. /// <remarks>If neither <see cref=\"UseJsonFormat\"/> nor <see cref=\"UseXmlFormat\"/> is set to true, then BinaryFormatSerializer will be configured to format storage string payload.</remarks> /// </summary> public bool UseJsonFormat { get; set; } public bool UseFullAssemblyNames { get; set; } public bool IndentJson { get; set; } public TypeNameHandling? TypeNameHandling { get; set; } #endregion /// <summary> /// Whether storage string payload should be formatted in Xml. /// <remarks>If neither <see cref=\"UseJsonFormat\"/> nor <see cref=\"UseXmlFormat\"/> is set to true, then BinaryFormatSerializer will be configured to format storage string payload.</remarks> /// </summary> public bool UseXmlFormat { get; set; } } The ADO.NET persistence has functionality to version data and define arbitrary (de)serializers with arbitrary application rules and streaming, but currently there is no method to expose them to application code. More information in ADO.NET Persistence Rationale . MemoryGrainStorage MemoryGrainStorage is a simple grain storage implementation which does not really use a persistent data store underneath. It is convenient to learn to work with Grain Storages quickly, but is not intended to be used in production scenarios. Note: This provider persists state to volatile memory which is erased at silo shut down. Use only for testing. Here's how to set up a memory storage provider via ISiloHostBuilder var siloHostBuilder = new SiloHostBuilder() .AddMemoryGrainStorage(\"OrleansStorage\", options=>options.NumStorageGrains = 10); You can set the following configuration properties via MemoryGrainStorageOptions /// <summary> /// Options for MemoryGrainStorage /// </summary> public class MemoryGrainStorageOptions { /// <summary> /// Default number of queue storage grains. /// </summary> public const int NumStorageGrainsDefaultValue = 10; /// <summary> /// Number of store grains to use. /// </summary> public int NumStorageGrains { get; set; } = NumStorageGrainsDefaultValue; /// <summary> /// Stage of silo lifecycle where storage should be initialized. Storage must be initialzed prior to use. /// </summary> public int InitStage { get; set; } = DEFAULT_INIT_STAGE; /// <summary> /// Default init stage /// </summary> public const int DEFAULT_INIT_STAGE = ServiceLifecycleStage.ApplicationServices; } Notes on Storage Providers If there is no [StorageProvider] attribute specified for a Grain<T> grain class, then a provider named Default will be searched for instead. If not found then this is treated as a missing storage provider. If a storage provider referenced by a grain class is not added to silo at configuration time, grains of that type will fail to activate at run time, and calls to them will be failing an Orleans.Storage.BadProviderConfigException error specifying that the grain type is not loaded. But the rest of the grain types will not be affected. Different grain types can use different configured storage providers, even if both are the same type: for example, two different Azure table storage provider instances, connected to different Azure storage accounts (see config file example above). All configuration details for storage providers is defined through ISiloHostBuilder. There are no mechanisms provided at this time to dynamically update or change the list of storage providers used by a silo. However, this is a prioritization / workload constraint rather than a fundamental design constraint. State Persitence API There are two parts to the state persistence APIs: grain state API and storage provider API. Grain State API The grain state storage functionality in the Orleans Runtime will provide read and write operations to automatically populate / save the GrainState data object for that grain. Under the covers, these functions will be connected (within the code generated by Orleans client-gen tool) through to the appropriate persistence provider configured for that grain. Grain State Read / Write Functions Grain state will automatically be read when the grain is activated, but grains are responsible for explicitly triggering the write for any changed grain state as and when necessary. See the Failure Modes section below for details of error handling mechanisms. GrainState will be read automatically (using the equivalent of base.ReadStateAsync() ) before the OnActivateAsync() method is called for that activation. GrainState will not be refreshed before any method calls to that grain, unless the grain was activated for this call. During any grain method call, a grain can request the Orleans runtime to write the current grain state data for that activation to the designated storage provider by calling base.WriteStateAsync() . The grain is responsible for explicitly performing write operations when they make significant updates to their state data. Most commonly, the grain method will return the base.WriteStateAsync() Task as the final result Task returned from that grain method, but it is not required to follow this pattern. The runtime will not automatically update stored grain state after any grain methods. During any grain method or timer callback handler in the grain, the grain can request the Orleans runtime to re-read the current grain state data for that activation from the designated storage provider by calling base.ReadStateAsync() . This will completely overwrite any current state data currently stored in the grain state object with the latest values read from persistent store. An opaque provider-specific Etag value ( string ) may be set by a storage provider as part of the grain state metadata populated when state was read. Some providers may choose to leave this as null if they do not use Etag s. Conceptually, the Orleans Runtime will take a deep copy of the grain state data object for its own use during any write operations. Under the covers, the runtime may use optimization rules and heuristics to avoid performing some or all of the deep copy in some circumstances, provided that the expected logical isolation semantics are preserved. Sample Code for Grain State Read / Write Operations Grains must extend the Grain<T> class in order to participate in the Orleans grain state persistence mechanisms. The T in the above definition will be replaced by an application-specific grain state class for this grain; see the example below. The grain class should also be annotated with a [StorageProvider] attribute that tells the runtime which storage provider (instance) to use with grains of this type. public class MyGrainState { public int Field1 { get; set; } public string Field2 { get; set; } } [StorageProvider(ProviderName=\"store1\")] public class MyPersistenceGrain : Grain<MyGrainState>, IMyPersistenceGrain { ... } Grain State Read The initial read of the grain state will occur automatically by the Orleans runtime before the grain’s OnActivateAsync() method is called; no application code is required to make this happen. From that point forward, the grain’s state will be available through the Grain<T>.State property inside the grain class. Grain State Write After making any appropriate changes to the grain’s in-memory state, the grain should call the base.WriteStateAsync() method to write the changes to the persistent store via the defined storage provider for this grain type. This method is asynchronous and returns a Task that will typically be returned by the grain method as its own completion Task. public Task DoWrite(int val) { State.Field1 = val; return base.WriteStateAsync(); } Grain State Refresh If a grain wishes to explicitly re-read the latest state for this grain from backing store, the grain should call the base.ReadStateAsync() method. This will reload the grain state from persistent store, via the defined storage provider for this grain type, and any previous in-memory copy of the grain state will be overwritten and replaced when the ReadStateAsync() Task completes. public async Task<int> DoRead() { await base.ReadStateAsync(); return State.Field1; } Failure Modes for Grain State Persistence Operations Failure Modes for Grain State Read Operations Failures returned by the storage provider during the initial read of state data for that particular grain will result in the activate operation for that grain to be failed; in this case, there will not be any call to that grain’s OnActivateAsync() life cycle callback method. The original request to that grain which caused the activation will be faulted back to the caller the same way as any other failure during grain activation. Failures encountered by the storage provider to read state data for a particular grain will result in the ReadStateAsync() Task to be faulted. The grain can choose to handle or ignore that faulted Task , just like any other Task in Orleans. Any attempt to send a message to a grain which failed to load at silo startup time due to a missing / bad storage provider config will return the permanent error Orleans.BadProviderConfigException . Failure Modes for Grain State Write Operations Failures encountered by the storage provider to write state data for a particular grain will result in the WriteStateAsync() Task to be faulted. Usually, this will mean the grain call will be faulted back to the client caller provided the WriteStateAsync() Task is correctly chained in to the final return Task for this grain method. However, it will be possible for certain advanced scenarios to write grain code to specifically handle such write errors, just like they can handle any other faulted Task . Grains that execute error-handling / recovery code must catch exceptions / faulted WriteStateAsync() Task s and not re-throw to signify that they have successfully handled the write error. Storage Provider API There is a service provider API for writing additional persistence providers – IGrainStorage . The Persistence Provider API covers read and write operations for GrainState data. /// <summary> /// Interface to be implemented for a storage able to read and write Orleans grain state data. /// </summary> public interface IGrainStorage { /// <summary>Read data function for this storage instance.</summary> /// <param name=\"grainType\">Type of this grain [fully qualified class name]</param> /// <param name=\"grainReference\">Grain reference object for this grain.</param> /// <param name=\"grainState\">State data object to be populated for this grain.</param> /// <returns>Completion promise for the Read operation on the specified grain.</returns> Task ReadStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); /// <summary>Write data function for this storage instance.</summary> /// <param name=\"grainType\">Type of this grain [fully qualified class name]</param> /// <param name=\"grainReference\">Grain reference object for this grain.</param> /// <param name=\"grainState\">State data object to be written for this grain.</param> /// <returns>Completion promise for the Write operation on the specified grain.</returns> Task WriteStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); /// <summary>Delete / Clear data function for this storage instance.</summary> /// <param name=\"grainType\">Type of this grain [fully qualified class name]</param> /// <param name=\"grainReference\">Grain reference object for this grain.</param> /// <param name=\"grainState\">Copy of last-known state data object for this grain.</param> /// <returns>Completion promise for the Delete operation on the specified grain.</returns> Task ClearStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); } Storage Provider Semantics Any attempt to perform a write operation when the storage provider detects an Etag constraint violation should cause the write Task to be faulted with transient error Orleans.InconsistentStateException and wrapping the underlying storage exception. public class InconsistentStateException : AggregateException { /// <summary>The Etag value currently held in persistent storage.</summary> public string StoredEtag { get; private set; } /// <summary>The Etag value currently held in memory, and attempting to be updated.</summary> public string CurrentEtag { get; private set; } public InconsistentStateException( string errorMsg, string storedEtag, string currentEtag, Exception storageException ) : base(errorMsg, storageException) { this.StoredEtag = storedEtag; this.CurrentEtag = currentEtag; } public InconsistentStateException(string storedEtag, string currentEtag, Exception storageException) : this(storageException.Message, storedEtag, currentEtag, storageException) { } } Any other failure conditions from a write operation should cause the write Task to be broken with an exception containing the underlying storage exception. Data Mapping Individual storage providers should decide how best to store grain state – blob (various formats / serialized forms) or column-per-field are obvious choices. The basic storage provider for Azure Table encodes state data fields into a single table column using Orleans binary serialization. ADO.NET Persistence Rationale The principles for ADO.NET backed persistence storage are: Keep business critical data safe an accessible while data, the format of data and code evolve. Take advantenge of vendor and storage specific functionality. In practice this means adhering to ADO.NET implementation goals and some added implementation logic in ADO.NET specific storage provider that allow evolving the shape of the data in the storage. In addition to the usual storage provider capabilities, the ADO.NET provider has built-in capability to Change storage data format from one format to another format (e.g. from JSON to binary) when roundtripping state. Shape the type to be saved or read from the storage in arbitrary ways. This helps to evolve the version state. Stream data out of the database. Both 1. and 2. can be applied on arbitrary decision parameters, such as grain ID , grain type , payload data . This happen so that one chooses a format, e.g. Simple Binary Encoding (SBE) and implements IStorageDeserializer and IStorageSerializer . The built-in (de)serializers have been built using this method. The OrleansStorageDefault (De)Serializer can be used as examples on how to implement other formats. When the (de)serializers have been implemented, they need to ba added to the StorageSerializationPicker property in AdoNetGrainStorage . This is an implementation of IStorageSerializationPicker . By default StorageSerializationPicker will be used. And example of changing data storage format or using (de)serializers can be seen at RelationalStorageTests . Currently there is no method to expose this to Orleans application consumption as there is no method to access the framework created AdoNetGrainStorage ."
  },
  "Documentation/clusters_and_clients/configuration_guide/configuring_ADO.NET_providers.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/configuring_ADO.NET_providers.html",
    "title": "Configuring ADO.NET Providers | Microsoft Orleans Documentation",
    "keywords": "Configuring ADO.NET Providers Any reliable deployment of Orleans requires using persistent storage to keep system state, specifically Orleans cluster membership table and reminders. One of the available options is using a SQL database via the ADO.NET providers. In order to use ADO.NET for persistence, clustering or reminders, one needs to configure the ADO.NET providers as part of the silo configuration, and, in case of clustering, also as part of the client configurations. The silo configuration code should look like this: var siloHostBuilder = new SiloHostBuilder(); var invariant = \"System.Data.SqlClient\"; // for Microsoft SQL Server var connectionString = \"Data Source=(localdb)\\MSSQLLocalDB;Initial Catalog=Orleans;Integrated Security=True;Pooling=False;Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\"; //use AdoNet for clustering siloHostBuilder.UseAdoNetClustering(options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); //use AdoNet for reminder service siloHostBuilder.UseAdoNetReminderService(options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); //use AdoNet for Persistence siloHostBuilder.AddAdoNetGrainStorage(\"GrainStorageForTest\", options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); The client configuration code should look like this: var siloHostBuilder = new SiloHostBuilder(); var invariant = \"System.Data.SqlClient\"; var connectionString = \"Data Source=(localdb)\\MSSQLLocalDB;Initial Catalog=Orleans;Integrated Security=True;Pooling=False;Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\"; //use AdoNet for clustering siloHostBuilder.UseAdoNetClustering(options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); Where the ConnectionString is set to a valid AdoNet Server connection string. In order to use ADO.NET providers for persistence, reminders or clustering, there are scripts for creating database artifacts, to which all servers that will be hosting Orleans silos need to have access. Lack of access to the target database is a typical mistake we see developers making. The scripts will be copied to project directory \\OrleansAdoNetContent where each supported ADO.NET extensions has its own directory, after you install or do a nuget restore on the AdoNet extension nugets. We split AdoNet nugets into per feature nugets: Microsoft.Orleans.Clustering.AdoNet for clustering, Microsoft.Orleans.Persistence.AdoNet for persistence and Microsoft.Orleans.Reminders.AdoNet for reminders."
  },
  "Documentation/clusters_and_clients/index.html": {
    "href": "Documentation/clusters_and_clients/index.html",
    "title": "Clusters and Clients | Microsoft Orleans Documentation",
    "keywords": "This is the overview page about Clusters and Clients."
  },
  "Documentation/clusters_and_clients/heterogeneous_silos.html": {
    "href": "Documentation/clusters_and_clients/heterogeneous_silos.html",
    "title": "Heterogeneous silos | Microsoft Orleans Documentation",
    "keywords": "Heterogeneous silos Overview On a given cluster, silos can support a different set of grain types: In this example the cluster supports grains of type A , B , C , D , E : Grain types A and B can be placed on Silo 1 and 2. Grain type C can be placed on Silo 1, 2 or 3. Grain type D can be only placed on Silo 3 Grain Type E can be only placed on Silo 4. All silos should reference interfaces of all grain types of the cluster, but grain classes should only be referenced by the silos that will host them. The client does not know which silo supports a given Grain Type. A given Grain Type implementation must be the same on each silo that supports it. The following scenario is NOT valid: On Silo 1 and 2: public class C: Grain, IMyGrainInterface { public Task SomeMethod() { … } } On Silo 3 public class C: Grain, IMyGrainInterface, IMyOtherGrainInterface { public Task SomeMethod() { … } public Task SomeOtherMethod() { … } } Configuration No configuration is needed, you can deploy different binaries on each silo in your cluster. However, if necessary, you can change the interval that silos and clients check for changes in types supported with the property TypeMapRefreshInterval from TypeManagementOptions For testing purposes, you can use the property ExcludedGrainTypes in GrainClassOptions , which is a list names of the types you want to exclude on the silos. Limitations Connected clients will not be notified if the set of supported Grain Types changed. In the previous example: If Silo 4 leaves the cluster, the client will still try to make calls to grain of type E . It will fail at runtime with a OrleansException. If the client was connected to the cluster before Silo 4 joined it, the client will not be able to make calls to grain of type E . It will fail will a ArgumentException Stateless grains are not supported: all silos in the cluster must support the same set of stateless grains."
  },
  "Documentation/Benefits.html": {
    "href": "Documentation/Benefits.html",
    "title": "Main Benefits | Microsoft Orleans Documentation",
    "keywords": "Benefits The main benefits of Orleans are: developer productivity , even for non-expert programmers; and transparent scalability by default with no special effort from the programmer. We expand on each of these benefits below. Developer Productivity The Orleans programming model raises productivity of both expert and non-expert programmers by providing the following key abstractions, guarantees and system services. Familiar object-oriented programming (OOP) paradigm . Actors are .NET classes that implement declared .NET actor interfaces with asynchronous methods. Thus actors appear to the programmer as remote objects whose methods can be directly invoked. This provides the programmer the familiar OOP paradigm by turning method calls into messages, routing them to the right endpoints, invoking the target actor’s methods and dealing with failures and corner cases in a completely transparent way. Single-threaded execution of actors . The runtime guarantees that an actor never executes on more than one thread at a time. Combined with the isolation from other actors, the programmer never faces concurrency at the actor level, and hence never needs to use locks or other synchronization mechanisms to control access to shared data. This feature alone makes development of distributed applications tractable for non-expert programmers. Transparent activation . The runtime activates an actor as-needed, only when there is a message for it to process. This cleanly separates the notion of creating a reference to an actor, which is visible to and controlled by application code, and physical activation of the actor in memory, which is transparent to the application. In many ways, this is similar to virtual memory in that it decides when to “page out” (deactivate) or “page in” (activate) an actor; the application has uninterrupted access to the full “memory space” of logically created actors, whether or not they are in the physical memory at any particular point in time. Transparent activation enables dynamic, adaptive load balancing via placement and migration of actors across the pool of hardware resources. This features is a significant improvement on the traditional actor model, in which actor lifetime is application-managed. Location transparency . An actor reference (proxy object) that the programmer uses to invoke the actor’s methods or pass to other components only contains the logical identity of the actor. The translation of the actor’s logical identity to its physical location and the corresponding routing of messages are done transparently by the Orleans runtime. Application code communicates with actors oblivious to their physical location, which may change over time due to failures or resource management, or because an actor is deactivated at the time it is called. Transparent integration with persistent store . Orleans allows for declarative mapping of actors’ in-memory state to persistent store. It synchronizes updates, transparently guaranteeing that callers receive results only after the persistent state has been successfully updated. Extending and/or customizing the set of existing persistent storage providers available is straight-forward. Automatic propagation of errors . The runtime automatically propagates unhandled errors up the call chain with the semantics of asynchronous and distributed try/catch. As a result, errors do not get lost within an application. This allows the programmer to put error handling logic at the appropriate places, without the tedious work of manually propagating errors at each level. Transparent Scalability by Default The Orleans programming model is designed to guide the programmer down a path of likely success in scaling their application or service through several orders of magnitude. This is done by incorporating the proven best practices and patterns, and providing an efficient implementation of the lower level system functionality. Here are some key factors that enable scalability and performance. Implicit fine grain partitioning of application state . By using actors as directly addressable entities, the programmer implicitly breaks down the overall state of their application. While the Orleans programming model does not prescribe how big or small an actor should be, in most cases it makes sense to have a relative large number of actors – millions or more – with each representing a natural entity of the application, such as a user account, a purchase order, etc. With actors being individually addressable and their physical location abstracted away by the runtime, Orleans has enormous flexibility in balancing load and dealing with hot spots in a transparent and generic way without any thought from the application developer. Adaptive resource management . With actors making no assumption about locality of other actors they interact with and because of the location transparency, the runtime can manage and adjust allocation of available HW resources in a very dynamic way by making fine grain decisions on placement/migration of actors across the compute cluster in reaction to load and communication patterns without failing incoming requests. By creating multiple replicas of a particular actor the runtime can increase throughput of the actor if necessary without making any changes to the application code. Multiplexed communication . Actors in Orleans have logical endpoints, and messaging between them is multiplexed across a fixed set of all-to-all physical connections (TCP sockets). This allows the runtime to host a very large number (millions) of addressable entities with low OS overhead per actor. In addition, activation/deactivation of an actor does not incur the cost of registering/unregistering of a physical endpoint, such as a TCP port or a HTTP URL, or even closing a TCP connection. Efficient scheduling . The runtime schedules execution of a large number of single-threaded actors across a custom thread pool with a thread per physical processor core. With actor code written in the non-blocking continuation based style (a requirement of the Orleans programming model) application code runs in a very efficient “cooperative” multi-threaded manner with no contention. This allows the system to reach high throughput and run at very high CPU utilization (up to 90%+) with great stability. The fact that a growth in the number of actors in the system and the load does not lead to additional threads or other OS primitives helps scalability of individual nodes and the whole system. Explicit asynchrony . The Orleans programming model makes the asynchronous nature of a distributed application explicit and guides programmers to write non-blocking asynchronous code. Combined with asynchronous messaging and efficient scheduling, this enables a large degree of distributed parallelism and overall throughput without the explicit use of multi-threading."
  },
  "Documentation/streaming/index.html": {
    "href": "Documentation/streaming/index.html",
    "title": "Orleans Streams | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Orleans v.1.0.0 added support for streaming extensions to the programing model. Streaming extensions provide a set of abstractions and APIs that make thinking about and working with streams simpler and more robust. Streaming extensions allow developers to write reactive applications that operate on a sequence of events in a structured way. The extensibility model of stream providers makes the programming model compatible with and portable across a wide range of existing queuing technologies, such as Event Hubs , ServiceBus , Azure Queues , and Apache Kafka . There is no need to write special code or run dedicated processes to interact with such queues. Why should I care? If you already know all about Stream Processing and are familiar with technologies like Event Hubs , Kafka , Azure Stream Analytics , Apache Storm , Apache Spark Streaming , and Reactive Extensions (Rx) in .NET , you may be asking why should you care. Why do we need yet another Stream Processing System and how Actors are related to Streams? \"Why Orleans Streams?\" is meant to answer that question. Programming Model There is a number of principles behind Orleans Streams Programming Model. Orleans streams are virtual . That is, a stream always exists. It is not explicitly created or destroyed, and it can never fail. Streams are identified by stream IDs, which are just logical names comprised of GUIDs and strings. Orleans Streams allow to decouple generation of data from its processing both in time and space . That means that stream producer and stream consumer may be on different servers, in different times and will withstand failures. Orleans streams are lightweight and dynamic . Orleans Streaming Runtime is designed to handle a large number of streams that come and go at a high rate. Orleans stream bindings are dynamic . Orleans Streaming Runtime is designed to handle cases where grains connect to and disconnect from streams at a high rate. Orleans Streaming Runtime transparently manages the lifecycle of stream consumption . After an application subscribes to a stream, from then on it will receive the stream's events, even in presence of failures. Orleans streams work uniformly across grains and Orleans clients . Programming APIs Applications interact with streams via APIs that are very similar to the well known Reactive Extensions (Rx) in .NET , by using Orleans.Streams.IAsyncStream<T> that implements Orleans.Streams.IAsyncObserver<T> and Orleans.Streams.IAsyncObservable<T> interfaces. In a typical example below a device generates some data, which is sent as an HTTP request to the service running in the Cloud. Orleans client running in the front end server receives this HTTP call and publishes the data into a matching device stream: public async Task OnHttpCall(DeviceEvent deviceEvent) { // Post data directly into device's stream. IStreamProvider streamProvider = GrainClient.GetStreamProvider(\"myStreamProvider\"); IAsyncStream<DeviceEventData> deviceStream = streamProvider.GetStream<DeviceEventData>(deviceEvent.DeviceId); await deviceStream.OnNextAsync(deviceEvent.Data); } In another example below a chat user (implemented as Orleans Grain) joins a chat room, gets a handle to a stream of chat messages generated by all others users in this room and subscribes to it. Notice that the chat user neither does not need to know about the chat room grain itself (there might not be such a grain in our system) nor about other user in that group that produce messages. Needless to say, to produce to the chat stream, users don't need to know who is currently subscribed to the stream. This demonstrates how chat users can be completely decoupled in time and space. public class ChatUser: Grain { public async Task JoinChat(string chatGroupName) { IStreamProvider streamProvider = base.GetStreamProvider(\"myStreamProvider\"); IAsyncStream<string> chatStream = streamProvider.GetStream<string>(chatGroupName); await chatStream.SubscribeAsync((string chatEvent) => Console.Out.Write(chatEvent)); } } Quick Start Sample The Quick Start Sample is a good quick overview of the overall workflow of using streams in the application. After reading it you should read the Streams Programming APIs to get a deeper understanding of the concepts. Streams Programming APIs A Streams Programming APIs provides detailed description of the programming APIs. Stream Providers Streams can come via physical channels of various shapes and forms and can have different semantics. Orleans Streaming is designed to support this diversity via the concept of Stream Providers , which is an extensibility point in the system. Orleans currently has implementation of two stream providers: TCP based Simple Message Stream Provider and Azure Queue based Azure Queue Stream Provider . More details on Steam Providers can be found at Stream Providers . Stream Semantics Stream Subsription Semantics : Orleans Streams guarantee Sequential Consistency for Stream Subsription operations. Specificaly, when consumer subscribes to a stream, once the Task representing the subsription operation was successfuly resolved, the consumer will see all events that were generated after it has subscribed. In addition, Rewindable streams allow to subscribe from an arbitrary point in time in the past by using StreamSequenceToken (more details can be found here ). Individual Stream Events Delivery Guarantees : Individual event delivery guarantees depend on individual stream providers. Some provide only best-effort at-most-once delivery (such as Simple Message Streams), while others provide at-least-once delivery (such as Azure Queue Streams). It is even possible to build a stream provider that will guarantee exactly-once delivery (we don't have such a provider yet, but it is possible to build one. Events Delivery Order : Event order also depends on a particular stream provider. In SMS streams, the producer explicitelly controls the order of events seen by the consumer by controlling the way it publishes them. Azure Queue streams do not guarantee FIFO order, since the underlaying Azure Queues do not guarantee order in failure cases. Applications can also control their own stream delivery ordering, by using StreamSequenceToken . Streams Implementation The Orleans Streams Implementation provides a high level overview of the internal implementation. Code Samples More examples of how to use streaming APIs within a grain can be found here . We plan to create more samples in the future. More Material Orleans Virtual Meetup about Streams Orleans Streaming Presentation from Virtual Meetup"
  },
  "Documentation/resources/Presentations/index.html": {
    "href": "Documentation/resources/Presentations/index.html",
    "title": "Orleans Presentations | Microsoft Orleans Documentation",
    "keywords": "Orleans Best Practices A collection of tips and trick to help design, build, and run an Orleans-based application. Orleans Presentation from the 28th International Symposium on Distributed Computing (DISC 2014) Orleans Presentation from the 15th International Workshop on High Performance Transaction Systems (HPTS 2013) Balancing Techniques in Orleans Uniform API is 42 - Virtual Meetup #3 Orleans at FreeBay - Virtual Meetup #4 Orleans Streaming - Virtual Meetup #5 - May 2015 Geo Distributed Orleans - Virtual Meetup #6 - October 2015 Orleankka Functional API for Orleans - Virtual Meetup #7 Orleans Roadmap - Virtual Meetup #8 - January 2016 Orleans Networking discussion- Virtual Meetup #8.5 - February 2016 Orleans on Service Fabric - Virtual Meetup #9 Part 1 - February 2016 Orleans with YAMS - Virtual Meetup #9 Part 2 - February 2016 Walk In Distributed Systems Park With Orleans"
  },
  "Documentation/resources/Migration/MigrationAzure2.0.html": {
    "href": "Documentation/resources/Migration/MigrationAzure2.0.html",
    "title": "Migration from Orleans 1.5 to 2.0 when using Azure | Microsoft Orleans Documentation",
    "keywords": "Migration from Orleans 1.5 to 2.0 when using Azure In Orleans 2.0, the configuration of silos and clients has changed. In Orleans 1.5 we used to have a monolith object that handled all the configuration pieces Providers were added to that configuration object, too. In Orleans 2.0, the configuration process is organizes around SiloHostBuilder , similar to how it is done in ASP.NET Core with the WebHostBuilder . In Orleans 1.5, the configuration for Azure looked like this: var config = AzureSilo.DefaultConfiguration(); config.AddMemoryStorageProvider(); config.AddAzureTableStorageProvider(\"AzureStore\", RoleEnvironment.GetConfigurationSettingValue(\"DataConnectionString\")); The AzureSilo class exposes a static method named DefaultConfiguration() that was used for loading configuration XML file. This way of configuring a silo is deprecated but still supported via the legacy support package . In Orleans 2.0, configuration is completely programmatic. The new configuration API looks like this: //Load the different settings from the services configuration var proxyPort = RoleEnvironment.CurrentRoleInstance.InstanceEndpoints[\"OrleansProxyEndpoint\"].IPEndpoint.Port; var siloEndpoint = RoleEnvironment.CurrentRoleInstance.InstanceEndpoints[\"OrleansSiloEndpoint\"].IPEndpoint; var connectionString = RoleEnvironment.GetConfigurationSettingValue(\"DataConnectionString\"); var deploymentId = RoleEnvironment.DeploymentId; var builder = new SiloHostBuilder() //Set service ID and cluster ID .Configure<ClusterOptions>(options => { options.ClusterId = deploymentId; options.ServiceIs = \"my-app\"; }) // Set silo name .Configure<SiloOptions>(options => options.SiloName = this.Name) //Then, we can configure the different endpoints .ConfigureEndpoints(siloEndpoint.Address, siloEndpoint.Port, proxyPort) //Then, we set the connection string for the storage .UseAzureStorageClustering(options => options.ConnectionString = connectionString) //If reminders are needed, add the service, the connection string is required .UseAzureTableReminderService(connectionString) //If Queues are needed, add the service, set the name and the Adapter, the one shown here //is the one provided with Orleans, but it can be a custom one .AddAzureQueueStreams<AzureQueueDataAdapterV2>(\"StreamProvider\", configurator => configurator.Configure(configure => { configure.ConnectionString = connectionString; })) //If Grain Storage is needed, add the service and set the name .AddAzureTableGrainStorage(\"AzureTableStore\"); AzureSilo to ISiloHost In Orleans 1.5, the AzureSilo class was the recommended way to host a silo in an Azure Worker Role. This is still supported via the Microsoft.Orleans.Hosting.AzureCloudServices NuGet package . public class WorkerRole : RoleEntryPoint { AzureSilo silo; public override bool OnStart() { // Do other silo initialization – for example: Azure diagnostics, etc return base.OnStart(); } public override void OnStop() { silo.Stop(); base.OnStop(); } public override void Run() { var config = AzureSilo.DefaultConfiguration(); config.AddMemoryStorageProvider(); config.AddAzureTableStorageProvider(\"AzureStore\", RoleEnvironment.GetConfigurationSettingValue(\"DataConnectionString\")); // Configure storage providers silo = new AzureSilo(); bool ok = silo.Start(config); silo.Run(); // Call will block until silo is shutdown } } Orleans 2.0 provides a more flexible and modular API for configuring and hosting a silo via SiloHostBuilder and ISiloHost . public class WorkerRole : RoleEntryPoint { private ISiloHost host; private ISiloHostBuilder builder; private readonly CancellationTokenSource cancellationTokenSource = new CancellationTokenSource(); private readonly ManualResetEvent runCompleteEvent = new ManualResetEvent(false); public override void Run() { try { this.RunAsync(this.cancellationTokenSource.Token).Wait(); runCompleteEvent.WaitOne(); } finally { this.runCompleteEvent.Set(); } } public override bool OnStart() { //builder is the SiloHostBuilder from the first section // Build silo host, so that any errors will restart the role instance this.host = this.builder.Build(); base.OnStart(); } public override void OnStop() { this.cancellationTokenSource.Cancel(); this.runCompleteEvent.WaitOne(); this.host.StopAsync().Wait(); base.OnStop(); } private Task RunAsync(CancellationToken cancellationToken) { return this.host.StartAsync(cancellationToken); } }"
  },
  "Documentation/resources/Migration/Migration1.5.html": {
    "href": "Documentation/resources/Migration/Migration1.5.html",
    "title": "Migration from Orleans 1.5 to 2.0 | Microsoft Orleans Documentation",
    "keywords": "Migration from Orleans 1.5 to 2.0 The bulk of the Orleans APIs stayed unchanged in 2.0 or implementation of those APIs were left in legacy classes for backward compatibility. At the same time, the newly introduced APIs provide some new capabilities or better ways of accomplishing those tasks. There are also more subtle differences when it comes to .NET SDK tooling and Visual Studio support that helps to be aware of. This document provides guidance for migrating application code from to Orleans 2.0. Visual Studio and Tooling requirements Orleans 2.0.0 is built on top of .NET Standard 2.0. Because of that, you need to upgrade development tools to ensure yourself a pleasant developing experience. We recommend to use Visual Studio 2017 or above to develop Orleans 2.0.0 applications. Based on our experience, version 15.5.2 and above works best. .NET Standard 2.0.0 is compatible with .NET 4.6.1 and above, .NET Core 2.0, and a list of other frameworks. Orleans 2.0.0 inherited that compatibility. For more information on .NET Standard compatibility with other framework, please refer to .NET Standard documentation : If you are developing a .NET Core or .NET application using Orleans, you will need to follow certain steps to set up your environment, such as installing .NET Core SDK. For more information, please refer to their documentation . Available options for configuration code Hosting Configuring and Starting a Silo (using the new SiloBuilder API and legacy ClusterConfiguration object) There's a number of new option classes in Orleans 2.0 that provide a new way for configuring a silo. To ease migration to the new API, there is a optional backward compatibility package, Microsoft.Orleans.Runtime.Legacy , that provides a bridge from the old 1.x configuration API to the new one. If you add Microsoft.Orleans.Runtime.Legacy package, a silo can still be configured programmatically via the legacy ClusterConfiguration object that can then be passed to SiloHostBuilder to build and start a silo. You still need to specify grain class assemblies via the ConfigureApplicationParts call. Here is an example of how a local silo can be configured in the legacy way: public class Program { public static async Task Main(string[] args) { try { var host = await StartSilo(); Console.WriteLine(\"Press Enter to terminate...\"); Console.ReadLine(); await host.StopAsync(); return 0; } catch (Exception ex) { Console.WriteLine(ex); return 1; } } private static async Task<ISiloHost> StartSilo() { // define the cluster configuration (temporarily required in the beta version, // will not be required by the final release) var config = ClusterConfiguration.LocalhostPrimarySilo(); // add providers to the legacy configuration object. config.AddMemoryStorageProvider(); var builder = new SiloHostBuilder() .UseConfiguration(config) // Add assemblies to scan for grains and serializers. // For more info read the Application Parts section .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(HelloGrain).Assembly) .WithReferences()) // Configure logging with any logging framework that supports Microsoft.Extensions.Logging. // In this particular case it logs using the Microsoft.Extensions.Logging.Console package. .ConfigureLogging(logging => logging.AddConsole()); var host = builder.Build(); await host.StartAsync(); return host; } } Configuring and Connecting a Client (using the new ClientBuilder API and legacy ClientConfiguration object) There's a number of new option classes in Orleans 2.0 that provide a new way for configuring a client. To ease migration to the new API, there is a optional backward compatibility package, Microsoft.Orleans.Core.Legacy , that provides a bridge from the old 1.x configuration API to the new one. If you added Microsoft.Orleans.Core.Legacy package, a client can still be configured programmatically via the legacy ClientConfiguration object that can then be passed to ClientBuilder to build and connect the client. You still need to specify grain interface assemblies via the ConfigureApplicationParts call. Here is an example of how a client can connect to a local silo, using legacy configuration: // define the client configuration (temporarily required in the beta version, // will not be required by the final release) var config = ClientConfiguration.LocalhostSilo(); var builder = new ClientBuilder() .UseConfiguration(config) // Add assemblies to scan for grains interfaces and serializers. // For more info read the Application Parts section .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IHello).Assembly)) .ConfigureLogging(logging => logging.AddConsole()) var client = builder.Build(); await client.Connect(); Logging Orleans 2.0 uses the same logging abstractions as ASP.NET Core 2.0. You can find replacement for most Orleans logging feature in ASP.NET Core logging. Orleans specific logging feature, such as ILogConsumer and message bulking, is still maintained in Microsoft.Orleans.Logging.Legacy package, so that you still have the option to use them. But how to configure your logging with Orleans changed in 2.0. Let me walk you through the process of migration. In 1.5, logging configuration is done through ClientConfiguration and NodeConfiguration . You can configure DefaultTraceLevel , TraceFileName , TraceFilePattern , TraceLevelOverrides , TraceToConsole , BulkMessageLimit , LogConsumers , etc through it. In 2.0, logging configuration is consistent with ASP.NET Core 2.0 logging, which means most of the configuration is done through Microsoft.Extensions.Logging.ILoggingBuilder . To configure DefaultTraceLevel and TraceLevelOverrides , you need to apply log filtering to ILoggingBuilder . For example, to set trace level to 'Debug' on orleans runtime, you can use sample below, siloBuilder.AddLogging(builder=>builder.AddFilter(\"Orleans\", LogLevel.Debug)); You can configure log level for you application code in the same way. If you want to set a default minimum trace level to be Debug, use sample below siloBuilder.AddLogging(builder=>builder.SetMinimumLevel(LogLevel.Debug); For more information on log filtering, please see their docs on https://docs.microsoft.com/en-us/aspnet/core/fundamentals/logging ; To configure TraceToConsole to be true , you need to reference Microsoft.Extensions.Logging.Console package and then use AddConsole() extension method on ILoggingBuilder . The same with TraceFileName and TraceFilePattern , if you want to log messages to a file, you need to use AddFile(\"file name\") method on ILoggingBuilder . If you still want to use Message Bulking feature, You need to configure it through ILoggingBuilder as well. Message bulking feature lives in Microsoft.Orleans.Logging.Legacy package. So you need to add dependency on that package first. And then configure it through ILoggingBuilder . Below is an example on how to configure it with ISiloHostBuilder siloBuiler.AddLogging(builder => builder.AddMessageBulkingLoggerProvider(new FileLoggerProvider(\"mylog.log\"))); This method would apply message bulking feature to the FileLoggerProvider , with default bulking config. Since we are going to eventually deprecate and remove LogConsumer feature support in the future, we highly encourage you to migrate off this feature as soon as possible. There's couple approaches you can take to migrate off. One option is to maintain your own ILoggerProvider , which creates ILogger who logs to all your existing log consumers. This is very similar to what we are doing in Microsoft.Orleans.Logging.Legacy package. You can take a look at LegacyOrleansLoggerProvider and borrow logic from it. Another option is replace your ILogConsumer with existing implementation of ILoggerProvider on nuget which provides identical or similar functionality, or implement your own ILoggerProvider which fits your specfic logging requirement. And configure those ILoggerProvider s with ILoggingBuilder . But if you cannot migrate off log consumer in the short term, you can still use it. The support for ILogConsumer lives in Microsoft.Orleans.Logging.Legacy package. So you need to add dependency on that package first, and then configure Log consumers through extension method AddLegacyOrleansLogging on ILoggingBuilder . There's native AddLogging method on IServiceCollection provided by ASP.NET for you to configure ILoggingBuilder . We also wrap that method under extension method on ISiloHostBuilder and IClientBuilder . So you can call AddLogging method on silo builder and client builder as well to configure ILoggingBuilder . below is an example: var severityOverrides = new OrleansLoggerSeverityOverrides(); severityOverrides.LoggerSeverityOverrides.Add(typeof(MyType).FullName, Severity.Warning); siloBuilder.AddLogging(builder => builder.AddLegacyOrleansLogging(new List<ILogConsumer>() { new LegacyFileLogConsumer($\"{this.GetType().Name}.log\") }, severityOverrides)); You can use this feature if you invested in custom implementation of ILogConsumer and cannot convert them to implementation of ILoggerProvider in the short term. Logger GetLogger(string loggerName) method on Grain base class and IProviderRuntime , and Logger Log { get; } method on IStorageProvider are still maintained as a deprecated feature in 2.0. You can still use it in your process of migrating off orleans legacy logging. But we recommend you to migrate off them as soon as possible. Provider Configuration In Orleans 2.0, configuration of the included providers has been standardized to obtain Service ID and Cluster ID from the ClusterOptions configured for the silo or client. Service ID is a stable identifier of the service or application that the cluster represents. Service ID does not change between deployments and upgrades of clusters that implement the service over time. Unlike Service ID, Cluster ID stays the same only through the lifecycle of a cluster of silos. If a running cluster gets shut down, and a new cluster for the same service gets deployed, the new cluster will have a new and unique Cluster ID, but will maintain the Service ID of the old cluster. Service ID is often used as part of a key for persisting data that needs to have continuity throughout the life of the service. Examples are grain state, reminders, and queues of persistent streams. On the other hand, data within a cluster membership table only makes sense within the scope of its cluster, and hence is normally keyed off Cluster ID. Prior to 2.0, behavior of Orleans providers was sometimes inconsistent with regards to using Service ID and Cluster ID (that was also previously called Deployment ID). Because of this unifications and the overall change of provider configuration API, data written to storage by some providers may change location or key. An example of a provider that is sensitive to this change is Azure Queue stream provider. If you are migrating an existing service from 1.x to 2.0, and need to maintain backward compatibility with regards to location or keys of data persisted by the providers you are using in the service, please verify that the data will be where your service or provider expects it to be. If your service happen to depend on the incorrect usage of Service ID and Cluster ID by a 1.x provider, you can override ClusterOptions for that specific provider by calling ISiloHostBuilder.AddProviderClusterOptions() or IClientBuilder.AddProviderClusterOptions() and force it to read/write data from/to the 1.x location in storage"
  },
  "Documentation/resources/orleans_architecture_principles_and_approach_I.html": {
    "href": "Documentation/resources/orleans_architecture_principles_and_approach_I.html",
    "title": "Orleans Architecture - Principles and Approach I | Microsoft Orleans Documentation",
    "keywords": "Now that Orleans is (finally) available as open source, it's important to be clear about the goals and principles that has motivated the design decisions behind Orleans so that new changes either fit within that framework or explicitly and intentionally revise those goals and principles. About the time I joined the Orleans project, we agreed that the goal was to produce a framework that would allow mainstream developers to easily build scalable distributed (cloud) applications. To break this down a bit: The target audience shouldn't exclude programmers who haven't done distributed systems development . We want to enable all developers, whether cloud experts or cloud beginners, to focus on their application logic and features -- which is to say, what actually provides business value -- rather than on generic distributed systems issues. The goal is to allow them to build cloud applications easily . Easily means that they shouldn't have to think about distribution any more than is absolutely required. Easily also means that Orleans should present as familiar a façade to the developer as possible; in a .NET context, that means C# objects and interfaces. Those applications should be \"scalable by default\" . Since our target users aren't necessarily distributed systems experts, we want to provide them a framework that will lead them to build scalable applications without explicitly thinking about it. This means that the framework has to make a lot of decisions for them in order to guarantee an acceptable degree of scalability, even if that means that the scalability isn't optimal for every application. We supplemented this goal with a set of architectural principles: We're focused on the 80% case . There are certainly applications that Orleans isn't appropriate for; that's OK. There are applications that Orleans is a reasonable fit for, but where you can get somewhat better performance by a bunch of hand-tuning that Orleans doesn't allow; that's OK too. The 80% that Orleans fits well and performs well enough on covers a lot of interesting applications, and we'd rather do a great job on 80% than a lousy job on 99%. Scalability is paramount . We'll trade off raw performance if that gets us better scaling. Availability is paramount . A cloud application should be like a utility: always there when you want it. Detect and fix problems , don't assume you can 100% prevent them. At cloud scale, bad things happen often, and even impossible bad things happen, just less often. This has led us to what is often termed \"recovery-oriented computing\", rather than trying to be fault-tolerant; our experience has shown that fault tolerance is fragile and often illusory. Even mathematically proven protocols are no protection against random bit flips in memory or disk controllers that fail while reporting success -- both real examples I've seen in production in my career. The above has led us to certain practices: API-first design : if we don't know how we're going to expose a feature to the developer, then we don't build it. Of course, the best way is for a feature have no developer exposure at all... Make it easy to do the right thing : keep things as simple as possible (but no simpler), don't provide a hammer if a screwdriver is the right tool. As one of our early adopters put it, we try to help our customers \"fall into the pit of success\". If there is a standard pattern that will work well for 80% of the applications out there, then don't worry about enabling every possible alternative. Orleans' embrace of asynchrony is a good example of this. Make it easy for developers to extend the framework without breaking it . Custom serialization and persistence providers are a couple of examples of this. Some sort of custom task scheduling extension would be an anti-example. Follow the principle of least surprise : as much as possible, things should be as familiar, but everything should behave the way it looks. The next post will start applying these principles to the current Orleans design and walk through the motivations for some specific decisions we made. Thanks for reading! Alan Geller Alan Geller, http://research.microsoft.com/en-us/people/ageller/ , works on quantum computing at Microsoft Research. He was one of the primary architects of Orleans from 2008 until 2012. Earlier, he was the platform architect for Amazon Web Services from 2004 to 2008, and before that built a wide variety of large-scale production distributed systems in telecommunications and financial services."
  },
  "Documentation/deployment/multi-cluster_support/SiloConfiguration.html": {
    "href": "Documentation/deployment/multi-cluster_support/SiloConfiguration.html",
    "title": "Multi-Cluster Silo Configuration | Microsoft Orleans Documentation",
    "keywords": "Orleans Silo Configuration To get a quick overview, we show all relevant configuration parameters (including optional ones) in XML syntax below: <?xml version=\"1.0\" encoding=\"utf-8\"?> <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <MultiClusterNetwork ClusterId=\"clusterid\" DefaultMultiCluster=\"uswest,europewest,useast\" BackgroundGossipInterval=\"30s\" UseGlobalSingleInstanceByDefault=\"false\" GlobalSingleInstanceRetryInterval=\"30s\" GlobalSingleInstanceNumberRetries=\"3\" MaxMultiClusterGateways=\"10\"> <GossipChannel Type=\"...\" ConnectionString=\"...\"/> <GossipChannel Type=\"...\" ConnectionString=\"...\"/> </MultiClusterNetwork> <SystemStore ... ServiceId=\"some-guid\" .../> </Globals> </OrleansConfiguration> var silo = new SiloHostBuilder() [...] .Configure<ClusterInfo>(options => { options.ClusterId = \"us3\"; options.ServiceId = \"myawesomeservice\"; }) .Configure<MultiClusterOptions>(options => { options.HasMultiClusterNetwork = true; options.DefaultMultiCluster = new[] { \"us1\", \"eu1\", \"us2\" }; options.BackgroundGossipInterval = TimeSpan.FromSeconds(30); options.UseGlobalSingleInstanceByDefault = false; options.GlobalSingleInstanceRetryInterval = TimeSpan.FromSeconds(30); options.GlobalSingleInstanceNumberRetries = 3; options.MaxMultiClusterGateways = 10; options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=usa;AccountKey=...\"); options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=europe;AccountKey=...\") [...] }) [...] As usual, all configuration settings can also be read and written programmatically, via the respective members of the GlobalConfiguration class. The Service Id is an arbitrary ID for identifying this service. It must be the same for all clusters and all silos. The MultiClusterNetwork section is optional - if not present, all multi-cluster support is disabled for this silo. The required parameters ClusterId and GossipChannel are explained in the section on Multi-Cluster Communication . The optional parameters MaxMultiClusterGateways and BackgroundGossipInterval are explained in the section on Multi-Cluster Communication . The optional parameter DefaultMultiCluster is explained in the section on Multi-Cluster Configuration . The optional parameters UseGlobalSingleInstanceByDefault , GlobalSingleInstanceRetryInterval and GlobalSingleInstanceNumberRetries are explained in the section on Global-Single-Instance Grains . Orleans Client Configuration No extra configuration is required for Orleans client. The same client may not connect to silos in different clusters (the silo refuses the connection in that situation)."
  },
  "Documentation/deployment/multi-cluster_support/GossipChannels.html": {
    "href": "Documentation/deployment/multi-cluster_support/GossipChannels.html",
    "title": "Multi-Cluster Communication | Microsoft Orleans Documentation",
    "keywords": "Multi-Cluster Communication The network must be configured in such a way that any Orleans silo can connect to any other Orleans silo via TCP/IP, regardless of where in the world it is located. Exactly how this is achieved is outside of the scope of Orleans, as it depends on how and where silos are deployed. For example, on Windows Azure, we can use VNETs to connect muliple deployments within a region, and gateways to connect VNETs across different regions. Cluster Id Each cluster has its own unique cluster id. The cluster id must be specified in the global configuration. Cluster ids may not be empty, nor may they contain commas. Also, if using Azure Table Storage, cluster ids may not contain the characters forbidden for row keys (/, , #, ?). We recommend using very short strings for the cluster ids, because cluster ids are transmitted frequently and may be stored in storage by some log-view providers. Cluster Gateways Each cluster automatically designates a subset of its active silos to serve as cluster gateways . Cluster gateways directly advertise their IP addresses to other clusters, and can thus serve as \"points of first contact\". By default, at most 10 silos (or whatever number is configured as MaxMultiClusterGateways ) are designated as cluster gateways. Communication between silos in different clusters does not always pass through a gateway. Once a silo has learned and cached the location of a grain activation (no matter in what cluster), it sends messages to that silo directly, even if the silo is not a cluster gateway. Gossip Gossip is a mechanism for clusters to share configuration and status information. As the name suggests, gossip is decentralized and bidirectional: each silo communicates directly with other silos, both in the same cluster and in other clusters, to exchange information in both directions. Content . Gossip contains some or all of the following information: The current time-stamped multi-cluster configuration . A dictionary that contains information about cluster gateways. The key is the silo address, and the value contains (1) a timestamp, (2) the cluster id, and (3) a status, which is either active or inactive. Fast & Slow Propagation . When a gateway changes its status, or when an operator injects a new configuration, this gossip information is immediately sent to all silos, clusters, and gossip channels. This happens fast, but is not reliable. Should the message be lost due to any reasons (e.g. races, broken sockets, silo failures), our periodic background gossip ensures that the information eventually spreads, albeit more slowly. All information is eventually propagated everywhere, and is highly resilient to occasional message loss and failures. All gossip data is timestamped, which ensures that newer information replaces older information regardless of the relative timing of messages. For example, newer multi-cluster configurations replace older ones, and newer information about a gateway replaces older information about that gateway. For more details on the representation of gossip data, see the MultiClusterData class. It has a Merge method that combines gossip data, resolving conflicts using timestamps. Gossip Channels When a silo is first started, or when it is restarted after a failure, it needs to have a way to bootstrap the gossip . This is the role of the gossip channel , which can be configured in the Silo Configuration . On startup, a silo fetches all the information from the gossip channels. After startup, a silo keeps gossiping periodically, every 30 seconds or whatever is configured as BackgroundGossipInterval . Each time it synchronizes its gossip information with a partner randomly selected from all cluster gateways and gossip channels. Notes: Though not strictly required, we recommend to always configure at least two gossip channels, in distinct regions, for better availability. Latency of communication with gossip channels is not critical. Multiple different services can use the same gossip channel without interference, as long as the ServiceId Guid (as specified by their respective configuration) is distinct. There is no strict requirement that all silos use the same gossip channels, as long as the channels are sufficient to let a silo initially connect with the \"gossiping community\" when it starts up. But if a gossip channel is not part of a silo's configuration, and that silo is a gateway, it does not push its status updates to the channel (fast propagation), so it may take longer before those reach the channel via periodic background gossip (slow propagation). Azure-Table-Based Gossip Channel We have already implemented a gossip channel based on Azure Tables. The configuration specifies standard connection strings used for Azure accounts. For example, a configuration could specify two gossip channels with separate Azure storage accounts usa and europe as follows: var silo = new SiloHostBuilder() [...] .Configure<MultiClusterOptions>(options => { [...] options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=usa;AccountKey=...\"); options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=europe;AccountKey=...\") [...] }) [...] Multiple different services can use the same gossip channel without interference, as long as the ServiceId guid specified by their respective configuration is distinct. Other Gossip Channel Implementations We are working on other gossip channel providers, similar to how membership and reminders are packaged for many different storage back-ends."
  },
  "1.5/Documentation/Runtime-Implementation-Details/Load-Balancing.html": {
    "href": "1.5/Documentation/Runtime-Implementation-Details/Load-Balancing.html",
    "title": "Load Balancing | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Load Balancing Load balancing, in a broad sense, is one of the pillars of the Orleans runtime . Orleans runtime tries to make everything balanced, since balancing allows to maximize resource usage and avoid hotspots, which leads to better performance, as well as helps with elasticity. Load balancing in Orleans applies in multiple places. Below is a non-exhaustive list of places where the runtime performs balancing: Default actor placement strategy is random - new activations are placed randomly across silos. That results in a balanced placement and prevents hotspots for most scenarios. A more advanced ActivationCountPlacement tries to equalize the number of activations on all silos, which results in a more even distribution of activations across silos. This is especially important for elasticity. Grain Directory service is built on top of a Distributed Hash Table, which inherently is balanced. The directory service maps grains to activations, each silo owns part of the global mapping table, and this table is globally partitioned in a balanced way across all silos. We use consistent hashing with virtual buckets for that. Clients connect to all gateways and spread their requests across them, in a balanced way. Reminder service is a distributed partitioned runtime service. The assignment of which silo is responsible to serve which reminder is balanced across all silos via consistent hashing, just like in grain directory. Performance critical components within a silo are partitioned, and the work across them is locally balanced . That way the silo runtime can fully utilize all available CPU cores and not create in-silo bottlenecks. This applies to all local resources: allocation of work to threads, sockets, dispatch responsibilities, queues, etc. StreamQueueBalance balances the responsibility of pulling events from persistence queues across silos in the cluster. Also notice that balancing, in a broad sense, does not necessarily mean loss of locality . One can be balanced and still maintain a good locality. For example, when balancing means sharding/partitioning, you can partition responsibility for a certain logical task, while still maintaining locality within each partition. That applies both for local and distributed balancing. Refer to this presentation on Balancing Techniques in Orleans for more details."
  },
  "1.5/Documentation/Presentations/index.html": {
    "href": "1.5/Documentation/Presentations/index.html",
    "title": "Orleans Presentations | Microsoft Orleans Documentation",
    "keywords": "Orleans Best Practices A collection of tips and trick to help design, build, and run an Orleans-based application. Orleans Presentation from the 28th International Symposium on Distributed Computing (DISC 2014) Orleans Presentation from the 15th International Workshop on High Performance Transaction Systems (HPTS 2013) Balancing Techniques in Orleans Uniform API is 42 - Virtual Meetup #3 Orleans at FreeBay - Virtual Meetup #4 Orleans Streaming - Virtual Meetup #5 - May 2015 Geo Distributed Orleans - Virtual Meetup #6 - October 2015 Orleankka Functional API for Orleans - Virtual Meetup #7 Orleans Roadmap - Virtual Meetup #8 - January 2016 Orleans Networking discussion- Virtual Meetup #8.5 - February 2016 Orleans on Service Fabric - Virtual Meetup #9 Part 1 - February 2016 Orleans with YAMS - Virtual Meetup #9 Part 2 - February 2016 Walk In Distributed Systems Park With Orleans"
  },
  "1.5/Documentation/Core-Features/Dependency-Injection.html": {
    "href": "1.5/Documentation/Core-Features/Dependency-Injection.html",
    "title": "Dependency Injection | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . What is Dependency Injection Dependency injection (DI) is a software design pattern that implements inversion of control for resolving dependencies. Orleans is using the abstraction written by the developers of ASP.NET Core . For a detailed explanation about how it works, check out the official documentation . DI in Orleans Dependency Injection is currently supported only on the server side within Orleans. Orleans makes it possible to inject dependencies into application Grains . However Orleans supports every container dependent injection mechanisms, one of the most commonly used method is constructor injection. Theoretically any type can be injected which was previously registered in a IServiceCollection during Silo startup. Note *: As Orleans is evolving, as of the current plans it will be possible to leverage dependency injection in other application classes as well, like StreamProviders . Configuring DI The DI configuration is a global configuration value and must be configured there. Orleans is using a similar approach as ASP.NET Core to configure DI. You must have a Startup class within your application which must contain a ConfigureServices method. It must return an object instance of type: IServiceProvider . Configuration is done by specifying the type of your Startup class via one of the methods described below. Note : Previously DI configuration was specified at the cluster node level, this was changed in the recent release. Configuring from Code It is possible to tell Orleans what Startup type you like to use with code based configuration. There is an extension method named UseStartup on the ClusterConfiguration class which you can use to do that. var configuration = new ClusterConfiguration(); configuration.UseStartupType<MyApplication.Configuration.MyStartup>(); Configuring via XML To register your Startup class with Orleans you add a Startup element to the Defaults section and in the Type attribute you specify the assembly-qualified name for the type. <?xml version=\"1.0\" encoding=\"utf-8\" ?> <tns:OrleansConfiguration xmlns:tns=\"urn:orleans\"> <tns:Defaults> <tns:Startup Type=\"MyApplication.Configuration.Startup,MyApplication\" /> </tns:Defaults> </tns:OrleansConfiguration> Example Here is a complete Startup class example: namespace MyApplication.Configuration { public class MyStartup { public IServiceProvider ConfigureServices(IServiceCollection services) { services.AddSingleton<IInjectedService, InjectedService>(); return services.BuildServiceProvider(); } } } This example shows how a Grain can utilize IInjectedService via constructor injection and also the complete declaration and implementation of the injected service: public interface ISimpleDIGrain : IGrainWithIntegerKey { Task<long> GetTicksFromService(); } public class SimpleDIGrain : Grain, ISimpleDIGrain { private readonly IInjectedService injectedService; public SimpleDIGrain(IInjectedService injectedService) { this.injectedService = injectedService; } public Task<long> GetTicksFromService() { return injectedService.GetTicks(); } } public interface IInjectedService { Task<long> GetTicks(); } public class InjectedService : IInjectedService { public Task<long> GetTicks() { return Task.FromResult(DateTime.UtcNow.Ticks); } } Test Framework Integration DI truly shines when coupled with a testing framework to verify the correctness of the code that build. You can read about the components for testing in Orleans by following our tutorials . You will need to do two things to set up DI with tests. First you will need to implement mocks of your services. This is done in our example using Moq , a popular mocking framework for .NET. Here is an example of mocking a service. public class MockServices { public IServiceProvider ConfigureServices(IServiceCollection services) { var mockInjectedService = new Mock<IInjectedService>(); mockInjectedService.Setup(t => t.GetTicks()).Returns(knownDateTime); services.AddSingleton<IInjectedService>(mockInjectedService.Object); return services.BuildServiceProvider(); } } To include these services in your test silo, you will need to specify MockServices as the silo startup class. Here is an example of doing this. [TestClass] public class IInjectedServiceTests: TestingSiloHost { private static TestingSiloHost host; [TestInitialize] public void Setup() { if (host == null) { host = new TestingSiloHost( new TestingSiloOptions { StartSecondary = false, AdjustConfig = clusterConfig => { clusterConfig.UseStartupType<MockServices>(); } }); } } }"
  },
  "1.5/Documentation/Convert-Orleans-v0.9-csproj-to-Use-v1.0-NuGet.html": {
    "href": "1.5/Documentation/Convert-Orleans-v0.9-csproj-to-Use-v1.0-NuGet.html",
    "title": "Convert Orleans v0.9 csproj to use V1.0 NuGet | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . How To Convert a .csproj File To Use Orleans NuGet Packages This note shows how to manually convert a Visual Studio .csproj file which was created with Orleans v0.9 Visual Studio templates from using assembly references based on the $(OrleansSDK) environment variable to using Orleans NuGet packages. These examples assume you are using the latest v1.0.3 NuGet packages from Feb-2015. For simplicity I will use \"v0.9\" to refer to the \"old\" .csproj and \"v1.0\" to refer to the \"new\" .csproj although strictly speaking \"v1.0 really means \">= v1.0.3\" in practice because there was significant restructuring and changes in the Orleans NuGet packages before that point. Grain Interface Project Orleans Grain Interface project -- Example: HelloWorldInterfaces.csproj You might want to preserve a copy of the old .csproj file before you start, if you do not have a copy already preserved in your source code control system. Steps to to change Orleans Grain Interface project: Do Build->Clean on the project to remove any old binaries. Remove old v0.9 assembly references for any Orleans binaries. <ItemGroup> <Reference Include=\"Orleans\"> <HintPath>$(OrleansSDK)\\Binaries\\OrleansClient\\Orleans.dll</HintPath> <Private>False</Private> </Reference> </ItemGroup> Remove old v0.9 Orleans code-gen metadata and script trigger. <PropertyGroup> <OrleansProjectType>Server</OrleansProjectType> </PropertyGroup> <Import Project=\"$(OrleansSDK)\\Binaries\\OrleansClient\\Orleans.SDK.targets\" /> Make sure to re-save the .csproj to disk at this point, otherwise the next step will fail ! Use Visual Studio Package manager to add the Microsoft.Orleans.Templates.Interfaces package to the grain interfaces project. Do this by right-click on project node in Solution Explorer, select \"Manage NuGet Packages...\" context menu item, then search for Orleans and select the Microsoft.Orleans.Templates.Interfaces package. This will add a packages.config file to the project, and add the normal NuGet link code into the .csproj This will also add the Orleans assembly references into the project, and recreate the code-gen metadata and script links for you. Ensure .csproj file is saved to disk again. Do Build->Rebuild on the project to rebuild with the new packages and binaries. Going forward, you should only need to change the version number in packages.config to use a newer package -- either manually edit the packages.config file or use NuGet Package Manager UI in Visual Studio. Orleans Grain Class project -- Example: HelloWorldGrains.csproj Steps to to change Orleans Grain Class project: Steps 1..4 and 6..8 are the same as for the grain interfaces .csproj above. Build->Clean Remove old v0.9 Orleans assembly references Remove old v0.9 Orleans code-gen metadata Save .csproj file to disk Use Visual Studio Package manager to add the Microsoft.Orleans.Templates.Grains package to the project. Follow Steps 6..8 from the grain interfaces .csproj above. Problems? If you have problems getting these conversions to work for you, then please post a full copy of your .csproj into a Gist on your GitHub account and then open a new Issue in the Orleans GitHub Project asking for assistance and pointing to the Gist for your specific project file."
  },
  "1.5/Documentation/Samples-Overview/Hello-World.html": {
    "href": "1.5/Documentation/Samples-Overview/Hello-World.html",
    "title": "Hello World | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Hello World In this sample, a client connects with an Orleans grain instance, sends it a greeting and receives a greeting back. The client then prints that greeting and that's that. Simple enough in theory, but since there's distribution involved, there's a bit more to it. There are three projects involved -- one for declaring the communication interfaces, one for the grain implementations, and one for the client, which also hosts the Orleans silo that loads the grain when activated. There's only one communication interface, in IHello.cs: public interface IHello : Orleans.IGrainWithIntegerKey { Task<string> SayHello(string greeting); } This is simple enough, and we can see that all replies must be represented as a Task or Task in communication interfaces. The implementation, found in HelloGrain.cs, is similarly trivial: public class HelloGrain : Orleans.Grain, HelloWorldInterfaces.IHello { Task<string> HelloWorldInterfaces.IHello.SayHello(string greeting) { return Task.FromResult(\"You said: '\" + greeting + \"', I say: Hello!\"); } } The class inherits from an Orleans-defined base class, and implements the communication interface defined earlier. Since there is nothing that the grain needs to wait on, the method is not declared async and instead returns its value using Task.FromResult() . The client, which orchestrates the grain code and is found in Program.cs, looks like this: Orleans.GrainClient.Initialize(\"DevTestClientConfiguration.xml\"); var friend = GrainClient.GrainFactory.GetGrain<IHello>(0); Console.WriteLine(\"\\n\\n{0}\\n\\n\", friend.SayHello(\"Good morning!\").Result); There's other code in the method, too, but that is unrelated to the client logic, it's hosting the Orleans silo."
  },
  "1.5/Documentation/Runtime-Implementation-Details/Runtime-Tables.html": {
    "href": "1.5/Documentation/Runtime-Implementation-Details/Runtime-Tables.html",
    "title": "Azure Runtime Tables | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Azure Runtime Tables Orleans maintains a number of internal tables for different runtime mechanisms. Here we list all the tables as they are organized if Azure is used as the system store, and provide more details on their internal structure. When SQL, ZooKeeper, Consul and other technologies are used for system store, organization and exact structure of the data may vary, but the general idea stays the same. Runtime tables: Orleans Silo Instances table Reminders table Silo Metrics table Clients Metrics table Silo Statistics table Clients Statistics table Orleans Silo Instances table Orleans Silo Instances table, also commonly referred to as Membership table, lists the set of silos that make an Orleans deployment. More details can be found in the description of the Cluster Management Protocol that maintains this table. All rows in this table consist of the following columns ( SiloInstanceTableEntry ): PartitionKey - deployment id. RowKey - Silo IP Address + \"-\" + Silo Port + \"-\" + Silo Generation number (epoch) DeploymentId - the deployment id of this Orleans service Address - IP address Port - silo to silo TCP port Generation - Generation number (epoch number) HostName - silo Hostname Status - status of this silo, as set by cluster management protocol. Any of the type Orleans.Runtime.SiloStatus ProxyPort - silo to clients TCP port Primary - whether this silo is primary or not. Deprecated. RoleName - If running in Azure - the name of this role. If running on premises, the name of the executing assembly. InstanceName - If running in Azure - the name of this role instance. If running on premises, the silo name that the silo host gave it. UpdateZone - Azure update zone, if running in Azure. FaultZone - Azure fault zone, if running in Azure. SuspectingSilos - the list of silos that suspect this silo. Managed by cluster management protocol. SuspectingTimes - the list of times when this silo was suspected. Managed by cluster management protocol. StartTime - the time when this silo was started. IAmAliveTime - the last time this silo reported that it is alive. Used for diagnostics and troubleshooting only. There is also a special row in this table, called membership version row, with the following columns: PartitionKey - deployment id. RowKey - \"VersionRow\" constant string DeploymentId MembershipVersion - the latest version of the current membership configuration. Naming: The silo instance row has 3 names: hostname, rolename and instance name. What is the difference? First, it is important to note that Orleans cluster protocol does not use any of these names for distinguishing between silos. Instead it uses IP:port:epoch as a unique identity of a silo instance. Therefore, setting of those 3 names has no impact on runtime correctness. It is in the table merely to help diagnostics and operational troubleshooting. Hostname is always set to the name of this host, as returned by Dns.GetHostName() . Role name is a logical name of the whole service and instance name is the name of this specific silo instance within this service. Role name and Instance name depend on the hosting - where the silo runs. Each silo host can set those differently. Azure host ( AzureSiloHost ) sets the role name to Azure role name ( myRoleInstance.Role.Name ) and instance name to Azure role Instance name ( myRoleInstance.Id ). On premises ( SiloHost ) the role name is the executing assembly name ( Assembly.GetExecutingAssembly().GetName().Name ) and the instance name is the name the host gave to that silo when it was started. Orleans Reminders table Orleans Reminders table durably stores all the reminders registered in the system. Each reminder has a separate row. All rows in this table consist of the following columns ( ReminderTableEntry ): PartitionKey - ServiceId + \"_\" + GrainRefConsistentHash RowKey - GrainReference + \"-\" ReminderName GrainReference - the grain reference of the grain that created this reminder. ReminderName - the name of this reminder ServiceId - the service id of the currently running Orleans service DeploymentId - the deployment id of the currently running Orleans service StartAt - the time when this reminder was supposed to tick in the first time Period - the time period for this reminder GrainRefConsistentHash - the consistent hash of the GrainReference Silo Metrics table Silo metrics table contains a small set of per-silo important key performance metrics (usually known as KPI - Key Performance Indicators ). Each silo has one row, periodically updated in-place by its silo ( SiloMetricsData ). PartitionKey - DeploymentId RowKey - silo name DeploymentId - the deployment id of this Orleans service Address - the silo address (ip:port:epoch) of this silo SiloName - the name of this silo (in Azure it is its Instance name) GatewayAddress - the gateway ip:port of tis silo HostName - the hostname of this silo CPU - current CPU utilization MemoryUsage - current memory usage ( GC.GetTotalMemory(false) ) Activations - number of activations on this silo RecentlyUsedActivations - number of activations on this silo that were used in the last 10 minutes (Note: this number may currently not be accurate if different age limits are used for different grain types). SendQueue - the current size of the send queue (number of messages waiting to be send). Only captures remote messages to other silos (not including messages to the clients). ReceiveQueue - the current size of the receive queue (number of messages that arrived to this silo and are waiting to be dispatched). Captures both remote and local messages from other silos as well as from the clients. RequestQueue SentMessages - total number of remote messages sent to other silos as well as to the clients. ReceivedMessages - total number of remote received messages, from other silos as well as from the clients. LoadShedding - whether this silo is currently overloaded and is in the load shedding mode. Clients - number of currently connected clients Clients Metrics table Silo metrics table containes a small set of per-Orleans-client important key performance metrics. Each client has one row, periodically updated in-place by its client. Client metrics are essentilay a subset of silo metrics ( ClientMetricsData ). PartitionKey - DeploymentId RowKey - Address DeploymentId - the deployment id of this Orleans service Address - the address (ip:port) of this client ClientId - the unique name of this client (pseudo client grain id) HostName - the hostname of this client CPU - current CPU utilization MemoryUsage - current memory usage ( GC.GetTotalMemory(false) ) SendQueue - the current size of the send queue (number of messages waiting to be send). Captures remote messages to other silos. ReceiveQueue - the current size of the receive queue (number of messages that arrived to this client and are waiting to be dispatched, including responses). SentMessages - total number of remote messages sent to silos. ReceivedMessages - total number of remote received messages from silos. ConnectedGatewayCount - number of gateways that this client is currently connected to. Silo Statistics table Silo Statistics table containes a large set of per-silo detailed statistic counters. Most of them are low level performance statistics, which are usualy used in troubleshooting scenarios. A set of examples and methodology of how those statistics can be used are described in our paper PAD: Performance Anomaly Detection in Multi-Server Distributed Systems and a proof of concept . Each statistic value is one row. This table is append only. Every silo periodicaly (usually every 5 minutes, configurable) appends all its latest statistic counter values. The number of counters per silo is currently about 200. So every 5 minutes every silo appends around 200 rows to this table. Each row is in the format ( StatsTableData ): PartitionKey - DeploymentId$ReverseTimestampToTheNearestHour - deploymentId and last hour RowKey - ReverseTimestampToTheNearestSecond$Name$counter - current second, silo name, monotonically growing sequence number DeploymentId - the deployment id of this Orleans service Time - the current time of the reporting on the reporting silo Address - the silo address (ip:port:epoch) of this silo Name - the name of this silo (in Azure it is its Instance name) HostName - the host name of this silo Statistic - the name of the statistic counter StatValue - the value of the statistic counter IsDelta - if this the statistic counter value is delta since last value reported or an absolute value The rationale behind the choice of partition key and row key is described here and here . Clients Statistics table Same as Silo Statistics table but for client."
  },
  "1.5/Documentation/Runtime-Implementation-Details/Relational-Storage.html": {
    "href": "1.5/Documentation/Runtime-Implementation-Details/Relational-Storage.html",
    "title": "Relational Storage | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Relational Storage Relational storage backend code in Orleans is built on generic ADO.NET functionality and is consequently database vendor agnostic. The Orleans data storage layout has been explained already in Runtime Tables . Setting up the connection strings are done as explained in Orleans Configuration Guide and SQL Tables . To make Orleans code function with a given relational database backend, the following is required: Appropriate ADO.NET library must be loaded to the process (multiple can exist in GAC or otherwise). This should be defined as usual, e.g. via DbProviderFactories element in application configuration. Configure the ADO.NET invariant via AdoInvariant attribute in the element defining the connection string, by default it is System.Data.SqlClient The database needs to exist and be compatible with the code. This is done by running a vendor specific database creation script. The scripts are found in the OrleansSqlUtils NuGet package and are published with every Orleans release. Currently there are two database scripts: SQL Server - CreateOrleansTables_SqlServer.sql . AdoInvariant is System.Data.SqlClient . MySQL - CreateOrleansTables_MySql.sql . AdoInvariant is MySql.Data.MySqlClient . If you need setup scripts for other ADO.NET supported databases, open an issue or please, stop by at Orleans Gitter . Goals of the design 1. Allow use of any backend that has a ADO.NET provider This should cover the broadest possible set of backends available for .NET, which is a factor in on-premises installations. Some providers are listed at ADO.NET Data Providers MSDN page , but for the sake of a remark, not all are listed, such as Teradata . 2. Maintain the potential to tune queries and database structure as appropriate, even while a deployment is running In many cases, the servers and databases are hosted by a third party in contractual relation with the client. It is not an unusual situation the hosting environment is virtualized and performance fluctuates due to unforeseen factors, such as noisy neighbors or faulty hardware. It may not be possible to alter and re-deploy either Orleans binaries (contractual reasons) or even application binaries, but usually it is possible to tweak the database deployment. Altering standard components , such as Orleans binaries, requires a lenghtier procedure as to what is afforded in a given situation. 3. Allow one to make use of vendor and version specific abilities Vendors have implemented different extensions and features within their products. It is sensible to make use of these features when they are available. These features are such as native UPSERT or PipelineDB in PostgreSQL, PolyBase or natively compiled tables and stored procedures in SQL Server – and myriads of other features. 4. Make it possible to optimize hardware resources When designing an application, it is often possible to anticipate which data needs to be inserted faster than other data and which data could be more likely put into cold storage which is cheaper (e.g. splitting data between SSD and HDD). As for an example, further considerations are that the physical location of some data could be more expensive (e.g. SSD RAID viz HDD RAID), more secured or some other decision attribute used. Related to point 3. Some databases offer special partitioning schemes, such as SQL Server Partitioned Tables and Indexes . This principle applies also throughout the application life-cycle. Considering one of the principles of Orleans itself is a high-availability system, it should be possible to adjust storage system without interruption to Orleans deployment or that it should be possible to adjust the queries according to data and other application parameters. One example of changes is in Brian Harry's blog post When a table is small, it almost doesn’t matter what the query plan is. When it’s medium an OK query plan is fine. When it's huge (millions upon millions or billions of rows) a tiny, slight variation in query plan can kill you. So, we hint our sensitive queries heavily. This is true in general. 5. No assumptions on what tools, libraries or deployment processes are used in organizations Many organizations have familiarity with a certain set of database tools, examples being Dacpac or Red Gate . It may be so that deploying a database requires either a permission or a person, such as someone in a DBA role, to do it. Usually this means also having the target database layout and a rough sketch of the queries the application will produce to the database to be used estimate the load. There might be processes, perhaps influenced by industry standards, which mandate script based deployment. Having the queries and database structures in an external script makes this possible. 6. Use the minimum set needed of interface functionality to load the ADO.NET libraries and functionality This is both fast and has less surface to be exposed to ADO.NET library implementation discrepancies. 7. Make the design shardable When it makes sense, for instance in relational storage provider, make the design readily shardable. This means for instance no database dependent data (e.g. IDENTITY ) and basically it means the information that distinguishes row data should build on only data from the actual parameters. 8. Make the design easy to test Creating a new backend should be ideally as easy as translating one of the deployment scripts and adding a new connection string to tests assuming default parameters, check if a given database is installed and then run the tests against it. 9. Taking into account the previous points, make both porting scripts for new backends and modifying already deployed backend scripts as transparent as possible Realization of the goals Orleans framework does not have knowledge of deployment specific hardware (which may change during active deployment), the change of data during the deployment life-cycle and some vendor specific features are usable in only some situations. For this reason, the interface between relational database and Orleans should adhere a minimum set of abstractions and rules to meet the goals but to make it also robust against misuse and easy to test if needed. Runtime Tables , Cluster Management and the concrete membership protocol implementation . Also, the SQL Server implementation contains SQL Server edition specific tuning. The interface contract between the database and Orleans is defined as follows: The general idea is that data is read and written through Orleans specific queries. Orleans operates on column names and types when reading and on parameter names and types when writing. The implementations must preserve input and output names and types. Orleans uses these parameters to reads query results by name and type. Vendor and deployment specific tuning is allowed and contributions are encouraged as long as the interface contract is maintained. The implementation across vendor specific scripts should preserve the constraint names. This simplifies troubleshooting by virtue of uniform naming across concrete implementations. Version – or ETag in application code – for Orleans represents a unique version. The type of its actual implementation is not important as long as it represents a unique version. In the implementation Orleans code excepts a signed 32-bit integer. For the sake of being explicit and removing ambiguity, Orleans expects some queries to return either TRUE as > 0 value or FALSE as = 0 value. That is, affected rows or such does not matter. If an error is raised or an exception is thrown the query must ensure the entire transaction is rolled back and may either return FALSE or propagate the exception. Currently all but one query are single row inserts or updates (note, one could replace UPDATE queries with INSERT ones provided the associated SELECT queries would provide the last write) except for statistic inserts. Statistic insert, as defined by InsertOrleansStatisticsKey writes the statistics in batches of predefined maximum size using UNION ALL for all databases except for Oracle, for which a UNION ALL FROM DUAL construct is used. InsertOrleansStatisticsKey is the only query that defines a kind of a template parameters of which Orleans multiplies as many times as there are parameters with differing values. Database engines support in-database programming, this is is similar to an idea of loading an executable script and invoke it to execute database operations. In pseudocode it could be depicted as const int Param1 = 1; const DateTime Param2 = DateTime.UtcNow; const string queryFromOrleansQueryTableWithSomeKey = \"SELECT column1, column2 FROM <some Orleans table> where column1 = @param1 AND column2 = @param2;\"; TExpected queryResult = SpecificQuery12InOrleans<TExpected>(query, Param1, Param2); These principles are also included in the database scripts . Some ideas on applying customized scripts Alter scripts in OrleansQuery for grain persistence with IF ELSE so that some state is saved using the default INSERT while some grain state uses, for instance, memory optimized tables . The SELECT queries need to be altered accordingly. The idea in 1. can be used to take advantage of other deployment or vendor specific aspects. Such as splitting data between SSD or HDD , putting some data on encrypted tables, or perhaps inserting statistics data via SQL Server to Hadoop or even linked servers . The altered scripts can be tested running the Orleans test suite or straight in the database using, for instance, SQL Server Unit Test Project . Guidelines for adding new ADO.NET providers Add a new database setup script according to the Realization of the goals section above. Add the vendor ADO invariant name to AdoNetInvariants and ADO.NET provider specific data to DbConstantsStore . These are (potentially) used in some query operations. e.g. to select the correct statistics insert mode (i.e. the UNION ALL with or without FROM DUAL ). Orleans has comprehensive tests for all system stores: membership, reminders and statistics. Adding tests for the new database script is done by copy-pasting existing test classes and changing the ADO invariant name. Also, derive from RelationalStorageForTesting in order to define test functionality for the ADO invariant."
  },
  "1.5/Documentation/Getting-Started-With-Orleans/Debugging.html": {
    "href": "1.5/Documentation/Getting-Started-With-Orleans/Debugging.html",
    "title": "Debugging and Symbols | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Debugging An Orleans-based application can be easily debugged during development by attaching a debugger to the silo host process or to the client process . For fast development iterations, it is convenient to use a single process that combines a silos and a client, such as a console application project that gets created by the Orleans Dev/Test Host project template that is part of the Microsoft Orleans Tools extension for Visual Studio. Similarly, debugger can be attached to the Worker/Web Role instance process when running inside the Azure Compute Emulator. In production, it is rarely a good idea to stop a silo at a breakpoint because the frozen silo will soon get voted dead by the cluster membership protocol and will not be able to communicate with other silos in the cluster. Hence, in productions tracing is the primary 'debugging' mechanism. Source Link Starting with the 2.0.0-beta1 release we added Source Link support to our Symbols. It means that if a project consumes the Orleans NuGet packages, when debugging the application code, they can step into the Orleans source code. In Steve Gordon's blog post , you can see what steps are needed to configure it. Symbols Starting with 1.3.0 release, symbols for Orleans binaries are published to Microsoft symbol servers. Make sure you enable Microsoft Symbol Servers in Visual Studio in Tools/Options/Debugging/Symbols for debugging Orleans code. Prior to 1.3.0, symbols were published to https://nuget.smbsrc.net/ symbol server. Add it to the list of symbol servers in Visual Studio in Tools/Options/Debugging/Symbols. Make sure there is a trailing slash in the URL. Visual Studio 2015 has a bug with parsing it. Sources You can download zipped sources for specific releases of Orleans from the Releases page . However, due to the LF/CR differences between Windows and Unix (default for GitHub), debugger may complain about a mismatch of the sources and symbols. The workaround is to check out the corresponding version tag on a Windows machine to get sources with the matching LF/CR ending."
  },
  "1.5/Documentation/Event-Sourcing/MultiInstance.html": {
    "href": "1.5/Documentation/Event-Sourcing/MultiInstance.html",
    "title": "Replicated Grains | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Replicated Grains Sometimes, there can be multiple instances of the same grain active, such as when operating a multi-cluster, and using the [OneInstancePerCluster] attribute. The JournaledGrain is designed to support replicated instances with minimal friction. It relies on log-consistency providers to run the necessary protocols to ensure all instances agree on the same sequence of events. In particular, it takes care of the following aspects: Consistent Versions : All versions of the grain state (except for tentative versions) are based on the same global sequence of events. In particular, if two instances see the same version number, then they see the same state. Racing Events : Multiple instances can simultaneously raise an event. The consistency provider resolves this race and ensures everyone agrees on the same sequence. Notifications/Reactivity : After an event is raised at one grain instance, the consistency provider not only updates storage, but also notifies all the other grain instances. For a general discussion of the consistency model see our TechReport and the GSP paper (Global Sequence Protocol). Conditional Events Racing events can be problematic if they have a conflict, i.e. should not both commit for some reason. For example, when withdrawing money from a bank account, two instances may independently determine that there are sufficient funds for a withdrawal, and issue a withdrawal event. But the combination of both events could overdraw. To avoid this, the JournaledGrain API supports a RaiseConditionalEvent method. bool success = await RaiseConditionalEvent(new WithdrawalEvent() { ... }); Conditional events double-check if the local version matches the version in storage. If not, it means the event sequence has grown in the meantime, which means this event has lost a race against some other event. In that case, the conditional event is not appended to the log, and RaiseConditionalEvent returns false. This is the analogue of using e-tags with conditional storage updates, and likewise provides a simple mechanism to avoid committing conflicting events. It is possible and sensible to use both conditional and unconditional events for the same grain, such as a DepositEvent and a WithdrawalEvent . Deposits need not be conditional: even if a DepositEvent loses a race, it does not have to be cancelled, but can still be appended to the global event sequence. Awaiting the task returned by RaiseConditionalEvent is sufficient to confirm the event, i.e. it is not necessary to also call ConfirmEvents . Explicit Synchronization Sometimes, it is desirable to ensure that a grain is fully caught up with the latest version. This can be enforced by calling await RefreshNow(); which both (1) confirms all unconfirmed events, and (2) loads the latest version from storage."
  },
  "Community/Documentation-Guidelines.html": {
    "href": "Community/Documentation-Guidelines.html",
    "title": "Documentation Guidelines | Microsoft Orleans Documentation",
    "keywords": "Documentation Guidelines The Orleans documentation is built in Markdown . We use a few simple conventions to ensure a homogeneous style throughout the full set of documents. These standards are being introduced. If you have issues with these guidelines then raise an issue or a Pull Request. If you find documentation that fails to meet the guidelines, then make a fix and submit a pull request. Also if you are using windows 10 you can go to the store and find free MarkDown editors like this Structure Language The documentation will follow US-English spelling. Desktop tools like http://markdownpad.com have spell checking features. Paragraph structure Each sentence should be written on a single line, and only one sentence per line. This makes merging changes easier and also helps identify verbose language. Paragraphs in Markdown are just one or more lines of consecutive text followed by one or more blank lines. Headings Heading should be used to structure a document. Avoid using other emphasis features like ALLCAPS, Italics or bold to identify a new topic. Using a header is not only more consistent, but also allows linking to the header. Footers At the end of a page, it is helpful to link to the next logical page in the documentation. If the page is the last in a sub-section then linking back to the index page is useful. Styles Code formatting Blocks of example code should be formatted with the triple back tick format followed by the language ``` csharp [StorageProvider(ProviderName=\"store1\")] public class MyGrain<IMyGrainState> ... { ... } ``` Which will render as [StorageProvider(ProviderName=\"store1\")] public class MyGrain<IMyGrainState> ... { ... } Inline code should be marked with a single backtick (`). This include references to: type names e.g. Task<T> variable names e.g. game namespaces e.g. Orleans.Storage.AzureTableStorage If showing text that is an output (e.g. text file content or console output) you can either use the triple back tick without specifying a language or you can indent the content. For example: 1 said: Welcome to my team! 0 said: Thanks! 1 said: Thanks! 0 said: Thanks! File names and paths When referencing a filename, directory/folder or URI then use standard italics to format. This can be done by surrounding the string with either with a single asterisk ( * ) or a single underscore ( _ ) Examples: OrleansRuntimeInterfaces.dll C:\\Binaries ../src/Grain.cs Tables Markdown supports tabular data . Tables could be used to structure data so that is is easily consumable for the reader. Suffix Unit ms millisecond(s) s second(s) m minute(s) Links When referencing another concept, the concept should be linked to. Forward and backward references with in a page can be linked to via the header. e.g. link back to Structure Links to other documents can either link to the page, or a sub-section/header within the page. External links should be exposed as a the full link e.g. https://github.com/dotnet/roslyn Contribution The Orleans documentation is managed as Markdown files in a Git repository hosted on GitHub in the gh-pages branch . See the GitHub Pages documentation on how to use the gh-pages branch convention for \"Project site\" documents."
  },
  "1.5/Tutorials/On-Premise-Deployment.html": {
    "href": "1.5/Tutorials/On-Premise-Deployment.html",
    "title": "On-Premise Deployment | Microsoft Orleans Documentation",
    "keywords": "On-Premise Deployment Overview While using Orleans to implement cloud-based services is a core scenario, there is nothing that intrinsically ties it to the cloud as the sole platform. Orleans can just as well be deployed to the internal, on-premise, equipment of your organization's. In this tutorial, we describe the steps to take. Orleans based services are xcopy-deployable. All you need to do to deploy an Orleans based service to a set of machines is copy the following set of file to the target machines and start the OrleansHost.exe host process: Contents of the build folder of your host project (it can use Microsoft.Orleans.Host NuGet package or use your own console application running the Silo). OrleansConfiguration.xml file with configuration for the deployment to replace the default placeholder (If you use file based config). Binaries with grain interfaces and grain implementation classes of the service along with any external dependencies to Application<service name> subdirectory of the folder on the target with binaries of the host which should contain Orleans DLLs as well. This simple task may be accomplished in many different ways and with different tools, but the Orleans GitHub repo includes a set of PowerShell scripts ( https://github.com/dotnet/orleans/tree/master/misc/scripts/RemoteDeployment ) that provide a way to deploy an Orleans based service to a cluster of machines and remote start the hosting processes on them. There are also scripts for removing a service, monitoring its performance, starting and stopping it, and collecting logs. These are the scripts we found useful for ourselves while building and testing Orleans. Prerequisites The following table lists the prerequisites for deploying and running Orleans on a remote machine: .Net Framework 4.5 Orleans runs under the .Net Framework 4.5, which can be installed from this link: ( https://www.microsoft.com/en-us/download/details.aspx?id=30653 ) Powershell 2.0 with WinRM Windows 7 and Windows Server 2008 R2 should have these installed by default. For earlier versions of Windows, select the appropriate download from this article: ( https://support.microsoft.com/en-us/help/968929/windows-management-framework-windows-powershell-2.0,-winrm-2.0,-and-bits-4.0 ). To confirm you are running the required version of PowerShell, start a PowerShell window and type Get-Host – the resulting output needs to say \"Version: 2.0\" WinRM Configuration Both the source and target machines must be configured for remote operations: Open a PowerShell window as an Administrator and run the command below on the target machine (enter 'y' at the prompts): winrm quickconfig Increase PowerShell job memory Set the memory limit on remotely invoked jobs to 4Gb: Set-Item wsman:localhost\\Shell\\MaxMemoryPerShellMB 4096 To change it on a remote machine, use the following steps: Connect-WSMan -ComputerName <string> Set-Item wsman:<computerName>\\Shell\\MaxMemoryPerShellMB Disconnect-WSMan –ComputerName <string> PowerShell Execution Policy set to run remote scripts Open a PowerShell window as an Administrator and run the command below on the target machine (enter 'y' at the prompt): Set-ExecutionPolicy RemoteSigned This will set the machine to require signing for remote scripts only. Note that the user running the scripts must be a member of the Administrators Group on the remote machines. Deployment Steps In this tutorial , we will deploy the HelloWorld sample to a set of servers. The Orleans repo includes a RemoteDeployment folder ( https://github.com/dotnet/orleans/tree/master/misc/scripts/RemoteDeployment ) where everything we need can be found. Start by building the Hello World sample , commenting out (or removing) the silo initialization and shutdown code: static void Main(string[] args) { //AppDomain hostDomain = // AppDomain.CreateDomain(\"OrleansHost\", null, new AppDomainSetup //{ // AppDomainInitializer = InitSilo, // AppDomainInitializerArguments = args, //}); Orleans.GrainClient.Initialize(\"ClientConfiguration.xml\"); var friend = GrainClient.GrainFactory.GetGrain<HelloWorldInterfaces.IHello>(0); Console.WriteLine(\"\\n\\n{0}\\n\\n\", friend.SayHello(\"Good morning!\").Result); Console.WriteLine(\"Orleans Silo is running.\\nPress Enter to terminate...\"); Console.ReadLine(); //hostDomain.DoCallBack(ShutdownSilo); } Also, start a new PowerShell window as Administrator and move to the RemoteDeployment folder. The basic steps to deploy Orleans code are: Setup a deployment manifest (Deployment.xml) . Adjust the Orleans server-side configuration (OrleansConfiguration.xml) to suit the environment. Run the PowerShell deployment scripts to deploy Orleans into your remote environment. Orleans Deployment Manifest The Orleans Deployment scripts use a manifest (XML) file to specify details of the deployment, including source and destination locations and local or remote machines to be deployed to. By making small changes to an existing deployment manifest xml file (typically by listing the different host machines), the same PowerShell scripts can deploy and run that Orleans system on a set of remote machines with equal ease as deploying and running that system on the local machine. The default file name for the manifest is Deployment.xml , and if you just modify this file, which is found in the RemoteDeployment folder, it will not be necessary to specify a different name. There are times, such as during testing, it may be advantageous to maintain multiple deployment files that specify a different set of silos. These other files may be specified explicitly to the deployment tools as specified in the respective sections below. A deployment manifest contains many different items, which collectively allow deployment of the Orleans runtime and applications onto a variety of local and remote configurations: Source location for the Orleans system runtime Located in the Path attribute of the <Deployment><Packages><Package> element where the Type attribute is set to \"System\". <Package Name=\"Orleans Runtime\" Type=\"System\" Path=\"..\\Binaries\\OrleansServer\" /> Source location for additional Orleans applications If you have any additional Orleans applications / grains to be included in this Orleans system, they are also located in the <Deployment><Packages><Package> nodes. The Type attribute must be set to \"Application\". <Package Name=\"HelloWorld\" Type=\"Application\" Path=\"..\\Binaries\\Applications\\HelloWorldGrains\" /> Source location for the server configuration file to be used by the Orleans host process Located in the Path attribute of the <Deployment><RuntimeConfiguration> element. The file name must be \"OrleansConfiguration.xml\" – if necessary, just change the path. <RuntimeConfiguration Path=\".\\OrleansConfiguration.xml\" /> Target location to install the Orleans server-side binaries on each machine Located in the <Deployment><TargetLocation> element. This must be an absolute local file system path (i.e. no \"..\" locations) that is valid on all the target hosts. <TargetLocation Path=\"C:\\Orleans\" /> The set of silos (host machines and optional silo names) this Orleans system should to be deployed to. Located in the <Deployment><Nodes><Node> elements. Typically: \"Primary\" on localhost , or multiple machines with one silo each. The HostName attribute specifies the machine name. The NodeName attribute specifies the name of the silo. Generally, this is arbitrary, with the exception that if multiple silos will run on any one machine, then silo names must be unique. <Nodes> <Node HostName=\"MACHINE1\" NodeName=\"Primary\" /> <Node HostName=\"MACHINE2\" NodeName=\"Node2\" /> <Node HostName=\"MACHINE3\" NodeName=\"Node3\" /> <Nodes /> Deployment Group ID This is a GUID which distinguishes one Orleans runtime system from another, even if both Orleans systems are running on the same machines. Located in the <Deployment> element. <Deployment Name=\"Deployment1\" DeploymentGroup=\"F219832A-1EE1-45DA-B35D-0BB3060C9FDA\" xmlns=\"urn:xcg-deployment\"> Orleans Silo Configuration Refer to Server Configuration for information on silo configuration. Orleans Powershell Scripts The following sections detail the PowerShell scripts provided with Orleans to aid with deployment and monitoring. (Use the /? option to get the latest usage info directly from the scripts.) Script Name Parameters Description DeployOrleansSilos.ps1 [$deploymentConfigFile] Copies the Orleans files to machines specified in the deploymentConfigFile (default is Deployment.xml). UndeployOrleansSilos.ps1 [$deploymentConfigFile] Stops and removes Orleans from the deployment servers deploymentConfigFile (default is Deployment.xml). MonitorOrleansSilos.ps1 [$deploymentConfigFile] [$networkInstance] [$samplesToLog] [$headerInterval] [$repeatHeaderInFile] Monitors CPU, Memory, Network Send, and Network Receive performance counters, and logs the data to files both as an aggregate of all data, and in separate files for each server. See usage text for details about the parameters. ShowOrleansSilos.ps1 [$deploymentConfigFile] Does a quick survey of the deployment silos and reports if Orleans is running on them. GatherOrleansSiloLogs.ps1 [$deploymentConfigFile] [$outputPath] Retrieve all log files from deployment silos and stores them in the specified output folder. UtilityFunctions.ps1 none Provides ancillary functionality to the other scripts. Deploying Orleans using Powershell Script Start a separate PowerShell command window as an administrator. Execute the DeployOrleansSilos.ps1 script, providing the location of the deployment configuration file (\"deployment.xml\" is the default and will be used if you don’t supply a value). .\\DeployOrleansSilos.ps1 .\\Deployment.xml The deployment will execute the following steps: Stop any running instances of Orleans that are running on the deployment machines. Copy the Orleans files and any application files that are listed in the deployment manifest. When the copy is completed, start the silos. This will pause after starting the first silo so that it is available for the other silos to register with. Pause to allow the start-up to complete. Report the progress of the deployment. When the deployment is complete, Orleans is ready for clients to connect to it. Confirming Orleans Status To determine if Orleans is running on the servers in the deployment manifest, run the ShowOrleansSilos.ps1 script. If you have used a deployment manifest file named something other than the default, specify it on the command line. .\\ShowOrleansSilos.ps1 .\\Deployment.xml If everything works well, you should see something like this: PS C:\\Orleans\\misc\\scripts\\RemoteDeployment> .\\ShowOrleansSilos.ps1 .\\Deployment.xml OrleansHost running on host001: Process 1: 1340 OrleansHost running on host002: Process 1: 4320 2 processes running Running the Client We've edited the Hello World program not to start a silo in-process, but in order to run the client, the client configuration file DevTestClientConfiguratio.xml needs to be edited according to the Client Configuration section. The setup needs to conform to how the server was set up, specifically whether or not Azure Storage is used to keep track of the deployment configuration. In the author's setup, Azure is not involved, so the client configuration looks like this: <ClientConfiguration xmlns=\"urn:orleans\"> <Gateway Address=\"host001\" Port=\"30000\"/> <Gateway Address=\"host002\" Port=\"30000\"/> <Statistics MetricsTableWriteInterval=\"30s\" PerfCounterWriteInterval=\"30s\" LogWriteInterval=\"300s\" WriteLogStatisticsToTable=\"true\"/> </ClientConfiguration> which corresponds to a server configuration that looks like this (relevant excerpts only): <Globals> <SeedNode Address=\"host001\" Port=\"11111\" /> <Liveness LivenessType =\"MembershipTableGrain\" /> ... </Globals> <Defaults> <Networking Address=\"\" Port=\"11111\" /> <ProxyingGateway Address=\"\" Port=\"30000\" /> ... </Defaults> Running the client in VS, I see this: Monitoring Orleans Once Orleans is deployed, you can start an optional script that will monitor the Orleans deployment using standard performance counters. Run a dedicated PowerShell command prompt as an administrator, and execute the .\\MonitorOrleans.ps1 script to start monitor performance counters for an Orleans Deployment. The following parameters configure the monitoring to suit individual circumstances: Parameter Default Description DeploymentConfigFile Deployment.xml The deployment manifest used to install Orleans. NetworkInstance corp The name of the network for the network performance counters. SamplesToLog 480 The number of samples to record in the current run. Use Ctrl-C to stop the script sooner. The default of 480, which taken in one minute intervals should continue for eight hours. HeaderInterval 10 The number of samples to write before repeating the header. RepeatHeaderInFile If this switch is present, the header will be repeated in the log file at the interval specified by the previous parameter. The script will store the data in the following types listed below. The files will be written to a folder called PerformanceData under the directory where the monitoring script is run from. File Type FileNameBase Description Machine Specific “PerfData-” + machine name + Date/Time stamp. Contains only the data for a single machine. If there are four machines in the deployment, then there will be four of these files. Combined “ConsolidatedPerfData-” + Date/Time stamp. Contains all of the data for all machines consolidated into a single file. Gathering Orleans Log Files To retrieve all log files from deployment silos and store them in the specified output folder, run the GatherOrleansSiloLogs.ps1 script. If you have used a deployment manifest file named something other than the default, specify it on the command line. You may also specify an output folder where the collected log files will be stored otherwise a .\\logs subdirectory will be used by default. .\\GatherOrleansSiloLogs.ps1 .\\Deployment.xml .\\GatherOrleansSiloLogs.ps1 .\\Deployment.xml .\\MyLogs Removing Orleans When it is time to remove an Orleans deployment, use the UndeployOrleansSilos.ps1 script. If you have used a deployment manifest file named something other than the default, specify it on the command line. .\\UnDeployOrleansSilos.ps1 .\\Deployment.xml Next We'll write our own storage provider, to save grain state to alternative to file instead of Microsoft Azure: Custom Storage Providers"
  },
  "1.5/Tutorials/Failure-Handling.html": {
    "href": "1.5/Tutorials/Failure-Handling.html",
    "title": "Handling Failures | Microsoft Orleans Documentation",
    "keywords": "Handling Failures Note: All of the containing guidance in this document is provided to serve as examples and food for thought. You should not think of them as prescriptive solutions to your problems, since failure handling is a rather application specific subject, and these patterns and others are only useful if applied with a good knowledge of the concrete case being worked on. The hardest thing in programming a distributed system is handling failures. The actor model and the way it works makes it much easier to deal with different kinds of failures but still as the developer you are responsible to deal with the failure possibilities and handle them in an appropriate way. Types of failures When you are coding your grains, all calls are asynchronous and potentially can go over the network. Each grain call can possibly fail due to one of the following reasons. The grain was activated on a silo which is unavailable at the moment due to a network partition crash or some other reason. If the silo has not been declared dead yet, your request might time out. The grain method call can throw an exception signaling that it failed and can not continue its job. An activation of the grain doesn't exist and cannot be created because the OnActivateAsync method throws an exception or is dead-locked. Network failures don't let you to communicate with the grain before timeout. And potentially other reasons Detection of failures Getting a reference to a grain always succeeds and is a local operation. However, method calls can fail, and when they do, you get an exception. You can catch the exception at any level you need and they are propagated even across silos. Recovering from failures Part of the recovery job is automatic in Orleans and if a grain is not accessible anymore, Orleans will reactivate it in the next method call. The thing you need to handle and make sure is correct in the context of your application is the state. A grain's state can be partially updated or the operation might be something which should be done across multiple grains and is carried on partially. After you see a grain operation fail you can do one or more of the following. Simply retry your action, especially if it doesn't involve any state changes which might be half done. This is by far the most typical case. Try to fix/reset the partially changed state by calling a method which resets the state to the last known correct state or just reads it from storage by calling ReadStateAsync . Reset the state of all related activations as well to ensure a clean state for all of them. Perform multi-grain state manipulations using a Process Manager or database transaction to make sure it's either done completely or nothing is changed to avoid the state being partially updated. Depending on your application, the retry logic might follow a simple or complex pattern, and you might have to do other stuff like notifying external systems and other things, but generally you either have to retry your action, restart the grain/grains involved or stop responding until something which is not available becomes available. If you have a grain responsible for database saves and the database is not available, you simply have to fail any request until the database comes back online. If your operation can simply be retried at the user's will like failure of saving a comment in a comment grain, you can retry when the user presses the retry button (until a certain number of times in order to not saturate the network). Specific details of how to do it are application specific but the possible strategies are the same. Strategy parameters and choosing a good strategy As described in the section above, choosing a strategy is application and context dependent and strategies usually have parameters which again have to be decided at the application level. For example you might want to retry a request maximum 5 times per minute and can deal with it being done eventually but for some other action you might not be able to continue if something is not working. If your Login grain fails , you cannot process any other requests from the user as an example. There is a guide in the Azure documentation about good patterns and practices for the cloud which applies to Orleans as well in most cases. A fairly complex example Since in Orleans grains are activated and deactivated automatically and you don't handle their life-cycle, you usually only deal with making sure that actor state is correct and actions are being started and finished correctly in relation to each other. Knowing the dependencies between grains and actions they perform is a big step toward understanding how to handle failure in any complex system. If you need to store relations between grains, you can simply do it and it is a widely followed practice too. As an example let's say we have a GameManager grain which starts and stops Game grains and adds Player grains to the games. If my GameManager grain fails to do its action regarding starting a game, the related game belonging to it should fail to do its Start() as well and the manager can do this for the game by doing orchestration. Managing memory in Orleans is automatic and the system deals with it, you only need to make sure that the game starts and only if manager can do its Start() as well. You can achieve this by either calling the related methods in a sequential manner or doing them in parallel and reset the state of all involved grains if any of them fail. If one of the games receives a call, it will be reactivated automatically, so if you need the manager to manage the game grains, then all calls to the game which are related to management should go through the GameManager . If you need orchestration between actors, Orleans doesn't solve it automagically for you and you need to do your orchestration but the fact that you are not dealing with creating/destroying actors means you don't need to worry about resource management. You don't need to answer any of these questions: Where should I create my supervision tree which actors should I register to be addressable by name? Is actor X alive so I can send it a message? ... So the game start example can be summarized like this: GameManager asks the Game grain to start Game grain adds the Player grains to itself Game asks Player grains to add game to themselves Game sets its state to be started. GameManager adds the game to its list of games. Now if, say, a player fails to add the game to itself, you don't need to kill all players and the game and start from scratch. You simply reset the state of other players which added the game to themselves, and reset the state of the Game and GameManager , if required, and redo your work or declare a failure. If you can deal with adding the game to the player later on, you can continue and retry doing that again in a reminder or at some other game call like Finish() method of the game. Next, we'll see how we can call our grains from an MVC web application. Front Ends for Orleans Services"
  },
  "1.5/Documentation/Samples-Overview/Azure-Web-Sample.html": {
    "href": "1.5/Documentation/Samples-Overview/Azure-Web-Sample.html",
    "title": "Azure Web Sample | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Azure Web Sample Important note : Worker and web role instances are not automatically removed or disabled, even when they go unused for a long time. To avoid a nasty surprise when your Azure bill comes, make sure to delete the instances after you have finished testing the application! This sample is essentially the same as the Hello World sample, except that it hosts the grains in an Azure Worker Role instead of in the client process itself. While the communication interface and grain implementation are identical, three projects replace the client: OrleansAzureSample , which is the Azure configuration project. OrleansAzureSilos , the Worker Role integration logic that hosts the Orleans silo in the cloud. WebRole , which provides a simple HTML UI for the Orleans backend. Run AzureWebSample Locally The sample is configured to run inside of the Azure Compute Emulator on your desktop by default, so make sure that OrleansAzureSample is set as the Startup Project in this solution and just press F5 to build and run the sample locally. You do not need to start Visual Studio with administrative privileges to run this sample in the emulator - it is designed to use both IIS Express and Express Emulator , so make sure these options are selected in OrleansAzureSample->Properties->Web. You may also need to select the \"Use IIS Express for web sites and projects\" in Tools->Options->Projects and Solutions->Web Projects. Run AzureWebSample in Azure Cloud To get the sample running in the Azure cloud, open the ServiceConfiguration.Cloud.cscfg file in the OrleansAzureSample project. Edit the connection strings, replacing MYACCOUNTNAME and MYACCOUNTKEY with data you get from the Azure portal, logged in to your account. It may be useful to set up a new storage account within your subscription just for samples testing. All four connection strings will look exactly the same. In the file ServiceDefinition.csdef , the configuration sets up all instances as ExtraSmall to avoid any unpleasant surprises. If you want something else, modify the settings as you see fit. Then, build the solution with Visual Studio and right-click on the OrleansAzureSample project, selecting 'Publish.' Visual Studio will take you through the process of publishing your project to Azure, which will take a few minutes. If things work out, you should see something like this: This means that the site and its backend are ready. Start a web browser and navigate to the link that VS displayed (or just click on it). You will be greeted by this screen: Click on \"Ask Orleans it's details\" and wait for the response. The first time you interact with the site, it may take a few seconds, since the whole system need to warm up. After that first message, it should go quickly."
  },
  "1.5/Documentation/Advanced-Concepts/Cancellation-Tokens.html": {
    "href": "1.5/Documentation/Advanced-Concepts/Cancellation-Tokens.html",
    "title": "Grain cancellation tokens | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Grain cancellation tokens The Orleans runtime provides mechanism called grain cancellation token, that enables the developer to cancel an executing grain operation. Description GrainCancellationToken is a wrapper around standard .NET System.Threading.CancellationToken , which enables cooperative cancellation between threads, thread pool work items or Task objects, and can be passed as grain method argument. A GrainCancellationTokenSource is a object that provides a cancellation token through its Token property and sends a cancellation message by calling its Cancel method. Usage Instantiate a CancellationTokenSource object, which manages and sends cancellation notification to the individual cancellation tokens. var tcs = new GrainCancellationTokenSource(); Pass the token returned by the GrainCancellationTokenSource.Token property to each grain method that listens for cancellation. var waitTask = grain.LongIoWork(tcs.Token, TimeSpan.FromSeconds(10)); A cancellable grain operation needs to handle underlying CancellationToken property of GrainCancellationToken just like it would do in any other .NET code. public async Task LongIoWork(GrainCancellationToken tc, TimeSpan delay) { while(!tc.CancellationToken.IsCancellationRequested) { await IoOperation(tc.CancellationToken); } } Call the GrainCancellationTokenSource.Cancel method to initiate cancellation. await tcs.Cancel(); Call the Dispose method when you are finished with the GrainCancellationTokenSource object. tcs.Dispose(); Important Considerations: The GrainCancellationTokenSource.Cancel method returns Task , and in order to ensure cancellation the cancel call must be retried in case of transient communication failure. Callbacks registered in underlying System.Threading.CancellationToken are subjects to single threaded execution guarantees within the grain activation on which they were registered. Each GrainCancellationToken can be passed through multiple methods invocations."
  },
  "Documentation/resources/Migration/index.html": {
    "href": "Documentation/resources/Migration/index.html",
    "title": "Migration | Microsoft Orleans Documentation",
    "keywords": "Migration Information ///TODO: after migration information is evaluated, write up a page about what is going to be kept, etc."
  },
  "Documentation/resources/Migration/Codegen.html": {
    "href": "Documentation/resources/Migration/Codegen.html",
    "title": "Code Generation in Orleans 2.0 | Microsoft Orleans Documentation",
    "keywords": "Code Generation in Orleans 2.0 Code generation has been improved in Orleans 2.0, improving startup times and providing a more deterministic, debuggable experience. As with earlier versions, Orleans provides both build-time and run-time code generation. During Build - This is the recommended option and only supports C# projects. In this mode, code generation will run every time your project is compiled. A build task is injected into your project's build pipeline and the code is generated in the project's intermediate output directory. To activate this mode, add the package Microsoft.Orleans.OrleansCodeGenerator.Build to all projects which contain Grains, Grain interfaces, serializers, or types which require serializers. Additional diagnostics can be emitted at build-time by specifying value for OrleansCodeGenLogLevel in the target project's csproj file. For example, <OrleansCodeGenLogLevel>Trace</OrleansCodeGenLogLevel> . During Configuration - This is the only supported option for F#, Visual Basic, and other non-C# projects. This mode generates code during the configuration phase. To access this, see the Configuration documentation. Both modes generate the same code, however run-time code generation can only generate code for publicly accessible types."
  },
  "Documentation/resources/Student-Projects.html": {
    "href": "Documentation/resources/Student-Projects.html",
    "title": "Student Projects | Microsoft Orleans Documentation",
    "keywords": "Student Projects We suggest 2 types of projects for students: The first type includes exploratory, open-ended, research-oriented projects with the goal of enabling new capabilities in Orleans. These projects would usually have broad scope and would be suitable for M.S. or Ph.D. student or advanced undergraduate students in their last year of studies. The end goal of these projects would be to contribute ideas and design to Orleans. We do not necessarily expect the code produced in these projects to be directly contributed to this repository, however this would be nice. The second type includes ideas for student education . These are either ideas for interesting applications that can be built on top of Orleans or some new capabilities for Orleans. These projects are suitable to be given in advanced undergraduate or graduate courses, where students learn about Cloud Computing and modern distributed technologies and want to gain real-world hands-on experience in building Cloud applications. We do not expect the code produced in these projects to be contributed directly to this repository. Research projects: Auto-scale. In this project students can start by exploring the existing auto-scaling mechanisms for controlling resource allocation in Windows Azure ( Autoscaling Application Block ). The next step involves exploring various statistics and resource consumption metrics collected by Orleans, and using them as an input for Azure Autoscaling. An advanced stage of this project may involve improving the internal Orleans mechanisms for reacting to elasticity changes, for example by implementing live actor migration to reduce the time taken to utilize new resources. Auto-generated front-ends for Orleans-based cloud services . This project seamlessly extends the Orleans actor model into the HTTP world. The ramp-up part of the project includes dynamically generating HTTP endpoints for actors based on their .NET interfaces and metadata. The main part involves automatically generating front-ends to support web sockets and bi-directional streaming of data, which requires complex code generation with optimizations for high performance. It also requires attention to fault tolerance, to maintain high availability of streaming sessions across server reboots and client reconnects and migration -- a significant research challenge. Storage provider for Entity Framework . This project involves enabling Orleans objects to store their state in a database and to subsequently query it. This might include adding support for Orleans object persistence on SQL Azure Database using Entity Framework (EF), which is Microsoft's open-source object-relational mapper for .NET, and exposing that data via LINQ queries. The implementation can be evaluated and tuned using standard database benchmarks and/or custom Orleans' applications. Distributed system benchmark . Define a list of benchmarks suitable for distributed systems like Orleans. The benchmark applications may be analogous in spirit to the TPC database benchmark or UCB \"Parallel Dwarfs\" implemented here and may be used to characterize the performance and scalability of distributed frameworks. Consider developing a new benchmark targeted for Orleans, for example, to compare the performance of storage providers. Declarative dataflow language over streams . Define and build a Trident-Storm like declarative language over Orleans streams. Develop an optimizer that configures the stream processing to minimize overall cost. Programming model for client devices . Extend Orleans to client devices, such as sensors, phones, tablets, and desktops. Enable grain logic to execute on the client. Potentially support tier splitting, that is, dynamically deciding which parts of the code execute on the device and which is offloaded to the cloud. Queries over grain/actor classes, secondary indices . Build a distributed, scalable, and reliable grain index. This includes formally defining the query model and implementing the distributed index. The index itself can be implemented as Orleans grains and/or stored in a database. Large scale simulations . Orleans is a great fit for building large scale simulations. Explore the usage of Orleans for different simulations, for example, protein interactions, network simulations, simulated annealing, etc. Course projects: Internet Of Things applications . For example, the application could enable sensors/devices to report their state to the cloud, where each device is represented in the cloud by an Orleans actor. Users can connect to the actor that represents their device via a web browser and check its status or control it. This project involves mastering a number of modern cloud technologies, including Windows Azure , Orleans, WebApi or ASP.NET, SignalR for streaming commands back from the cloud to the device, and writing a sensor/device/phone app. Twitter-like large scalable chat service in the cloud based on Orleans . Each user could be represented by an Orleans Actor, which contains its list of followers. Faceboook-like social app based on Orleans . Each user could be represented by an Orleans Actor, which includes a list of friends and wall on which friends can write. Simple storage provider . Add a storage provider for a storage system, such as a key-value store or database system. A simple one could use the Orleans serializer , as in the existing Azure Table storage provider . A more sophisticated one would map state variables of an Orleans class to fine-grained structures of the storage system. A complex one is the Entity Framework storage provider mentioned above under Research Projects . Compare the performance of different storage providers for different types and sizes of actor state. Comparison with other distributed application frameworks . Take a sample application written for another application framework, such as Google App Engine or Akka , and translate it into Orleans. Summarize the relative strengths and weaknesses of each framework by comparing the apps. Concluded Research projects: Below are a number of examples of previous successful research projects. Distributed log analysis, correlation and debugging . Debugging large-scale distributed systems is a challenging task due to enormous amounts of data and complex dynamic interactions between the distributed components, running on different processes and different machines. The goal of this project was to analyze prior art on this topic, propose a solution, and then implement prototype tools for collecting, correlating and analyzing application error log file data across a multi-machine distributed application runtime environment. This involved exploring the problem space from a variety of perspectives, including: a. Approaches to efficient logging, collection and analysis of failure information from various log-capture mechanisms in a distributed Orleans runtime environment. b. Possible applications of machine learning to find log patterns that signal serious production issues, and then detecting these patterns in near real time as a production monitoring utility. c. Ways to help individual developers perform real-time debugging of run-time issues with their applications. This project was performed successfully and result in a published paper PAD: Performance Anomaly Detection in Multi-Server Distributed Systems and a proof of concept implementation of a distributed log analysis tool. Horton - Distributed Graph Database . Horton was a research project with a goal to build a system to store, manage and query large-scale distributed graphs. It was implemented entirely as an Orleans application. The project resulted in a number of publications and a number of very successful student projects."
  },
  "Documentation/resources/links.html": {
    "href": "Documentation/resources/links.html",
    "title": "Links | Microsoft Orleans Documentation",
    "keywords": "Links By Orleans team Orleans Architecture: Principles and Approach I Episode 142: Microsoft Research project Orleans simplify development of scalable cloud services Orleans: Thinking Big and Small Available Now: Preview of Project “Orleans” – Cloud Services at Scale Orleans: Distributed Virtual Actors for Programmability and Scalability By others Introducing Orleans Microsoft Orleans v2.0 - A comprehensive guide for beginners and experts alike (PowerPoint) A First Look at Project Orleans A Second Look at Project Orleans Project Orleans: An Introduction Introduction To Project Orleans Introduction to Orleans Project Orleans: Different Than Erlang, Designed for a Broad Group of Developers Two Reasons You May Want to Use Microsoft’s Project Orleans Hatay Tuna & Christian Martinez - Applied Actor Model with Orleans Actor Programming with Orleans: What’s Different? Orleans – a “cloud native” runtime built for #azure Project Orleans - Actor Model framework A look at Microsoft Orleans through Erlang-tinted glasses Using Codename “Orleans” in Enterprise Applications Beyond the introduction Grains, Grains and more Grains Fine-graining your Orleans Grains inside the IoT universe Monitorable Grains Aggregating Results in Orleans Creating RESTful Services using Orleans Tackle Distribution, High Throughput and Low-Latency with Orleans – A “cloud native” Runtime Built for #Azure Saving state only once in a while in #ProjectOrleans Using Orleans for building scalable cloud applications Orleans in an IoT universe Orleans Preview & Halo 4 Using Project “Orleans” in Halo Orleans & Thinking Outside the Box John Azariah & Mahesh Krishnan - Immutability, State and Scale - Functional, Distributed Applications in Azure last edited: 5 June 2018"
  },
  "Documentation/resources/index.html": {
    "href": "Documentation/resources/index.html",
    "title": "Resources | Microsoft Orleans Documentation",
    "keywords": "This is section is about everything else: community contributions and guidlines, links, etc."
  },
  "Documentation/grains/stateless_worker_grains.html": {
    "href": "Documentation/grains/stateless_worker_grains.html",
    "title": "Stateless Worker Grains | Microsoft Orleans Documentation",
    "keywords": "Stateless Worker Grains By default, the Orleans runtime creates no more than one activation of a grain within the cluster. This is the most intuitive expression of the Virtual Actor model with each grain corresponding to an entity with a unique type/identity. However, there are also cases when an application needs to perform functional stateless operations that are not tied to a particular entity in the system. For example, if client sends requests with compressed payloads that need to be decompressed before they could be routed to the target grain for processing, such decompression/routing logic is not tied to a specific entity in the application, and can easily scale out. When the [StatelessWorker] attribute is applied to a grain class, it indicates to the Orleans runtime that grains of that class should be treated as Stateless Worker grains. Stateless Worker grains have the following properties that make their execution very different from that of normal grain classes. The Orleans runtime can and will create multiple activations of a Stateless Worker grain on different silos of the cluster. Requests made to Stateless Worker grains are always executed locally, that is on the same silo where the request originated, either made by a grain running on the silo or received by the silo's client gateway. Hence, calls to Stateless Worker grains from other grains or from client gateways never incur a remote message. The Orleans Runtime automatically creates additional activations of a Stateless Worker grain if the already existing ones are busy. The maximum number of activations of a Stateless Worker grain the runtime creates per silo is limited by default by the number of CPU cores on the machine, unless specified explicitly by the optional maxLocalWorkers argument. Because of 2 and 3, Stateless Worker grain activations are not individually addressable. Two subsequent requests to a Stateless Worker grain may be processed by different activations of it. Stateless Worker grains provide a straightforward way of creating an auto-managed pool of grain activations that automatically scales up and down based on the actual load. The runtime always scans for available Stateless Worker grain activations in the same order. Because of that, it always dispatches a requests to the first idle local activation it can find, and only gets to the last one if all previous activations are busy. If all activations are busy and the activation limit hasn't been reached, it creates one more activation at the end of the list, and dispatches the request to it. That means that when the rate of requests to a Stateless Worker grain increases, and existing activations are all currently busy, the runtime expands the pool of its activations up to the limit. Conversely, when the load drops, and it can be handled by a smaller number of activations of the Stateless Worker grain, the activations at the tail of the list will not be getting requests dispatched to them. They will become idle, and eventually deactivated by the standard activation collection process. Hence, the pool of activations will eventually shrink to match the load. The following example defines a Stateless Worker grain class MyStatelessWorkerGrain with the default maximum activation number limit. [StatelessWorker] public class MyStatelessWorkerGrain : Grain, IMyStatelessWorkerGrain { ... } Making a call to a Stateless Worker grain is the same as to any other grain. The only difference is that in most cases a single grain ID is used, 0 or Guid.Empty . Multiple grain IDs can be used when having multiple Stateless Worker grain pools, one per ID, is desirable. var worker = GrainFactory.GetGrain<IMyStatelessWorkerGrain>(0); await worker.Process(args); This one defines a Stateless Worker grain class with no more than one grain activation per silo. [StatelessWorker(1)] // max 1 activation per silo public class MyLonelyWorkerGrain : ILonelyWorkerGrain { ... } Note that [StatelessWorker] attribute does not change reentrancy of the target grain class. Just like any other grains, Stateless Worker grains are non-reentrant by default. They can be explicitly made reentrant by adding a [Reentrant] attribute to the grain class. State The \"Stateless\" part of \"Stateless Worker\" does not mean that a Stateless Worker cannot have state and is limited only to executing functional operations. Like any other grain, a Stateless Worker grain can load and keep in memory any state it needs. It's just because multiple activations of a Stateless Worker grain can be created on the same and different silos of the cluster, there is no easy mechanism to coordinate state held by different activations. There are several useful patterns that involve Stateless Worker holding state. Scaled out hot cache items For hot cache items that experience high throughput, holding each such item in a Stateless Worker grain makes it a) automatically scale out within a silo and across all silos in the cluster; and b) makes the data always locally available on the silo that received the client request via its client gateway, so that the requests can be answered without an extra network hop to another silo. Reduce style aggregation In some scenarios applications need to calculate certain metrics across all grains of a particular type in the cluster, and report the aggregates periodically. Examples are reporting number of players per game map, average duration of a VoIP call, etc. If each of the many thousands or millions of grains were to report their metrics to a single global aggregator, the aggregator would get immediately overloaded unable to process the flood of reports. The alternative approach is to turn this task into a 2 (or more) step reduce style aggregation. The first layer of aggregation is done by reporting grain sending their metrics to a Stateless Worker pre-aggregation grain. The Orleans runtime will automatically create multiple activations of the Stateless Worker grain with each silo. Since all such calls will be processed locally with no remote calls or serialization of the messages, the cost of such aggregation will be significantly less than in a remote case. Now each of the pre-aggregation Stateless Worker grain activations, independently or in coordination with other local activations, can send their aggregated reports to the global final aggregator (or to another reduction layer if necessary) without overloading it."
  },
  "Documentation/grains/reentrancy.html": {
    "href": "Documentation/grains/reentrancy.html",
    "title": "Reentrancy | Microsoft Orleans Documentation",
    "keywords": "Reentrancy Grain activations are single-threaded and, by default, process each request from beginning to completion before the next request can begin being processing. In some circumstances, it may be desirable for an activation to process other requests while one request is waiting for an asynchronous operation to complete. For this and other reasons, Orleans gives the developer some control over the request interleaving behavior. Multiple requests may be interleaved in the following cases: The grain class is marked as [Reentrant] The interface method is marked as [AlwaysInterleave] The requests within the same call chain The grain's MayInterleave predicate returns true Each of those cases are discussed in the following sections. Reentrant grains Grain implementation classes may be marked with the [Reentrant] attribute to indicate that different requests may be freely interleaved. In other words, a reentrant activation may start executing another request while a previous request has not finished processing. Execution is still limited to a single thread, so the activation is still executing one turn at a time, and each turn is executing on behalf of only one of the activation’s requests. Reentrant grain code will never run multiple pieces of grain code in parallel (execution of grain code will always be single-threaded), but reentrant grains may see the execution of code for different requests interleaving. That is, the continuation turns from different requests may interleave. For example, with the below pseudo-code, when Foo and Bar are 2 methods of the same grain class: Task Foo() { await task1; // line 1 return Do2(); // line 2 } Task Bar() { await task2; // line 3 return Do2(); // line 4 } If this grain is marked [Reentrant] , the execution of Foo and Bar may interleave. For example, the following order of execution is possible: Line 1, line 3, line 2 and line 4. That is, the turns from different requests interleave. If the grain was not reentrant, the only possible executions would be: line 1, line 2, line 3, line 4 OR: line 3, line 4, line 1, line 2 (new request cannot start before the previous one finished). The main tradeoff in choosing between reentrant and non-reentrant grains is the code complexity to make interleaving work correctly and the difficulty to reason about it. In a trivial case when the grains are stateless and the logic is simple, fewer (but not too few, so that all the hardware threads are used) reentrant grains should be in general slightly more efficient. If the code is more complex, then a larger number of non-reentrant grains, even if slightly less efficient overall, should save you a lot of grief of figuring out non-obvious interleaving issues. In the end answer will depend on the specifics of the application. Interleaving methods Grain interface methods marked with [AlwaysInterleave] will be interleaved regardless of whether the grain is reentrant or not. Consider the following example: public interface ISlowpokeGrain : IGrainWithIntegerKey { Task GoSlow(); [AlwaysInterleave] Task GoFast(); } public class SlowpokeGrain : Grain, ISlowpokeGrain { public async Task GoSlow() { await Task.Delay(TimeSpan.FromSeconds(10)); } public async Task GoFast() { await Task.Delay(TimeSpan.FromSeconds(10)); } } Now consider the call flow initiated by the following client request: var slowpoke = client.GetGrain<ISlowpokeGrain>(0); // A) This will take around 20 seconds await Task.WhenAll(slowpoke.GoSlow(), slowpoke.GoSlow()); // B) This will take around 10 seconds. await Task.WhenAll(slowpoke.GoFast(), slowpoke.GoFast(), slowpoke.GoFast()); Calls to GoSlow will not be interleaved, so the execution of the two GoSlow() calls will take around 20 seconds. On the other hand, because GoFast is marked [AlwaysInterleave] , the three calls to it will be executed concurrently and will complete in approximately 10 seconds total instead of requiring at least 30 seconds to complete. Reentrancy within a call chain In order to avoid deadlocks, the scheduler allows reentrancy within a given call chain. Consider the following example of two grains which have mutually recursive methods, IsEven and IsOdd : public interface IEvenGrain : IGrainWithIntegerKey { Task<bool> IsEven(int num); } public interface IOddGrain : IGrainWithIntegerKey { Task<bool> IsOdd(int num); } public class EvenGrain : Grain, IEvenGrain { public async Task<bool> IsEven(int num) { if (num == 0) return true; var oddGrain = this.GrainFactory.GetGrain<IOddGrain>(0); return await oddGrain.IsOdd(num - 1); } } public class OddGrain : Grain, IOddGrain { public async Task<bool> IsOdd(int num) { if (num == 0) return false; var evenGrain = this.GrainFactory.GetGrain<IEvenGrain>(0); return await evenGrain.IsEven(num - 1); } } Now consider the call flow initiated by the following client request: var evenGrain = client.GetGrain<IEvenGrain>(0); await evenGrain.IsEven(2); The above code calls IEvenGrain.IsEven(2) , which calls IOddGrain.IsOdd(1) , which calls IEvenGrain.IsEven(0) , which returns true back up the call chain to the client. Without call chain reentrancy, the above code will result in a deadlock when IOddGrain calls IEvenGrain.IsEven(0) . With call chain reentrancy, however, the call is allowed to proceed as it is deemed to be the intention of the developer. This behavior can be disabled by setting SchedulingOptions.AllowCallChainReentrancy to false . For example: siloHostBuilder.Configure<SchedulingOptions>( options => options.AllowCallChainReentrancy = false); Reentrancy using a predicate Grain classes can specify a predicate used to determine interleaving on a call-by-call basis by inspecting the request. The [MayInterleave(string methodName)] attribute provides this functionality. The argument to the attribute is the name of a static method within the grain class which accepts an InvokeMethodRequest object and returns a bool indicating whether or not the request should be interleaved. Here is an example which allows interleaving if the request argument type has the [Interleave] attribute: [AttributeUsage(AttributeTargets.Class | AttributeTargets.Struct)] public sealed class InterleaveAttribute : Attribute { } // Specify the may-interleave predicate. [MayInterleave(nameof(ArgHasInterleaveAttribute))] public class MyGrain : Grain, IMyGrain { public static bool ArgHasInterleaveAttribute(InvokeMethodRequest req) { // Returning true indicates that this call should be interleaved with other calls. // Returning false indicates the opposite. return req.Arguments.Length == 1 && req.Arguments[0]?.GetType().GetCustomAttribute<InterleaveAttribute>() != null; } public Task Process(object payload) { // Process the object. } }"
  },
  "Documentation/grains/observers.html": {
    "href": "Documentation/grains/observers.html",
    "title": "Observers | Microsoft Orleans Documentation",
    "keywords": "Observers There are situations in which a simple message/response pattern is not enough, and the client needs to receive asynchronous notifications. For example, a user might want to be notified when a new instant message has been published by a friend. Client observers is a mechanism that allows notifying clients asynchronously. An observer is a one-way asynchronous interface that inherits from IGrainObserver , and all its methods must be void. The grain sends a notification to the observer by invoking it like a grain interface method, except that it has no return value, and so the grain need not depend on the result. The Orleans runtime will ensure one-way delivery of the notifications. A grain that publishes such notifications should provide an API to add or remove observers. In addition, it is usually convenient to expose a method that allows an existing subscription to be cancelled. Grain developers may use the Orleans ObserverSubscriptionManager<T> generic class to simplify development of observed grain types. To subscribe to a notification, the client must first create a local C# object that implements the observer interface. It then calls a static method on the observer factory, CreateObjectReference() , to turn the C# object into a grain reference, which can then be passed to the subscription method on the notifying grain. This model can also be used by other grains to receive asynchronous notifications. Unlike in the client subscription case, the subscribing grain simply implements the observer interface as a facet, and passes in a reference to itself (e.g. this.AsReference<IMyGrainObserverInterface> ). Code Example Let's assume that we have a grain that periodicaly sends messages to clients. For simplicity, the message in our example will be a string. We first define the interface on the client that will receive the message. the interface will look like this public interface IChat : IGrainObserver { void ReceiveMessage(string message); } The only special thing is that the interface should inherit from IGrainObserver . Now any client that wants to observe those messages should implement a class which implements IChat . The simplest case would be something like this: public class Chat : IChat { public void ReceiveMessage(string message) { Console.WriteLine(message); } } Now on the server we should have a Grain which sends these chat messages to clients. The Grain also should have a mechanism for clients to subscribe and unsubscribe themselves to receive notifications. For subscription the Grain can use the utility class ObserverSubscriptionManager . This class throws an OrleansException if you try to subscribe an observer that is already subscribed (or unsubscribe an observer that is not subscribed), so it is important to handle this case by using the IsSubscribed() method or by handling the OrleansException : class HelloGrain : Grain, IHello { private ObserverSubscriptionManager<IChat> _subsManager; public override async Task OnActivateAsync() { // We created the utility at activation time. _subsManager = new ObserverSubscriptionManager<IChat>(); await base.OnActivateAsync(); } // Clients call this to subscribe. public Task Subscribe(IChat observer) { if (!_subsManager.IsSubscribed(observer)) { _subsManager.Subscribe(observer); } return Task.CompletedTask; } //Also clients use this to unsubscribe themselves to no longer receive the messages. public Task UnSubscribe(IChat observer) { if (_subsManager.IsSubscribed(observer)) { _subsManager.Unsubscribe(observer); } return Task.CompletedTask; } } To send the message to clients the Notify method of the ObserverSubscriptionManager<IChat> instance can be used. The method takes an Action<T> method or lambda expression (where T is of type IChat here). You can call any method on the interface to send it to clients. In our case we only have one method ReceiveMessage and our sending code on the server would look like this: public Task SendUpdateMessage(string message) { _subsManager.Notify(s => s.ReceiveMessage(message)); return Task.CompletedTask; } Now our server has a method to send messages to observer clients, two methods for subscribing/unsubscribing and the client implemented a class to be able to observe the grain messages. The last step is to create an observer reference on the client using our previously implemented Chat class and let it receive the messages after subscribing it. The code would look like this: //First create the grain reference var friend = GrainClient.GrainFactory.GetGrain<IHello>(0); Chat c = new Chat(); //Create a reference for chat usable for subscribing to the observable grain. var obj = await GrainClient.GrainFactory.CreateObjectReference<IChat>(c); //Subscribe the instance to receive messages. await friend.Subscribe(obj); Now whenever our grain on the server calls the SendUpdateMessage method, all subscribed clients will receive the message. In our client code, the Chat instance in variable c will receive the message and output it to the console. Note: Objects passed to CreateObjectReference are held via a WeakReference<T> and will therefore be garbage collected if no other references exist. Users should maintain a reference for each observer which they do not want to be collected. Note: Observers are inherently unreliable since you don't get any response back to know if the message is received and processed or simply failed due to any condition which might arise in a distributed system. Because of that your observers should poll the grain periodically or use any other mechanism to ensure that they received all messages which they should have received. In some situations you can afford to lose some messages and you don't need any additional mechanism but if you need to make sure that all observers are always receiving the messages and are receiving all of them, both periodic resubscriptions and polling the observer grain, can help to ensure eventual processing of all messages."
  },
  "Documentation/grains/external_tasks_and_grains.html": {
    "href": "Documentation/grains/external_tasks_and_grains.html",
    "title": "External Tasks and Grains | Microsoft Orleans Documentation",
    "keywords": "External Tasks and Grains By design, any sub-Tasks spawned from grain code (for example, by using await or ContinueWith or Task.Factory.StartNew ) will be dispatched on the same per-activation TPL Task Scheduler as the parent task and therefore inherit the same single-threaded execution model as the rest of grain code. This is the main point behind single threaded execution of grain turn based concurency . In some cases grain code might need to “break out” of the Orleans task scheduling model and “do something special”, such as explicitly pointing a Task to a different task scheduler or using the .NET Thread pool. An example of such cases is when grain code has to execute a synchronous remote blocking call (such as remote IO). Doing that in the grain context will block the grain as well as one of the Orleans threads and thus should never be made. Instead, the grain code can execute this piece of blocking code on the thread pool thread and join ( await ) the completion of that execution and proceed in the grain context. We expect that escaping from the Orleans scheduler will be a very advanced and seldom required usage scenario beyond the “normal” usage patterns. Task based APIs: 1) await , Task.Factory.StartNew , Task.ContinuewWith , Task.WhenAny , Task.WhenAll , Task.Delay all respect the current Task Scheduler. That means that using them in the default way, without passing a different TaskScheduler, will cause them to execute in the grain context. 2) Both Task.Run and the endMethod delegate of Task.Factory.FromAsync do NOT respect the current task Scheduler. They both use the TaskScheduler.Default scheduler, which is the .NET thread pool task Scheduler. Therefore, the code inside Task.Run and the endMethod will ALWAYS run on the .NET thread pool outside of the single-threaded execution model for Orleans grains, as detailed here . However, any code after the await Task.Run or await Task.Factory.FromAsync will run back under the scheduler at the point the task was created, which is the grain scheduler. 3) configureAwait(false) is an explicit API to escape the current task Scheduler. It will cause the code after an awaited Task to be executed on the TaskScheduler.Default scheduler, which is the .NET thread pool, and will thus break the single-threaded execution of the Orleans grain. You should in general never ever use configureAwait(false) directly in grain code. 4) Methods with signature async void should not be used with grains. They are intended for graphical user interface event handlers. Example: Below is sample code that demonstrates the usage of TaskScheduler.Current , Task.Run and a special custom scheduler to escape from Orlean grain context and how to get back to it. public async Task MyGrainMethod() { // Grab the Orleans task scheduler var orleansTs = TaskScheduler.Current; await TaskDelay(10000); // Current task scheduler did not change, the code after await is still running in the same task scheduler. Assert.AreEqual(orleansTs, TaskScheduler.Current); Task t1 = Task.Run( () => { // This code runs on the thread pool scheduler, not on Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); Assert.AreEqual(TaskScheduler.Default, TaskScheduler.Current); } ); await t1; // We are back to the Orleans task scheduler. // Since await was executed in Orleans task scheduler context, we are now back to that context. Assert.AreEqual(orleansTS, TaskScheduler.Current); // Example of using ask.Factory.StartNew with a custom scheduler to escape from the Orleans scheduler Task t2 = Task.Factory.StartNew(() => { // This code runs on the MyCustomSchedulerThatIWroteMyself scheduler, not on the Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); Assert.AreEqual(MyCustomSchedulerThatIWroteMyself, TaskScheduler.Current); }, CancellationToken.None, TaskCreationOptions.None, scheduler: MyCustomSchedulerThatIWroteMyself); await t2; // We are back to Orleans task scheduler. Assert.AreEqual(orleansTS, TaskScheduler.Current); } Advanced Example - making a grain call from code that runs on a thread pool An even more advanced scenario is a piece of grain code that needs to “break out” of the Orleans task scheduling model and run on a thread pool (or some other, non-Orleans context), but still needs to call another grain. If you try to make a grain call but are not within an Orleans context, you will get an exception that says you are \"trying to send a message on a silo not from within a grain and not from within a system target (RuntimeContext is not set to SchedulingContext)\". Below is code that demonstrates how a grain call can be made from a piece of code that runs inside a grain but not in the grain context. public async Task MyGrainMethod() { // Grab the Orleans task scheduler var orleansTs = TaskScheduler.Current; Task<int> t1 = Task.Run(async () => { // This code runs on the thread pool scheduler, not on Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); // You can do whatever you need to do here. Now let's say you need to make a grain call. Task<Task<int>> t2 = Task.Factory.StartNew(() => { // This code runs on the Orleans task scheduler since we specified the scheduler: orleansTs. Assert.AreEqual(orleansTS, TaskScheduler.Current); return GrainFactory.GetGrain<IFooGrain>(0).MakeGrainCall(); }, CancellationToken.None, TaskCreationOptions.None, scheduler: orleansTs); int res = await (await t2); // double await, unrelated to Orleans, just part of TPL APIs. // This code runs back on the thread pool scheduler, not on the Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); return res; } ); int result = await t1; // We are back to the Orleans task scheduler. // Since await was executed in the Orleans task scheduler context, we are now back to that context. Assert.AreEqual(orleansTS, TaskScheduler.Current); } Dealing with libraries Some external libraries that your code is using might be using ConfigureAwait(false) internally. In fact, it is a good and correct practice in .NET to use ConfigureAwait(false) when implementing general purpose libraries . This is not a problem in Orleans. As long as the code in the grain that invokes the library method is awaiting the library call with a regular await , the grain code is correct. The result will be exactly as desired -- the library code will run continuations on the Default scheduler (which happens to be ThreadPoolTaskScheduler but it does not guarantee that the continuations will definitely run on a ThreadPool thread, as continuations are often inlined in the previous thread), while the grain code will run on the Orleans scheduler. Another frequently-asked question is whether there is a need to execute library calls with Task.Run -- that is, whether there is a need to explicitly offload the library code to ThreadPool (for grain code to do Task.Run(()=> myLibrary.FooAsync()) ). The answer is No. There is no need to offload any code to ThreadPool, except for the case of library code that is making a blocking synchronous calls. Usually, any well-written and correct .NET async library (methods that return Task and are named with an Async suffix) do not make blocking calls. Thus there is no need to offload anything to ThreadPool, unless you suspect the async library is buggy or if you are deliberately using a synchronous blocking library. Summary What are you trying to do? How to do it Run background work on .NET thread-pool threads. No grain code or grain calls allowed. Task.Run Grain interface call Method return types = Task or Task<T> Run worker task from grain code with Orleans turn-based concurrency guarantees. Task.Factory.StartNew Timeouts for executing work items Task.Delay + Task.WhenAny Use with async / await The normal .NET Task-Async programming model. Supported & recommended ConfigureAwait(false) Do not use inside grain code. Allowed only inside libraries. Calling async library await the library call"
  },
  "Documentation/grains/developing_a_grain.html": {
    "href": "Documentation/grains/developing_a_grain.html",
    "title": "Developing a Grain | Microsoft Orleans Documentation",
    "keywords": "Setup Before you write code to implement a grain class, create a new Class Library project targeting .NET 4.6.1 or higher in Visual Studio and add the Microsoft.Orleans.OrleansCodeGenerator.Build NuGet package to it. PM> Install-Package Microsoft.Orleans.OrleansCodeGenerator.Build Grain Interfaces and Classes Grains interact with each other and get called from outside by invoking methods declared as part of the respective grain interfaces. A grain class implements one or more previously declared grain interfaces. All methods of a grain interface must return a Task (for void methods) or a Task<T> (for methods returning values of type T ). The following is an excerpt from the Orleans version 1.5 Presence Service sample: //an example of a Grain Interface public interface IPlayerGrain : IGrainWithGuidKey { Task<IGameGrain> GetCurrentGame(); Task JoinGame(IGameGrain game); Task LeaveGame(IGameGrain game); } //an example of a Grain class implementing a Grain Interface public class PlayerGrain : Grain, IPlayerGrain { private IGameGrain currentGame; // Game the player is currently in. May be null. public Task<IGameGrain> GetCurrentGame() { return Task.FromResult(currentGame); } // Game grain calls this method to notify that the player has joined the game. public Task JoinGame(IGameGrain game) { currentGame = game; Console.WriteLine( \"Player {0} joined game {1}\", this.GetPrimaryKey(), game.GetPrimaryKey()); return Task.CompletedTask; } // Game grain calls this method to notify that the player has left the game. public Task LeaveGame(IGameGrain game) { currentGame = null; Console.WriteLine( \"Player {0} left game {1}\", this.GetPrimaryKey(), game.GetPrimaryKey()); return Task.CompletedTask; } } Returning Values from Grain Methods A grain method that returns a value of type T is defined in a grain interface as returning a Task<T> . For grain methods not marked with the async keyword, when the return value is available, it is usually returned via the following statement: public Task<SomeType> GrainMethod1() { ... return Task.FromResult(<variable or constant with result>); } A grain method that returns no value, effectively a void method, is defined in a grain interface as returning a Task . The returned Task indicates asynchronous execution and completion of the method. For grain methods not marked with the async keyword, when a \"void\" method completes its execution, it needs to return the special value of Task.CompletedTask : public Task GrainMethod2() { ... return Task.CompletedTask; } A grain method marked as async returns the value directly: public async Task<SomeType> GrainMethod3() { ... return <variable or constant with result>; } A \"void\" grain methods marked as async that returns no value simply returns at the end of their execution: public async Task GrainMethod4() { ... return; } If a grain method receives the return value from another asynchronous method call, to a grain or not, and doesn't need to perform error handling of that call, it can simply return the Task it receives from that asynchronous call as its return value: public Task<SomeType> GrainMethod5() { ... Task<SomeType> task = CallToAnotherGrain(); return task; } Similarly, a \"void\" grain method can return a Task returned to it by another call instead of awaiting it. public Task GrainMethod6() { ... Task task = CallToAsyncAPI(); return task; } Grain Reference A Grain Reference is a proxy object that implements the same grain interface as the corresponding grain class. It encapsulates a logical identity (type and unique key) of the target grain. A grain reference is what is used for making calls to the target grain. Each grain reference is for a single grain (a single instance of the grain class), but one can create multiple independent references for the same grain. Since a grain reference represents a logical identity of the target grain, it is independent from the physical location of the grain, and stays valid even after a complete restart of the system. Developers can use grain references like any other .NET object. It can be passed to a method, used as a method return value, etc., and even saved to persistent storage. A grain reference can be obtained by passing the identity of a grain to the GrainFactory.GetGrain<T>(key) method, where T is the grain interface and key is the unique key of the grain within the type. The following are examples of how to obtain a grain reference of the IPlayerGrain interface defined above. From inside a grain class: //construct the grain reference of a specific player IPlayerGrain player = GrainFactory.GetGrain<IPlayerGrain>(playerId); From Orleans Client code. Prior to 1.5.0: IPlayerGrain player = GrainClient.GrainFactory.GetGrain<IPlayerGrain>(playerId); Since 1.5.0: IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); Grain Method Invocation The Orleans programming model is based on the Asynchronous Programming with Async and Await . Using the grain reference from the previous example, here's how one performs a grain method invocation: //Invoking a grain method asynchronously Task joinGameTask = player.JoinGame(this); //The await keyword effectively makes the remainder of the method execute asynchronously at a later point (upon completion of the Task being awaited) without blocking the thread. await joinGameTask; //The next line will execute later, after joinGameTask is completed. players.Add(playerId); It is possible to join two or more Tasks ; the join operation creates a new Task that is resolved when all of its constituent Task s are completed. This is a useful pattern when a grain needs to start multiple computations and wait for all of them to complete before proceeding. For example, a front-end grain that generates a web page made of many parts might make multiple back-end calls, one for each part, and receive a Task for each result. The grain would then await the join of all of these Tasks ; when the join Task is resolved, the individual Task s have been completed, and all the data required to format the web page has been received. Example: List<Task> tasks = new List<Task>(); Message notification = CreateNewMessage(text); foreach (ISubscriber subscriber in subscribers) { tasks.Add(subscriber.Notify(notification)); } // WhenAll joins a collection of tasks, and returns a joined Task that will be resolved when all of the individual notification Tasks are resolved. Task joinedTask = Task.WhenAll(tasks); await joinedTask; // Execution of the rest of the method will continue asynchronously after joinedTask is resolve. Virtual methods A grain class can optionally override OnActivateAsync and OnDeactivateAsync virtual methods that get invoked by the Orleans runtime upon activation and deactivation of each grain of the class. This gives the grain code a chance to perform additional initialization and cleanup operations. An exception thrown by OnActivateAsync fails the activation process. While OnActivateAsync , if overridden, is always called as part of the grain activation process, OnDeactivateAsync is not guaranteed to get called in all situations, for example, in case of a server failure or other abnormal events. Because of that, applications should not rely on OnDeactivateAsync for performing critical operations, such as persistence of state changes, and only use it for best effort operations."
  },
  "Documentation/deployment/multi-cluster_support/Overview.html": {
    "href": "Documentation/deployment/multi-cluster_support/Overview.html",
    "title": "Multi-Cluster Support | Microsoft Orleans Documentation",
    "keywords": "Multi-Cluster Support Orleans v.1.3.0 added support for federating several Orleans clusters into a loosely connected multi-cluster that acts like a single service. Multi-clusters facilitate geo-distribution of a service, that is, make it easier to run an Orleans application in multiple data-centers around the world. Also, a multi-cluster can be run within a single datacenter to get better failure and performance isolation. All mechanisms are designed with particular attention to (1) minimize communication between clusters, and (2) let each cluster run autonomously even if other clusters fail or become unreachable. Configuration and Operation Below we document how to configure and operate a multi-cluster. Communication . Clusters communicate via the same silo-to-silo connections that are used within a cluster. To exchange status and configuration information, Clusters use a gossip mechanism and gossip channel implementations. Silo Configuration . Silos need to be configured so they know which cluster they belong to (each cluster is identified by a unique string). Also, each silo needs to be configured with connection strings that allow them to connect to one or more gossip channels on startup. Multi-Cluster Configuration Injection . At runtime, the service operator can specify and/or change the multi-cluster configuration , which contains a list of cluster ids, to specify which clusters are part of the current multi-cluster. This is done by calling the management grain in any one of the clusters. Multi-Cluster Grains Below we document how to use multi-cluster functionality at the application level. Global-Single-Instance Grains . Developers can indicate when and how clusters should coordinate their grain directories with respect to a particular grain class. The [GlobalSingleInstance] attribute means we want the same behavior as as when running Orleans in a single global cluster: that is, route all calls to a single activation of the grain. Conversely, the [OneInstancePerCluster] attribute indicates that each cluster can have its own independent activation. This is appropriate if communication between clusters is undesired. Log-View Grains (not in v.1.3.0) . A special type of grain that uses a new API, similar to event sourcing, for synchronizing or persisting grain state. It can be used to automatically and efficiently synchronize the state of a grain between clusters and with storage. Because its synchronization algorithms are safe to use with reentrant grains, and are optimized to use batching and replication, it can perform better than standard grains when a grain is frequently accessed in multiple clusters, and/or when it is written to storage frequently. Support for log-view grains is not part of the master branch yet. We have a prerelease including samples and a bit of documentation in the geo-orleans branch . It is currently being evaluated in production by an early adopter."
  },
  "Documentation/core_concepts/what_is_a_grain.html": {
    "href": "Documentation/core_concepts/what_is_a_grain.html",
    "title": "What is a grain | Microsoft Orleans Documentation",
    "keywords": "What is a grain? Grains are the key primitives of the Orleans programming model. Grains are the building blocks of an Orleans application, they are atomic units of isolation, distribution, and persistence. Grains are objects that represent application entities. Just like in the classic Object Oriented Programming, a grain encapsulates state of an entity and encodes its behavior in the code logic. Grains can hold references to each other and interact by invoking each other’s methods exposed via interfaces. Orleans aims to greatly simplify building a scalable application and eliminate most of the concurrency challenges By not sharing data between grains instances except via message passing. By providing the single-threaded execution guarantee to each individual grain. A typical grain encapsulates state and behavior of a single entity (e.g. a specific user or a device or a session). Grain Identity An individual grain is a uniquely addressable instance of a grain type (class). Each grain has a unique identity, also referred to as a grain key, within its type. Grain identity within its type can be a long integer, a GUID, a string, or a combination of a long+string or GUID+string. Accessing a Grain A grain class implements one or more grain interfaces, formal code contracts for interacting with grains of that type. To invoke a grain, a caller needs to know the grain interface that the grain class implements that includes the method that the caller wants to call and the unique identity (key) of the target grain. For example, here's how a user profile grain can be called to update user's address if email is used as a user identity. var user = grainFactory.GetGrain<IUserProfile>(userEmail); await user.UpdateAddress(newAddress); A call to GetGrain is an inexpensive local operation of constructing a grain reference with an embedded identity and type of the target grain. Note that there is no need to create or instantiate the target grain. We make a call to it to update user's address as if the user's grain is already instantiated for us. This is one of the biggest advantages of the Orleans programming model - we never need to create, instantiate or delete grains. We can write our code as if all possible grains, for example millions of user profiles, are always in memory waiting for us to call them. Behind the scenes, the Orleans runtime performs all the heavy lifting of managing resources to transparently bring grains to memory when needed. Behind the Scenes - Grain Lifecycle Grains live in execution containers called silos. Silos form a cluster that combines resources of multiple physical or virtual machines. When there is work (request) for a grain, Orleans ensures there is an instance of the grain on one of the Silos in the cluster. If there is no instance of the grain on any silo, the Orleans runtime creates one. This process is called Activation. In the case that a grain is using Grain Persistence, the runtime automatically reads the state from the backing store upon activation. Once activated on a silo, a grain processes incoming requests (method calls) from other grains or from outside of the cluster (usually from frontend web servers). In the course of processing a request a grain may call other grains or some external services. If a grain stops receiving requests and stays idle, after a configurable period of inactivity Orleans removes the grain from memory (deactivates it) to free up resources for other grains. If and when there's a new request for that grain, Orleans will activate it again, potentially on a different silo, so the caller gets the impression that the grain stayed in memory the whole time. A grain goes through the lifecycle from existing only as its persisted state (if it has any) in storage to being instantiated in memory to being removed from memory. Orleans controls the process of activating and deactivating grains transparently. When coding a grain, a developer assumes all grains are always activated. The sequence of key events in grain lifecycle looks like this. Another grain or a client makes a call to a method of the grain (via a grain reference) The grain gets activated (if it is not already activated somewhere in the cluster) and an instance of the grain class, called a grain activation, is created Constructor of the grain is executed leveraging Dependency Injection, if applicable If Declarative Persistence is used, the grain state is read from storage If overridden, OnActivateAsync is called The grain processes incoming requests The grain remains idle for some time Silo runtime decides to deactivate the grain Silo runtime calls OnDeactivateAsync , if overridden Silo runtime removes the grain from memory Upon a graceful shutdown of a silo, all grain activations it holds get deactivated. Any requests waiting to be processed in grains' queues get forwarded to other silos in the cluster, where new activations of deactivated grains get created on an as-needed basis. If a silo shuts down or dies ungracefully, other silos in the cluster detect the failure, and start creating new activations of grains lost on the failed silo, as new requests for those grains arrive. Note that detection of a silo failure takes some time (configurable), and hence the process of reactivating lost grains isn't instantaneous. Grain Execution A grain activation performs work in chunks and finishes each chunk before it moves on to the next. Chunks of work include method invocations in response to requests from other grains or external clients, and closures scheduled on completion of a previous chunk. The basic unit of execution corresponding to a chunk of work is known as a turn. While Orleans may execute many turns belonging to different activations in parallel, each activation will always execute its turns one at a time. This means that there is no need to use locks or other synchronization methods to guard against data races and other multi-threading hazards."
  },
  "Documentation/core_concepts/what_is_a_cluster.html": {
    "href": "Documentation/core_concepts/what_is_a_cluster.html",
    "title": "What is a Cluster | Microsoft Orleans Documentation",
    "keywords": "What is a cluster? ///TODO: write about relationship among client, cluster, and silo. Explain terminology."
  },
  "Documentation/core_concepts/what_is_a_client.html": {
    "href": "Documentation/core_concepts/what_is_a_client.html",
    "title": "What is a Client | Microsoft Orleans Documentation",
    "keywords": "What Is Grain Client? The term \"Client\" or sometimes \"Grain Client\" is used for application code that interacts with grains but itself is not part of a grain logic. Client code runs outside of the cluster of Orleans servers called silos where grains are hosted. Hence, a client acts as a connector or conduit to the cluster and to all grains of the application. Usually, clients are used on the frontend web servers to connect to an Orleans cluster that serves as a middle tier with grains executing business logic. In a typical setup, a frontend web server: Receives a web request Performs necessary authentication and authorization validation Decides which grain(s) should process the request Uses Grain Client to make one or more method call to the grain(s) Handles successful completion or failures of the grain calls and any returned values Sends a response for the web request Initialization of Grain Client Before a grain client can be used for making calls to grains hosted in an Orleans cluster, it needs to be configured, initialized, and connected to the cluster. Configuration is provided via a ClientConfiguration object that contains a hierarchy of configuration properties for programmatically configuring a client. There is also a way to configure a client via a XML file, but that option will be deprecated in the future. More information is in the Client Configuration guide. Here we will simply use a helper method that creates a configuration object hardcoded for connecting to a local silo running as localhost . ClientConfiguration clientConfig = ClientConfiguration.LocalhostSilo(); Once we have a configuration object, we can build a client via the ClientBuilder class. IClusterClient client = new ClientBuilder().UseConfiguration(clientConfig).Build(); Lastly, we need to call Connect() method on the constructed client object to make it connect to the Orleans cluster. It's an asynchronous method that returns a Task . So we need to wait for its completion with an await or .Wait() . await client.Connect(); Making Calls to Grains Making calls to grain from a client is really no different from making such calls from within grain code. The same GetGrain<T>(key) method, where T is the target grain interface, is used in both cases to obtain grain references. The slight difference is in through what factory object we invoke GetGrain . In client code we do that through the connected client object. IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); Task t = player.JoinGame(game) await t; A call to a grain method returns a Task or a Task<T> as required by the grain interface rules. The client can use the await keyword to asynchronously await the returned Task without blocking the thread, or in some cases the Wait() method to block the current thread of execution. The major difference between making calls to grains from client code and from within another grain is the single-threaded execution model of grains. Grains are constrained to be single-threaded by the Orleans runtime, while clients may be multi-threaded. Orleans does not provide any such guarantee on the client side, and so it is up to the client to manage its own concurrency using whatever synchronization constructs are appropriate for its environment – locks, events, Tasks , etc. Receiving notifications There are situations in which a simple request-response pattern is not enough, and the client needs to receive asynchronous notifications. For example, a user might want to be notified when a new message has been published by someone that she is following. Observers is one such mechanism that enables exposing client side objects as grain-like targets to get invoked by grains. Calls to observers do not provide any indication of success or failure, as they are sent as one-way best effort message. So it is a responsibility of the application code to build a higher level reliability mechanism on top of observers where necessary. Another mechanism that can be used for delivering asynchronous messages to clients is Streams. Streams expose indications of success or failure of delivery of individual messages, and hence enable reliable communication back to the client. Example Here is an extended version of the example given above of a client application that connects to Orleans, finds the player account, subscribes for updates to the game session the player is part of with an observer, and prints out notifications until the program is manually terminated. namespace PlayerWatcher { class Program { /// <summary> /// Simulates a companion application that connects to the game /// that a particular player is currently part of, and subscribes /// to receive live notifications about its progress. /// </summary> static void Main(string[] args) { RunWatcher().Wait(); // Block main thread so that the process doesn't exit. // Updates arrive on thread pool threads. Console.ReadLine(); } static async Task RunWatcher() { try { // Connect to local silo var config = ClientConfiguration.LocalhostSilo(); var client = new ClientBuilder().UseConfiguration(config).Build(); await client.Connect(); // Hardcoded player ID Guid playerId = new Guid(\"{2349992C-860A-4EDA-9590-000000000006}\"); IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); IGameGrain game = null; while (game == null) { Console.WriteLine(\"Getting current game for player {0}...\", playerId); try { game = await player.GetCurrentGame(); if (game == null) // Wait until the player joins a game { await Task.Delay(5000); } } catch (Exception exc) { Console.WriteLine(\"Exception: \", exc.GetBaseException()); } } Console.WriteLine(\"Subscribing to updates for game {0}...\", game.GetPrimaryKey()); // Subscribe for updates var watcher = new GameObserver(); await game.SubscribeForGameUpdates( await client.CreateObjectReference<IGameObserver>(watcher)); Console.WriteLine(\"Subscribed successfully. Press <Enter> to stop.\"); } catch (Exception exc) { Console.WriteLine(\"Unexpected Error: {0}\", exc.GetBaseException()); } } } /// <summary> /// Observer class that implements the observer interface. Need to pass a grain reference to an instance of this class to subscribe for updates. /// </summary> class GameObserver : IGameObserver { // Receive updates public void UpdateGameScore(string score) { Console.WriteLine(\"New game score: {0}\", score); } } } }"
  },
  "1.5/Documentation/Installation/Prerequisites.html": {
    "href": "1.5/Documentation/Installation/Prerequisites.html",
    "title": "Prerequisites | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Prerequisites Orleans is a set of .NET libraries delivered via NuGet packages . In order to use Orleans, you need .NET Framework 4.6.1 (since 1.5.0, 4.5.1 for prior versions) or higher and a copy of Visual Studio 2015 or higher. Note that the Express versions of Visual Studio do not support extension packages, but you can use Orleans by adding references to the NuGet packages directly. In production, Orleans requires persistent storage for reliable cluster membership. The following storage technologies are supported for managing cluster membership state (only need one of those): Azure Table Storage - Tested with Azure SDK 2.4 - 2.8 SQL Server 2008 or higher ZooKeeper 3.4.0 or higher MySQL 5.0 or higher PostgreSQL 9.5 or higher Consul 0.6.0 or higher DynamoDB - Tested with AWSSDK - Amazon DynamoDB 3.1.5.3 Another production deployment option is to use Azure Service Fabric . There is a NuGet package that helps with that. It has a dependency on Service Fabric 2.1.163."
  },
  "1.5/Documentation/Grain-Versioning/Version-selector-strategy.html": {
    "href": "1.5/Documentation/Grain-Versioning/Version-selector-strategy.html",
    "title": "Version selector strategy | Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here . Version selector strategy When several versions of the same grain interface exist in the cluster, and a new activation has to be created, a compatible version will be chosen according to the strategy defined in GlobalConfiguration.DefaultVersionSelectorStrategy . Orleans out of the box supports the following strategies: All compatible versions (default) Using this strategy, the version of the new activation will be chosen randomly across all compatible versions. For example if we have 2 versions of a given grain interface, V1 and V2: V2 is backward compatible with V1 In the cluster there are 2 silos that support V2, 8 support V1 The request was made from a V1 client/silo In this case, there is a 20% chance that the new activation will be a V2 and 80% chance that it will be a V1. Latest version Using this strategy, the version of the new activation will always be the latest compatible version. For example if we have 2 versions of a given grain interface, V1 and V2 (V2 is backward or fully compatible with V1) then all new activations will be V2. Minimum version Using this strategy, the version of the new activation will always be the requested or the minimum compatible version. For example if we have 2 versions of a given grain interface, V2, V3, all fully compatibles: If the request was made from a V1 client/silo, the new activation will be a V2 If the request was made from a V3 client/silo, the new activation will be a V2 too"
  },
  "1.5/warning-banner.html": {
    "href": "1.5/warning-banner.html",
    "title": "| Microsoft Orleans Documentation",
    "keywords": "Important You are looking at the 1.5 documentation Orleans 2.0 is a significant overhaul from the 1.x versions. You can find 2.0 documentation here ."
  },
  "Tutorials/index.html": {
    "href": "Tutorials/index.html",
    "title": "Step by Step Tutorials | Microsoft Orleans Documentation",
    "keywords": "These tutorials are for the 2.0 release Orleans 2.0 is a significant overhaul from the 1.x versions. For 1.5 Documentation and Tutorials , refer to the respective sections that are snapshots of the documentation as of the 2.0 release."
  },
  "Tutorials/Declarative-Persistence.html": {
    "href": "Tutorials/Declarative-Persistence.html",
    "title": "Declarative Persistence | Microsoft Orleans Documentation",
    "keywords": "Declarative Persistence In the second tutorial, we saw how grain state survived the client being shut down, which opens up for a lot of cache-like scenarios, where Orleans is relied upon as a kind of 'cache with behavior,' an object-oriented cache, if you will. That is already very valuable and goes a long way toward achieving server-side scalability with a simple, familiar, programming model and the built-in single-threaded execution guarantees. However, it is sometimes the case that some of the state you are accumulating belongs in some form of permanent storage, so that it can survive a silo shutdown, or a grain migrating from one silo to another for load-balancing or a complete restart/shutdown of the service. What we have seen so far will not support such situations. Fortunately, Orleans offers a simple declarative model for identifying the state that needs to be stored in a permanent location, while leaving the decision when to save and restore state under programmatic control. You are not required to use the declarative persistence mechanism and can still access storage directly from your grain code, but it’s a nice way to save you some boilerplate code and build applications that are portable across various storage services. Getting Started We'll continue to build on our employee-and-manager sample. The first thing we need to do is make the identities of our workers and managers a little more predictable. In the sample, they were assigned GUIDs using Guid.NewGuid() , which is convenient, but doesn't let us find them in a subsequent run. Therefore, we'll create a set of GUIDs first, then use them as the worker identities. The modified client program looks like this: private static async Task DoClientWork(IClusterClient client) { ... var ids = new string[] { \"42783519-d64e-44c9-9c29-399e3afaa625\", \"d694a4e0-1bc3-4c3f-a1ad-ba95103622bc\", \"9a72b0c6-33df-49db-ac05-14316edd332d\", \"6526a751-b9ac-4881-9bfb-836ecce2ca9f\", \"ae4b106f-3c96-464a-b48d-3583ed584b17\", \"b715c40f-d8d2-424d-9618-76afbc0a2a0a\", \"5ad92744-a0b1-487b-a9e7-e6b91e9a9826\", \"e23a55af-217c-4d76-8221-c2b447bf04c8\", \"2eef0ac5-540f-4421-b9a9-79d89400f7ab\" }; var e0 = client.GetGrain<IEmployee>(Guid.Parse(ids[0])); var e1 = client.GetGrain<IEmployee>(Guid.Parse(ids[1])); var e2 = client.GetGrain<IEmployee>(Guid.Parse(ids[2])); var e3 = client.GetGrain<IEmployee>(Guid.Parse(ids[3])); var e4 = client.GetGrain<IEmployee>(Guid.Parse(ids[4])); var m0 = client.GetGrain<IManager>(Guid.Parse(ids[5])); var m1 = client.GetGrain<IManager>(Guid.Parse(ids[6])); ... } Note: If you are transitioning from Orleans 1.5, you will notice that the Client is no longer static. Please refer to Migration from Orleans 1.5 to 2.0 page. Next, we'll do some silo configuration, in order to configure the storage provider that will give us access to persistent storage. The SiloHost project includes a file Program.cs which is where we find the following section: var builder = new SiloHostBuilder() .UseLocalhostClustering() .Configure<EndpointOptions>(options => options.AdvertisedIPAddress = IPAddress.Loopback) .ConfigureLogging(logging => logging.AddConsole()); var host = builder.Build(); await host.StartAsync(); return host; If this is hosted in Azure Cloud Services, then one can use either of the following before calling builder.Build() to use Azure to persist grain state: // Stores grains as composition of fields builder.AddAzureTableGrainStorage(option => option.ConnectionString = your_connection_string); // Stores grains as blobs builder.AddAzureBlobGrainStorage(option => option.ConnectionString = your_connection_string); The MemoryStorage provider is fairly uninteresting, since it doesn't actually provide any permanent storage; it's intended for debugging persistent grains while having no access to a persistent store. In our case, that makes it hard to demonstrate persistence, so we will rely on a real storage provider. Depending on whether you have already set up (and want to use) an Azure storage account, or would like to rely on the Azure storage emulator, you should add one of the other two lines, but not both. You can use either the AddAzureTableStorageProvider() function or the AddAzureBlobStorageProvider() function depending on how you want to store information. In the case of the former, you have to start the Azure storage emulator after installing the latest version of the Azure SDK. In the case of the latter, you will have to create a Azure storage account and enter the name and keys in the configuration file. With one of those enabled, we're ready to tackle the grain code. Note: With Orleans 2.0, a lot of functionality have been split off into smaller packages to allow more granular configuration and deployment. This includes the Azure storage provider. Please install Orleans.Persistence.AzureStorage package if you would like to use Azure as a storage provider. You could find some of the other storage providers maintained by the Orleans community by searching for Orleans.Persistence . Declaring State Identifying that a grain should use persistent state takes three steps: declaring a class for the state, changing the grain base class, and identifying the storage provider. The first step, declaring a state class in the grain implementations project, simply means identifying the information of an actor that should be persisted and creating what looks like a record of the persistent data -- each state component is represented by a property with a getter and a setter. For employees, we want to persist all the state: public class EmployeeState { public int Level { get; set; } public IManager Manager { get; set; } } and for managers, we must store the direct reports, but the _me reference may continue to be created during activation. public class ManagerState { public List<IEmployee> Reports { get; set; } } Then, we change the grain class declaration to identify the state interface (e.g., from Orleans.Grain to Orleans.Grain<EmployeeState> ) and remove the variables that we want persisted. Make sure to remove level , and manager from the Employee class and _reports from the Manager class. In addition, we must update the other functions to reflect these removals. We also add an attribute to identify the storage provider: [StorageProvider(ProviderName = \"AzureStore\")] public class Employee : Orleans.Grain<EmployeeState>, Interfaces.IEmployee and [StorageProvider(ProviderName=\"AzureStore\")] public class Manager : Orleans.Grain<ManagerState>, IManager At risk of stating the obvious, the name of the storage provider attribute should match the name as it was used in configuring the Silo. This indirection is what allows you to delay choices around where to store grain state until deployment. Given these declarative changes, the grain should no longer rely on a private fields to keep compensation level and manager. Instead, the grain base class gives us access to the state via a State property that is available to the grain. For example: public Task SetManager(IManager manager) { State.Manager = manager; return TaskDone.Done; } Controlling Checkpoints The question that remains is when the persistent state gets saved to the storage provider. One choice that the Orleans designers could have made would be to have the runtime save state after every method invocation, but that turns out to be undesirable because it is far too conservative -- not all invocations will actually modify the state on all invocations, and some will never modify it. Rather than employing a complex system to evaluate state differentials after each method, Orleans asks the grain developer to add the necessary logic to determine whether state needs to be saved or not. Saving the state using the storage provider is easily accomplished by calling base.WriteStateAsync() . Thus, the final version of the Promote() and SetManager() methods looks like this: public Task Promote(int newLevel) { State.Level = newLevel; return base.WriteStateAsync(); } public Task SetManager(IManager manager) { State.Manager = manager; return base.WriteStateAsync(); } In the Manager class, there's only one method that need to be modified to write out data, AddDirectReport() . It should look like this: public async Task AddDirectReport(IEmployee employee) { if (State.Reports == null) { State.Reports = new List<IEmployee>(); } State.Reports.Add(employee); await employee.SetManager(this); var data = new GreetingData { From = this.GetPrimaryKey(), Message = \"Welcome to my team!\" }; await employee.Greeting(data); Console.WriteLine(\"{0} said: {1}\", data.From.ToString(), data.Message); await base.WriteStateAsync(); } Let's try this out! Set a breakpoint in Employee.Promote() . When we run the client code the first time and hit the breakpoint, the level field should be 0 and the newLevel parameter either 10 or 11 : Let the application finish (reach the 'Hit Enter...' prompt) and exit. Run it again, and compare what happens when you look at state this second time around: Just Making Sure... It's worth checking what Azure thinks about the data. Using a storage explorer such as Azure Storage Explorer (ASE) or the one built in to Server Explorer in Visual Studio 2013, open the storage account (or developer storage of the emulator) and find the 'OrleansGrainState' table. It should look something like this (you have to hit 'Query' in ASE): If everything is working correctly, the grain keys should appear in the PartitionKey column, and the qualified class name of the grains should appear in the RowKey column. Mixing Things A grain may contain a combination of persisted and transient state. Any transient state should be represented by private fields in the grain class. A common use for mixing the two is to cache some computed version of the persisted state in private fields while it is present in memory. For example, a stack of elements may be externally represented as a List<T> , but internally, as a Stack<T> . In the case of our Manager class, the _me field is simply a cached value, something we don't even need to keep as a field in the first place, it can be created any time we need it, but since it's going to be a commonly used value, it's worth keeping it around in a transient field. Automatic loading of state If a grain type has state, at activation time the state will be loaded from storage and then OnActivateAsync is called so you can be sure that the state is loaded when initializing your grain. This is the only case that Orleans calls ReadStateAsync automatically. If you want to write the state or read it in some other place, you should do it on your own. Normally you should not need to call ReadStateAsync yourself unless you are doing something specific regarding handling corrupted state or something else. Handling failures using persistence Generally speaking reading and writing a grain's state is a good mechanism to handle failures as well as serving its original intent. There is a possibility that your grain call fails in the middle of a method due to different reasons and you end up with a state which is half changed. In this case reading from storage can return your state to the last correct state. Alternatively, having gotten into such a state, the grain can request to get immediately deactivated by calling DeactivateOnIdle(), so that its a next request to it would trigger reactivation of the grain, which would reread the persistent state and reconstruct its in-memory copy. Deactivation is the cleanest way of resetting a grain to its last know good state, but if you want to avoid the cost of the reactivation process, you can reset its state and rerun any initialization logic (for example, by calling OnActivateAsync ) instead of deactivating the grain. Next Next, we'll see how we can call our grains from an MVC web application. Handling Failure"
  },
  "Documentation/clusters_and_clients/monitoring/silo_error_code_monitoring.html": {
    "href": "Documentation/clusters_and_clients/monitoring/silo_error_code_monitoring.html",
    "title": "Silo Error Code Monitoring | Microsoft Orleans Documentation",
    "keywords": "Silo Error Code Monitoring Group Log Type Log Code Values Threshold Description Azure Problems Warning or Error 100800 - 100899 Any Error or Warning Transient problems reading or writing to Azure table store will be logged as Warning. Transient read errors will automatically be retried. A final Error log message means there is a real problem connecting to Azure table storage. Membership Connectivity Problems Warning or Error 100600 - 100699 Any Error or Warning Warning logs are an early indication of network connectivity problems and/or silo restart / migration. Ping timeouts and silo-dead votes will show up as Warning messages. Silo detesting it was voted dead will show as Error message. Grain call timeouts Warning 100157 Multiple Warnings logged in short space of time Grain-call timeout problems are generally caused by temporary network connectivity issues or silo restart / reboot problems. The system should recover after a short time (depending on Liveness config settings) at which point Timeouts should clear. Ideally, monitoring for just the bulk log code 600157 variety of these warnings should be sufficient. Silo Restart / Migration Warning 100601 or 100602 Any Warning Warning printed when silo detects it was restarted on same machine {100602) or migrated to different machine (100601) Network Socket Problems Warning or Error 101000 to 101999, 100307,100015, 100016 Any Error or Warning Socket disconnects are logged as Warning messages. Problems opening sockets or during message transmission are logged as Errors. Bulk log message compaction Any 500000 or higher Message summary based on bulk message threshold settings If multiple logs of the same log code occur within a designated time interval (the default is >5 within 1 minute) then additional log messages with that log code are suppressed and output as a \"bulk\" entry with log code equal to the original log code + 500000. So for example, multiple 100157 entries will show in the logs as 5 x 100157 + 1 x 600157 log entry per minute. Grain problems Warning or Error 101534 Any Error or Warning Detection of “stuck” requests for non-reentrant grains . The error code is reported every time a request takes longer than 5x request timeout time to execute."
  },
  "Documentation/clusters_and_clients/configuration_guide/startup_tasks.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/startup_tasks.html",
    "title": "Startup Tasks | Microsoft Orleans Documentation",
    "keywords": "Startup Tasks In many cases, some task needs to be performed automatically as soon as a silo becomes available. Startup Tasks provide this functionality. Some use cases include, but are not limited to: Starting background timers to perform periodic housekeeping tasks Pre-loading some cache grains with data downloaded from external backing storage Any exceptions that are thrown from a startup task during startup will be reported in the silo log and will stop the silo. This fail-fast approach is the standard way that Orleans handles silo start-up issues, and is intended to allow any problems with silo configuration and/or bootstrap logic to be easily detected during testing phases rather than being silently ignored and causing unexpected problems later in the silo lifecycle. Configuring Startup Tasks Startup tasks can be configured using the ISiloHostBuilder either by registering a delegate to be invoked during startup or by registering a implementation of IStartupTask . Example: Registering a delegate siloHostBuilder.AddStartupTask( async (IServiceProvider services, CancellationToken cancellation) => { // Use the service provider to get the grain factory. var grainFactory = services.GetRequiredService<IGrainFactory>(); // Get a reference to a grain and call a method on it. var grain = grainFactory.GetGrain<IMyGrain>(0); await grain.Initialize(); }); Example: Registering an IStartupTask implementation First we must define an implementation of IStartupTask : public class CallGrainStartupTask : IStartupTask { private readonly IGrainFactory grainFactory; public CallGrainStartupTask(IGrainFactory grainFactory) { this.grainFactory = grainFactory; } public async Task Execute(CancellationToken cancellationToken) { var grain = this.grainFactory.GetGrain<IMyGrain>(0); await grain.Initialize(); } } Then that implementation must be registered with the ISiloHostBuilder : siloHostBuilder.AddStartupTask<CallGrainStartupTask>();"
  },
  "Documentation/clusters_and_clients/configuration_guide/shutting_down_orleans.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/shutting_down_orleans.html",
    "title": "Shutting down Orleans | Microsoft Orleans Documentation",
    "keywords": "This document explains how to gracefully shutdown an Orleans silo before application exit, first as a Console app, and then as a Docker container app. Graceful shutdown - Console app The following code shows how to gracefully shutdown an Orleans silo console app in response to the user pressing Ctrl+C, which generates the Console.CancelkeyPress event. Normally when that event handler returns, the application will exit immediately, causing a catastrophic Orleans silo crash and loss of in-memory state. But in the sample code below, we set a.Cancel = true; to prevent the application closing before the Orleans silo has completed its graceful shutdown. using Microsoft.Extensions.Logging; using Orleans.Configuration; using Orleans.Hosting; using System; using System.Net; using System.Threading; using System.Threading.Tasks; namespace MySiloHost { class Program { static readonly ManualResetEvent _siloStopped = new ManualResetEvent(false); static ISiloHost silo; static bool siloStopping = false; static readonly object syncLock = new object(); static void Main(string[] args) { SetupApplicationShutdown(); silo = CreateSilo(); silo.StartAsync().Wait(); /// Wait for the silo to completely shutdown before exiting. _siloStopped.WaitOne(); } static void SetupApplicationShutdown() { /// Capture the user pressing Ctrl+C Console.CancelKeyPress += (s, a) => { /// Prevent the application from crashing ungracefully. a.Cancel = true; /// Don't allow the following code to repeat if the user presses Ctrl+C repeatedly. lock (syncLock) { if (!siloStopping) { siloStopping = true; Task.Run(StopSilo).Ignore(); } } /// Event handler execution exits immediately, leaving the silo shutdown running on a background thread, /// but the app doesn't crash because a.Cancel has been set = true }; } static ISiloHost CreateSilo() { return new SiloHostBuilder() .Configure(options => options.ClusterId = \"MyTestCluster\") /// Prevent the silo from automatically stopping itself when the cancel key is pressed. .Configure<ProcessExitHandlingOptions>(options => options.FastKillOnProcessExit = false) .UseDevelopmentClustering(options => options.PrimarySiloEndpoint = new IPEndPoint(IPAddress.Loopback, 11111)) .ConfigureLogging(b => b.SetMinimumLevel(LogLevel.Debug).AddConsole()) .Build(); } static async Task StopSilo() { await silo.StopAsync(); _siloStopped.Set(); } } } Of course, there are many other ways of achieving the same goal. Below is shown a way, popular online, and misleading, that DOES NOT work properly. It does not work because it sets up a race condition between two methods trying to exit first: the Console.CancelKeyPress event handler method, and the static void Main(string[] args) method. When the event handler method finishes first, which happens at least half the time, the application will hang instead of exiting smoothly. class Program { static readonly ManualResetEvent _siloStopped = new ManualResetEvent(false); static ISiloHost silo; static bool siloStopping = false; static readonly object syncLock = new object(); static void Main(string[] args) { Console.CancelKeyPress += (s, a) => { Task.Run(StopSilo); /// Wait for the silo to completely shutdown before exiting. _siloStopped.WaitOne(); /// Now race to finish ... who will finish first? /// If I finish first, the application will hang! :( }; silo = CreateSilo(); silo.StartAsync().Wait(); /// Wait for the silo to completely shutdown before exiting. _siloStopped.WaitOne(); /// Now race to finish ... who will finish first? } static async Task StopSilo() { await silo.StopAsync(); _siloStopped.Set(); } } Graceful shutdown - Docker app To be completed."
  },
  "Documentation/clusters_and_clients/configuration_guide/index.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/index.html",
    "title": "Orleans Configuration Guide | Microsoft Orleans Documentation",
    "keywords": "Orleans Configuration Guide This Configuration Guide explains the key configuration parameters and how they should be used for most typical usage scenarios. Orleans can be used in a variety of configurations that fit different usage scenarios, such as local single node deployment for development and testing, cluster of servers, multi-instance Azure worker role, etc. This guide provides instructions for the key configuration parameters that are necessary to make Orleans run in one of the target scenarios. There are also other configuration parameters that primarily help fine tune Orleans for better performance. Silos and Clients are configured programmatically via a SiloHostBuilder and ClientBuilder respectively and a number of supplemental option classes. Option classes in Orleans follow the ASP.NET Options pattern, and can be loaded via files, environment variables etc. Please refer to the Options pattern documentation for more information. If you want to configure a silo and a client for local development, look at the Local Development Configuration section. The Server Configuration and Client Configuration sections of the guide cover configuring silos and clients, respectively. The section on Typical Configurations provides a summary of a few common configurations. A list of important core options that can be configured can be found on this section . Important : Make sure you properly configure .NET Garbage Collection as detailed in Configuring .NET Garbage Collection ."
  }
}