{
  "Documentation/streaming/streams_quick_start.html": {
    "href": "Documentation/streaming/streams_quick_start.html",
    "title": "Orleans Streams Quick Start | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Quick Start This guide will show you a quick way to setup and use Orleans Streams. To learn more about the details of the streaming features, read other parts of this documentation. Required Configurations In this guide we'll use a Simple Message based Stream which uses grain messaging to send stream data to subscribers. We will use the in-memory storage provider to store lists of subscriptions so it is not a wise choice for real production applications. On silo, where hostBuilder is an ISiloHostBuilder hostBuilder.AddSimpleMessageStreamProvider(\"SMSProvider\") .AddMemoryGrainStorage(\"PubSubStore\"); On cluster client, where clientBuilder is an IClientBuilder clientBuilder.AddSimpleMessageStreamProvider(\"SMSProvider\"); Now we can create streams, send data using them as producers and also receive data as subscribers. Producing Events Producing events for streams is relatively easy. You should first get access to the stream provider which you defined in the config above ( SMSProvider ) and then choose a stream and push data to it. //Pick a guid for a chat room grain and chat room stream var guid = some guid identifying the chat room //Get one of the providers which we defined in config var streamProvider = GetStreamProvider(\"SMSProvider\"); //Get the reference to a stream var stream = streamProvider.GetStream<int>(guid, \"RANDOMDATA\"); As you can see our stream has a GUID and a namespace. This will make it easy to identify unique streams. For example, in a chat room namespace can \"Rooms\" and GUID be the owning RoomGrain's GUID. Here we use the GUID of some known chat room. Now using the OnNext method of the stream we can push data to it. Let's do it inside a timer and using random numbers. You could use any other data type for the stream as well. RegisterTimer(s => { return stream.OnNextAsync(new System.Random().Next()); }, null, TimeSpan.FromMilliseconds(1000), TimeSpan.FromMilliseconds(1000)); Subscribing and receiving streaming data For receiving data we can use implicit/explicit subscriptions, which are fully described in other pages of the manual. Here we use implicit subscriptions which are easier. When a grain type wants to implicitly subscribe to a stream it uses the attribute ImplicitStreamSubscription (namespace)] . For our case we'll define a ReceiverGrain like this: [ImplicitStreamSubscription(\"RANDOMDATA\")] public class ReceiverGrain : Grain, IRandomReceiver Now whenever some data is pushed to the streams of namespace RANDOMDATA as we have in the timer, a grain of type ReceiverGrain with the same guid of the stream will receive the message. Even if no activations of the grain currently exist, the runtime will automatically create a new one and send the message to it. In order for this to work however, we need to complete the subscription process by setting our OnNext method for receiving data. So our ReceiverGrain should call in its OnActivateAsync something like this //Create a GUID based on our GUID as a grain var guid = this.GetPrimaryKey(); //Get one of the providers which we defined in config var streamProvider = GetStreamProvider(\"SMSProvider\"); //Get the reference to a stream var stream = streamProvider.GetStream<int>(guid, \"RANDOMDATA\"); //Set our OnNext method to the lambda which simply prints the data, this doesn't make new subscriptions await stream.SubscribeAsync<int>(async (data, token) => Console.WriteLine(data)); We are all set now. The only requirement is that something triggers our producer grain's creation and then it will registers the timer and starts sending random ints to all interested parties. Again, this guide skips lots of details and is only good for showing the big picture. Read other parts of this manual and other resources on RX to gain a good understanding on what is available and how. Reactive programming can be a very powerful approach to solve many problems. You could for example use LINQ in the subscriber to filter numbers and do all sorts of interesting stuff. Next Orleans Streams Programming APIs"
  },
  "Documentation/streaming/index.html": {
    "href": "Documentation/streaming/index.html",
    "title": "Orleans Streams | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Orleans v.1.0.0 added support for streaming extensions to the programing model. Streaming extensions provide a set of abstractions and APIs that make thinking about and working with streams simpler and more robust. Streaming extensions allow developers to write reactive applications that operate on a sequence of events in a structured way. The extensibility model of stream providers makes the programming model compatible with and portable across a wide range of existing queuing technologies, such as Event Hubs , ServiceBus , Azure Queues , and Apache Kafka . There is no need to write special code or run dedicated processes to interact with such queues. Why should I care? If you already know all about Stream Processing and are familiar with technologies like Event Hubs , Kafka , Azure Stream Analytics , Apache Storm , Apache Spark Streaming , and Reactive Extensions (Rx) in .NET , you may be asking why should you care. Why do we need yet another Stream Processing System and how Actors are related to Streams? \"Why Orleans Streams?\" is meant to answer that question. Programming Model There is a number of principles behind Orleans Streams Programming Model. Orleans streams are virtual . That is, a stream always exists. It is not explicitly created or destroyed, and it can never fail. Streams are identified by stream IDs, which are just logical names comprised of GUIDs and strings. Orleans Streams allow to decouple generation of data from its processing both in time and space . That means that stream producer and stream consumer may be on different servers, in different times and will withstand failures. Orleans streams are lightweight and dynamic . Orleans Streaming Runtime is designed to handle a large number of streams that come and go at a high rate. Orleans stream bindings are dynamic . Orleans Streaming Runtime is designed to handle cases where grains connect to and disconnect from streams at a high rate. Orleans Streaming Runtime transparently manages the lifecycle of stream consumption . After an application subscribes to a stream, from then on it will receive the stream's events, even in presence of failures. Orleans streams work uniformly across grains and Orleans clients . Programming APIs Applications interact with streams via APIs that are very similar to the well known Reactive Extensions (Rx) in .NET , by using Orleans.Streams.IAsyncStream<T> that implements Orleans.Streams.IAsyncObserver<T> and Orleans.Streams.IAsyncObservable<T> interfaces. In a typical example below a device generates some data, which is sent as an HTTP request to the service running in the Cloud. Orleans client running in the front end server receives this HTTP call and publishes the data into a matching device stream: public async Task OnHttpCall(DeviceEvent deviceEvent) { // Post data directly into device's stream. IStreamProvider streamProvider = GrainClient.GetStreamProvider(\"myStreamProvider\"); IAsyncStream<DeviceEventData> deviceStream = streamProvider.GetStream<DeviceEventData>(deviceEvent.DeviceId); await deviceStream.OnNextAsync(deviceEvent.Data); } In another example below a chat user (implemented as Orleans Grain) joins a chat room, gets a handle to a stream of chat messages generated by all others users in this room and subscribes to it. Notice that the chat user neither does not need to know about the chat room grain itself (there might not be such a grain in our system) nor about other user in that group that produce messages. Needless to say, to produce to the chat stream, users don't need to know who is currently subscribed to the stream. This demonstrates how chat users can be completely decoupled in time and space. public class ChatUser: Grain { public async Task JoinChat(string chatGroupName) { IStreamProvider streamProvider = base.GetStreamProvider(\"myStreamProvider\"); IAsyncStream<string> chatStream = streamProvider.GetStream<string>(chatGroupName); await chatStream.SubscribeAsync((string chatEvent) => Console.Out.Write(chatEvent)); } } Quick Start Sample The Quick Start Sample is a good quick overview of the overall workflow of using streams in the application. After reading it you should read the Streams Programming APIs to get a deeper understanding of the concepts. Streams Programming APIs A Streams Programming APIs provides detailed description of the programming APIs. Stream Providers Streams can come via physical channels of various shapes and forms and can have different semantics. Orleans Streaming is designed to support this diversity via the concept of Stream Providers , which is an extensibility point in the system. Orleans currently has implementation of two stream providers: TCP based Simple Message Stream Provider and Azure Queue based Azure Queue Stream Provider . More details on Steam Providers can be found at Stream Providers . Stream Semantics Stream Subsription Semantics : Orleans Streams guarantee Sequential Consistency for Stream Subsription operations. Specificaly, when consumer subscribes to a stream, once the Task representing the subsription operation was successfuly resolved, the consumer will see all events that were generated after it has subscribed. In addition, Rewindable streams allow to subscribe from an arbitrary point in time in the past by using StreamSequenceToken (more details can be found here ). Individual Stream Events Delivery Guarantees : Individual event delivery guarantees depend on individual stream providers. Some provide only best-effort at-most-once delivery (such as Simple Message Streams), while others provide at-least-once delivery (such as Azure Queue Streams). It is even possible to build a stream provider that will guarantee exactly-once delivery (we don't have such a provider yet, but it is possible to build one. Events Delivery Order : Event order also depends on a particular stream provider. In SMS streams, the producer explicitelly controls the order of events seen by the consumer by controlling the way it publishes them. Azure Queue streams do not guarantee FIFO order, since the underlaying Azure Queues do not guarantee order in failure cases. Applications can also control their own stream delivery ordering, by using StreamSequenceToken . Streams Implementation The Orleans Streams Implementation provides a high level overview of the internal implementation. Code Samples More examples of how to use streaming APIs within a grain can be found here . We plan to create more samples in the future. More Material Orleans Virtual Meetup about Streams [Orleans Streaming Presentation from Virtual Meetup]( http://dotnet.github.io/orleans/Presentations/Orleans Streaming - Virtual meetup - 5-22-2015.pptx)"
  },
  "Documentation/streaming/streams_programming_APIs.html": {
    "href": "Documentation/streaming/streams_programming_APIs.html",
    "title": "Orleans Streams Programming APIs | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Programming APIs Applications interact with streams via APIs that are very similar to the well known Reactive Extensions (Rx) in .NET . The main difference is that Orleans stream extensions are asynchronous , to make processing more efficient in Orleans' distributed and scalable compute fabric. Async Stream An application starts by using a stream provider to get a handle to a stream. You can read more about stream providers here , but for now you can think of it as stream factory that allows implementers to customize streams behavior and semantics: IStreamProvider streamProvider = base.GetStreamProvider(\"SimpleStreamProvider\"); IAsyncStream<T> stream = streamProvider.GetStream<T>(Guid, \"MyStreamNamespace\"); Application can get a reference to the stream provider either by calling the GetStreamProvider method on the Grain class when inside a grain, or by calling GrainClient.GetStreamProvider() method when on the client. Orleans.Streams.IAsyncStream<T> is a logical, strongly-typed handle to a virtual stream . It is similar in spirit to Orleans Grain Reference. Calls to GetStreamProvider and GetStream are purely local. The arguments to GetStream are a GUID and an additional string that we call a stream namespace (which can be null). Together the GUID and the namespace string comprise the stream identity (similar in sprit to the arguments to GrainFactory.GetGrain ). The combination of GUID and namespace string provide extra flexibility in determining stream identities. Just like grain 7 may exist within the Grain type PlayerGrain and a different grain 7 may exist within the grain type ChatRoomGrain , Stream 123 may exist with the stream namespace PlayerEventsStream and a different stream 123 may exist within the stream namespace ChatRoomMessagesStream . Producing and Consuming IAsyncStream<T> implements both Orleans.Streams.IAsyncObserver<T> and Orleans.Streams.IAsyncObservable<T> interfaces. That way an application can use the stream either to produce new events into the stream by using Orleans.Streams.IAsyncObserver<T> or to subscribe to and consume events from a stream by using Orleans.Streams.IAsyncObservable<T> . public interface IAsyncObserver<in T> { Task OnNextAsync(T item, StreamSequenceToken token = null); Task OnCompletedAsync(); Task OnErrorAsync(Exception ex); } public interface IAsyncObservable<T> { Task<StreamSubscriptionHandle<T>> SubscribeAsync(IAsyncObserver<T> observer); } To produce events into the stream, an application just calls await stream.OnNextAsync<T>(event) To subscribe to a stream, an application calls StreamSubscriptionHandle<T> subscriptionHandle = await stream.SubscribeAsync(IAsyncObserver) The argument to SubscribeAsync can either be an object that implements the IAsyncObserver interface or a combination of lambda functions to process incoming events. More options for SubscribeAsync are available via AsyncObservableExtensions class. SubscribeAsync returns a StreamSubscriptionHandle<T> , which is an opaque handle that can be used to unsubscribe from the stream (similar in spirit to an asynchronous version of IDisposable ). await subscriptionHandle.UnsubscribeAsync() It is important to note that the subscription is for a grain, not for an activation . Once the grain code subscribed to the stream, this subscription surpasses the life of this activation and stays durable forever, until the grain code (potentially in a different activation) explicitly unsubscribes. This is the heart of a virtual stream abstraction : not only all the streams always exists, logically, but also that a stream subscription is durable and lives beyond a particular physical activation that issued this subscription. Multiplicity An Orleans stream may have multiple producers and multiple consumers. A message published by a producer will be delivered to all consumers that were subscribed to the stream before the message was published. In addition, the consumer can subscribe to the same stream multiple times. Each time it subscribes it gets back a unique StreamSubscriptionHandle<T> . If a grain (or client) is subscribed X times to the same stream, it will receive the same event X times, once for each subscription. The consumer can also unsubscribe from an individual subscription or find out all its current subscriptions, by calling: IList<StreamSubscriptionHandle<T>> allMyHandles = await IAsyncStream<T>.GetAllSubscriptionHandles() Recovering From Failures If the producer of a stream dies (or its grain is deactivated), there is nothing it needs to do. Next time this grain wants to produce more events it can get the stream handle again and produce new events in the same way. Consumer logic is a little bit more involved. As we said before, once consumer grain subscribed to a stream, this subscription is valid until it explicitly unsubscribes. If the consumer of the stream dies (or its grain is deactivated) and new event is generated on the stream, the consumer grain will be automatically re-activated (just like any regular Orleans grain is automatically activated upon message to it). The only thing that the grain code needs to do now is to provide a IAsyncObserver<T> to process the data. The consumer basically need to re-attach processing logic as part of OnActivateAsync method. To do that it can call: StreamSubscriptionHandle<int> newHandle = await subscriptionHandle.ResumeAsync(IAsyncObserver) The consumer uses the previous handle it got when it first subscribed in order to \"resume processing\". Notice that ResumeAsync merely updates an existing subscription with the new instance of IAsyncObserver logic and does not change the fact that this consumer is already subscribed to this stream. How the consumer has an old subscriptionHandle? There are 2 options. The consumer may have persisted the handle it was given back from the original SubscribeAsync operation and can use it now. Alternatively, if the consumer does not have the handle, it can ask the IAsyncStream<T> for all its active subscription handles, by calling: IList<StreamSubscriptionHandle<T>> allMyHandles = await IAsyncStream<T>.GetAllSubscriptionHandles() The consumer can now resume all of them, or unsubscribe from some if he wishes to. COMMENT: If the consumer grain implements the the IAsyncObserver interface directly ( public class MyGrain<T> : Grain, IAsyncObserver<T> ), it should in theory not be required to re-attach the IAsyncObserver and thus will not need to call ResumeAsync . The streaming runtime should be able to automatically figure out that the grain already implements IAsyncObserver and will just invoke those IAsyncObserver methods. However, the streaming runtime currently does not support this and the grain code still needs to explicitly call ResumeAsync , even if the grain implements IAsyncObserver directly. Supporting this is on our TODO list. Explicit and Implicit Subscriptions By default, stream consumer has to explicitly subscribe to the stream. This subscription would usually be triggered by some external message that the grain (or client) receive that instructs them to subscribe. For example, in a chat service when user joins a chat room his grain receives a JoinChatGroup message with the chat name and it will cause the user grain to subscribe to this chat stream. In addition, Orleans Streams also support \"Implicit Subscriptions\" . In this model the grain does not explicitely subscribe to the stream. This grain is subscribed automatically, implicitly, just based on its grain identity and an ImplicitStreamSubscription attribute. Implicit subscriptions main value is allowing the stream activity to trigger the grain activation (hence triggering the subscription) automaticaly. For example, using SMS streams, if one grain wanted to produce a stream and another grain process this stream, the producer would need to know the identity of the consumer grain and make a grain call to it telling it to subscribe to the stream. Only after that it can start sending events. Instead, using implicit subscriptions, the producer can just start producing events onto a stream, and the consumer grain will automatically be activated and subscribe to the stream. In that case, the producer doesn't care at all who is reading the events Grain implementation class of type MyGrainType can declare an attribute [ImplicitStreamSubscription(\"MyStreamNamespace\")] . This tells the streaming runtime that when an event is generated on a stream whose identity is GUID XXX and \"MyStreamNamespace\" namespace, it should be delivered to grain whose identity is XXX of type MyGrainType . That is, the runtime maps stream <XXX, MyStreamNamespace> to consumer grain <XXX, MyGrainType> . The presence of ImplicitStreamSubscription causes the streaming runtime to automatically subscribe this grain to a stream and deliver the stream events to it. However, the grain code still needs to tell the runtime how it wants events to be processed. Essentially, it need to attach the IAsyncObserver . Therefore, when the grain is activated, the grain code inside OnActivateAsync needs to call: IStreamProvider streamProvider = base.GetStreamProvider(\"SimpleStreamProvider\"); IAsyncStream<T> stream = streamProvider.GetStream<T>(this.GetPrimaryKey(), \"MyStreamNamespace\"); StreamSubscriptionHandle<T> subscription = await stream.SubscribeAsync(IAsyncObserver<T>); Writing Subscription Logic Below are the guidelines on how to write the subscription logic for various cases: explicit and implicit subscriptions, rewindable and non-rewindable streams. The main difference between explicit and implicit subscriptions is that for implicit the grain always has exactly one implicit subscription for every stream namespace, there is no way to create multiple subscriptions (there is no subscription multiplicity), there is no way to unsubscribe, and the grain logic always only needs to attach the processing logic. That also means that for implicit subscriptions there is never a need to Resume a subscription. On the other hand, for explicit subscriptions, one needs to Resume the subscription, otherwise if the grain subscribes again it will result in the grain being subscribed multiple times. Implicit Subscriptions: For implicit subscriptions the grain needs to subscribe to attach the processing logic. This should be done in the grain's OnActivateAsync method. The grain should simply execute await stream.SubscribeAsync(OnNext ...) in its OnActivateAsync method. That will cause this particular activation to attach the OnNext function to process that stream. The grain can optionally specify the StreamSequenceToken as an argument to SubscribeAsync , which will cause this implicit subscription to start consuming from that token. There is never a need for implicit subscription to call ResumeAsync . public async override Task OnActivateAsync() { var streamProvider = GetStreamProvider(PROVIDER_NAME); var stream = streamProvider.GetStream<string>(this.GetPrimaryKey(), \"MyStreamNamespace\"); await stream.SubscribeAsync(OnNextAsync) } Explicit Subscriptions: For explicit subscriptions, a grain must call SubscribeAsync to subscribe to the stream. This creates a subscription, as well as attaches the processing logic. The explicit subscription will exist until the grain unsubscribes, so if a grain gets deactivated and reactivated, the grain is still explicitly subscribed, but no processing logic will be attached. In this case the grain needs to re-attach the processing logic. To do that, in its OnActivateAsync , the grain first needs to find out what subscriptions it has, by calling stream.GetAllSubscriptionHandles() . The grain must execute ResumeAsync on each handle it wishes to continue processing or UnsubscribeAsync on any handles it is done with. The grain can also optionally specify the StreamSequenceToken as an argument to the ResumeAsync calls, which will cause this explicit subscription to start consuming from that token. public async override Task OnActivateAsync() { var streamProvider = GetStreamProvider(PROVIDER_NAME); var stream = streamProvider.GetStream<string>(this.GetPrimaryKey(), \"MyStreamNamespace\"); var subscriptionHandles = await stream.GetAllSubscriptionHandles(); if (!subscriptionHandles.IsNullOrEmpty()) subscriptionHandles.ForEach(async x => await x.ResumeAsync(OnNextAsync)); } Stream Order and Sequence Tokens The order of events delivery between an individual producer and an individual consumer depends on a stream provider. With SMS the producer explicitly controls the order of events seen by the consumer by controlling the way he publishes them. By default (if the FireAndForget options for SMS provider is set to false) and if the producer awaits every OnNextAsync call, the events arrive in FIFO order. In SMS it is up to the producer to decide how to handle delivery failures that will be indicated by a broken Task returned by the OnNextAsync call. Azure Queue streams do not guarantee FIFO order, since the underlying Azure Queues do not guarantee order in failure cases (they do guarantee FIFO order in failure free executions). When a producer produces the event into Azure Queue, if the enqueue operation failed, it is up to the producer to attempt another enqueue and later on deal with potential duplicates messages. On the delivery side, Orleans Streaming runtime dequeues the event from the Azure Queue and attempts to deliver it for processing to consumers. Orleans Streaming runtime deletes the event from the queue only upon successful processing. If the delivery or processing failed, the event is not delete from the queue and will automatically re-appear in the queue much later. The Streaming runtime will try to deliver it again, thus potentially breaking the FIFO order. The described behaivour matches the regular semantics of Azure Queues. Application Defined Order : To deal with the above ordering issues, application can optionally specify its own ordering. This is achived via a notion of StreamSequenceToken . StreamSequenceToken is an opaque IComparable object that can be used to order events. A producer can pass an optional StreamSequenceToken to the OnNext call. This StreamSequenceToken will be passed all the way to the consumer and will be delivered together with the event. That way, application can reason and reconstruct it's order independently from the streaming runtime. Rewindable Streams Some streams only allow application to subscribe to them starting at the latest point in time, while other streams allow \"going back in time\". The latter capability is dependent on the underlying queuing technology and the particular stream provider. For example, Azure Queues only allow consuming the latest enqueued events, while EventHub allows replaying events from an arbitrary point in time (up to some expiration time). Streams that support going back in time are called Rewindable Streams . The consumer of a rewindable stream can pass a StreamSequenceToken to the SubscribeAsync call and the runtime will deliver events to it starting from that StreamSequenceToken (a null token means the consumer wants to receive events starting from the latest). The ability to rewind a stream is very useful in recovery scenarios. For example, consider a grain that subscribes to a stream and periodically checkpoints its state together with the latest sequence token. When recovering from a failure, the grain can re-subscribe to the same stream from the latest checkpointed sequence token, thereby recovering without losing any events that were generated since the last checkpoint. Current Status of Rewindable Streams: Both SMS and Azure Queue providers are not-rewindable and Orleans currently does not include an implementation of rewindable streams. We are actively working on this. Stateless Automatically Scaled-Out Processing By default Orleans Streaming is targeted to support a large number of relatively small streams, each is processed by one or more statefull grains. Collectively, the processing of all the streams together is sharded among a large number of regular (statefull) grains. The application code controls this sharding by assigning stream ids, grain ids and explicitly subscribing. The goal is sharded statefull processing . However, there is also an interesting scenario of automatically scaled-out stateless processing . In this scenario application has a small number of streams (or even one large stream) and the goal is stateless processing. For example, a global stream of all messages for all events and the processing involving some kind of decoding/deciphering and potentially forwarding them for further statefull processing into another set of streams. The stateless scaled-out stream processing can be supported in Orleans via StatelessWorker grains. Current Status of Stateless Automatically Scaled-Out Processing: This is currently not implemented (due to priority constrains). An attempt to subscribe to a stream from a StatelessWorker grain will result in undefined behavior. We are currently considering to support this option . Grains and Orleans Clients Orleans streams work uniformly across grains and Orleans clients . That is, exactly the same APIs can be used inside a grain and in an Orleans client to produce and consume events. This greatly simplifies the application logic, making special client-side APIs, such as Grain Observers, redundant. Fully Managed and Reliable Streaming Pub-Sub To track stream subscriptions, Orleans uses a runtime component called Streaming Pub-Sub which serves as a rendezvous point for stream consumers and stream producers. Pub Sub tracks all stream subscriptions, persists them, and matches stream consumers with stream producers. Applications can choose where and how the Pub-Sub data is stored. The Pub-Sub component itself is implemented as grains (called PubSubRendezvousGrain ) and it is using Orleans Declarative Persistence for those grains. PubSubRendezvousGrain uses storage provider named PubSubStore . As with any grain, you can designate an implementation for a storage provider. For Streaming Pub-Sub you can change the implementation of the PubSubStore at silo construction time using the silo host builder: The below configures the Pub Sub to store its state in azure tables. hostBuilder.AddAzureTableGrainStorage(\"PubSubStore\", options=>{ options.ConnectionString = \"Secret\"; }); That way Pub-Sub data will be durably stored in Azure Table. For initial development you can use the memory storage as well. In addition to the Pub-Sub, Orleans Streaming Runtime delivers events from producers to consumers, manages all runtime resources allocated to actively used streams, and transparently garbage collects runtime resources from unused streams. Configuration In order to use streams you need to enable stream providers via the silo host or cluster client builders. You can read more about stream providers here . Sample stream provider setup: hostBuilder.AddSimpleMessageStreamProvider(\"SMSProvider\") .AddAzureQueueStreams<AzureQueueDataAdapterV2>(\"AzureQueueProvider\", optionsBuilder => optionsBuilder.Configure( options=>{ options.ConnectionString = \"Secret\"; })) .AddAzureTableGrainStorage(\"PubSubStore\", options=>{ options.ConnectionString = \"Secret\"; }); Next Orleans Stream Providers"
  },
  "Documentation/streaming/streams_why.html": {
    "href": "Documentation/streaming/streams_why.html",
    "title": "Why Orleans Streams? | Microsoft Orleans Documentation",
    "keywords": "Why Orleans Streams? There are already a wide range of technologies that allow you to build stream processing systems. Those include systems to durably store stream data (e.g., Event Hubs and Kafka ) and systems to express compute operations over stream data (e.g., Azure Stream Analytics , Apache Storm , and Apache Spark Streaming ). Those are great systems that allow you to build efficient data stream processing pipelines. Limitations of Existing Systems However, those systems are not suitable for fine-grained free-form compute over stream data . The Streaming Compute systems mentioned above all allow you to specify a unified data-flow graph of operations that are applied in the same way to all stream items . This is a powerful model when data is uniform and you want to express the same set of transformation, filtering, or aggregation operations over this data. But there are other use cases where you need to express fundamentally different operations over different data items. And in some of them as part of this processing you occasionally need to make an external call, such as invoke some arbitrary REST API. The unified data-flow stream processing engines either do not support those scenarios, support them in a limited and constrained way, or are inefficient in supporting them. This is because they are inherently optimized for a large volume of similar items, and usually limited in terms of expressiveness, processing . Orleans Streams target those other scenarios. Motivation It all started with requests from Orleans users to support returning a sequence of items from a grain method call. As you can imagine, that was only the tip of the iceberg. They actually needed much more than that. A typical scenario for Orleans Streams is when you have per user streams and you want to perform different processing for each user , within the context of an individual user. We may have millions of users but some of them are interested in weather and can subscribe to weather alerts for a particular location, while some are interested in sports events; somebody is tracking status of a particular flight. Processing those events requires different logic, but you don't want to run two independent instances of stream processing. Some users are interested in only a particular stock and only if certain external condition applies, condition that may not necessarily be part of the stream data (thus needs to be checked dynamically at runtime as part of processing). Users change their interests all the time, hence their subscriptions to specific streams of events come and go dynamically, thus the streaming topology changes dynamically and rapidly . On top of that, the processing logic per user evolves and changes dynamically as well, based on user state and external events . External events may modify the processing logic for a particular user. For example, in a game cheating detection system, when a new way to cheat is discovered the processing logic needs to be updated with the new rule to detect this new violation. This needs to be done of course without disrupting the ongoing processing pipeline . Bulk data-flow stream processing engines were not build to support such scenarios. It goes almost without saying that such a system has to run on a number of network-connected machines, not on a single node. Hence, the processing logic has to be distributed in a scalable and elastic manner across a cluster of servers. New Requirements We identified 4 basic requirements for our Stream Processing system that will allow it to target the above scenarios. Flexible stream processing logic Support for highly dynamic topologies Fine-grained stream granularity Distribution Flexible stream processing logic We want the system to support different ways of expressing the stream processing logic. The existing systems we mentioned above require the developer to write a declarative data-flow computation graph, usually by following a functional programming style. This limits the expressiveness and flexibility of the processing logic. Orleans streams are indifferent to the way processing logic is expressed. It can be expressed as a data-flow (e.g., by using Reactive Extensions (Rx) in .NET ); as a functional program; as a declarative query; or in a general imperative logic. The logic can be stateful or stateless, may or may not have side effects, and can trigger external actions. All power goes to the developer. Support for dynamic topologies We want the system to allow for dynamically evolving topologies. The existing systems we mentioned above are usually limited to only static topologies that are fixed at deployment time and cannot evolve at runtime. In the following example of a dataflow expression everything is nice and simple until you need to change it. Stream.GroupBy(x=> x.key).Extract(x=>x.field).Select(x=>x+2).AverageWindow(x, 5sec).Where(x=>x > 0.8) * Change the threshold condition in the Where filter, add an additional Select statement or add another branch in the data-flow graph and produce a new output stream. In existing systems this is not possible without tearing down the entire topology and restarting the data-flow from scratch. Practically, those systems will checkpoint the existing computation and will be able to restart from the latest checkpoint. Still, such a restart is disruptive and costly to an online service that produces results in real time. Such a restart becomes especially impractical when we are talking about a large number of such expressions being executed with similar but different (per-user, per-deveice, et.) parameters and that keep constantly changing. We want the system to allow for evolving the stream processing graph at runtime, by adding new links or nodes to the computation graph, or by changing the processing logic within the computation nodes. Fine grained stream granularity In the existing systems, the smallest unit of abstraction is usually the whole flow (topology). However, many of our target scenarios require individual node/link in the topology to be a logical entity by itself. That way each entity can be potentially managed independently. For example, in the big stream topology comprising of multiple links, different links can have different characteristics and can be implemented over different physical transports. Some links can go over TCP sockets, while others over reliable queues. Different links can have different delivery guarantees. Different nodes can have different checkpointing strategies, and their processing logic can be expressed in different models or even different languages. Such flexibility is usually not possible in existing systems. The unit of abstraction and flexibility argument is similar to comparison of SoA (Service Oriented Architectures) vs. Actors. Actor systems allow more flexibility, since each is essentially an independently managed ''tiny service''. Similarly, we want the system to allow for such a fine grained control. Distribution And of course, our system should have all the properties of a \"good distributed system\" . That includes: Scalability - supports large number of streams and compute elements. Elasticity - allows to add/remove resources to grow/shrink based on load. Reliability - be resilient to failures Efficiency - use the underlying resources efficiently Responsiveness - enable near real time scenarios. These were the requirements we had in mind for building Orleans Streaming . Clarificaton : Orleans currently does not directly support writing declarative dataflow expressions like in the example above. The current Orleans Streaming APIs are more low level building blocks, as described here . Providing declarative dataflow expressions is our future goal. Next Orleans Streams Programming APIs"
  },
  "Documentation/streaming/stream_providers.html": {
    "href": "Documentation/streaming/stream_providers.html",
    "title": "Orleans Stream Providers | Microsoft Orleans Documentation",
    "keywords": "Stream Providers Streams can come in different shapes and forms. Some streams may deliver events over direct TCP links, while others deliver events via durable queues. Different stream types may use different batching strategies, different caching algorithms, or different back pressure procedures. We did not want to constrain streaming applications to only a small subset of those behavioral choices. Instead, Stream Providers are extensibility points to Orleans Streaming Runtime that allow users to implement any type of stream. This extensibility point is similar in spirit to Orleans Storage Providers . Orleans currently ships with many stream providers, including : Simple Message Stream Provider and Azure Queue Stream Provider . Simple Message Stream Provider Simple Message Stream Provider, also known as the SMS provider, delivers events over TCP by utilizing regular Orleans grain messaging. Since events in SMS are delivered over unreliable TCP links, SMS does not guarantee reliable event delivery and does not automatically resend failed messages for SMS streams. The producer of the SMS stream has a way to know if its event was successfully received and processed or not: by default the call to stream.OnNextAsync returns a Task that represents the processing status of the stream consumer. If this Task fails, the producer can decide to send the same event again, thus achieving reliability on the application level. Although individual stream messages delivery is best effort, SMS streams themselves are reliable. That is, the subscriber-to-producer binding performed by Pub Sub is fully reliable. Azure Queue (AQ) Stream Provider Azure Queue (AQ) Stream Provider delivers events over Azure Queues. On the producer side, AQ Stream Provider enqueues events directly into Azure Queue. On the consumer side, AQ Stream Provider manages a set of pulling agents that pull events from a set of Azure Queues and deliver them to application code that consumes them. One can think of the pulling agents as a distributed \"micro-service\" -- a partitioned, highly available, and elastic distributed component. The pulling agents run inside the same silos that host application grains. Thus, there is no need to run separate Azure worker roles to pull from the queues. The existence of pulling agents, their management, backpressure, balancing the queues between them, and handing off queues from a failed agent to another agent are fully managed by Orleans Streaming Runtime and are transparent to application code that uses streams. Queue Adapters Different stream providers that deliver events over durable queues exhibit similar behavior and are subject to a similar implementation. Therefore, we provide a generic extensible PersistentStreamProvider that allows developers to plug in different types of queues without writing a completely new stream provider from scratch. PersistentStreamProvider uses an IQueueAdapter component, which abstracts specific queue implementation details and provides means to enqueue and dequeue events. All the rest is handled by the logic inside the PersistentStreamProvider . Azure Queue Provider mentioned above is also implemented this way: it is an instance of PersistentStreamProvider that uses an AzureQueueAdapter . Next Orleans Streams Implementation Details"
  },
  "Documentation/streaming/streams_implementation.html": {
    "href": "Documentation/streaming/streams_implementation.html",
    "title": "Streams Implementation Details | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Implementation Details This section provides a high level overview of Orleans Stream implementation. It describes concepts and details that are not visible on the application level. If you only plan to use streams, you do not have to read this section. Terminology : We refer by the word \"queue\" to any durable storage technology that can ingest stream events and allows either to pull events or provides a push-based mechanism to consume events. Usually, to provide scalability, those technologies provide sharded/partitioned queues. For example, Azure Queues allow to create multiple queues, Event Hubs have multiple hubs, Kafka topics, ... Persistent Streams All Orleans Persistent Stream Providers share a common implementation PersistentStreamProvider . This generic stream provider needs be configured with a with a technology specific IQueueAdapterFactory . For instance, for testing purposes we have queue adapters that generate their own test data rather than reading the from a queue. The below code shows how we configure a persistent stream provider to use our custom (generator) queue adapter. It does this by configuring the persistent stream provider with a factory function use to create the adapter. hostBuilder.AddPersistentStreams(StreamProviderName, GeneratorAdapterFactory.Create); When stream producers generate a new stream item and calls stream.OnNext() , Orleans Streaming Runtime invokes the appropriate method on the IQueueAdapter of that stream provider which enqueues the item directly onto the appropriate queue. Pulling Agents At the heart of the Persistent Stream Provider are the pulling agents. Pulling agents pull events from a set of durable queues and deliver them to the application code in grains that consumes them. One can think of the pulling agents as a distributed \"micro-service\" -- a partitioned, highly available, and elastic distributed component. The pulling agents run inside the same silos that host application grains and are fully managed by the Orleans Streaming Runtime. StreamQueueMapper and StreamQueueBalancer Pulling agents are parametrized with IStreamQueueMapper and IStreamQueueBalancer . IStreamQueueMapper provides a list of all queues and is also responsible for mapping streams to queues. That way, the producer side of the Persistent Stream Provider know which queue to enqueue the message into. IStreamQueueBalancer expresses the way queues are balanced across Orleans silos and agents. The goal is to assign queues to agents in a balanced way, to prevent bottlenecks and support elasticity. When new silo is added to the Orleans cluster, queues are automatically rebalanced across the old and new silos. StreamQueueBalancer allows to customize that process. Orleans has a number of built in StreamQueueBalancers, to support different balancing scenarios (large and small number of queues) and different environments (Azure, on prem, static). Using the test generator example from above, the below code shows how one could configure the queue mapper and queue balancer. hostBuilder .AddPersistentStreams(StreamProviderName, GeneratorAdapterFactory.Create, providerConfigurator=>providerConfigurator .Configure<HashRingStreamQueueMapperOptions>(ob=>ob.Configure( options=>{ options.TotalQueueCount = 8; })) .UseDynamicClusterConfigDeploymentBalancer() ); The above code configures the GeneratorAdapter to use a queue mapper with 8 queues, and balences the queues across the cluster using the DynamicClusterConfigDeploymentBalancer. Pulling Protocol Every silo runs a set of pulling agents, every agent is pulling from one queue. Pulling agents themselves are implemented by the internal runtime component, called SystemTarget . SystemTargets are essentially runtime grains, are subject to single threaded concurrency, can use regular grain messaging and are as lightweight as grains. As opposite to grain, SystemTargets are not virtual: they are explicitly created (by the runtime) and are also not location transparent. By implementing pulling agents as SystemTargets Orleans Streaming Runtime can rely on a lot of built-in Orleans features and can also scale to a very large number of queues, since creating a new pulling agent is as cheap as creating a new grain. Every pulling agent runs periodic timer that pulls from the queue (by invoking IQueueAdapterReceiver ) GetQueueMessagesAsync() method. The returned messages are put in the internal per-agent data structure called IQueueCache . Every message is inspected to find out its destination stream. The agent uses the Pub Sub to find out the list of stream consumers that subscribed to this stream. Once the consumer list if retrieved, the agent stores it locally (in its pub-sub cache) so it does not need to consult with Pub Sub on every message. The agent also subscribes with the pub-sub to receive notification of any new consumers that subscribe to that stream. This handshake between the agent and the pub-sub guarantees strong streaming subscription semantics : once the consumer has subscribed to the stream it will see all events that were generated after it has subscribed (in addition, using StreamSequenceToken allows to subscribe in the past). Queue Cache IQueueCache is an internal per-agent data structure that allows to decouple bringing new events from the queue from delivering them to consumers. It also allows to decouple delivery to different streams and to different consumers. Imagine a situation when one stream has 3 stream consumers and one of them is slow. If care not taken, it is possible that this slow consumer will impact agent's progress, slowing the consumption of other consumers of that stream, and even potentially slowing the de-queuing and delivering of events for other stream. To prevent that and allow maximum parallelism in the agent, we use IQueueCache . IQueueCache buffers stream events and provides a way to the agent to deliver events to each consumer at its pace. The per-consumer delivery is implemented by the internal component called IQueueCacheCursor , which tracks per consumer progress. That way each consumer receives events at its own pace :fast consumers receive events as quickly as they are dequeued from the queue, while slow consumers receive them later on. Once the message was delivered to all consumers, it can be deleted from the cache. Backpressure Backpressure in Orleans Streaming Runtime applies in two places: bringing stream events from the queue to the agent and delivering the events from the agent to stream consumers . The latter is provided by the built-in Orleans messaging delivery mechanism. Every stream event is delivered from the agent to consumers via the standard Orleans grain messaging, one at a time. That is, the agents sends one event (or a limited size batch of events) to each individual stream consumer and awaits this call. The next event will not start being delivered until the Task for the previous event was resolved or broken. That way we naturally limit the per-consumer delivery rate to one message at a time. With regard to bringing stream events from the queue to the agent Orleans Streaming provides a new special Backpressure mechanism. Since the agent decouples de-queuing of events from the queue and delivering them to consumers, it is possible that a single slow consumer will fall behind so much that the IQueueCache will fill up. To prevent IQueueCache from growing indefinitely, we limit its size (the size limit is configurable). However, the agent never throws away undelivered events. Instead, when the cache starts to fill up, the agents slows the rate of dequeing events from the queue. That way, we can \"ride\" the slow delivery periods by adjusting the rate at which we consume from the queue (\"backpressure\") and get back into fast consumption rate later on. To detect the \"slow delivery\" valleys the IQueueCache uses an internal data structure of cache buckets that track the progress of delivery of events to individual stream consumer. This results in a very responsive and self-adjusting systems."
  },
  "Documentation/grains/observers.html": {
    "href": "Documentation/grains/observers.html",
    "title": "Observers | Microsoft Orleans Documentation",
    "keywords": "Observers There are situations in which a simple message/response pattern is not enough, and the client needs to receive asynchronous notifications. For example, a user might want to be notified when a new instant message has been published by a friend. Client observers is a mechanism that allows notifying clients asynchronously. An observer is a one-way asynchronous interface that inherits from IGrainObserver , and all its methods must be void. The grain sends a notification to the observer by invoking it like a grain interface method, except that it has no return value, and so the grain need not depend on the result. The Orleans runtime will ensure one-way delivery of the notifications. A grain that publishes such notifications should provide an API to add or remove observers. In addition, it is usually convenient to expose a method that allows an existing subscription to be cancelled. Grain developers may use the Orleans ObserverSubscriptionManager<T> generic class to simplify development of observed grain types. To subscribe to a notification, the client must first create a local C# object that implements the observer interface. It then calls a static method on the observer factory, CreateObjectReference() , to turn the C# object into a grain reference, which can then be passed to the subscription method on the notifying grain. This model can also be used by other grains to receive asynchronous notifications. Unlike in the client subscription case, the subscribing grain simply implements the observer interface as a facet, and passes in a reference to itself (e.g. this.AsReference<IMyGrainObserverInterface> ). Code Example Let's assume that we have a grain that periodicaly sends messages to clients. For simplicity, the message in our example will be a string. We first define the interface on the client that will receive the message. the interface will look like this public interface IChat : IGrainObserver { void ReceiveMessage(string message); } The only special thing is that the interface should inherit from IGrainObserver . Now any client that wants to observe those messages should implement a class which implements IChat . The simplest case would be something like this: public class Chat : IChat { public void ReceiveMessage(string message) { Console.WriteLine(message); } } Now on the server we should have a Grain which sends these chat messages to clients. The Grain also should have a mechanism for clients to subscribe and unsubscribe themselves to receive notifications. For subscription the Grain can use the utility class ObserverSubscriptionManager . This class throws an OrleansException if you try to subscribe an observer that is already subscribed (or unsubscribe an observer that is not subscribed), so it is important to handle this case by using the IsSubscribed() method or by handling the OrleansException : class HelloGrain : Grain, IHello { private ObserverSubscriptionManager<IChat> _subsManager; public override async Task OnActivateAsync() { // We created the utility at activation time. _subsManager = new ObserverSubscriptionManager<IChat>(); await base.OnActivateAsync(); } // Clients call this to subscribe. public Task Subscribe(IChat observer) { if (!_subsManager.IsSubscribed(observer)) { _subsManager.Subscribe(observer); } return Task.CompletedTask; } //Also clients use this to unsubscribe themselves to no longer receive the messages. public Task UnSubscribe(IChat observer) { if (_subsManager.IsSubscribed(observer)) { _subsManager.Unsubscribe(observer); } return Task.CompletedTask; } } To send the message to clients the Notify method of the ObserverSubscriptionManager<IChat> instance can be used. The method takes an Action<T> method or lambda expression (where T is of type IChat here). You can call any method on the interface to send it to clients. In our case we only have one method ReceiveMessage and our sending code on the server would look like this: public Task SendUpdateMessage(string message) { _subsManager.Notify(s => s.ReceiveMessage(message)); return Task.CompletedTask; } Now our server has a method to send messages to observer clients, two methods for subscribing/unsubscribing and the client implemented a class to be able to observe the grain messages. The last step is to create an observer reference on the client using our previously implemented Chat class and let it receive the messages after subscribing it. The code would look like this: //First create the grain reference var friend = GrainClient.GrainFactory.GetGrain<IHello>(0); Chat c = new Chat(); //Create a reference for chat usable for subscribing to the observable grain. var obj = await GrainClient.GrainFactory.CreateObjectReference<IChat>(c); //Subscribe the instance to receive messages. await friend.Subscribe(obj); Now whenever our grain on the server calls the SendUpdateMessage method, all subscribed clients will receive the message. In our client code, the Chat instance in variable c will receive the message and output it to the console. Note: Objects passed to CreateObjectReference are held via a WeakReference<T> and will therefore be garbage collected if no other references exist. Users should maintain a reference for each observer which they do not want to be collected. Note: Observers are inherently unreliable since you don't get any response back to know if the message is received and processed or simply failed due to any condition which might arise in a distributed system. Because of that your observers should poll the grain periodically or use any other mechanism to ensure that they received all messages which they should have received. In some situations you can afford to lose some messages and you don't need any additional mechanism but if you need to make sure that all observers are always receiving the messages and are receiving all of them, both periodic resubscriptions and polling the observer grain, can help to ensure eventual processing of all messages."
  },
  "Documentation/grains/reentrancy.html": {
    "href": "Documentation/grains/reentrancy.html",
    "title": "Reentrancy | Microsoft Orleans Documentation",
    "keywords": "Reentrancy Grain activations are single-threaded and, by default, process each request from beginning to completion before the next request can begin being processing. In some circumstances, it may be desirable for an activation to process other requests while one request is waiting for an asynchronous operation to complete. For this and other reasons, Orleans gives the developer some control over the request interleaving behavior. Multiple requests may be interleaved in the following cases: The grain class is marked as [Reentrant] The interface method is marked as [AlwaysInterleave] The requests within the same call chain The grain's MayInterleave predicate returns true Each of those cases are discussed in the following sections. Reentrant grains Grain implementation classes may be marked with the [Reentrant] attribute to indicate that different requests may be freely interleaved. In other words, a reentrant activation may start executing another request while a previous request has not finished processing. Execution is still limited to a single thread, so the activation is still executing one turn at a time, and each turn is executing on behalf of only one of the activations requests. Reentrant grain code will never run multiple pieces of grain code in parallel (execution of grain code will always be single-threaded), but reentrant grains may see the execution of code for different requests interleaving. That is, the continuation turns from different requests may interleave. For example, with the below pseudo-code, when Foo and Bar are 2 methods of the same grain class: Task Foo() { await task1; // line 1 return Do2(); // line 2 } Task Bar() { await task2; // line 3 return Do2(); // line 4 } If this grain is marked [Reentrant] , the execution of Foo and Bar may interleave. For example, the following order of execution is possible: Line 1, line 3, line 2 and line 4. That is, the turns from different requests interleave. If the grain was not reentrant, the only possible executions would be: line 1, line 2, line 3, line 4 OR: line 3, line 4, line 1, line 2 (new request cannot start before the previous one finished). The main tradeoff in choosing between reentrant and non-reentrant grains is the code complexity to make interleaving work correctly and the difficulty to reason about it. In a trivial case when the grains are stateless and the logic is simple, fewer (but not too few, so that all the hardware threads are used) reentrant grains should be in general slightly more efficient. If the code is more complex, then a larger number of non-reentrant grains, even if slightly less efficient overall, should save you a lot of grief of figuring out non-obvious interleaving issues. In the end answer will depend on the specifics of the application. Interleaving methods Grain interface methods marked with [AlwaysInterleave] will be interleaved regardless of whether the grain is reentrant or not. Consider the following example: public interface ISlowpokeGrain : IGrainWithIntegerKey { Task GoSlow(); [AlwaysInterleave] Task GoFast(); } public class SlowpokeGrain : Grain, ISlowpokeGrain { public async Task GoSlow() { await Task.Delay(TimeSpan.FromSeconds(10)); } public async Task GoFast() { await Task.Delay(TimeSpan.FromSeconds(10)); } } Now consider the call flow initiated by the following client request: var slowpoke = client.GetGrain<ISlowpokeGrain>(0); // A) This will take around 20 seconds await Task.WhenAll(slowpoke.GoSlow(), slowpoke.GoSlow()); // B) This will take around 10 seconds. await Task.WhenAll(slowpoke.GoFast(), slowpoke.GoFast(), slowpoke.GoFast()); Calls to GoSlow will not be interleaved, so the execution of the two GoSlow() calls will take around 20 seconds. On the other hand, because GoFast is marked [AlwaysInterleave] , the three calls to it will be executed concurrently and will complete in approximately 10 seconds total instead of requiring at least 30 seconds to complete. Reentrancy within a call chain In order to avoid deadlocks, the scheduler allows reentrancy within a given call chain. Consider the following example of two grains which have mutually recursive methods, IsEven and IsOdd : public interface IEvenGrain : IGrainWithIntegerKey { Task<bool> IsEven(int num); } public interface IOddGrain : IGrainWithIntegerKey { Task<bool> IsOdd(int num); } public class EvenGrain : Grain, IEvenGrain { public async Task<bool> IsEven(int num) { if (num == 0) return true; var oddGrain = this.GrainFactory.GetGrain<IOddGrain>(0); return await oddGrain.IsOdd(num - 1); } } public class OddGrain : Grain, IOddGrain { public async Task<bool> IsOdd(int num) { if (num == 0) return false; var evenGrain = this.GrainFactory.GetGrain<IEvenGrain>(0); return await evenGrain.IsEven(num - 1); } } Now consider the call flow initiated by the following client request: var evenGrain = client.GetGrain<IEvenGrain>(0); await evenGrain.IsEven(2); The above code calls IEvenGrain.IsEven(2) , which calls IOddGrain.IsOdd(1) , which calls IEvenGrain.IsEven(0) , which returns true back up the call chain to the client. Without call chain reentrancy, the above code will result in a deadlock when IOddGrain calls IEvenGrain.IsEven(0) . With call chain reentrancy, however, the call is allowed to proceed as it is deemed to be the intention of the developer. This behavior can be disabled by setting SchedulingOptions.AllowCallChainReentrancy to false . For example: siloHostBuilder.Configure<SchedulingOptions>( options => options.AllowCallChainReentrancy = false); Reentrancy using a predicate Grain classes can specify a predicate used to determine interleaving on a call-by-call basis by inspecting the request. The [MayInterleave(string methodName)] attribute provides this functionality. The argument to the attribute is the name of a static method within the grain class which accepts an InvokeMethodRequest object and returns a bool indicating whether or not the request should be interleaved. Here is an example which allows interleaving if the request argument type has the [Interleave] attribute: [AttributeUsage(AttributeTargets.Class | AttributeTargets.Struct)] public sealed class InterleaveAttribute : Attribute { } // Specify the may-interleave predicate. [MayInterleave(nameof(ArgHasInterleaveAttribute))] public class MyGrain : Grain, IMyGrain { public static bool ArgHasInterleaveAttribute(InvokeMethodRequest req) { // Returning true indicates that this call should be interleaved with other calls. // Returning false indicates the opposite. return req.Arguments.Length == 1 && req.Arguments[0]?.GetType().GetCustomAttribute<InterleaveAttribute>() != null; } public Task Process(object payload) { // Process the object. } }"
  },
  "Documentation/grains/request_context.html": {
    "href": "Documentation/grains/request_context.html",
    "title": "Request Context | Microsoft Orleans Documentation",
    "keywords": "Request Context RequestContext is an Orleans feature that allows application metadata, such as a trace ID, to flow with requests. Application metadata may be added on the client; it will flow with Orleans requests to the receiving grain. The feature is implemented by a public static class, RequestContext, in the Orleans namespace. This class exposes two simple methods: void Set(string key, object value) is used to store a value in the request context. The value can be any Serializable type. Object Get(string key) is used to retrieve a value from the current request context. The backing storage for RequestContext is thread-static. When a thread (whether client-side or within Orleans) sends a request, the contents of the sending threads RequestContext is included with the Orleans message for the request; when the grain code receives the request, that metadata is accessible from the local RequestContext. If the grain code does not modify the RequestContext, then any grain it makes a request of will receive the same metadata, and so on. Application metadata also is maintained when you schedule a future computation using StartNew or ContinueWith; in both cases, the continuation will execute with the same metadata as the scheduling code had at the moment the computation was scheduled (that is, the system makes a copy of the current metadata and passes that to the continuation, so changes after the call to StartNew or ContinueWith will not be seen by the continuation). Note that application metadata does not flow back with responses; that is, code that runs as a result of a response being received, either within a ContinueWith continuation or after a call to Wait or GetValue, will still run within the current context that was set by the original request. For example, to set a trace ID in the client to a new GUID, one would simply call: RequestContext.Set(\"TraceId\", new Guid()); Within grain code (or other code that runs within Orleans on a scheduler thread), the trace ID of the original client request could be used, for instance, when writing a log: Logger.Info(\"Currently processing external request {0}\", RequestContext.Get(\"TraceId\")); While any serializable object may be sent as application metadata, its worth mentioning that large or complex objects may add noticeable overhead to message serialization time. For this reason, the use of simple types (strings, GUIDs, or numeric types) is recommended."
  },
  "Documentation/grains/scheduler.html": {
    "href": "Documentation/grains/scheduler.html",
    "title": "Scheduler | Microsoft Orleans Documentation",
    "keywords": "Scheduler Orleans Scheduler is a component within the Orleans runtime responsible for executing application code and parts of the runtime code to ensure the single threaded execution semantics . It implements a custom TPL Task scheduler. Orleans Task scheduler is a hierarchical 2 level scheduler. At the first level there is the global OrleansTaskScheduler that is responsible for execution of system activities. At the second level every grain activation has its own ActivationTaskScheduler , which provides the single threaded execution semantics. At a high level, the execution path is the following: A request arrives to the correct silo and the destination activation is found. A request is translated into a Task that is queued for execution by that activation, on its ActivationTaskScheduler. Any subsequent Task created as part of the grain method execution is natively enqueued to the same ActivationTaskScheduler, via the standard TaskScheduler mechanism. Every ActivationTaskScheduler has a queue of tasks queued for execution. Orleans Scheduler has a set of worker threads that are collectively used by all the activation schedulers. Those threads periodically scan all the scheduler queues for work to execute. A thread takes a queue (each queue is taken by one thread at a time) and starts executing Tasks in that queue in FIFO order. The combination of one thread at a time taking a queue and the thread executing Tasks sequentially is what provides the single threaded execution semantics. Work Items: Orleans uses a notion of Work Items to designate the entry point into the scheduler. Every new request is enqueued initially as a work item which simply wraps the execution of the first Task for that request. Work items simply provide more contextual information about the scheduling activity (the caller, the name of the activity, logging) and sometimes some extra work that has to be done on behalf of that scheduling activity (post invocation activity in Invoke work item). There are currently the following work item types: Invoke work item  this is the mostly frequently used work item type. It represents execution of an application request. Request/Response work items  executes a system request (request to a SystemTarget) TaskWorkItem  represent a Task queued to the top level OrleansTaskScheduler. Used instead of a direct Task just for convenience of data structures (more details below). WorkItemGroup  group of work items that share the same scheduler. Used to wrap a queue of Tasks for each ActivationTaskScheduler. ClosureWorkItem  a wrapper around a closure (arbitrary lambda) that is queued to the system context. Scheduling Context: Scheduling Context is a tag, just an opaque object that represents scheduling target  activation data, system target or system null context. High level Principles: Tasks are always queued to the correct scheduler 1.1 Tasks are never moved around from one scheduler to another. 1.2 We never create tasks on behalf of other tasks to execute them. 1.3 WorkItems are wrapped within Task (that is, in order to execute a work item, we create a Task whose lambda function will just run the work item lambda). By always going via tasks we ensure that any activity is executed via an appropriate Task scheduler. Tasks are executed on the scheduler where they were queued by using base.TryExecute (and not by RunSynchronously) There is a one to one mapping between ATS, WorkItem Group and Scheduling Context: 3.1 Activation Task Scheduler (ATS) is a custom TPL scheduler. We keep ATS thin and store all the data in WorkItemGroup. ATS points to its WorkItemGroup. 3.2 WorkItem Group is the actual holder (data object) of the activation Tasks. The Tasks are stored in a List - the queue of all tasks for its ATS. WorkItemGroup points back to its ATS. Data Flow and Execution of Tasks and Work items: The entry point is always a work item enqueued into OrleansTaskScheduler. It can be one of the Invoke/Request/Response/Closure WorkItem. Wrapped into a Task and enqueued into the correct ActivationTaskScheduler based on the context via Task.Start. A Task that is queued to its ActivationTaskScheduler is put into the WorkItemGroup queue. When a Task is put into a WorkItemGroup queue, WorkItemGroup makes sure it appears in OrleansTaskScheduler global RunQueue. RunQueue is the global queue of runnable WorkItemGroups, those that have at least one Task queued, and thus ready to be executed. Worker threads scan the RunQueue of OrleansTaskScheduler which hold WorkItemGroups and call WorkItemGroups.Execute WorkItemGroups.Execute scans the queue of its tasks and executes them via ActivationTaskScheduler.RunTask(Task) 6.1 ActivationTaskScheduler.RunTask(Task) calls base.TryExecute. 6.2 Task that were enqueued directly to the scheduler via TPL will just execute 6.3 Tasks that wrap work items will call workItem.Execute which will execute the Closure work item delegate. Low level design  Work Items: Queueing work items to OrleansTaskScheduler is how the whole chain of execution for every request starts in the Orleans runtime. This is our entry point into the Scheduler. Work items are first submitted to OrleansTaskScheduler (since this is the interface presented to the rest of the system). 2.1 Only closure/invoke/resume work items can be submitted this way. 2.2 TaskWorkItem cannot be submitted to OrleansTaskScheduler directly (read more below on handling of TaskWorkItem). Every work item must be wrapped into Task and enqueued to the right scheduler via Task.Start. 3.1 This will make sure the TaskScheduler.Current is set correctly on any Task that is created implicitly during execution of this workItem. 3.2 Wrapping is done by creating a Task via WrapWorkItemAsTask that will execute the work item and enqueuing it to the right scheduler via Task.Start(scheduler). 3.3 Work items for the null context are queued to OrleansTaskScheduler. 3.4 Work items for non-null contexts are queued to ActivationTaskScheduler Low level design  Queueing Tasks: Tasks are queued directly to the right scheduler 1.1 Tasks are queued implicitly by TPL via protected override void QueueTask(Task task) 1.2 A Task that has a non-null context is always enqueued to ActivationTaskScheduler 1.3 A Task that has the null context is always enqueued to OrleansTaskScheduler Queueing Tasks to ActivationTaskScheduler: 2.1 We never wrap a Task in another Task. A Task gets added directly to the WorkItem Group queue Queueing Tasks to OrleansTaskScheduler: 3.1 When a Task is enqueued to the OrleansTaskScheduler, we wrap it into a TaskWorkItem and put it into this schedulers queue of work items. 3.2 This is just a matter of data structures, nothing inherent about it: 3.3 OrleansTaskScheduler usually holds work item groups to schedule them, so its RunQueue has a BlockingCollection . 3.4 Since tasks to the null context are also queued to OrleansTaskScheduler, we reuse the same data structure, thus we have to wrap each Task in a TaskWorkItem. 3.5 We should be able to get rid of this wrapping completely by adjusting the RunQueue data structure. This may simplify the code a bit, but in general should not matter. Also, in the future we should move away from the null context anyway, so this issue will be gone anyway Inlining tasks: Since Tasks are always queued to the right scheduler, in theory it should always be safe to inline any Task."
  },
  "Documentation/grains/stateless_worker_grains.html": {
    "href": "Documentation/grains/stateless_worker_grains.html",
    "title": "Stateless Worker Grains | Microsoft Orleans Documentation",
    "keywords": "Stateless Worker Grains By default, the Orleans runtime creates no more than one activation of a grain within the cluster. This is the most intuitive expression of the Virtual Actor model with each grain corresponding to an entity with a unique type/identity. However, there are also cases when an application needs to perform functional stateless operations that are not tied to a particular entity in the system. For example, if client sends requests with compressed payloads that need to be decompressed before they could be routed to the target grain for processing, such decompression/routing logic is not tied to a specific entity in the application, and can easily scale out. When the [StatelessWorker] attribute is applied to a grain class, it indicates to the Orleans runtime that grains of that class should be treated as Stateless Worker grains. Stateless Worker grains have the following properties that make their execution very different from that of normal grain classes. The Orleans runtime can and will create multiple activations of a Stateless Worker grain on different silos of the cluster. Requests made to Stateless Worker grains are always executed locally, that is on the same silo where the request originated, either made by a grain running on the silo or received by the silo's client gateway. Hence, calls to Stateless Worker grains from other grains or from client gateways never incur a remote message. The Orleans Runtime automatically creates additional activations of a Stateless Worker grain if the already existing ones are busy. The maximum number of activations of a Stateless Worker grain the runtime creates per silo is limited by default by the number of CPU cores on the machine, unless specified explicitly by the optional maxLocalWorkers argument. Because of 2 and 3, Stateless Worker grain activations are not individually addressable. Two subsequent requests to a Stateless Worker grain may be processed by different activations of it. Stateless Worker grains provide a straightforward way of creating an auto-managed pool of grain activations that automatically scales up and down based on the actual load. The runtime always scans for available Stateless Worker grain activations in the same order. Because of that, it always dispatches a requests to the first idle local activation it can find, and only gets to the last one if all previous activations are busy. If all activations are busy and the activation limit hasn't been reached, it creates one more activation at the end of the list, and dispatches the request to it. That means that when the rate of requests to a Stateless Worker grain increases, and existing activations are all currently busy, the runtime expands the pool of its activations up to the limit. Conversely, when the load drops, and it can be handled by a smaller number of activations of the Stateless Worker grain, the activations at the tail of the list will not be getting requests dispatched to them. They will become idle, and eventually deactivated by the standard activation collection process. Hence, the pool of activations will eventually shrink to match the load. The following example defines a Stateless Worker grain class MyStatelessWorkerGrain with the default maximum activation number limit. [StatelessWorker] public class MyStatelessWorkerGrain : Grain, IMyStatelessWorkerGrain { ... } Making a call to a Stateless Worker grain is the same as to any other grain. The only difference is that in most cases a single grain ID is used, 0 or Guid.Empty . Multiple grain IDs can be used when having multiple Stateless Worker grain pools, one per ID, is desirable. var worker = GrainFactory.GetGrain<IMyStatelessWorkerGrain>(0); await worker.Process(args); This one defines a Stateless Worker grain class with no more than one grain activation per silo. [StatelessWorker(1)] // max 1 activation per silo public class MyLonelyWorkerGrain : ILonelyWorkerGrain { ... } Note that [StatelessWorker] attribute does not change reentrancy of the target grain class. Just like any other grains, Stateless Worker grains are non-reentrant by default. They can be explicitly made reentrant by adding a [Reentrant] attribute to the grain class. State The \"Stateless\" part of \"Stateless Worker\" does not mean that a Stateless Worker cannot have state and is limited only to executing functional operations. Like any other grain, a Stateless Worker grain can load and keep in memory any state it needs. It's just because multiple activations of a Stateless Worker grain can be created on the same and different silos of the cluster, there is no easy mechanism to coordinate state held by different activations. There are several useful patterns that involve Stateless Worker holding state. Scaled out hot cache items For hot cache items that experience high throughput, holding each such item in a Stateless Worker grain makes it a) automatically scale out within a silo and across all silos in the cluster; and b) makes the data always locally available on the silo that received the client request via its client gateway, so that the requests can be answered without an extra network hop to another silo. Reduce style aggregation In some scenarios applications need to calculate certain metrics across all grains of a particular type in the cluster, and report the aggregates periodically. Examples are reporting number of players per game map, average duration of a VoIP call, etc. If each of the many thousands or millions of grains were to report their metrics to a single global aggregator, the aggregator would get immediately overloaded unable to process the flood of reports. The alternative approach is to turn this task into a 2 (or more) step reduce style aggregation. The first layer of aggregation is done by reporting grain sending their metrics to a Stateless Worker pre-aggregation grain. The Orleans runtime will automatically create multiple activations of the Stateless Worker grain with each silo. Since all such calls will be processed locally with no remote calls or serialization of the messages, the cost of such aggregation will be significantly less than in a remote case. Now each of the pre-aggregation Stateless Worker grain activations, independently or in coordination with other local activations, can send their aggregated reports to the global final aggregator (or to another reduction layer if necessary) without overloading it."
  },
  "Documentation/grains/timers_and_reminders.html": {
    "href": "Documentation/grains/timers_and_reminders.html",
    "title": "Timers and Reminders | Microsoft Orleans Documentation",
    "keywords": "Timers and Reminders The Orleans runtime provides two mechanisms, called timers and reminders, that enable the developer to specify periodic behavior for grains. Timers Description Timers are used to create periodic grain behavior that isn't required to span multiple activations (instantiations of the grain). It is essentially identical to the standard . NET System.Threading.Timer class. In addition, it is subject to single threaded execution guarantees within the grain activation that it operates. Each activation may have zero or more timers associated with it. The runtime executes each timer routine within the runtime context of the activation that it is associated with. Usage To start a timer, use the Grain.RegisterTimer method, which returns an IDisposable reference: public IDisposable RegisterTimer( Func<object, Task> asyncCallback, // function invoked when the timer ticks object state, // object tp pass to asyncCallback TimeSpan dueTime, // time to wait before the first timer tick TimeSpan period) // the period of the timer Cancel the timer by disposing it. A timer will cease to trigger if the activation is deactivated or when a fault occurs and its silo crashes. Important Considerations When activation collection is enabled, the execution of a timer callback does not change the activation's state from idle to in use. This means that a timer cannot be used to postpone deactivation of otherwise idle activations. The period passed to Grain.RegisterTimer is the amount of time that passes from the moment the Task returned by asyncCallback is resolved to the moment that the next invocation of asyncCallback should occur. This not only makes it impossible for successive calls to asyncCallback to overlap but also makes it so that the length of time asyncCallback takes to complete affects the frequency at which asyncCallback is invoked. This is an important deviation from the semantics of System.Threading.Timer . Each invocation of asyncCallback is delivered to an activation on a separate turn and will never run concurrently with other turns on the same activation. Note however, asyncCallback invocations are not delivered as messages and are thus not subject to message interleaving semantics. This means that invocations of asyncCallback should be considered to behave as if running on a reentrant grain with respect to other messages to that grain. Reminders Description Reminders are similar to timers with a few important differences: Reminders are persistent and will continue to trigger in all situations (including partial or full cluster restarts) unless explicitly cancelled. Reminders are associated with a grain, not any specific activation. If a grain has no activation associated with it and a reminder ticks, one will be created. e.g.: If an activation becomes idle and is deactivated, a reminder associated with the same grain will reactivate the grain when it ticks next. Reminders are delivered by message and are subject to the same interleaving semantics as all other grain methods. Reminders should not be used for high-frequency timers-- their period should be measured in minutes, hours, or days. Configuration Reminders, being persistent, rely upon storage to function. You must specify which storage backing to use before the reminder subsystem will function. The reminder functionality is controlled by the SystemStore element in the server-side configuration. It works with either Azure Table or SQL Server as the store. Azure Table configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var silo = new SiloHostBuilder() [...] .UseAzureTableReminderService(options => options.ConnectionString = connectionString) [...] SQL: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; const string invariant = \"YOUR_INVARIANT\"; var silo = new SiloHostBuilder() [...] .UseAdoNetReminderService(options => { options.ConnectionString = connectionString; options.Invariant = invariant; }) [...] If you just want a placeholder implementation of reminders to work with without needing to set up an Azure account or SQL database, then this will give you a development-only implementation of the reminder system: var silo = new SiloHostBuilder() [...] .UseInMemoryReminderService() [...] Usage A grain that uses reminders must implement the IRemindable.RecieveReminder method. Task IRemindable.ReceiveReminder(string reminderName, TickStatus status) { Console.WriteLine(\"Thanks for reminding me-- I almost forgot!\"); return TaskDone.Done; } To start a reminder, use the Grain.RegisterOrUpdateReminder method, which returns an IOrleansReminder object: protected Task<IOrleansReminder> RegisterOrUpdateReminder(string reminderName, TimeSpan dueTime, TimeSpan period) reminderName is a string that must uniquely identify the reminder within the scope of the contextual grain. dueTime specifies a quantity of time to wait before issuing the first timer tick. period specifies the period of the timer. Since reminders survive the lifetime of any single activation, they must be explicitly cancelled (as opposed to being disposed). You cancel a reminder by calling Grain.UnregisterReminder : protected Task UnregisterReminder(IOrleansReminder reminder) reminder is the handle object returned by Grain.RegisterOrUpdateReminder . Instances of IOrleansReminder aren't guaranteed to be valid beyond the lifespan of an activation. If you wish to identify a reminder in a way that persists, use a string containing the reminder's name. If you only have the reminder's name and need the corresponding instance of IOrleansReminder , call the Grain.GetReminder method: protected Task<IOrleansReminder> GetReminder(string reminderName) Which Should I Use? We recommend that you use timers in the following circumstances: It doesn't matter (or is desirable) that the timer ceases to function if the activation is deactivated or failures occur. If the resolution of the timer is small (e.g. reasonably expressible in seconds or minutes). The timer callback can be started from Grain.OnActivateAsync or when a grain method is invoked. We recommend that you use reminders in the following circumstances: When the periodic behavior needs to survive the activation and any failures. To perform infrequent tasks (e.g. reasonably expressible in minutes, hours, or days). Combining Timers and Reminders You might consider using a combination of reminders and timers to accomplish your goal. For example, if you need a timer with a small resolution that needs to survive across activations, you can use a reminder that runs every five minutes, whose purpose is to wake up a grain that restarts a local timer that may have been lost due to a deactivation."
  },
  "Documentation/grains/transactions.html": {
    "href": "Documentation/grains/transactions.html",
    "title": "Transactions in Orleans 2.0 | Microsoft Orleans Documentation",
    "keywords": "Orleans Transactions (Beta) Orleans transactions are in a beta state and should not be used in production systems. Orleans supports distributed transactions against persistent grain state. Setup Orleans transactions are opt-in. A silo must be configured to use transactions. If it is not, any calls to transactional grains will receive an OrleansTransactionsDisabledException. Transaction Manager Orleans transactions requires a transaction manager which is authoritative on the state of a transaction. Currently, the transaction manager is run within the cluster and must be configured. This can be programmatically configured on the silo host builder using UseInClusterTransactionManager and TransactionsConfiguration. The TransactionsConfiguration contains the following configurable values: TransactionIdAllocationBatchSize - To avoid a storage call on every transaction start, transaction Ids are allocated in batches. This is the number of new transaction Ids allocated per transaction Id generation request (storage call). AvailableTransactionIdThreshold - A new batch of transaction Ids will be automatically allocated if the available ids drop below this threshold. TransactionRecordPreservationDuration - How long to preserve a transaction record in the TM memory after the transaction has completed. This is used to answer queries about the outcome of the transaction. It is suggested that you use the defaults for these values unless they demonstrate themselves as insufficient. Transaction Log The transaction manager must persist transaction results for recoverability purposes. To support a range of backend storage solutions an abstraction has been provided for log storage. We currently support an azure storage version of the log storage, and an in-memory version for development and test purposes. This can be programmatically configured on the silo host builder using UseAzureTransactionLog or UseInMemoryTransactionLog. Transactional State To support various transactional storage patterns the grain facing interface and supporting logic is pluggable. We currently only support ITransactionalState. This can be programmatically enabled on the silo host builder using UseTransactionalState. To use a transactional state, a storage provider needs also be configured. Example: var builder = new SiloHostBuilder() [...] .AddAzureTableGrainStorageAsDefault(options => options.ConnectionString = YOUR_STORAGE_CONNECTION_STRING) .UseInClusterTransactionManager() .UseAzureTransactionLog(options => options.ConnectionString = YOUR_STORAGE_CONNECTION_STRING) .UseTransactionalState(); var host = builder.Build(); await host.StartAsync(); Programming Model For a grain to support transactions, transactional operations on a grain must be marked as being part of a transaction using the Transaction attribute. Calls can be marked as Required, meaning the call can take part in a transaction among multiple other grains or as RequiresNew indicating that it will already start its own transaction. Example: public interface IATMGrain : IGrainWithIntegerKey { [Transaction(TransactionOption.RequiresNew)] Task Transfer(Guid fromAccount, Guid toAccount, uint amountToTransfer); } The Transfer operation in the above atm grain will always start a new transaction which involves the two referenced accounts. public interface IAccountGrain : IGrainWithGuidKey { [Transaction(TransactionOption.Required)] Task Withdraw(uint amount); [Transaction(TransactionOption.Required)] Task Deposit(uint amount); [Transaction(TransactionOption.Required)] Task<uint> GetBalance(); } The Withdraw and Deposit operations in the above account grain can take part in transactional operations, like the Transfer operation in the ATM grain, with other transactional grains. To use a transactional state within a grain, one needs only define a serializable state class to be persisted and declare the state in the grains constructor. Example: public class AccountGrain : Grain, IAccountGrain { private readonly ITransactionalState<Balance> balance; public AccountGrain( [TransactionalState(\"balance\")] ITransactionalState<Balance> balance) { this.balance = balance ?? throw new ArgumentNullException(nameof(balance)); } Task IAccountGrain.Deposit(uint ammount) { this.balance.State.Value += ammount; this.balance.Save(); return Task.CompletedTask; } Task IAccountGrain.Withdrawal(uint ammount) { this.balance.State.Value -= ammount; this.balance.Save(); return Task.CompletedTask; } Task<uint> IAccountGrain.GetBalance() { return Task.FromResult(this.balance.State.Value); } } In the above example the attribute TransactionalState is used to declare that the balance construction argument should be associated with a transactional state named balance. With this declaration Orleans will wire up an ITransactionalState instance with a state loaded from the default storage provider for the grain to use. The state can be accessed and modified via the State property. Any changes to the state need be recorded by calling Save(). The transaction infrastructure will ensure that any such changes performed as part of a transaction, even among multiple grains distributed over an Orleans cluster, will either all be committed or reverted together."
  },
  "Documentation/core_concepts/what_is_a_client.html": {
    "href": "Documentation/core_concepts/what_is_a_client.html",
    "title": "What is a Client | Microsoft Orleans Documentation",
    "keywords": "What Is Grain Client? The term \"Client\" or sometimes \"Grain Client\" is used for application code that interacts with grains but itself is not part of a grain logic. Client code runs outside of the cluster of Orleans servers called silos where grains are hosted. Hence, a client acts as a connector or conduit to the cluster and to all grains of the application. Usually, clients are used on the frontend web servers to connect to an Orleans cluster that serves as a middle tier with grains executing business logic. In a typical setup, a frontend web server: Receives a web request Performs necessary authentication and authorization validation Decides which grain(s) should process the request Uses Grain Client to make one or more method call to the grain(s) Handles successful completion or failures of the grain calls and any returned values Sends a response for the web request Initialization of Grain Client Before a grain client can be used for making calls to grains hosted in an Orleans cluster, it needs to be configured, initialized, and connected to the cluster. Configuration is provided via a ClientConfiguration object that contains a hierarchy of configuration properties for programmatically configuring a client. There is also a way to configure a client via a XML file, but that option will be deprecated in the future. More information is in the Client Configuration guide. Here we will simply use a helper method that creates a configuration object hardcoded for connecting to a local silo running as localhost . ClientConfiguration clientConfig = ClientConfiguration.LocalhostSilo(); Once we have a configuration object, we can build a client via the ClientBuilder class. IClusterClient client = new ClientBuilder().UseConfiguration(clientConfig).Build(); Lastly, we need to call Connect() method on the constructed client object to make it connect to the Orleans cluster. It's an asynchronous method that returns a Task . So we need to wait for its completion with an await or .Wait() . await client.Connect(); Making Calls to Grains Making calls to grain from a client is really no different from making such calls from within grain code. The same GetGrain<T>(key) method, where T is the target grain interface, is used in both cases to obtain grain references. The slight difference is in through what factory object we invoke GetGrain . In client code we do that through the connected client object. IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); Task t = player.JoinGame(game) await t; A call to a grain method returns a Task or a Task<T> as required by the grain interface rules. The client can use the await keyword to asynchronously await the returned Task without blocking the thread, or in some cases the Wait() method to block the current thread of execution. The major difference between making calls to grains from client code and from within another grain is the single-threaded execution model of grains. Grains are constrained to be single-threaded by the Orleans runtime, while clients may be multi-threaded. Orleans does not provide any such guarantee on the client side, and so it is up to the client to manage its own concurrency using whatever synchronization constructs are appropriate for its environment  locks, events, Tasks , etc. Receiving notifications There are situations in which a simple request-response pattern is not enough, and the client needs to receive asynchronous notifications. For example, a user might want to be notified when a new message has been published by someone that she is following. Observers is one such mechanism that enables exposing client side objects as grain-like targets to get invoked by grains. Calls to observers do not provide any indication of success or failure, as they are sent as one-way best effort message. So it is a responsibility of the application code to build a higher level reliability mechanism on top of observers where necessary. Another mechanism that can be used for delivering asynchronous messages to clients is Streams. Streams expose indications of success or failure of delivery of individual messages, and hence enable reliable communication back to the client. Example Here is an extended version of the example given above of a client application that connects to Orleans, finds the player account, subscribes for updates to the game session the player is part of with an observer, and prints out notifications until the program is manually terminated. namespace PlayerWatcher { class Program { /// <summary> /// Simulates a companion application that connects to the game /// that a particular player is currently part of, and subscribes /// to receive live notifications about its progress. /// </summary> static void Main(string[] args) { RunWatcher().Wait(); // Block main thread so that the process doesn't exit. // Updates arrive on thread pool threads. Console.ReadLine(); } static async Task RunWatcher() { try { // Connect to local silo var config = ClientConfiguration.LocalhostSilo(); var client = new ClientBuilder().UseConfiguration(config).Build(); await client.Connect(); // Hardcoded player ID Guid playerId = new Guid(\"{2349992C-860A-4EDA-9590-000000000006}\"); IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); IGameGrain game = null; while (game == null) { Console.WriteLine(\"Getting current game for player {0}...\", playerId); try { game = await player.GetCurrentGame(); if (game == null) // Wait until the player joins a game { await Task.Delay(5000); } } catch (Exception exc) { Console.WriteLine(\"Exception: \", exc.GetBaseException()); } } Console.WriteLine(\"Subscribing to updates for game {0}...\", game.GetPrimaryKey()); // Subscribe for updates var watcher = new GameObserver(); await game.SubscribeForGameUpdates( await client.CreateObjectReference<IGameObserver>(watcher)); Console.WriteLine(\"Subscribed successfully. Press <Enter> to stop.\"); } catch (Exception exc) { Console.WriteLine(\"Unexpected Error: {0}\", exc.GetBaseException()); } } } /// <summary> /// Observer class that implements the observer interface. Need to pass a grain reference to an instance of this class to subscribe for updates. /// </summary> class GameObserver : IGameObserver { // Receive updates public void UpdateGameScore(string score) { Console.WriteLine(\"New game score: {0}\", score); } } } }"
  },
  "Documentation/core_concepts/what_is_a_cluster.html": {
    "href": "Documentation/core_concepts/what_is_a_cluster.html",
    "title": "What is a Cluster | Microsoft Orleans Documentation",
    "keywords": "What is a cluster? ///TODO: write about relationship among client, cluster, and silo. Explain terminology."
  },
  "Documentation/deployment/azure_web_apps_with_azure_cloud_services.html": {
    "href": "Documentation/deployment/azure_web_apps_with_azure_cloud_services.html",
    "title": "Using Azure Web Apps with Azure Cloud Services | Microsoft Orleans Documentation",
    "keywords": "Using Azure Web Apps with Azure Cloud Services If you would like to connect to an Azure Cloud Services Silo from an Azure Web App rather than a Web Role hosted within the same cloud service you can. For this to work securely you will need to assign both the Azure Web App and the Worker Role hosting the Silo to an Azure Virtual Network . First we'll setup the Azure Web App, you can follow this guide which will create the virtual network and assign it to the Azure Web App. Now we can assign the cloud service to the virtual network by modifying the ServiceConfiguration file. <NetworkConfiguration> <VirtualNetworkSite name=\"virtual-network-name\" /> <AddressAssignments> <InstanceAddress roleName=\"role-name\"> <Subnets> <Subnet name=\"subnet-name\" /> </Subnets> </InstanceAddress> </AddressAssignments> </NetworkConfiguration> Also make sure the Silo endpoints are configured. <Endpoints> <InternalEndpoint name=\"OrleansSiloEndpoint\" protocol=\"tcp\" port=\"11111\" /> <InternalEndpoint name=\"OrleansProxyEndpoint\" protocol=\"tcp\" port=\"30000\" /> </Endpoints> You can now connect from the Web App to the rest of the cluster. Potential Issues If the Web App is having difficulty connecting to the Silo: Make sure you have at least two roles , or two instances of one role in your Azure Cloud Service, or the InternalEndpoint firewall rules may not be generated. Check that both the Web App and the Silo are using the same ClusterId and ServiceId . Make sure the network security group is set up to allow internal virtual network connections. If you haven't got one you can create and assign one easily using the following PowerShell : New-AzureNetworkSecurityGroup -Name \"Default\" -Location \"North Europe\" Get-AzureNetworkSecurityGroup -Name \"Default\" | Set-AzureNetworkSecurityGroupToSubnet -VirtualNetworkName \"virtual-network-name\" -SubnetName \"subnet-name\""
  },
  "Documentation/deployment/cluster_management.html": {
    "href": "Documentation/deployment/cluster_management.html",
    "title": "Cluster Management in Orleans | Microsoft Orleans Documentation",
    "keywords": "Cluster Management in Orleans Orleans provides cluster management via a built-in membership protocol, which we sometimes refer to as Silo Membership . The goal of this protocol is for all silos (Orleans servers) to agree on the set of currently alive silos, detect failed silos, and allow new silos to join the cluster. The protocol relies on an external service to provide an abstraction of MembershipTable . MembershipTable is a flat No-SQL like durable table that we use for 2 purposes. First, it is used as a rendezvous point for silos to find each other and Orleans clients to find silos. Second, it is used to store the current membership view (list of alive silos) and helps coordinate the agreement on the membership view. We currently have 6 implementations of the MembershipTable : based on Azure Table Storage , SQL server, Apache ZooKeeper , Consul IO , AWS DynamoDB , and in-memory emulation for development. In addition to the MembershipTable each silo participates in fully distributed peer-to-peer membership protocol that detects failed silos and reaches agreement on a set alive silos. We start by describing the internal implementation of the Orleans's membership protocol below and later on describe the implementation of the MembershipTable . The Basic Membership Protocol: Upon startup every silo writes itself into a well-known MembershipTable (passed via config). A combination of silo identity ( ip:port:epoch ) and service deployment id are used as unique keys in the table. Epoch is just time in ticks when this silo started, and as such ip:port:epoch is guaranteed to be unique in a given Orleans deployment. Silos monitor each other directly, via application pings (\"are you alive\" heartbeats ). Pings are sent as direct messages from silo to silo, over the same TCP sockets that silos communicate. That way, pings fully correlate with actual networking problems and server health. Every silo pings X other silos. A silo picks whom to ping by calculating consistent hashes on other silos' identity, forming a virtual ring of all identities and picking X successor silos on the ring (this is a well-known distributed technique called consistent hashing and is widely used in many distributed hash tables, like Chord DHT ). If a silo S does not get Y ping replies from a monitored servers P, it suspects it by writing its timestamped suspicion into Ps row in the MembershipTable . If P has more than Z suspicions within K seconds, then S writes that P is dead into Ps row, and broadcasts a request for all silos to re-read the membership table (which theyll do anyway periodically). In more details: 5.1 Suspicion is written to the MembershipTable , in a special column in the row corresponding to P. When S suspects P it writes: at time TTT S suspected P. 5.2 One suspicion is not enough to declare P as dead. You need Z suspicions from different silos in a configurable time window T, typically 3 minutes, to declare P as dead. The suspicion is written using optimistic concurrency control provided by the MembershipTable . 5.3 The suspecting silo S reads P's row. 5.4 If S is the last suspector (there have already been Z-1 suspectors within time period T, as written in the suspicion column), S decides to declare P as Dead. In this case, S adds itself to list of suspectors and also writes in P's Status column that P is Dead. 5.5 Otherwise, if S is not the last suspector, S just adds itself to the suspectors column. 5.6 In either case the write back uses the version number or etag that was read, so the updates to this row are serialized. In case the write has failed due to version/etag mismatch, S retries (read again, and try to write, unless P was already marked dead). 5.7 At a high level this sequence of \"read, local modify, write back\" is a transaction. However, we are not using storage transactions to do that. Transaction code executes locally on a server and we use optimistic concurrency provided by the MembershipTable to ensure isolation and atomicity. Every silo periodically reads the entire membership table for its deployment. That way silos learn about new silos joining and about other silos being declared dead. Configuration : we provide a default configuration, which was hand tuned during our production usage in Azure. Currently the default is: every silo is monitored by 3 other silos, 2 suspicions are enough to declare a silo dead, suspicions only from last 3 minutes (otherwise they are outdated). Pings are send every 10 seconds and you needs to miss 3 pings to suspect a silo. Enforcing Perfect Failure detection  it is theoretically possible that a silo will be declared dead if it lost communication with other silos, while the silo process itself is still running. To solve this problem once the silo is declared dead in the table it is considered dead by everyone, even if it is in fact not dead (just partitioned temporarily or heartbeat messages got lost). Everyone stops communicating with it and once it learns that it is dead (by reading its own new status from the table) it commits suicide and shuts down its process. As a result, there must be an infrastructure in place to restart the silo as a new process (a new epoch number is generated upon start). When it's hosted in Azure, that happens automatically. When it isn't, another infrastructure is required. For example, a Windows Service configured to auto restart on failure. Optimization to reduce the frequency of periodical table reads and speed up all silos learning about new joining silos and dead silos . Every time any silo writes anything successfully to the table (suspicion, new join, ) it also broadcasts to all other silos  go and reread the table now. The silo does NOT tell others what it wrote in the table (since this information could already be outdated/wrong), it just tells them to re-read the table. That way we learn very quickly about membership changes without the need to wait for the full periodic read cycle. We still need the periodic read, in case the re-read the table message gets lost. Properties of the Basic Membership Protocol and FAQ: Can handle any number of failures  our algorithm can handle any number of failures (that is, f<=n), including full cluster restart. This is in contrast with traditional Paxos based solutions, which require quorum, which is usually a majority. We have seen in production situations when more than half of the silos were down. Our system stayed functional, while Paxos based membership would not be able to make progress. Traffic to the table is very light - The actual pings go directly between servers and not to the table. This would generate a lot of traffic plus would be less accurate from the failure detection perspective - if a silo could not reach the table, it would miss to write its I am alive heartbeat and others would kill him. Tunable accuracy vs. completeness  both perfect and accurate failure detection is not possible in general . One usually wants an ability to tradeoff accuracy (dont want to declare a silo that is really alive as dead) with completeness (want to declare dead a silo that is indeed dead as soon as possible). The configurable #votes to declare dead and #missed pings allows to trade those two. Scale - the basic protocol can handle thousands and probably even tens of thousands of servers. This is in contrast with traditional Paxos based solutions, such as group communication protocols, which are known not to scale beyond tens. Diagnostics - the table is also very convenient for diagnostics and troubleshooting. System administrator can instantaneously find in the table the current list of alive silos, as well as see the history of all killed silos and suspicions. This is especially useful when diagnosing problems. Why do we need reliable persistent storage for implementation of the MembershipTable ? - we use persistent storage (Azure table, SQL server, AWS DynamoDB, Apache ZooKeeper or Consul IO KV) for the MembershipTable for 2 purposes. First, it is used as a rendezvous point for silos to find each other and Orleans clients to find silos. Second, we use the reliable storage to help us coordinate the agreement on the membership view. While we perform failure detection directly in a peer to peer fashion between the silos, we store the membership view in a reliable storage and use the concurrency control mechanism provided by this storage to reach agreement of who is alive and who is dead. That way, in a sense, our protocol outsources the hard problem of distributed consensus to the cloud. In that we fully utilize the power of the underlying cloud platform, using it truly as \"Platform as a Service\". What happens if the table is not accessible for some time? (storage service is down, unavailable, or there are communication problems with it)  our protocol will NOT declare silos as dead by mistake in such a case. Currently operational silos will keep working without any problems. However, we won't be able to declare a silo dead (if we detected some silo is dead via missed pings we wont be able to write this fact to the table) and also won't be able to allow new silos to join. So completeness will suffer, but accuracy will not - partitioning from the table will never cause us to declare silo as dead by mistake. Also, in case of a partial network partition (if some silos can access the table and some not), it could happen that we will declare a dead silo as dead, but it will take some time until all other silos learn about it. So detection could be delayed, but we will never wrongly kill someone due to table un-availability. Direct IAmAlive writes into the table for diagnostics only - in addition to heartbeats that are sent between the silos, each silo also periodically updates an \"I Am Alive\" column in his row in the table. This \"I Am Alive\" column is only used for manual troubleshooting and diagnostics and is not used by the membership protocol itself. It is usually written at much lower frequency (once every 5 minutes) and serves as a very useful tool for system administrators to check the liveness of the cluster or easily find out when the silo was last alive. Extension to totally order membership views: The basic membership protocol described above was later extended to support totally ordered membership views. We will briefly describe the reasons for this extension and how it is implemented. The extension does not change anything in the above design, just adds an additional property that all membership configurations are globally totally ordered. Why it is useful to totally order membership views? This allows serializing the joining of new silos to the cluster. That way, when a new silo joins the cluster it can validate two-way connectivity to every other silo that has already started. If some of the already joined silos do not answer it (potentially indicating a network connectivity problem with the new silo), the new silo is not allowed to join. This ensures that at least when a silo starts, there is a full connectivity between all silos in the cluster (this is implemented). Higher level protocols in the silo, such as distributed grain directory, can utilize the fact that membership views are ordered and use this information to perform smarter duplicate activations resolution. In particular, when directory finds out that 2 activations were created when membership was in flux, it may decide to deactivate the older activation that was created based on the now-outdated membership information (this is currently not implemented). Extended Membership Protocol: For implementation of this feature we utilize the support for transactions over multiple rows that is provided by the MembershipTable .. We add a membership-version row to the table that tracks table changes. When silo S wants to write suspicion or death declaration for silo P: 3.1 S reads the latest table content. If P is already dead, do nothing. Otherwise, 3.2 In the same transaction, write the changes to P's row as well as increment the version number and write it back to the table. 3.3 Both writes are conditioned with eTags. 3.4 If transaction aborts due to eTag mismatch on either P's row or on the version row, attempt again. All writes to the table modify and increment the version row. That way all writes to the table are serialized (via serializing the updates to the version row) and since silos only increment the version number, the writes are also totally ordered in increasing order. Scalability of the Extended Membership Protocol: In the extended version of the protocol all writes are serialized via one row. This can potentially hurt the scalability of the cluster managemenet protocol, since it increases the risk of conflicts between concurrent table writes. To partially mitigate this problem silos retry all their writes to the table by using exponential backoff. We have observed the extended protocols to work smoothly in production environment in Azure with up to 200 silos. However, we do think the protocol might have problems to scale beyond a thousand silos. In such large setups the updates to version row may be easily disabled, essentially maintaining the rest of the cluster managemenet protocol and giving up on the total ordering property. Please also note that we refer here to the scalability of the cluster management protocol, not the rest of Orleans. We believe that other parts of the Orleans runtime (messaging, distributed directory, grain hosting, client to gateway connectivity) are scalable way beyond hundreds of silos. Membership Table: As already mentioned, MembershipTable is used as a rendezvous point for silos to find each other and Orleans clients to find silos and also helps coordinate the agreement on the membership view. We currently have 6 implementation of the MembershipTable : based on Azure Table, SQL server, Apache ZooKeeper, Consul IO, AWS DynamoDB, and in-memory emulation for development. The interface for MembershipTable is defined in IMembershipTable . Azure Table Storage - in this implementation we use Azure deployment ID as partition key and the silo identity ( ip:port:epoch ) as row key. Together they guarantee a unique key per silo. For concurrency control we use optimistic concurrency control based on Azure Table ETags . Every time we read from the table we store the etag for every read row and use that eTag when we try to write back. etags are automatically assigned and checked by Azure Table service on every write. For multi-row transactions we utilize the support for batch transactions provided by Azure table , which guarantees serializale transactions over rows with the same partition key. SQL Server - in this implementation the configured deployment ID is used to distinguish between deployments and which silos belong to which deployments. The silo identity is defined as a combination of deploymentID, ip, port, epoch in appropriate tables and columns. The relational backend uses optimistic concurrency control and transactions, similar to the procedure of using ETags on Azure Table implementation. The relational implementation expects the database engine to generate the ETag used. In case of SQL Server, on SQL Server 2000 the generated ETag is one acquired from a call to NEWID() . On SQL Server 2005 and later ROWVERSION is used. Orleans reads and writes relational ETags as opaque VARBINARY(16) tags and stores them in memory as base64 encoded strings. Orleans supports multi-row inserts using UNION ALL (for Oracle including DUAL), which is currently used to insert statistics data. The exact implementation and rationale for SQL Server can be seen at CreateOrleansTables_SqlServer.sql . Apache ZooKeeper - in this implementation we use the configured deployment ID as a root node and the silo identity ( ip:port@epoch ) as its child node. Together they guarantee a unique path per silo. For concurrency control we use optimistic concurrency control based on the node version . Every time we read from the deployment root node we store the version for every read child silo node and use that version when we try to write back. Each time a node's data changes, the version number increases atomically by the ZooKeeper service. For multi-row transactions we utilize the multi method , which guarantees serializale transactions over silo nodes with the same parent deployment ID node. Consul IO - we used Consul's Key/Value store to impelement the membershop table. Refer to Consul-Deployment for more details. AWS DynamoDB - In this implementation we use the cluster Deployment ID as the Partition Key and Silo Identity ( ip-port-generation ) as the RangeKey making the record unity. The optimistic concurrency is made by the ETag attribute by making conditional writes on DynamoDB. The implementation logic is quite similar to Azure Table Storage. We only implemented the basic membership protocol (and not the extended protocol). In-memory emulation for development setup. We use a special system grain, called MembershipTableGrain , for that implementation. This grain lives on a designated primary silo, which is only used for a development setup . In any real production usage primary silo is not required . Configuration: Membership protocol is configured via the Liveness element in the Globals section in OrleansConfiguration.xml file. The default values were tuned in years of production usage in Azure and we believe they represent good default settings. There is no need in general to change them. Sample config element: <Liveness ProbeTimeout = \"5s\" TableRefreshTimeout =\"10s DeathVoteExpirationTimeout =\"80s\" NumMissedProbesLimit = \"3\" NumProbedSilos=\"3\" NumVotesForDeathDeclaration=\"2\" /> There are 4 types of liveness implemented. The type of the liveness protocol is configured via the SystemStoreType attribute of the SystemStore element in the Globals section in OrleansConfiguration.xml file. MembershipTableGrain - membership table is stored in a grain on primary silo. This is a development setup only . AzureTable - membership table is stored in Azure table. SqlServer - membership table is stored in a relational database. ZooKeeper - membership table is stored in a ZooKeeper ensemble . Consul - configured as Custom system store with MembershipTableAssembly = \"OrleansConsulUtils\" . Refer to Consul-Deployment for more details. DynamoDB - configured as a Custom system store with MembershipTableAssembly = \"OrleansAWSUtils\" . For all liveness types the common configuration variables are defined in Globals.Liveness element: ProbeTimeout - The number of seconds to probe other silos for their liveness or for the silo to send \"I am alive\" heartbeat messages about itself. Default is 10 seconds. TableRefreshTimeout - The number of seconds to fetch updates from the membership table. Default is 60 seconds. DeathVoteExpirationTimeout - Expiration time in seconds for death vote in the membership table. Default is 120 seconds NumMissedProbesLimi t - The number of missed \"I am alive\" heartbeat messages from a silo or number of un-replied probes that lead to suspecting this silo as dead. Default is 3. NumProbedSilos - The number of silos each silo probes for liveness. Default is 3. NumVotesForDeathDeclaration - The number of non-expired votes that are needed to declare some silo as dead (should be at most NumMissedProbesLimit). Default is 2. UseLivenessGossip - Whether to use the gossip optimization to speed up spreading liveness information. Default is true. IAmAliveTablePublishTimeout - The number of seconds to periodically write in the membership table that this silo is alive. Used only for diagnostics. Default is 5 minutes. NumMissedTableIAmAliveLimit - The number of missed \"I am alive\" updates in the table from a silo that causes warning to be logged. Does not impact the liveness protocol. Default is 2. MaxJoinAttemptTime - The number of seconds to attempt to join a cluster of silos before giving up. Default is 5 minutes. ExpectedClusterSize - The expected size of a cluster. Need not be very accurate, can be an overestimate. Used to tune the exponential backoff algorithm of retries to write to Azure table. Default is 20. Design Rationale: A natural question that might be asked is why not to rely completely on Apache ZooKeeper for the cluster membership implementation, potentially by using it's out of the box support for group membership with ephemeral nodes ? Why did we bother implementing our own membership protocol? There were primarily three reasons: 1) Deployment/Hosting in the Cloud - Zookeeper is not a hosted service (at least at the time of this writing July 2015 and definitely when we first implemented this protocol in the summer of 2011 there was no version of Zookeeper running as a hosted service by any major cloud provider). It means that in the Cloud environment Orleans customers would have to deploy/run/manage their own instance of a ZK cluster. This is just yet another unnecessary burden, that we did not want to force on our customers. By using Azure Table we rely on a hosted, managed service which makes our customers lives much simpler. Basically, in the Cloud, use Cloud as a Platform, not as an Infrastructure. On the other hand, when running on premises and managing your own servers, relying on ZK as an implementation of the MembershipTable is a viable option. 2) Direct failure detection - when using ZK's group membership with ephemeral nodes the failure detection is performed between the Orleans servers (ZK clients) and ZK servers. This may not necessarily correlate with the actual network problems between Orleans servers. Our desire was that the failure detection would accurately reflect the intra-cluster state of the communication. Specifically, in our design, if an Orleans silo cannot communicate with the MembershipTable it is not considered dead and can keep working. As opposite to that, have we used ZK group membership with ephemeral nodes a disconnection from a ZK server may cause an Orleans silo (ZK client) to be declared dead, while it may actually be alive and fully functional. 3) Portability and flexibility - as part of Orleans's philosophy, we do not want to force a strong dependence on any particular technology, but rather have a flexible design where different components can be easily switched with different implementations. This is exactly the purpuse that MembershipTable abstraction serves. Acknowledgements: We would to acknowledge the contribution of Alex Kogan to the design and implementation of the first version of this protocol. This work was done as part of summer internship in Microsoft Research in the Summer of 2011. The implementation of ZooKeeper based MembershipTable was done by Shay Hazor , the implementation of SQL MembershipTable was done by Veikko Eeva , the implementation of AWS DynamoDB MembershipTable was done by Gutemberg Ribeiro and the implementation of Consul based MembershipTable was done by Paul North ."
  },
  "Documentation/deployment/service_fabric_hosting.html": {
    "href": "Documentation/deployment/service_fabric_hosting.html",
    "title": "Service Fabric Hosting | Microsoft Orleans Documentation",
    "keywords": "Service Fabric Hosting Orleans can be hosted on Service Fabric using the Microsoft.Orleans.Hosting.ServiceFabric package. Silos should be hosted as unpartitioned, stateless services since Orleans manages distribution of grains itself using fine-grained, dynamic distribution. Other hosting options (partitioned, stateful) are currently untested and unsupported. A sample which demonstrates hosting on Service Fabric is available at Samples/2.0/ServiceFabric . Hosting support is available in the Microsoft.Orleans.Hosting.ServiceFabric package. It allows an Orleans Silo to run as a Service Fabric ICommunicationListener . The Silo lifecycle follows the typical communication listener lifecycle: it is initialized via the ICommunicationListener.OpenAsync method and is gracefully terminated via the ICommunicationListener.CloseAsync method or abruptly terminated via the ICommunicationListener.Abort method. OrleansCommunicationListener provides the ICommunicationListener implementation. The recommended approach is to create the communication listener using OrleansServiceListener.CreateStateless(Action<StatelessServiceContext, ISiloHostBuilder> configure) in the Orleans.Hosting.ServiceFabric namespace. Each time the communication listener is opened, the configure delegate passed to CreateStateless is invoked to configure the new Silo. Example: Configuring Service Fabric hosting The following example demonstrates a Service Fabric StatelessService class which hosts an Orleans silo. The full sample can be found in the Samples/2.0/ServiceFabric directory of the Orleans repository. /// <summary> /// An instance of this class is created for each service instance by the Service Fabric runtime. /// </summary> internal sealed class StatelessCalculatorService : StatelessService { public StatelessCalculatorService(StatelessServiceContext context) : base(context) { } /// <summary> /// Optional override to create listeners (e.g., TCP, HTTP) for this service replica to handle /// client or user requests. /// </summary> /// <returns>A collection of listeners.</returns> protected override IEnumerable<ServiceInstanceListener> CreateServiceInstanceListeners() { // Listeners can be opened and closed multiple times over the lifetime of a service instance. // A new Orleans silo will be both created and initialized each time the listener is opened // and will be shutdown when the listener is closed. var listener = OrleansServiceListener.CreateStateless( (fabricServiceContext, builder) => { builder.Configure<ClusterOptions>(options => { // The service id is unique for the entire service over its lifetime. This is // used to identify persistent state such as reminders and grain state. options.ServiceId = fabricServiceContext.ServiceName.ToString(); // The cluster id identifies a deployed cluster. Since Service Fabric uses rolling // upgrades, the cluster id can be kept constant. This is used to identify which // silos belong to a particular cluster. options.ClusterId = \"development\"; }); // Configure clustering. Other clustering providers are available, but for the purpose // of this sample we will use Azure Storage. // TODO: Pick a clustering provider and configure it here. builder.UseAzureStorageClustering( options => options.ConnectionString = \"UseDevelopmentStorage=true\"); // Optional: configure logging. builder.ConfigureLogging(logging => logging.AddDebug()); builder.AddStartupTask<StartupTask>(); // Service Fabric manages port allocations, so update the configuration using those // ports. // Gather configuration from Service Fabric. var activation = fabricServiceContext.CodePackageActivationContext; var endpoints = activation.GetEndpoints(); // These endpoint names correspond to TCP endpoints specified in ServiceManifest.xml var siloEndpoint = endpoints[\"OrleansSiloEndpoint\"]; var gatewayEndpoint = endpoints[\"OrleansProxyEndpoint\"]; var hostname = fabricServiceContext.NodeContext.IPAddressOrFQDN; builder.ConfigureEndpoints(hostname, siloEndpoint.Port, gatewayEndpoint.Port); // Add your application assemblies. builder.ConfigureApplicationParts(parts => { parts.AddApplicationPart(typeof(CalculatorGrain).Assembly).WithReferences(); // Alternative: add all loadable assemblies in the current base path // (see AppDomain.BaseDirectory). parts.AddFromApplicationBaseDirectory(); }); }); return new[] { listener }; } /// <summary> /// This is the main entry point for your service instance. /// </summary> /// <param name=\"cancellationToken\"> /// Canceled when Service Fabric needs to shut down this service instance. /// </param> protected override async Task RunAsync(CancellationToken cancellationToken) { while (true) { cancellationToken.ThrowIfCancellationRequested(); await Task.Delay(TimeSpan.FromSeconds(10), cancellationToken); } } }"
  },
  "Documentation/grains/types_of_grains.html": {
    "href": "Documentation/grains/types_of_grains.html",
    "title": "Types of Grains | Microsoft Orleans Documentation",
    "keywords": "There are different types of grains ///TODO find page about grain types - make sure it includes stateless workers and stateful/persistent grains"
  },
  "Documentation/grains/event_sourcing/event_sourcing_configuration.html": {
    "href": "Documentation/grains/event_sourcing/event_sourcing_configuration.html",
    "title": "Configuration | Microsoft Orleans Documentation",
    "keywords": "Configuration Configuring Project References Grain Interfaces As before, interfaces depend only on the Microsoft.Orleans.Core package, because the grain interface is independent of the implementation. Grain Implementations JournaledGrains need to derive from JournaledGrain<S,E> or JournaledGrain<S> , which is defined in the Microsoft.Orleans.EventSourcing package. Log-Consistency Providers We currently include three log-consistency providers (for state storage, log storage, and custom storage). All three are contained in the Microsoft.Orleans.EventSourcing package as well. Therefore, all Journaled Grains already have access to those. For a description of what these providers do and how they differ, see Included Log-Consistency Providers . Cluster Configuration Log-consistency providers are configured just like any other Orleans providers. For example, to include all three providers (of course, you probably won't need all three), add this to the <Globals> element of the configuration file: <LogConsistencyProviders> <Provider Type=\"Orleans.EventSourcing.StateStorage.LogConsistencyProvider\" Name=\"StateStorage\" /> <Provider Type=\"Orleans.EventSourcing.LogStorage.LogConsistencyProvider\" Name=\"LogStorage\" /> <Provider Type=\"Orleans.EventSourcing.CustomStorage.LogConsistencyProvider\" Name=\"CustomStorage\" /> </LogConsistencyProviders> The same can be achieved programmatically. Assuming the project contains the Microsoft.Orleans.EventSourcing package, and config is a ClusterConfiguration object: using Orleans.Runtime.Configuration; // pick up the necessary extension methods config.AddLogStorageBasedLogConsistencyProvider(\"LogStorage\"); config.AddStateStorageBasedLogConsistencyProvider(\"StateStorage\"); config.AddCustomStorageBasedLogConsistencyProvider(\"CustomStorage\"); Grain Class Attributes Each journaled grain class must have a LogConsistencyProvider attribute to specify the log-consistency provider. Some providers additionally require a StorageProvider attribute. LogConsistencyProvider Attributes To specify the log-consistency provider, add a [LogConsistencyProvider(ProviderName=...)] attribute to the grain class, and give the name of the provider as configured by the Cluster Configuration. For example: [LogConsistencyProvider(ProviderName = \"CustomStorage\")] public class ChatGrain : JournaledGrain<XDocument, IChatEvent>, IChatGrain, ICustomStorage { ... } StorageProvider Attributes Some log-consistency providers (including LogStorage and StateStorage ) use a standard StorageProvider to communicate with storage. This provider is specified using a separate StorageProvider attribute, as follows: [LogConsistencyProvider(ProviderName = \"LogStorage\")] [StorageProvider(ProviderName = \"AzureBlobStorage\")] public class ChatGrain : JournaledGrain<XDocument, IChatEvent>, IChatGrain { ... } Default Providers It is possible to omit the LogConsistencyProvider and/or the StorageProvider attributes, if a default is specified in the configuration. This is done by using the special name Default for the respective provider. For example: <LogConsistencyProviders> <Provider Type=\"Orleans.EventSourcing.LogStorage.LogConsistencyProvider\" Name=\"Default\" /> </LogConsistencyProviders> <StorageProviders> <Provider Type=\"Orleans.Storage.MemoryStorage\" Name=\"Default\" /> </StorageProviders>"
  },
  "Documentation/grains/event_sourcing/immediate_vs_delayed_confirmation.html": {
    "href": "Documentation/grains/event_sourcing/immediate_vs_delayed_confirmation.html",
    "title": "Immediate vs. Delayed Confirmation | Microsoft Orleans Documentation",
    "keywords": "Immediate Confirmation For many applications, we want to ensure that events are confirmed immediately, so that the persisted version does not lag behind the current version in memory, and we do not risk losing the latest state if the grain should fail. We can guarantee this by following these rules: Confirm all RaiseEvent calls using ConfirmEvents before the grain method returns. Make sure tasks returned by RaiseConditionalEvent complete before the grain method returns. Avoid [Reentrant] or [AlwaysInterleave] attributes, so only one grain call can be processed at a time. If we follow these rules, it means that after an event is raised, no other grain code can execute until the event has been written to storage. Therefore, it is impossible to observe inconsistencies between the version in memory and the version in storage. While this is often exactly what we want, it also has some potential disadvantages. Potential Disadvantages if the connection to a remote cluster or to storage is temporarily interrupted , then the grain becomes unavailable: effectively, the grain cannot execute any code while it is stuck waiting to confirm the events, which can take an indefinite amount of time (the log-consistency protocol keeps retrying until storage connectivity is restored). when handling a lot of of updates to a single grain instance , confirming them one at a time can become very inefficient, i.e. have poor throughput. Delayed Confirmation To improve availability and throughput in the situations mentioned above, grains can choose to do one or both of the following: allow grain methods to raise events without waiting for confirmation. allow reentrancy, so the grain can keep processing new calls even if previous calls get stuck waiting for confirmation. This means it is possible for grain code to execute while some events are still in the process of being confirmed. The JournaledGrain API has some specific provisions to give developers precise control over how to deal with unconfirmed events that are currently \"in flight\". The following property can be examined to find out what events are currently unconfirmed: IEnumerable<EventType> UnconfirmedEvents { get; } Also, since the state returned by the State property does not include the effect of unconfirmed events, there is an alternative property StateType TentativeState { get; } which returns a \"tentative\" state, obtained from \"State\" by applying all the unconfirmed events. The tentative state is essentially a \"best guess\" at what will likely become the next confirmed state, after all unconfirmed events are confirmed. However, there is no guarantee that it actually will, because the grain may fail, or because the events may race against other events and lose, causing them to be canceled (if they are conditional) or appear at a later position in the sequence than anticipated (if they are unconditional). Concurrency Guarantees Note that Orleans turn-based scheduling (cooperative concurrency) guarantees always apply, even when using reentrancy or delayed confirmation. This means that even though several methods may be in progress, only one can be actively executing --- all others are stuck at an await, so there are never any true races caused by parallel threads. In particular, note that: The properties State , TentativeState , Version , and UnconfirmedEvents can change during the execution of a method. But such changes can only happen while stuck at an await. These guarantees assume that the user code stays within the recommended practice with respect to tasks and async/await (in particular, does not use thread pool tasks, or only uses them for code that does not call grain functionality and that are properly awaited)."
  },
  "Documentation/grains/event_sourcing/index.html": {
    "href": "Documentation/grains/event_sourcing/index.html",
    "title": "Event Sourcing Overview | Microsoft Orleans Documentation",
    "keywords": "Event Sourcing Event sourcing provides a flexible way to manage and persist grain state. An event-sourced grain has many potential advantages over a standard grain. For one, it can be used with many different storage provider configurations, and supports geo-replication across multiple clusters. Moreover, it cleanly separates the grain class from definitions of the grain state (represented by a grain state object) and grain updates (represented by event objects). The documentation is structured as follows: JournaledGrain Basics explains how to define an event-sourced grains by deriving from JournaledGrain , how to access the current state, and how to raise events that update the state. Replicated Instances explains how the event-sourcing mechanism handles replicated grain instances and ensures consistency. It discusses the possibility of racing events and conflicts, and how to address them. Immediate/Delayed Confirmation explains how delayed confirmation of events, and reentrancy, can improve availability and throughput. Notifications explains how to subscribe to notifications, allowing grains to react to new events. Event Sourcing Configuration explains how to configure projects, clusters, and log-consistency providers. Built-In Log-Consistency Providers explains how the three currently included log-consistency providers work. JournaledGrain Diagnostics explains how to monitor for connection errors, and get simple statistics. The behavior documented above is reasonably stable, as far as the JournaledGrain API is concerned. However, we expect to extend or change the list of log consistency providers soon, to more easily allow developers to plug in standard event storage systems."
  },
  "Documentation/grains/event_sourcing/journaledgrain_basics.html": {
    "href": "Documentation/grains/event_sourcing/journaledgrain_basics.html",
    "title": "JournaledGrain API | Microsoft Orleans Documentation",
    "keywords": "JournaledGrain Basics Journaled grains derive from <JournaledGrain<StateType,EventType> , with the following type parameters: The StateType represents the state of the grain. It must be a class with a public default constructor. EventType is a common supertype for all the events that can be raised for this grain, and can be any class or interface. All state and event objects should be serializable (because the log-consistency providers may need to persist them, and/or send them in notification messages). For grains whose events are POCOs (plain old C# objects), JournaledGrain<StateType> can be used as a shorthand for JournaledGrain<StateType,Object> . Reading the Grain State To read the current grain state, and determine its version number, the JournaledGrain has properties GrainState State { get; } int Version { get; } The version number is always equal to the total number of confirmed events, and the state is the result of applying all the confirmed events to the initial state. The initial state, which has version 0 (because no events have been applied to it), is determined by the default constructor of the GrainState class. Important: The application should never directly modify the object returned by State . It is meant for reading only. Rather, when the application wants to modify the state, it must do so indirectly by raising events. Raising Events Raising events is accomplished by calling the RaiseEvent function. For example, a grain representing a chat can raise a PostedEvent to indicate that a user submitted a post: RaiseEvent(new PostedEvent() { Guid = guid, User = user, Text = text, Timestamp = DateTime.UtcNow }); Note that RaiseEvent kicks off a write to storage access, but does not wait for the write to complete. For many applications, it is important to wait until we have confirmation that the event has been persisted. In that case, we always follow up by waiting for ConfirmEvents : RaiseEvent(new DepositTransaction() { DepositAmount = amount, Description = description }); await ConfirmEvents(); Note that even if you don't explicitly call ConfirmEvents , the events will eventually be confirmed - it happens automatically in the background. State Transition Methods The runtime updates the grain state automatically whenever events are raised. There is no need for the application to explicitly update the state after raising an event. However, the application still has to provide the code that specifies how to update the state in response to an event. This can be done in two ways. (a) The GrainState class can implement one or more Apply methods on the StateType . Typically, one would create multiple overloads, and the closest match is chosen for the runtime type of the event: class GrainState { Apply(E1 @event) { // code that updates the state } Apply(E2 @event) { // code that updates the state } } (b) The grain can override the TransitionState function: protected override void TransitionState(State state, EventType @event) { // code that updates the state } The transition methods are assumed to have no side effects other than modifying the state object, and should be deterministic (otherwise, the effects are unpredictable). If the transition code throws an exception, that exception is caught and included in a warning in the Orleans log, issued by the log-consistency provider. When, exactly, the runtime calls the transition methods depends on the chosen log consistency provider and its configuration. It is best for applications not to rely on a particular timing, except when specifically guaranteed by the log consistency provider. Some providers, such as the LogStorage log-consistency provider, replay the event sequence every time the grain is loaded. Therefore, as long as the event objects can still be properly deserialized from storage, it is possibly to radically modify the GrainState class and the transition methods. But for other providers, such as the StateStorage log-consistency provider, only the GrainState object is persisted, so developers must ensure that it can be deserialized correctly when read from storage. Raising Multiple Events It is possible to make multiple calls to RaiseEvent before calling ConfirmEvents: RaiseEvent(e1); RaiseEvent(e2); await ConfirmEvents(); However, this is likely to cause two successive storage accesses, and it incurs a risk that the grain fails after writing only the first event. Thus, it is usually better to raise multiple events at once, using RaiseEvents(IEnumerable<EventType> events) This guarantees that the given sequence of events is written to storage atomically. Note that since the version number always matches the length of the event sequence, raising multiple events increases the version number by more than one at a time. Retrieving the Event Sequence The following method from the base JournaledGrain class allows the application to retrieve a specified segment of the sequence of all confirmed events: Task<IReadOnlyList<EventType>> RetrieveConfirmedEvents(int fromVersion, int toVersion) However, it is not supported by all log consistency providers. If not supported, or if the specified segment of the sequence is no longer available, a NotSupportedException is thrown. To retrieve all events up to the latest confirmed version, one would call await RetrieveConfirmedEvents(0, Version); Only confirmed events can be retrieved: an exception is thrown if toVersion is larger than the current value of the property Version . Since confirmed events never change, there are no races to worry about, even in the presence of multiple instances or delayed confirmation. However, in such situations, it is possible that the value of the property Version is larger by the time the await resumes than at the time RetrieveConfirmedEvents is called, so it may be advisable to save its value in a variable. See also the section on Concurrency Guarantees."
  },
  "Documentation/grains/event_sourcing/journaledgrain_diagnostics.html": {
    "href": "Documentation/grains/event_sourcing/journaledgrain_diagnostics.html",
    "title": "JournaledGrain Diagnostics | Microsoft Orleans Documentation",
    "keywords": "JournaledGrain Diagnostics Monitoring Connection Errors By design, log consistency providers are resilient under connection errors (including both connections to storage, and connections between clusters). But just tolerating errors is not enough, as applications usually need to monitor any such issues, and bring them to the attention of an operator if they are serious. JournaledGrain subclasses can override the following methods to receive notifiations when there are connection errors observed, and when those errors are resolved: protected override void OnConnectionIssue(ConnectionIssue issue) { /// handle the observed error described by issue } protected override void OnConnectionIssueResolved(ConnectionIssue issue) { /// handle the resolution of a previously reported issue } ConnectionIssue is an abstract class, with several common fields describing the issue, including how many times it has been observed since the last time connection was successful. The actual type of connection issue is defined by subclasses. Connection issues are categorized into types, such as PrimaryOperationFailed or NotificationFailed , and sometimes have extra keys (such as RemoteCluster ) that further narrow the category. If the same category of issue happens several times (for example, we keep getting a NotificationFailed that targets the same RemoteCluster ), it is reported each time by OnConnectionIssue . Once this category of issue is resolved (for example, we are finally successful with sending a notification to this RemoteCluster ), then OnConnectionIssueResolved is called once, with the same issue object that was last reported by OnConnectionIssue . Connection issues, and their resolution, for independent categories, are reported independently. Simple Statistics We currently offer a simple support for basic statistics (in the future, we will probably replace this with a more standard telemetry mechanism). Statistics collection can be enabled or disabled for a JournaledGrain by calling void EnableStatsCollection() void DisableStatsCollection() The statistics can be retrieved by calling LogConsistencyStatistics GetStats()"
  },
  "Documentation/grains/event_sourcing/log_consistency_providers.html": {
    "href": "Documentation/grains/event_sourcing/log_consistency_providers.html",
    "title": "Log-Consistency Providers | Microsoft Orleans Documentation",
    "keywords": "Built-In Log-Consistency Providers The Microsoft.Orleans.EventSourcing package includes several log-consistency providers that cover basic scenarios suitable to get started, and allow some extensibility. Orleans.EventSourcing. StateStorage .LogConsistencyProvider This provider stores grain state snapshots , using a standard storage provider that can be configured independently. The data that is kept in storage is an object that contains both the grain state (as specified by the first type parameter to JournaledGrain ) and some meta-data (the version number, and a special tag that is used to avoid duplication of events when storage accesses fail). Since the entire grain state is read/written every time we access storage, this provider is not suitable for objects whose grain state is very large. This provider does not support RetrieveConfirmedEvents : it cannot retrieve the events from storage because the events are not persisted. Orleans.EventSourcing. LogStorage .LogConsistencyProvider This provider stores the complete event sequence as a single object , using a standard storage provider that can be configured independently. The data that is kept in storage is an object that contains a List<EventType> object , and some meta-data (a special tag that is used to avoid duplication of events when storage accesses fail). This provider does support RetrieveConfirmedEvents . All events are always available and kept in memory. Since the whole event sequence is read/written every time we access storage, this provider is not suitable for use in production , unless the event sequences are guaranteed to remain pretty short. The main purpose of this provider is to illustrate the semantics of the event sourcing, and for samples/testing environments. Orleans.EventSourcing. CustomStorage .LogConsistencyProvider This provider allows the developer to plug in their own storage interface, which is then called by the conistency protocol at appropriate times. This provider does not make specific assumptions about whether what is stored are state snapshots or events - the programmer assumes control over that choice (and may store either or both). To use this provider, a grain must derive from JournaledGrain<StateType,EventType> , as before, but additionally must also implement the following interface: public interface ICustomStorageInterface<StateType, EventType> { Task<KeyValuePair<int,StateType>> ReadStateFromStorage(); Task<bool> ApplyUpdatesToStorage(IReadOnlyList<EventType> updates, int expectedversion); } The consistency provider expects these to behave a certain way. Programmers should be aware that: The first method, ReadStateFromStorage , is expected to return both the version, and the state read. If there is nothing stored yet, it should return zero for the version and a state that matches corresponds to the default constructor for StateType . ApplyUpdatesToStorage must return false if the expected version does not match the actual version (this is analogous to an e-tag check). If ApplyUpdatesToStorage fails with an exception, the consistency provider retries. This means some events could be duplicated if such an exception is thrown, but the event was actually persisted. The developer is responsible to make sure this is safe: e.g. either avoid this case by not throwing an exception, or ensure duplicated events are harmless for the application logic, or add some extra mechanism to filter duplicates. This provider does not support RetrieveConfirmedEvents . Of course, since the developer controls the storage interface anyway, they don't need to call this in the first place, but can implement their own event retrieval."
  },
  "Documentation/grains/event_sourcing/notifications.html": {
    "href": "Documentation/grains/event_sourcing/notifications.html",
    "title": "Notifications | Microsoft Orleans Documentation",
    "keywords": "Notifications It is often convenient to have the ability to react to state changes. All callbacks are subject to Orleans' turn-based guarantees; see also the section on Concurrency Guarantees. Tracking Confirmed State To be notified of any changes to the confirmed state, JournaledGrain subclasses can override this method: protected override void OnStateChanged() { // read state and/or event log and take appropriate action } OnStateChanged is called whenever the confirmed state is updated, i.e. the version number increases. This can happen when A newer version of the state was loaded from storage. An event that was raised by this instance has been successfully written to storage. A notification message was received from some other instance. Note that since all grains initially have version zero, until the initial load from storage completes, this means that OnStateChanged is called whenever the initial load completes with a version larger than zero. Tracking Tentative State To be notified of any changes to the tentative state, JournaledGrain subclasses can override this method: protected override void OnTentativeStateChanged() { // read state and/or events and take appropriate action } OnTentativeStateChanged is called whenever the tentative state changes, i.e. if the combined sequence (ConfirmedEvents + UnconfirmedEvents) changes. In particular, a callback to OnTentativeStateChanged() always happens during RaiseEvent ."
  },
  "Documentation/resources/Contributing.html": {
    "href": "Documentation/resources/Contributing.html",
    "title": "Contributing to Orleans | Microsoft Orleans Documentation",
    "keywords": "Contributing to Orleans Some notes and guidelines for developers wanting to contribute to Orleans. Contributing To This Project Here are some pointers for anyone looking for mini-features and work items that would make a positive contribution to Orleans. These are just a few ideas, so if you think of something else that would be useful, then spin up a discussion thread on GitHub to discuss the proposal, and go for it! Orleans GitHub Repository Pull requests are always welcome! Ideas for Contributions Intern and Student Projects Some suggestions for possible intern / student projects. Documentation Guidelines A style guide for writing documentation for this site. Code Contributions: This project uses the same contribution process as the other DotNet projects on GitHub. DotNet Project Contribution Guidelines Guidelines and workflow for contributing to DotNet projects on GitHub. DotNet CLA Contribution License Agreement for DotNet projects on GitHub. .NET Framework Design Guidelines Some basic API design rules, coding standards, and style guide for .NET Framework APIs. Coding Standards and Conventions We try not to be too OCD about coding style wars, but in case of disputes we do fall back to the core principles in the two \".NET Coding Standards\" books used by the other DotNet OSS projects on GitHub: C# Coding Style Guide .NET Framework Design Guidelines There are lots of other useful documents on the .NET CoreCLR and .NET Core Framework documentation sites which are worth reading, although most experienced C# developers will probably have picked up many of those best-practices by osmosis, particularly around performance and memory management. Source Code Organization Orleans has not religiously followed a \"One Class Per File\" rule, but instead we have tried to use pragmatic judgment to maximize the change of \"code understand-ability\" for developers on the team. If lots of small-ish classes share a \"common theme\" and/or are always dealt with together, then it is OK to place those into one source code file in most cases. See for example the various \"log consumer\" classes were originally placed in single source file, as they represented a single unit of code comprehension. As a corollary, it is much easier to find the source code for a class if it is in a file with the same name as the class [similar to Java file naming rules], so there is a tension and value judgment here between code find-ability and minimizing / constraining the number of projects in a solution and files within a project [which both have direct impact on the Visual Studio \"Opening\" and \"Building\" times for large projects]. Code search tools in VS and ReSharper definitely help here. Dependencies and Inter-Project References One topic that we are very strict about is around dependency references between components and sub-systems. Component / Project References References between projects in a solution must always use \" Project References \" rather than \" DLL References \" to ensure that component build relationships are known to the build tools. Right : <ProjectReference Include=\"..\\Orleans\\Orleans.csproj\"> <Project>{BC1BD60C-E7D8-4452-A21C-290AEC8E2E74}</Project> <Name>Orleans</Name> </ProjectReference> Wrong : <Reference Include=\"Orleans\" > <HintPath>..\\Orleans\\bin\\Debug\\Orleans.dll</HintPath> </Reference> In order to help ensure we keep inter-project references clean, then on the build servers [and local Build.cmd script] we deliberately use side-by-side input .\\src and output .\\Binaries directories rather than the more normal in-place build directory structure (eg. [PROJ]\\bin\\Release ) used by VS on local dev machines. Unified Component Versions We use the same unified versions of external component throughout the Orleans code base, and so should never need to add bindingRedirect entries in App.config files. Also, in general it should almost never be necessary to have Private=True elements in Orleans project files, except to override a conflict with a Windows / VS \"system\" component. Some package management tools can occasionally get confused when making version changes, and sometimes think that we are using multiple versions of the same assembly within a solution, which of course we never do. We long for the day when package management tools for .NET can make version changes transactionally! Until then, it is occasionally necessary to \"fix\" the misguided actions of some .NET package management tools by hand-editing the .csproj files (they are just XML text files) back to sanity and/or using the \"Discard Edited Line\" functions that most good Git tools such as Atlassian SourceTree provide. Using \"sort\" references and unified component versions avoids creating brittle links between Orleans run-time and/or external components, and has proved highly effective in the last several years at reducing stress levels for the Orleans Team during important deployment milestones. :)"
  },
  "Documentation/resources/Documentation-Guidelines.html": {
    "href": "Documentation/resources/Documentation-Guidelines.html",
    "title": "Documentation Guidelines | Microsoft Orleans Documentation",
    "keywords": "Documentation Guidelines The Orleans documentation is built in Markdown . We use a few simple conventions to ensure a homogeneous style throughout the full set of documents. These standards are being introduced. If you have issues with these guidelines then raise an issue or a Pull Request. If you find documentation that fails to meet the guidelines, then make a fix and submit a pull request. Also if you are using windows 10 you can go to the store and find free MarkDown editors like this Structure Language The documentation will follow US-English spelling. Desktop tools like http://markdownpad.com have spell checking features. Paragraph structure Each sentence should be written on a single line, and only one sentence per line. This makes merging changes easier and also helps identify verbose language. Paragraphs in Markdown are just one or more lines of consecutive text followed by one or more blank lines. Headings Heading should be used to structure a document. Avoid using other emphasis features like ALLCAPS, Italics or bold to identify a new topic. Using a header is not only more consistent, but also allows linking to the header. Footers At the end of a page, it is helpful to link to the next logical page in the documentation. If the page is the last in a sub-section then linking back to the index page is useful. Styles Code formatting Blocks of example code should be formatted with the triple back tick format followed by the language ``` csharp [StorageProvider(ProviderName=\"store1\")] public class MyGrain<IMyGrainState> ... { ... } ``` Which will render as [StorageProvider(ProviderName=\"store1\")] public class MyGrain<IMyGrainState> ... { ... } Inline code should be marked with a single backtick (`). This include references to: type names e.g. Task<T> variable names e.g. game namespaces e.g. Orleans.Storage.AzureTableStorage If showing text that is an output (e.g. text file content or console output) you can either use the triple back tick without specifying a language or you can indent the content. For example: 1 said: Welcome to my team! 0 said: Thanks! 1 said: Thanks! 0 said: Thanks! File names and paths When referencing a filename, directory/folder or URI then use standard italics to format. This can be done by surrounding the string with either with a single asterisk ( * ) or a single underscore ( _ ) Examples: OrleansRuntimeInterfaces.dll C:\\Binaries ../src/Grain.cs Tables Markdown supports tabular data . Tables could be used to structure data so that is is easily consumable for the reader. Suffix Unit ms millisecond(s) s second(s) m minute(s) Links When referencing another concept, the concept should be linked to. Forward and backward references with in a page can be linked to via the header. e.g. link back to Structure Links to other documents can either link to the page, or a sub-section/header within the page. External links should be exposed as a the full link e.g. https://github.com/dotnet/roslyn Contribution The Orleans documentation is managed as Markdown files in a Git repository hosted on GitHub in the gh-pages branch . See the GitHub Pages documentation on how to use the gh-pages branch convention for \"Project site\" documents."
  },
  "Documentation/resources/Ideas-for-Contributions.html": {
    "href": "Documentation/resources/Ideas-for-Contributions.html",
    "title": "Ideas for Contributions | Microsoft Orleans Documentation",
    "keywords": "Ideas for Contributions These are some of the ideas for contributing to Orleans. Just an initial list for consideration, meant to be a live document. If you are interested in any of these or one that is not listed, create an issue to discuss it. We roughly put them into 3 size categories based on our gut feel, which may be wrong: Small - hours of work Medium - couple of days of work Large - big projects, multiple days up to weeks of work Project template/wizard for Azure deployment [Medium/Large] Worker role for silos (in our experience it is better to star a silo as a standalone process and wait on the process handle in the worker roles code) Worker/web role for frontend clients Configuration of diagnostics, ETW tracing, etc. Try Azure SDK plug-in as suggested here by @richorama. Cluster monitoring dashboard [Medium] https://github.com/OrleansContrib/OrleansMonitor may be a good start Proper support for F# [Medium/Large] See Issue #38 Orleans backplane for SignalR [Medium] See Issue #73 Port Orleans to coreclr [Medium] See Issue #368 Some APIs from the full .NET got deprecated in coreclr, mainly around files and reflection, but at large the porting effort shouldn't be too big. This will allow to run Orleans efficiently cross platform. Secure communication between silos and clients Add support for secure communication mode with certificates used for encryption of messages."
  },
  "Documentation/tutorials_and_samples/Adventure.html": {
    "href": "Documentation/tutorials_and_samples/Adventure.html",
    "title": "Adventure | Microsoft Orleans Documentation",
    "keywords": "Adventure A simple multiplayer text adventure game inspired by old-fashioned, text-based adventure games. Instructions Open OrleansAdventure.sln in Visual Studio. Start the 'AdventureSetup' project. Once AdventureSetup is running, start the 'AdventureClient' project. You will then be prompted to enter your name on the command line. Enter it and begin the game. Overview The AdventureSetup program reads a game description (\"map\") from AdventureConfig.txt. It sets up a series of \"rooms\" e.g. forest, beach, caves, a clearing etc . These locations are connected to other rooms to model the places and layout of the game. The sample configuration describes only a handful of locations. Rooms can contain \"things\" such as keys, swords etc. The AdventureClient program sets up your player and provides a simple text based user interface to allow you to play the game. You can move around rooms and interact with things using a simple command language, saying things such as \"go north\" or \"take brass key\". Why Orleans? Orleans allows the game to be described via very simple C# code while allowing it to scale to a massive multiplayer game. For this motivation to be meaningful, the labyrinth of rooms needs to be very large and need to support a large number of simultaneous players. One value of Orleans is that the service can be designed for growth, the overhead of running it at a small scale is not significant, and you can remain confident that it will scale if the need arises. How is it modeled? Player and Rooms are modeled as grains. These grains allow us to distribute the game with each grain modelling state and functionality. Things such as keys are modeled as plain old objects - they are really just simple immutable data structures that move around rooms and among players; they don't need to be grains. Possible improvements Make the map much, much, bigger Make the brass key unlock something Allow players to message each other Make eating food and drinking water possible and meaningful"
  },
  "Documentation/index.html": {
    "href": "Documentation/index.html",
    "title": "Introduction | Microsoft Orleans Documentation",
    "keywords": "This is the overview page about Orleans ///TODO: create an INDEX section with every document in this project listed alphabetically and/or arranged by subject. This documentation is for the 2.0 release Orleans 2.0 is a significant overhaul from the 1.x versions. The 2.0 release is cross-platform via .NET Standard 2.0 and .NET Core . It has a more modular and flexible structure due to heavy use of Dependency Injection, a modern configuration API, and a revamped provider model. Orleans 2.0 still supports most of the 1.x API via optional legacy packages. Orleans 1.5 will continue to be supported for some time, but 2.0 is where all the investments are going. For 1.5 Documentation and Tutorials, refer to the respective sections that are snapshots of the documentation as of the 2.0 release. Introduction Orleans is a framework that provides a straightforward approach to building distributed high-scale computing applications, without the need to learn and apply complex concurrency or other scaling patterns. Background Cloud applications and services are inherently parallel and distributed. They are also interactive and dynamic; often requiring near real time direct interactions between cloud entities. Such applications are very difficult to build today. The development process demands expert level programmers and typically requires expensive iterations of the design and the architecture, as the workload grows. Most of todays high scale properties are built as a composition of stateless n-tier services with most of application logic residing in the middle tier. While the model allows to scale out by adding more servers to the middle tier, it is constrained by the performance and scalability of the storage layer because most requests coming to the middle tier from the frontend web servers require one or more reads from storage, and updates are even more complicated and prone to concurrency issues and conflicts due to lack of coordination between the middle tier servers. It often requires caching in the stateless layer to get acceptable performance, adding complexity and introducing cache consistency issues. The other problem with the stateless n-tier model is that it doesn't support well horizontal communications between individual application entities exposed by the middle tier, which makes it hard to implement complex business logic with multiple entities performing individual operations as part of processing a request. Orleans as a Stateful Middle Tier Orleans provides an intuitive way of building a stateful middle tier, where various business logic entities appear as sea of isolated globally addressable .NET objects (grains) of different application defined types distributed across a cluster of servers (silos). A grain type is a simple .NET class that implements one or more application defined grain interfaces. Individual grains are instances of application defined grain classes that get automatically created by the Orleans runtime on servers on an as-needed basis to handle requests for those grains. Grains naturally map to most application entities, such as users, devices, sessions, inventories, orders, etc., which makes it very easy to build business logic that is object-oriented but scales transparently across a cluster of servers. Each grain has a stable logical identity (key) within its grain type chosen by the application logic, for example, user email or device ID or inventory SKU code. Orleans guarantees single-threaded execution of each individual grain, hence protecting the application logic from perils of concurrency and races. In the world of microservices, Orleans is used as a framework for implementing a microservice that can be deployed and managed by a microservices deployment/management solution of developer's choice. Grain Lifecycle Grain can have persistent state in storage or in-memory state or a combination of both. Any grain can be called by any other grain or by a frontend (client) by using the target grain's logical identity without the need to ever create or instantiate the target grain. The Orleans programming model makes grains appear as if they are in memory the whole time. In reality, a grain goes through the lifecycle from existing only as its persisted state in storage to being instantiated in memory to being removed from memory. The Orleans runtime behind the scene instantiates (activates) grains when there's work for them to do, and removes them from memory (deactivates) to reclaim hardware resources when they are idle for too long. This grain lifecycle management work of the runtime is transparent to the application code, and liberates it from the complicated task of distributed resource management. Application logic can be written with the whole \"address space\" of grains available to it without the need to have hardware resources to keep all grains in memory at the same time, conceptually similar to how virtual memory works in operating systems. In addition, the virtual nature of grains allows Orleans to handle server failures mostly transparently to the application logic because grains that were executing on a failed server get automatically re-instantiated on other servers in the cluster once the failure is detected. Virtual Actors Implementation of Orleans is based on the Actor Model that's been around since 1970s. However, unlike actors in more traditional actor systems such as Erlang or Akka, Orleans Grains are virtual actors. The biggest difference is that physical instantiations of grains are completely abstracted away and are automatically managed by the Orleans runtime. The Virtual Actor Model is much more suitable for high-scale dynamic workloads like cloud services and is the major innovation of Orleans. You can read more details in the Technical Report on Orleans. Origin of Orleans Orleans was created at Microsoft Research and designed for use in the cloud . Since 2011, it has been used extensively in the cloud and on premises by several Microsoft product groups, most notably by game studios, such as 343 Industries and The Coalition as a platform for cloud services behind Halo 4/5 and Gears of War 4, as well as by a number of other companies. Orleans was open-sourced in January 2015, and attracted many developers that formed one of the most vibrant open source communities in the .NET ecosystem . In an active collaboration between the developer community and the Orleans team at Microsoft, features are added and improved on a daily basis. Microsoft Research continues to partner with the Orleans team to bring new major features, such as geo-distribution , indexing , and distributed transactions , that are pushing the state of the art. Orleans has become the framework of choice for building distributed systems and cloud services for many .NET developers."
  },
  "Documentation/clusters_and_clients/heterogeneous_silos.html": {
    "href": "Documentation/clusters_and_clients/heterogeneous_silos.html",
    "title": "Heterogeneous silos | Microsoft Orleans Documentation",
    "keywords": "Heterogeneous silos Overview On a given cluster, silos can support a different set of grain types: In this example the cluster supports grains of type A , B , C , D , E : Grain types A and B can be placed on Silo 1 and 2. Grain type C can be placed on Silo 1, 2 or 3. Grain type D can be only placed on Silo 3 Grain Type E can be only placed on Silo 4. All silos should reference interfaces of all grain types of the cluster, but grain classes should only be referenced by the silos that will host them. The client does not know which silo supports a given Grain Type. A given Grain Type implementation must be the same on each silo that supports it. The following scenario is NOT valid: On Silo 1 and 2: public class C: Grain, IMyGrainInterface { public Task SomeMethod() {  } } On Silo 3 public class C: Grain, IMyGrainInterface, IMyOtherGrainInterface { public Task SomeMethod() {  } public Task SomeOtherMethod() {  } } Configuration No configuration is needed, you can deploy different binaries on each silo in your cluster. However, if necessary, you can change the interval that silos and clients check for changes in types supported with the property TypeMapRefreshInterval from TypeManagementOptions For testing purposes, you can use the property ExcludedGrainTypes in GrainClassOptions , which is a list names of the types you want to exclude on the silos. Limitations Connected clients will not be notified if the set of supported Grain Types changed. In the previous example: If Silo 4 leaves the cluster, the client will still try to make calls to grain of type E . It will fail at runtime with a OrleansException. If the client was connected to the cluster before Silo 4 joined it, the client will not be able to make calls to grain of type E . It will fail will a ArgumentException Stateless grains are not supported: all silos in the cluster must support the same set of stateless grains."
  },
  "Documentation/clusters_and_clients/index.html": {
    "href": "Documentation/clusters_and_clients/index.html",
    "title": "Clusters and Clients | Microsoft Orleans Documentation",
    "keywords": "This is the overview page about Clusters and Clients."
  },
  "Documentation/clusters_and_clients/configuration_guide/client_configuration.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/client_configuration.html",
    "title": "Client Configuration | Microsoft Orleans Documentation",
    "keywords": "Note If you just want to start a local silo and a local client for development purpose, look at the Local Development Configuration page. Client Configuration A client for connecting to a cluster of silos and sending requests to grains is configured programmatically via a ClientBuilder and a number of supplemental option classes. Like silo options, client option classes follow the ASP.NET Options . There are several key aspects of client configuration: Orleans clustering information Clustering provider Application parts Example of a client configuration: var client = new ClientBuilder() // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"MyAwesomeOrleansService\"; }) // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) // Application parts: just reference one of the grain interfaces that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IValueGrain).Assembly)) .Build(); Let's breakdown the steps used in this sample: Orleans clustering information [...] // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"orleans-docker\"; options.ServiceId = \"AspNetSampleApp\"; }) [...] Here we set two things: the ClusterId to \"my-first-cluster\" : this is a unique ID for the Orleans cluster. All clients and silo that uses this ID will be able to directly talk to each other. Some will choose to use a different ClusterId for each deployments for example. the ServiceId to \"AspNetSampleApp\" : this is a unique ID for your application, that will be used by some provider (for example for persistence providers). This ID should be stable (not change) accross deployments . Clustering provider [...] // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) [...] The client will discover all gateway available in the cluster using this provider. Several providers are available, here in this sample we use the Azure Table provider. To get more detail, look in the matching section in the Server Configuration page. Application parts [...] // Application parts: just reference one of the grain interfaces that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IValueGrain).Assembly)).WithReferences()) [...]; To get more detail, look in the matching section in the Server Configuration page."
  },
  "Documentation/clusters_and_clients/configuration_guide/configuring_ADO.NET_providers.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/configuring_ADO.NET_providers.html",
    "title": "Configuring ADO.NET Providers | Microsoft Orleans Documentation",
    "keywords": "Configuring ADO.NET Providers Any reliable deployment of Orleans requires using persistent storage to keep system state, specifically Orleans cluster membership table and reminders. One of the available options is using a SQL database via the ADO.NET providers. In order to use ADO.NET for persistence, clustering or reminders, one needs to configure the ADO.NET providers as part of the silo configuration, and, in case of clustering, also as part of the client configurations. The silo configuration code should look like this: var siloHostBuilder = new SiloHostBuilder(); var invariant = \"System.Data.SqlClient\"; // for Microsoft SQL Server var connectionString = \"Data Source=(localdb)\\MSSQLLocalDB;Initial Catalog=Orleans;Integrated Security=True;Pooling=False;Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\"; //use AdoNet for clustering siloHostBuilder.UseAdoNetClustering(options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); //use AdoNet for reminder service siloHostBuilder.UseAdoNetReminderService(options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); //use AdoNet for Persistence siloHostBuilder.AddAdoNetGrainStorage(\"GrainStorageForTest\", options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); The client configuration code should look like this: var siloHostBuilder = new SiloHostBuilder(); var invariant = \"System.Data.SqlClient\"; var connectionString = \"Data Source=(localdb)\\MSSQLLocalDB;Initial Catalog=Orleans;Integrated Security=True;Pooling=False;Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\"; //use AdoNet for clustering siloHostBuilder.UseAdoNetClustering(options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); Where the ConnectionString is set to a valid AdoNet Server connection string. In order to use ADO.NET providers for persistence, reminders or clustering, there are scripts for creating database artifacts, to which all servers that will be hosting Orleans silos need to have access. Lack of access to the target database is a typical mistake we see developers making. The scripts will be copied to project directory \\OrleansAdoNetContent where each supported ADO.NET extensions has its own directory, after you install or do a nuget restore on the AdoNet extension nugets. We split AdoNet nugets into per feature nugets: Microsoft.Orleans.Clustering.AdoNet for clustering, Microsoft.Orleans.Persistence.AdoNet for persistence and Microsoft.Orleans.Reminders.AdoNet for reminders."
  },
  "Documentation/clusters_and_clients/configuration_guide/local_development_configuration.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/local_development_configuration.html",
    "title": "Local development configuration | Microsoft Orleans Documentation",
    "keywords": "Local development configuration For a working sample application that targets Orleans 2.0 see: https://github.com/dotnet/orleans/tree/master/Samples/2.0/HelloWorld The sample hosts the client and the silo in .NET Core console applications that work in different platforms, but the same can be done with .NET Framework 4.6.1+ console applications (that work only on Windows). Silo configuration For local development, please refer to the below example of how to configure a silo for that case. It configures and starts a silo listening on `loopback' address and 11111 and 30000 as silo and gateway ports respectively. Add the Microsoft.Orleans.Server NuGet meta-package to the project. After you get comfortable with the API, you can pick and choose which exact packages included in Microsoft.Orleans.Server you actually need, and reference them instead. PM> Install-Package Microsoft.Orleans.Server You need to configure ClusterOptions via ISiloBuilder.Configure method, specify that you want DevelopmentClustering as your clustering choice with this silo being the primary, and then configure silo endpoints. ConfigureApplicationParts call explicitly adds the assembly with grain classes to the application setup. It also adds any referenced assembly due to the WithReferences extension. After these steps are completed, the silo host gets built and the silo gets started. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for hosting a silo, as well as a .NET Core console application. Here is an example of how a local silo can be started: public class Program { public static async Task Main(string[] args) { try { var host = await StartSilo(); Console.WriteLine(\"Press Enter to terminate...\"); Console.ReadLine(); await host.StopAsync(); return; } catch (Exception ex) { Console.WriteLine(ex); return; } } private static async Task<ISiloHost> StartSilo() { var builder = new SiloHostBuilder() // Use localhost clustering for a single local silo .UseLocalhostClustering() // Configure ClusterId and ServiceId .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"MyAwesomeService\"; }) // Configure connectivity .Configure<EndpointOptions>(options => options.AdvertisedIPAddress = IPAddress.Loopback) // Configure logging with any logging framework that supports Microsoft.Extensions.Logging. // In this particular case it logs using the Microsoft.Extensions.Logging.Console package. .ConfigureLogging(logging => logging.AddConsole()); var host = builder.Build(); await host.StartAsync(); return host; } } Client configuration For local development, please refer to the below example of how to configure a client for that case. It configures a client that would connect to a loopback silo. Add the Microsoft.Orleans.Client NuGet meta-package to the project. After you get comfortable with the API, you can pick and choose which exact packages included in Microsoft.Orleans.Client you actually need, and reference them instead. PM> Install-Package Microsoft.Orleans.Client You need to configure ClientBuilder with a cluster ID that matches the one you specified for local silo and specify static clustering as your clustering choice pointing it to the gateway port of the silo ConfigureApplicationParts call explicitly adds the assembly with grain interfaces to the application setup. After these steps are completed, we can build the client and Connect() method on it to connect to the cluster. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for running a client or reuse the console application project you created for hosting a silo. Here is an example of how a client can connect to a local silo: client = new ClientBuilder() // Use localhost clustering for a single local silo .UseLocalhostClustering() // Configure ClusterId and ServiceId .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"MyAwesomeService\"; }) .ConfigureLogging(logging => logging.AddConsole()) var client = builder.Build(); await client.Connect();"
  },
  "Documentation/clusters_and_clients/configuration_guide/serialization.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/serialization.html",
    "title": "Serialization and Writing Custom Serializers | Microsoft Orleans Documentation",
    "keywords": "Serialization and Writing Custom Serializers Orleans has an advanced and extensible serialization framework. Orleans serializes data types passed in grain request and response messages as well as grain persistent state objects. As part of this framework, Orleans automatically generates serialization code for those data types. In addition to generating a more efficient serialization/deserialization for types that are already .NET-serializable, Orleans also tries to generate serializers for types used in grain interfaces that are not .NET-serializable. The framework also includes a set of efficient built-in serializers for frequently used types: lists, dictionaries, strings, primitives, arrays, etc. There are 2 important features of Orleans's serializer that set it apart from a lot of other third party serialization frameworks: dynamic types/arbitrary polymorphism and object identity. Dynamic types and arbitrary polymorphism - Orleans does not put any restrictions on the types that can be passed in grain calls and maintains the dynamic nature of the actual data type. That means, for example, that if the method in the grain interfaces is declared to accept IDictionary but at runtime the sender passes SortedDictionary , the receiver will indeed get SortedDictionary (although the \"static contract\"/grain interface did not specify this behaviour). Maintaining Object identity - if the same object is passed multiple types in the arguments of a grain call or is indirectly pointed more than once from the arguments, Orleans will serialize it only once. At the receiver side Orleans will restore all references correctly, so that two pointers to the same object still point to the same object after deserialization as well. Object identity is important to preserve in scenarios like the following. Imagine actor A is sending a dictionary with 100 entries to actor B, and 10 of the keys in the dictionary point to the same object, obj, on A's side. Without preserving object identity, B would receive a dictionary of 100 entries with those 10 keys pointing to 10 different clones of obj. With object identity preserved, the dictionary on B's side looks exactly like on A's side with those 10 keys pointing to a single object obj. The above two behaviours are provided by the standard .NET binary serializer and it was therefore important for us to support this standard and familiar behaviour in Orleans as well. Generated Serializers Orleans uses the following rules to decide which serializers to generate. The rules are: 1) Scan all types in all assemblies which reference the core Orleans library. 2) Out of those assemblies: generate serializers for types that are directly referenced in grain interfaces method signatures or state class signature or for any type that is marked with [Serializable] attribute. 3) In addition, a grain interface or implementation project can point to arbitrary types for serialization generation by adding a [KnownType] or [KnownAssembly] assembly level attributes to tell code generator to generate serializers for a specific types or all eligible types within an assembly. Serialization Providers Orleans supports integration with third-party serializers using a provider model. This requires an implementation of the IExternalSerializer type described in the custom serialization section of this document. Integrations for some common serializers are maintained alongside Orleans, for example: Protocol Buffers : Orleans.Serialization.ProtobufSerializer from the Microsoft.Orleans.OrleansGoogleUtils NuGet package. Bond : Orleans.Serialization.BondSerializer from the Microsoft.Orleans.Serialization.Bond NuGet package. Newtonsoft.Json AKA Json.NET : Orleans.Serialization.OrleansJsonSerializer from the core Orleans library. Custom implementation of IExternalSerializer is described in the Writing Custom Serializers section below. Configuration It is important to ensure that serialization configuration is identical on all clients and silos. If configurations are not consistent, serialization errors may occur. Serialization providers, which implement IExternalSerializer , can be specified using the SerializationProviders property of ClientConfiguration and GlobalConfiguration in code: var cfg = new ClientConfiguration(); cfg.SerializationProviders.Add(typeof(FantasticSerializer).GetTypeInfo()); var cfg = new GlobalConfiguration(); cfg.SerializationProviders.Add(typeof(FantasticSerializer).GetTypeInfo()); Alternatively, they can be specified in XML configuration under the <SerializationProviders /> property of <Messaging> : <Messaging> <SerializationProviders> <Provider type=\"GreatCompany.FantasticSerializer, GreatCompany.SerializerAssembly\"/> </SerializationProviders> </Messaging> In both cases, multiple providers can be configured. The collection is ordered, meaning that if a provider which can serialize types A and B is specified before a provider which can only serialize type B , then the latter provider will not be used. Writing Custom Serializers In addition to automatic serialization generation, application code can provide custom serialization for types it chooses. Orleans recommends using the automatic serialization generation for the majority of your application types and only write custom serializers in rare cases when you believe it is possible to get improved performance by hand-coding serializers. This note describes how to do so, and identifies some specific cases when it might be helpful. There are 3 ways in which applications can customize serialization: Add serialization methods to your type and mark them with appropriate attributes ( CopierMethod , SerializerMethod , DeserializerMethod ). This method is preferable for types that your application owns, that is, the types that you can add new methods to. Implement IExternalSerializer and register it during configuration time. This method is useful for integrating an external serialization library. Write a separate static class annotated with an [Serializer(typeof(YourType))] with the 3 serialization methods in it and the same attributes as above. This method is useful for types that the application does not own, for example, types defined in other libraries your application has no control over. Each of these methods are detailed in the sections below. Introduction Orleans serialization happens in three stages: objects are immediately deep copied to ensure isolation; before being put on the wire; objects are serialized to a message byte stream; and when delivered to the target activation, objects are recreated (deserialized) from the received byte stream. Data types that may be sent in messages -- that is, types that may be passed as method arguments or return values -- must have associated routines that perform these three steps. We refer to these routines collectively as the serializers for a data type. The copier for a type stands alone, while the serializer and deserializer are a pair that work together. You can provide just a custom copier, or just a custom serializer and a custom deserializer, or you can provide custom implementations of all three. Serializers are registered for each supported data type at silo start-up and whenever an assembly is loaded. Registration is necessary for custom serializer routines for a type to be used. Serializer selection is based on the dynamic type of the object to be copied or serialized. For this reason, there is no need to create serializers for abstract classes or interfaces, because they will never be used. When to Consider Writing a Custom Serializer It is rare that a hand-crafted serializer routine will perform meaningfully better than the generated versions. If you are tempted to do so, you should first consider the following options: If there are fields or properties within your data types that don't have to be serialized or copied, you can mark them with the NonSerialized attribute. This will cause the generated code to skip these fields when copying and serializing. Use Immutable<T> & [Immutable] where possible to avoid copying immutable data. The section on Optimizing Copying below for details. If you're avoiding using the standard generic collection types, don't. The Orleans runtime contains custom serializers for the generic collections that use the semantics of the collections to optimize copying, serializing, and deserializing. These collections also have special \"abbreviated\" representations in the serialized byte stream, resulting in even more performance advantages. For instance, a Dictionary<string, string> will be faster than a List<Tuple<string, string>> . The most common case where a custom serializer can provide a noticeable performance gain is when there is significant semantic information encoded in the data type that is not available by simply copying field values. For instance, arrays that are sparsely populated may often be more efficiently serialized by treating the array as a collection of index/value pairs, even if the application keeps the data as a fully realized array for speed of operation. A key thing to do before writing a custom serializer is to make sure that the generated serializer is really hurting your performance. Profiling will help a bit here, but even more valuable is running end-to-end stress tests of your application with varying serialization loads to gauge the system-level impact, rather than the micro-impact of serialization. For instance, building a test version that passes no parameters to or results from grain methods, simply using canned values at either end, will zoom in on the impact of serialization and copying on system performance. Method 1: Adding Serialization Methods to the Type All serializer routines should be implemented as static members of the class or struct they operate on. The names shown here are not required; registration is based on the presence of the respective attributes, not on method names. Note that serializer methods need not be public. Unless you implement all three serialization routines, you should mark your type with the Serializable attribute so that the missing methods will be generated for you. Copier Copier methods are flagged with the Orleans.CopierMethod attribute: [CopierMethod] static private object Copy(object input, ICopyContext context) { ... } Copiers are usually the simplest serializer routines to write. They take an object, guaranteed to be of the same type as the type the copier is defined in, and must return a semantically-equivalent copy of the object. If, as part of copying the object, a sub-object needs to be copied, the best way to do so is to use the SerializationManager's DeepCopyInner routine: var fooCopy = SerializationManager.DeepCopyInner(foo, context); It is important to use DeepCopyInner, instead of DeepCopy, in order to maintain the object identity context for the full copy operation. Maintaining Object Identity An important responsibility of a copy routine is to maintain object identity. The Orleans runtime provides a helper class for this. Before copying a sub-object \"by hand\" (i.e., not by calling DeepCopyInner), check to see if it has already been referenced as follows: var fooCopy = context.CheckObjectWhileCopying(foo); if (fooCopy == null) { // Actually make a copy of foo context.RecordObject(foo, fooCopy); } The last line, the call to RecordObject , is required so that possible future references to the same object as foo references will get found properly by CheckObjectWhileCopying . Note that this should only be done for class instances, not struct instances or .NET primitives (strings, Uris, enums). If you use DeepCopyInner to copy sub-objects, then object identity is handled for you. Serializer Serialization methods are flagged with the SerializerMethod attribute: [SerializerMethod] static private void Serialize(object input, ISerializationContext context, Type expected) { ... } As with copiers, the \"input\" object passed to a serializer is guaranteed to be an instance of the defining type. The \"expected\" type may be ignored; it is based on compile-time type information about the data item, and is used at a higher level to form the type prefix in the byte stream. To serialize sub-objects, use the SerializationManager 's SerializeInner routine: SerializationManager.SerializeInner(foo, context, typeof(FooType)); If there is no particular expected type for foo, then you can pass null for the expected type. The BinaryTokenStreamWriter class provides a wide variety of methods for writing data to the byte stream. An instance of the class can be obtained via the context.StreamWriter property. See the class for documentation. Deserializer Deserialization methods are flagged with the DeserializerMethod attribute: [DeserializerMethod] static private object Deserialize(Type expected, IDeserializationContext context) { ... } The \"expected\" type may be ignored; it is based on compile-time type information about the data item, and is used at a higher level to form the type prefix in the byte stream. The actual type of the object to be created will always be the type of the class in which the deserializer is defined. To deserialize sub-objects, use the SerializationManager 's DeserializeInner routine: var foo = SerializationManager.DeserializeInner(typeof(FooType), context); Or, alternatively, var foo = SerializationManager.DeserializeInner<FooType>(context); If there is no particular expected type for foo, use the non-generic DeserializeInner variant and pass null for the expected type. The BinaryTokenStreamReader class provides a wide variety of methods for reading data from the byte stream. An instance of the class can be obtained via the context.StreamReader property. See the class for documentation. Method 2: Writing a Serializer Provider In this method, you implement Orleans.Serialization.IExternalSerializer and add it to the SerializationProviders property on both ClientConfiguration on the client and GlobalConfiguration on the silos. Configuration is detailed in the Serialization Providers section above. Implementation of IExternalSerializer follows the pattern described for serialization methods from Method 1 above with the addition of an Initialize method and an IsSupportedType method which Orleans uses to determine if the serializer supports a given type. This is the interface definition: public interface IExternalSerializer { /// <summary> /// Initializes the external serializer. Called once when the serialization manager creates /// an instance of this type /// </summary> void Initialize(Logger logger); /// <summary> /// Informs the serialization manager whether this serializer supports the type for serialization. /// </summary> /// <param name=\"itemType\">The type of the item to be serialized</param> /// <returns>A value indicating whether the item can be serialized.</returns> bool IsSupportedType(Type itemType); /// <summary> /// Tries to create a copy of source. /// </summary> /// <param name=\"source\">The item to create a copy of</param> /// <param name=\"context\">The context in which the object is being copied.</param> /// <returns>The copy</returns> object DeepCopy(object source, ICopyContext context); /// <summary> /// Tries to serialize an item. /// </summary> /// <param name=\"item\">The instance of the object being serialized</param> /// <param name=\"context\">The context in which the object is being serialized.</param> /// <param name=\"expectedType\">The type that the deserializer will expect</param> void Serialize(object item, ISerializationContext context, Type expectedType); /// <summary> /// Tries to deserialize an item. /// </summary> /// <param name=\"context\">The context in which the object is being deserialized.</param> /// <param name=\"expectedType\">The type that should be deserialized</param> /// <returns>The deserialized object</returns> object Deserialize(Type expectedType, IDeserializationContext context); } Method 3: Writing a Serializer for Individual Types In this method you write a new class annotated with an attribute [SerializerAttribute(typeof(TargetType))] , where TargetType is the type which is being serialized, and implement the 3 serialization routines. The rules for how to write those routines are identical to method 1. Orleans uses the [SerializerAttribute(typeof(TargetType))] to determine that this class is a serializer for TargetType and this attribute can be specified multiple times on the same class if it's able to serialize multiple types. Below is an example for such a class: public class User { public User BestFriend { get; set; } public string NickName { get; set; } public int FavoriteNumber { get; set; } public DateTimeOffset BirthDate { get; set; } } [Orleans.CodeGeneration.SerializerAttribute(typeof(User))] internal class UserSerializer { [CopierMethod] public static object DeepCopier(object original, ICopyContext context) { var input = (User) original; var result = new User(); // Record 'result' as a copy of 'input'. Doing this immediately after construction allows for // data structures which have cyclic references or duplicate references. // For example, imagine that 'input.BestFriend' is set to 'input'. In that case, failing to record // the copy before trying to copy the 'BestFriend' field would result in infinite recursion. context.RecordCopy(original, result); // Deep-copy each of the fields. result.BestFriend = (User)context.SerializationManager.DeepCopy(input.BestFriend); result.NickName = input.NickName; // strings in .NET are immutable, so they can be shallow-copied. result.FavoriteNumber = input.FavoriteNumber; // ints are primitive value types, so they can be shallow-copied. result.BirthDate = (DateTimeOffset)context.SerializationManager.DeepCopy(input.BirthDate); return result; } [SerializerMethod] public static void Serializer(object untypedInput, ISerializationContext context, Type expected) { var input = (User) untypedInput; // Serialize each field. SerializationManager.SerializeInner(input.BestFriend, context); SerializationManager.SerializeInner(input.NickName, context); SerializationManager.SerializeInner(input.FavoriteNumber, context); SerializationManager.SerializeInner(input.BirthDate, context); } [DeserializerMethod] public static object Deserializer(Type expected, IDeserializationContext context) { var result = new User(); // Record 'result' immediately after constructing it. As with with the deep copier, this // allows for cyclic references and de-duplication. context.RecordObject(result); // Deserialize each field in the order that they were serialized. result.BestFriend = SerializationManager.DeserializeInner<User>(context); result.NickName = SerializationManager.DeserializeInner<string>(context); result.FavoriteNumber = SerializationManager.DeserializeInner<int>(context); result.BirthDate = SerializationManager.DeserializeInner<DateTimeOffset>(context); return result; } } Serializing Generic Types The TargetType parameter of [Serializer(typeof(TargetType))] can be an open-generic type, for example, MyGenericType<> . In that case, the serializer class must have the same generic parameters as the target type. Orleans will create a concrete version of the serializer at runtime for every concrete MyGenericType<T> type which is serialized, for example, one for each of MyGenericType<int> and MyGenericType<string> . Hints for Writing Serializers and Deserializers Often the simplest way to write a serializer/deserializer pair is to serialize by constructing a byte array and writing the array length to the stream, followed by the array itself, and then deserialize by reversing the process. If the array is fixed-length, you can omit it from the stream. This works well when you have a data type that you can represent compactly and that doesn't have sub-objects that might be duplicated (so you don't have to worry about object identity). Another approach, which is the approach the Orleans runtime takes for collections such as dictionaries, works well for classes with significant and complex internal structure: use instance methods to access the semantic content of the object, serialize that content, and deserialize by setting the semantic contents rather than the complex internal state. In this approach, inner objects are written using SerializeInner and read using DeserializeInner. In this case, it is common to write a custom copier, as well. If you write a custom serializer, and it winds up looking like a sequence of calls to SerializeInner for each field in the class, you don't need a custom serializer for that class. Fallback Serialization Orleans supports transmission of arbitrary types at runtime and therefore the in-built code generator cannot determine the entire set of types which will be transmitted ahead of time. Additionally, certain types cannot have serializers generated for them because they are inaccessible (for example, private ) or have fields which are inaccessible (for example, readonly ). Therefore, there is a need for just-in-time serialization of types which were unexpected or could not have serializers generated ahead-of-time. The serializer responsible for these types is called the fallback serializer . Orleans ships with two fallback serializers: Orleans.Serialization.BinaryFormatterSerializer which uses .NET's BinaryFormatter ; and Orleans.Serialization.ILBasedSerializer which emits CIL instructions at runtime to create serializers which leverage Orleans' serialization framework to serialize each field. This means that if an inaccessible type MyPrivateType contains a field MyType which has a custom serializer, that custom serializer will be used to serialize it. The fallback serializer can be configured using the FallbackSerializationProvider property on both ClientConfiguration on the client and GlobalConfiguration on the silos. var cfg = new ClientConfiguration(); cfg.FallbackSerializationProvider = typeof(FantasticSerializer).GetTypeInfo(); var cfg = new GlobalConfiguration(); cfg.FallbackSerializationProvider = typeof(FantasticSerializer).GetTypeInfo(); Alternatively, the fallback serialization provider can be specified in XML configuration: <Messaging> <FallbackSerializationProvider type=\"GreatCompany.FantasticFallbackSerializer, GreatCompany.SerializerAssembly\"/> </Messaging> .NET Core uses the ILBasedSerializer by default, whereas .NET 4.6 uses BinaryFormatterSerializer by default. Optimize Copying Using Immutable Types Orleans has a feature that can be used to avoid some of the overhead associated with serializing messages containing immutable types. This section describes the feature and its application, starting with context on where it is relevant. Serialization in Orleans When a grain method is invoked, the Orleans runtime makes a deep copy of the method arguments and forms the request out of the copies. This protects against the calling code modifying the argument objects before the data is passed to the called grain. If the called grain is on a different silo, then the copies are eventually serialized into a byte stream and sent over the network to the target silo, where they are deserialized back into objects. If the called grain is on the same silo, then the copies are handed directly to the called method. Return values are handled the same way: first copied, then possibly serialized and deserialized. Note that all 3 processes, copying, serializing, and deserializing, respect object identity. In other words, if you pass a list that has the same object in it twice, on the receiving side you'll get a list with the same object in it twice, rather than with two objects with the same values in them. Optimizing Copying In many cases, the deep copying is unnecessary. For instance, a possible scenario is a web front-end that receives a byte array from its client and passes that request, including the byte array, on to a grain for processing. The front-end process doesn't do anything with the array once it has passed it on to the grain; in particular, it doesn't reuse the array to receive a future request. Inside the grain, the byte array is parsed to fetch the input data, but not modified. The grain returns another byte array that it has created to get passed back to the web client; it discards the array as soon as it returns it. The web front-end passes the result byte array back to its client, without modification. In such a scenario, there is no need to copy either the request or response byte arrays. Unfortunately, the Orleans runtime can't figure this out by itself, since it can't tell whether or not the arrays are modified later on by the web front-end or by the grain. In the best of all possible worlds, we'd have some sort of .NET mechanism for indicating that a value is no longer modified; lacking that, we've added Orleans-specific mechanisms for this: the Immutable<T> wrapper class and the [Immutable] attribute. Using Immutable<T> The Orleans.Concurrency.Immutable<T> wrapper class is used to indicate that a value may be considered immutable; that is, the underlying value will not be modified, so no copying is required for safe sharing. Note that using Immutable<T> implies that neither the provider of the value nor the recipient of the value will modify it in the future; it is not a one-sided commitment, but rather a mutual dual-side commitment. Using Immutable<T> is simple: in your grain interface, instead of passing T , pass Immutable<T> . For instance, in the above described scenario, the grain method that was: Task<byte[]> ProcessRequest(byte[] request); Becomes: Task<Immutable<byte[]>> ProcessRequest(Immutable<byte[]> request); To create an Immutable<T> , simply use the constructor: Immutable<byte[]> immutable = new Immutable<byte[]>(buffer); To get the value inside the immutable, use the .Value property: byte[] buffer = immutable.Value; Using [Immutable] For user-defined types, the [Orleans.Concurrency.Immutable] attribute can be added to the type. This instructs Orleans' serializer to avoid copying instances of this type. The following code snippet demonstrates using [Immutable] to denote an immutable type. This type will not be copied during transmission. [Immutable] public class MyImmutableType { public MyImmutableType(int value) { this.MyValue = value; } public int MyValue { get; } } Immutability in Orleans For Orleans' purposes, immutability is a rather strict statement: the contents of the data item will not be modified in any way that could change the item's semantic meaning, or that would interfere with another thread simultaneously accessing the item. The safest way to ensure this is to simply not modify the item at all: bitwise immutability, rather than logical immutability. In some cases it is safe to relax this to logical immutability, but care must be taken to ensure that the mutating code is properly thread-safe; because dealing with multithreading is complex, and uncommon in an Orleans context, we strongly recommend against this approach and recommend sticking to bitwise immutability. Serialization Best Practices Serialization serves two primary purposes in Orleans: As a wire format for transmitting data between grains and clients at runtime. As a storage format for persisting long-lived data for later retrieval. The serializers generated by Orleans are suitable for the first purpose due to their flexibility, performance, and versatility. They are not as suitable for the second purpose, since they are not explicitly version-tolerant. It is recommended that users configure a version-tolerant serializer such as Protocol Buffers for persistent data. Protocol Buffers is supported via Orleans.Serialization.ProtobufSerializer from the Microsoft.Orleans.OrleansGoogleUtils NuGet package. The best-practices for the particular serializer of choice should be used in order to ensure version-tolerance. Third-party serializers can be configured using the SerializationProviders configuration property as described above."
  },
  "Documentation/clusters_and_clients/configuration_guide/shutting_down_orleans.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/shutting_down_orleans.html",
    "title": "Shutting down Orleans | Microsoft Orleans Documentation",
    "keywords": "This document explains how to gracefully shutdown an Orleans silo before application exit, first as a Console app, and then as a Docker container app. Graceful shutdown - Console app The following code shows how to gracefully shutdown an Orleans silo console app in response to the user pressing Ctrl+C, which generates the Console.CancelkeyPress event. Normally when that event handler returns, the application will exit immediately, causing a catastrophic Orleans silo crash and loss of in-memory state. But in the sample code below, we set a.Cancel = true; to prevent the application closing before the Orleans silo has completed its graceful shutdown. using Microsoft.Extensions.Logging; using Orleans.Configuration; using Orleans.Hosting; using System; using System.Net; using System.Threading; using System.Threading.Tasks; namespace MySiloHost { class Program { static readonly ManualResetEvent _siloStopped = new ManualResetEvent(false); static ISiloHost silo; static bool siloStopping = false; static readonly object syncLock = new object(); static void Main(string[] args) { SetupApplicationShutdown(); silo = CreateSilo(); silo.StartAsync().Wait(); /// Wait for the silo to completely shutdown before exiting. _siloStopped.WaitOne(); } static void SetupApplicationShutdown() { /// Capture the user pressing Ctrl+C Console.CancelKeyPress += (s, a) => { /// Prevent the application from crashing ungracefully. a.Cancel = true; /// Don't allow the following code to repeat if the user presses Ctrl+C repeatedly. lock (syncLock) { if (!siloStopping) { siloStopping = true; Task.Run(StopSilo).Ignore(); } } /// Event handler execution exits immediately, leaving the silo shutdown running on a background thread, /// but the app doesn't crash because a.Cancel has been set = true }; } static ISiloHost CreateSilo() { return new SiloHostBuilder() .Configure(options => options.ClusterId = \"MyTestCluster\") /// Prevent the silo from automatically stopping itself when the cancel key is pressed. .Configure<ProcessExitHandlingOptions>(options => options.FastKillOnProcessExit = false) .UseDevelopmentClustering(options => options.PrimarySiloEndpoint = new IPEndPoint(IPAddress.Loopback, 11111)) .ConfigureLogging(b => b.SetMinimumLevel(LogLevel.Debug).AddConsole()) .Build(); } static async Task StopSilo() { await silo.StopAsync(); _siloStopped.Set(); } } } Of course, there are many other ways of achieving the same goal. Below is shown a way, popular online, and misleading, that DOES NOT work properly. It does not work because it sets up a race condition between two methods trying to exit first: the Console.CancelKeyPress event handler method, and the static void Main(string[] args) method. When the event handler method finishes first, which happens at least half the time, the application will hang instead of exiting smoothly. class Program { static readonly ManualResetEvent _siloStopped = new ManualResetEvent(false); static ISiloHost silo; static bool siloStopping = false; static readonly object syncLock = new object(); static void Main(string[] args) { Console.CancelKeyPress += (s, a) => { Task.Run(StopSilo); /// Wait for the silo to completely shutdown before exiting. _siloStopped.WaitOne(); /// Now race to finish ... who will finish first? /// If I finish first, the application will hang! :( }; silo = CreateSilo(); silo.StartAsync().Wait(); /// Wait for the silo to completely shutdown before exiting. _siloStopped.WaitOne(); /// Now race to finish ... who will finish first? } static async Task StopSilo() { await silo.StopAsync(); _siloStopped.Set(); } } Graceful shutdown - Docker app To be completed."
  },
  "Documentation/clusters_and_clients/configuration_guide/typical_configurations.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/typical_configurations.html",
    "title": "Typical Configurations | Microsoft Orleans Documentation",
    "keywords": "Typical Configurations Below are examples of typical configurations that can be used for development and production deployments. Local Development See Local Development Configuration Reliable Production Deployment Using Azure For a reliable production deployment using Azure, you need to use the Azure Table option for cluster membership. This configuration is typical of deployments to either on-premise servers, containers, or Azure virtual machine instances. The format of the DataConnection string is \"DefaultEndpointsProtocol=https;AccountName=<Azure storage account>;AccountKey=<Azure table storage account key>\" Silo configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var silo = new SiloHostBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAzureStorageClustering(options => options.ConnectionString = connectionString) .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Client configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var client = new ClientBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAzureStorageClustering(options => options.ConnectionString = connectionString) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Reliable Production Deployment Using SQL Server For a reliable production deployment using SQL server, a SQL server connection string needs to be supplied. Silo configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var silo = new SiloHostBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAdoNetClustering(options => { options.ConnectionString = connectionString; options.Invariant = \"System.Data.SqlClient\"; }) .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Client configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var client = new ClientBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAdoNetClustering(options => { options.ConnectionString = connectionString; options.Invariant = \"System.Data.SqlClient\"; }) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Unreliable Deployment on a Cluster of Dedicated Servers For testing on a cluster of dedicated servers when reliability isnt a concern you can leverage MembershipTableGrain and avoid dependency on Azure Table. You just need to designate one of the nodes as a Primary. On the silos: var primarySiloEndpoint = new IPEndpoint(PRIMARY_SILO_IP_ADDRESS, 11111); var silo = new SiloHostBuilder() .UseDevelopmentClustering(primarySiloEndpoint) .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) .ConfigureLogging(logging => logging.AddConsole()) .Build(); On the clients: var gateways = new IPEndPoint[] { new IPEndPoint(PRIMARY_SILO_IP_ADDRESS, 11111), new IPEndPoint(OTHER_SILO__IP_ADDRESS_1, 11111), [...] new IPEndPoint(OTHER_SILO__IP_ADDRESS_N, 11111), }; var client = new ClientBuilder() .UseStaticClustering(gateways) .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"AdventureApp\"; }) .ConfigureLogging(logging => logging.AddConsole()) .Build();"
  },
  "Documentation/clusters_and_clients/monitoring/client_error_code_monitoring.html": {
    "href": "Documentation/clusters_and_clients/monitoring/client_error_code_monitoring.html",
    "title": "Client Error Code Monitoring | Microsoft Orleans Documentation",
    "keywords": "Client Error Code Monitoring Group Log Type Log Code Values Threshold Description Azure Problems Warning or Error 100800 - 100899 Any Error or Warning Transient problems reading or writing to Azure table store will be logged as Warning. Transient read errors will automatically be retried. A final Error log message means there is a real problem connecting to Azure table storage. Gateway connectivity problems Warning or Error 100901 - 100904, 100912, 100913, 100921, 100923, 100158, 100161, 100178, , 101313 Any Error or Warning Problems connecting to gateways. No active gateways in the Azure table. Connection to active gateway lost. Grain call timeouts Warning 100157 Multiple Warnings logged in short space of time Grain-call timeout problems are generally caused by temporary network connectivity issues or silo restart / reboot problems. System should recover after a short time (depending on Liveness config settings) at which point Timeouts should clear. Ideally, monitoring for just the bulk log code 600157 variety of these warnings should be sufficient. Network Socket Problems Warning or Error 101000 to 101999, 100307, 100015, 100016 Any Error or Warning Socket disconnects are logged as Warning messages. Problems opening sockets or during message transmission are logged as Errors. Bulk log message compaction Any 500000 or higher Message summary based on bulk message threshold settings If multiple logs of the same log code occur within a designated time interval (the default is >5 within 1 minute) then additional log messages with that log code are suppressed and output as a \"bulk\" entry with log code equal to the original log code + 500000. So for example, multiple 100157 entries will show in the logs as 5 x 100157 + 1 x 600157 log entry per minute."
  },
  "Documentation/core_concepts/code_generation.html": {
    "href": "Documentation/core_concepts/code_generation.html",
    "title": "Code Generation | Microsoft Orleans Documentation",
    "keywords": "Code Generation The Orleans runtime makes use of generated code in order to ensure proper serialization of types that are used across the cluster as well as for generating boilerplate which abstracts away the implementation details of method shipping, exception propagation, and other internal runtime concepts. Enabling Code Generation Code generation can be performed either when your projects are being built or when your application initializes. During Build The preferred method for performing code generation is at build time. Enable build time code generation by installing the Microsoft.Orleans.OrleansCodeGenerator.Build package into all projects which contain grains, grain interfaces, custom serializers, or types which are sent between grains. Installing this package injects a target into the project which will generate code at build time. The Microsoft.Orleans.OrleansCodeGenerator.Build package only supports C# projects. Other languages are supported either using the Microsoft.Orleans.OrleansCodeGenerator package described below, or by creating a C# project which can act as the target for code generated from assemblies written in other languages. Additional diagnostics can be emitted at build-time by specifying value for OrleansCodeGenLogLevel in the target project's csproj file. For example, <OrleansCodeGenLogLevel>Trace</OrleansCodeGenLogLevel> . During Initialization Code generation can be performed during initialization on the client and silo by installing the Microsoft.Orleans.OrleansCodeGenerator package and using the IApplicationPartManager.WithCodeGeneration extension method. builder.ConfigureApplicationParts( parts => parts .AddApplicationPart(typeof(IRuntimeCodeGenGrain).Assembly) .WithCodeGeneration()); In the above example, builder may be an instance of either ISiloHostBuilder or IClientBuilder . An optional ILoggerFactory instance can be passed to WithCodeGeneration to enable logging during code generation, for example: ILoggerFactory codeGenLoggerFactory = new LoggerFactory(); codeGenLoggerFactory.AddProvider(new ConsoleLoggerProvider()); builder.ConfigureApplicationParts( parts => parts .AddApplicationPart(typeof(IRuntimeCodeGenGrain).Assembly) .WithCodeGeneration(codeGenLoggerFactory)); Influencing Code Generation Generate code for a specific type Code is automatically generated for grain interfaces, grain classes, grain state, and types passed as arguments in grain methods. If a type does not fit this criteria, the following methods can be used to further guide code generation. Adding [Serializable] to a type instructs the code generator to generate a serializer for that type. Adding [assembly: GenerateSerializer(Type)] to a project instructs the code generator to treat that type as serializable and will cause an error if a serializer could not be generated for that type, for example because the type is not accessible. This error will halt a build if code generation is enabled. This attribute also allows generating code for specific types from another assembly. [assembly: KnownType(Type)] also instructs the code generator to include a specific type (which may be from a referenced assembly), but does not cause an exception if the type is inaccessible. Generate serializers for all subtypes Adding [KnownBaseType] to an interface or class instructs the code generator to generates serialization code for all types which inherit/implement that type. Generate code for all types in another assembly There are cases where generated code can not be included in a particular assembly at build time. For example, this can include shared libraries which do not reference Orleans, assemblies written in languages other than C#, and assemblies which the developer does not have the source code for. In these cases, generated code for those assemblies can be placed into a separate assembly which is referenced during initialization. In order to enable this for an assembly: Create a C# project Install the Microsoft.Orleans.OrleansCodeGenerator.Build package Add a reference to the target assembly Add [assembly: KnownAssembly(\"OtherAssembly\")] at the top level of a C# file The KnownAssembly attribute instructs the code generator to inspect the specified assembly and generate code for the types within it. The attribute can be used multiple times within a project. The generated assembly must then be added to the client/silo during initialization: builder.ConfigureApplicationParts( parts => parts.AddApplicationPart(\"CodeGenAssembly\")); In the above example, builder may be an instance of either ISiloHostBuilder or IClientBuilder . KnownAssemblyAttribute has an optional property, TreatTypesAsSerializable , which can be set to true to instruct the code generator to act as though all types within that assembly are marked as serializable."
  },
  "Documentation/core_concepts/index.html": {
    "href": "Documentation/core_concepts/index.html",
    "title": "Core Concepts | Microsoft Orleans Documentation",
    "keywords": "This is the overview page about Core Concepts - only pages with information about grains, silos, cluster, clients, packages, and code generation go here."
  },
  "Documentation/core_concepts/what_are_orleans_packages.html": {
    "href": "Documentation/core_concepts/what_are_orleans_packages.html",
    "title": "Orleans NuGet Packages | Microsoft Orleans Documentation",
    "keywords": "Orleans NuGet packages as of v2.0.0-rc2 Key Packages There are 5 key NuGet packages you will need to use in most scenarios: Microsoft Orleans Core Abstractions PM> Install-Package Microsoft.Orleans.Core.Abstractions Contains Orleans.Core.Abstractions.dll, which defines Orleans public types that are needed for developing application code (grain interfaces and classes). This package is needs to be directly or indirectly referenced by any Orleans project. Add it to your projects that define grain interfaces and classes. Microsoft Orleans Build-time Code Generation PM> Install-Package Microsoft.Orleans.OrleansCodeGenerator.Build Build time support for grain interfaces and implementation projects. Add it to your grain interfaces and implementation projects to enable code generation of grain references and serializers. Microsoft Orleans Server Libraries PM> Install-Package Microsoft.Orleans.Server A meta-package for easily building and starting a silo. Includes the following packages: Microsoft.Orleans.Core.Abstractions Microsoft.Orleans.Core Microsoft.Orleans.OrleansRuntime Microsoft.Orleans.OrleansProviders Microsoft Orleans Client Libraries PM> Install-Package Microsoft.Orleans.Client A meta-package for easily building and starting an Orleans client (frontend). Includes the following packages: Microsoft.Orleans.Core.Abstractions Microsoft.Orleans.Core Microsoft.Orleans.OrleansProviders Microsoft Orleans Core Library PM> Install-Package Microsoft.Orleans.Core Contains implementation for most Orleans public types used by application code and Orleans clients (frontends). Reference it for building libraries and client applications that use Orleans types but don't deal with hosting or silos. Included in Microsoft.Orleans.Client and Microsoft.Orleans.Server meta-packages, and is referenced, directly or indirectly, by most other packages. Hosting Microsoft Orleans Runtime PM> Install-Package Microsoft.Orleans.OrleansRuntime Library for configuring and starting a silo. Reference it in your silo host project. Included in Microsoft.Orleans.Server meta-package. Microsoft Orleans Runtime Abstractions PM> Install-Package Microsoft.Orleans.Runtime.Abstractions Contains interfaces and abstractions for types implemented in Microsoft.Orleans.OrleansRuntime. Microsoft Orleans Hosting on Azure Cloud Services PM> Install-Package Microsoft.Orleans.Hosting.AzureCloudServices Contains helper classes for hosting silos and Orleans clients as Azure Cloud Services (Worker Roles and Web Roles). Microsoft Orleans Service Fabric Hosting Support PM> Install-Package Microsoft.Orleans.Hosting.ServiceFabric Contains helper classes for hosting silos as a stateless Service Fabric service. Clustering Providers The below packages include plugins for persisting cluster membership data in various storage technologies. Microsoft Orleans clustering provider for Azure Table Storages PM> Install-Package Microsoft.Orleans.Clustering.AzureStorage Includes the plugin for using Azure Tables for storing cluster membership data. Microsoft Orleans clustering provider for ADO.NET Providers PM> Install-Package Microsoft.Orleans.Clustering.AdoNet Includes the plugin for using ADO.NET for storing cluster membership data in one of the supported databases. Microsoft Orleans Consul Utilities PM> Install-Package Microsoft.Orleans.OrleansConsulUtils Includes the plugin for using Consul for storing cluster membership data. Microsoft Orleans ZooKeeper Utilities PM> Install-Package Microsoft.Orleans.OrleansZooKeeperUtils Includes the plugin for using ZooKeeper for storing cluster membership data. Microsoft Orleans clustering provider for AWS DynamoDB PM> Install-Package Microsoft.Orleans.Clustering.DynamoDB Includes the plugin for using AWS DynamoDB for storing cluster membership data. Reminder Providers The below packages include plugins for persisting reminders in various storage technologies. Microsoft Orleans Reminders Azure Table Storage PM> Install-Package Microsoft.Orleans.Reminders.AzureStorage Includes the plugin for using Azure Tables for storing cluster membership data. Microsoft Orleans Reminders ADO.NET Providers PM> Install-Package Microsoft.Orleans.Reminders.AdoNet Includes the plugin for using ADO.NET for storing reminders in one of the supported databases. Microsoft Orleans reminders provider for AWS DynamoDB PM> Install-Package Microsoft.Orleans.Reminders.DynamoDB Includes the plugin for using AWS DynamoDB for storing reminders. Grain Storage Providers The below packages include plugins for persisting grain state in various storage technologies. Microsoft Orleans Persistence Azure Storage PM> Install-Package Microsoft.Orleans.Persistence.AzureStorage Includes the plugins for using Azure Tables or Azure Blobs for storing grain state. Microsoft Orleans Persistence ADO.NET Providers PM> Install-Package Microsoft.Orleans.Persistence.AdoNet Includes the plugin for using ADO.NET for storing grain state in one of the supported databases. Microsoft Orleans Persistence DynamoDB PM> Install-Package Microsoft.Orleans.Persistence.DynamoDB Includes the plugin for using AWS DynamoDB for storing grain state. Stream Providers The below packages include plugins for delivering streaming events. Microsoft Orleans ServiceBus Utilities PM> Install-Package Microsoft.Orleans.OrleansServiceBus Includes the stream provider for Azure Event Hubs. Microsoft Orleans Streaming Azure Storage PM> Install-Package Microsoft.Orleans.Streaming.AzureStorage Includes the stream provider for Azure Queues. Microsoft Orleans Streaming AWS SQS PM> Install-Package Microsoft.Orleans.Streaming.SQS Includes the stream provider for AWS SQS service. Microsoft Orleans Google Cloud Platform Utilities PM> Install-Package Microsoft.Orleans.OrleansGCPUtils Includes the stream provider for GCP PubSub service. Additional Packages Microsoft Orleans Code Generation PM> Install-Package Microsoft.Orleans.OrleansCodeGenerator Includes the run time code generator. Microsoft Orleans Event-Sourcing PM> Install-Package Microsoft.Orleans.EventSourcing Contains a set of base types for creating grain classes with event-sourced state. Development and Testing Microsoft Orleans Providers PM> Install-Package Microsoft.Orleans.OrleansProviders Contains a set of persistence and stream providers that keep data in memory. Intended for testing. In general, not recommended for production use, unless data loss is care of a silo failure is acceptable. Microsoft Orleans Testing Host Library PM> Install-Package Microsoft.Orleans.TestingHost Includes the library for hosting silos and clients in a testing project. Legacy Packages The below packages are for backward compatibility and easier migration from Orleans 1.x to 2.0 Microsoft Orleans Core Legacy Library PM> Install-Package Microsoft.Orleans.Core.Legacy Contains 1.x style client configuration objects and logging APIs. Makes migration easier by not requiring to change client code to the new client builder API and logging. Microsoft Orleans Runtime Legacy Library PM> Install-Package Microsoft.Orleans.Runtime.Legacy Contains 1.x style silo configuration objects and hosting APIs. Makes migration easier by not requiring to change silo configuration and hosting code to the new silo host builder API. Microsoft Orleans Azure Utilities PM> Install-Package Microsoft.Orleans.OrleansAzureUtils A meta-package that includes all packages with Azure providers to simplify upgrading of 1.x projects. Microsoft Orleans Sql Utilities PM> Install-Package Microsoft.Orleans.OrleansSqlUtils A meta-package that includes all packages with ADO.NET providers to simplify upgrading of 1.x projects. Microsoft Orleans AWS Utilities PM> Install-Package Microsoft.Orleans.OrleansAWSUtils A meta-package that includes all packages with AWS providers to simplify upgrading of 1.x projects. Microsoft Orleans Service Fabric Support PM> Install-Package Microsoft.Orleans.ServiceFabric A meta-package that includes all packages with Service Fabric providers to simplify upgrading of 1.x projects. Microsoft Orleans Management Tool PM> Install-Package Microsoft.Orleans.OrleansManager Includes Orleans management tool - OrleansManager.exe. Serializers Microsoft Orleans Bond Serializer PM> Install-Package Microsoft.Orleans.Serialization.Bond Includes support for Bond serializer . Microsoft Orleans Google Utilities PM> Install-Package Microsoft.Orleans.OrleansGoogleUtils Includes Google Protocol Buffers serializer. Microsoft Orleans protobuf-net Serializer PM> Install-Package Microsoft.Orleans.ProtobufNet Includes protobuf-net version of Protocol Buffers serializer. Telemetry Microsoft Orleans Telemetry Consumer - Performance Counters PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.Counters Windows Performance Counters implementation of Orleans Telemetry API. Microsoft Orleans Telemetry Consumer - Azure Application Insights PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.AI Includes the telemetry consumer for Azure Application Insights. Microsoft Orleans Telemetry Consumer - NewRelic PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.NewRelic Includes the telemetry consumer for NewRelic. Tools Microsoft Orleans Performance Counter Tool PM> Install-Package Microsoft.Orleans.CounterControl Includes OrleansCounterControl.exe, which registers Windows performance counter categories for Orleans statistics and for deployed grain classes. Requires elevation. Can be executed in Azure as part of a role startup task. Transactions Microsoft Orleans Transactions support PM> Install-Package Microsoft.Orleans.Transactions Includes support for cross-grain transactions (beta). Microsoft Orleans Transactions on Azure PM> Install-Package Microsoft.Orleans.Transactions.AzureStorage Includes a plugin for persisting transaction log in Azure Table (beta)."
  },
  "Documentation/deployment/consul_deployment.html": {
    "href": "Documentation/deployment/consul_deployment.html",
    "title": "Using Consul as a Membership Provider | Microsoft Orleans Documentation",
    "keywords": "Using Consul as a Membership Provider Introduction to Consul Consul is a distributed, highly available and datacenter-aware service discovery platform which includes simple service registration, health checking, failure detection and key/value storage. It is built on the premise that every node in the datacenter is running a Consul agent which is either acting as a server or client which communicate via a scalable gossip protocol. There is a very detailed overview of Consul including comparisons with similar solutions here . Consul is written in GO and is open source ; compiled downloads are available for Mac OS X, FreeBSD, Linux, Solaris and Windows Why Choose Consul? As an Orleans Membership Provider , Consul is a good choice when you need to deliver an on-premise solution which does not require your potential customers to have existing infrastructure and a co-operative IT provider. Consul is a very lightweight single executable, has no dependencies and as such can easily be built into your own middleware solution. And when Consul is already your solution for discovering, checking and maintaining your microservices, it makes sense to fully integrate with Orleans membership for simplicity and ease of operation. We therefore implemented a membership table in Consul (also known as \"Orleans Custom System Store\"), which fully integrates with Orleans's Cluster Management . Setting up Consul There is very extensive documentation available on Consul.io about setting up a stable Consul cluster and it doesn't make sense to repeat that here; however for your convenience we include this guide so you can very quickly get Orleans running with a standalone Consul agent. 1) Create a folder to install Consul into, e.g. C:\\Consul 2) Create a subfolder: C:\\Consul\\Data (Consul will not create this if it doesn't exist) 3) Download and unzip Consul.exe into C:\\Consul\\ 4) Open a command prompt at C:\\Consul\\ 5) Enter Consul.exe agent -server -bootstrap -data-dir \"C:\\Consul\\Data\" -client=0.0.0.0 agent Instructs Consul to run the agent process that hosts the services. Without this the Consul process will attempt to use RPC to configure a running agent. -server Defines the agent as a server and not a client (A Consul client is an agent that hosts all the services and data, but does not have voting rights to decide, and cannot become, the cluster leader -bootstrap The first (and only the first!) node in a cluster must be bootstrapped so that it assumes the cluster leadership. -data-dir [path] Specifies the path where all Consul data is stored, including the cluster membership table -client=0.0.0.0 Informs Consul which IP to open the service on. There are many other parameters, and the option to use a json configuration file. Please consult the Consul documentation for a full listing of the options. 6) Verify that Consul is running and ready to accept membership requests from Orleans by opening the services endpoint in your browser. Configuration of Orleans Server There is currently a known issue with the \"Custom\" membership provider OrleansConfiguration.xml configuration file that will fail to parse correctly. For this reason you have to provide a placeholder SystemStore in the xml and then configure the provider in code before starting the Silo. OrleansConfiguration.xml <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <SystemStore SystemStoreType=\"None\" DataConnectionString=\"http://localhost:8500\" DeploymentId=\"MyOrleansDeployment\" /> </Globals> <Defaults> <Networking Address=\"localhost\" Port=\"22222\" /> <ProxyingGateway Address=\"localhost\" Port=\"30000\" /> </Defaults> </OrleansConfiguration> Code public void Start(ClusterConfiguration config) { _siloHost = new SiloHost(System.Net.Dns.GetHostName(), config); _siloHost.Config.Globals.LivenessType = GlobalConfiguration.LivenessProviderType.Custom; _siloHost.Config.Globals.MembershipTableAssembly = \"OrleansConsulUtils\"; _siloHost.Config.Globals.ReminderServiceType = GlobalConfiguration.ReminderServiceProviderType.Disabled; _siloHost.InitializeOrleansSilo(); var startedok = _siloHost.StartOrleansSilo(); if (!startedok) throw new SystemException(String.Format(\"Failed to start Orleans silo '{0}' as a {1} node\", _siloHost.Name, _siloHost.Type)); Log.Information(\"Orleans Silo is running.\\n\"); } Alternatively you could configure the silo entirely in code. Client The client configuration is much simpler ClientConfiguration.xml <ClientConfiguration xmlns=\"urn:orleans\"> <SystemStore SystemStoreType=\"Custom\" CustomGatewayProviderAssemblyName=\"OrleansConsulUtils\" DataConnectionString=\"http://192.168.1.26:8500\" DeploymentId=\"MyOrleansDeployment\" /> </ClientConfiguration> Client SDK If you are interested in using Consul for your own service discovery there are Client SDKs for most popular languages. Implementation Detail The Membership Table Provider makes use of Consul's Key/Value store functionality with CAS. When each Silo starts it registers two KV entries, one which contains the Silo details and one which holds the last time the Silo reported it was alive (the latter refers to diagnostics \"I am alive\" entries and not to failure detection hearbeats which are sent directly between the silos and are not written into the table). All writes to the table are performed with CAS to provide concurrency control, as necessitated by Orleans's Cluster Management Protocol . Once the Silo is running you can view these entries in your web browser here , this will display something like: [ \"orleans/MyOrleansDeployment/192.168.1.26:11111@191780753\", \"orleans/MyOrleansDeployment/192.168.1.26:11111@191780753/iamalive\" ] You will notice that the keys are prefixed with \"orleans/\" this is hard coded in the provider and is intended to avoid key space collision with other users of Consul. Each of these keys can be read by appending their key name (sans quotes of course) to the Consul KV root . Doing so will present you with the following: [ { \"LockIndex\": 0, \"Key\": \"orleans/MyOrleansDeployment/192.168.1.26:22222@191780753\", \"Flags\": 0, \"Value\": \"[BASE64 UTF8 Encoded String]\", \"CreateIndex\": 10, \"ModifyIndex\": 12 } ] Decoding the string will give you the actual Orleans Membership data: http://localhost:8500/v1/KV/orleans/MyOrleansDeployment/[SiloAddress] { \"Hostname\": \"[YOUR_MACHINE_NAME]\", \"ProxyPort\": 22222, \"StartTime\": \"2016-01-29T16:25:54.9538838Z\", \"Status\": 3, \"SuspectingSilos\": [] } http://localhost:8500/v1/KV/orleans/MyOrleansDeployment/[SiloAddress]/IAmAlive \"2016-01-29T16:35:58.9193803Z\" When the Clients connect, they read the KVs for all silos in the cluster in one HTTP GET by using the uri http://192.168.1.26:8500/v1/KV/orleans/MyOrleansDeployment/?recurse . Limitations Orleans Extended Membership Protocol (Table Version & ETag) Consul KV currrently does not currently support atomic updates. Therefore, the Orleans Consul Membership Provider only implements the the Orleans Basic Membership Protocol, as described here and does not support the Extended Membership Protocol. This Extended protocol was introduced as an additional, but not essential, silo connectivity validation and as a foundation to functionality that has not yet been implemented. Providing your infrastructure is correctly configured you will not experience any detrimental effect of the lack of support. Multiple Datacenters The Key Value Pairs in Consul are not currently replicated between Consul datacenters. There is a separate project to address this but it has not yet been proven to support Orleans. When running on Windows When Consul starts on Windows it logs the following message: ==> WARNING: Windows is not recommended as a Consul server. Do not use in production. This is displayed simply due to lack of focus on testing when running in a Windows environment and not because of any actual known issues. Read the discussion here before deciding if Consul is the right choice for you. Potential Future Enhanecements 1) Prove that the Consul KV replication project is able to support an Orleans cluster in a WAN environment between multiple Consul datacenters. 2) Implement the Reminder Table in Consul. 3) Implement the Extended Membership Protocol. The team behind Consul does plan on implementing atomic operations, once this functionality is available it will be possible to remove the limitations in the provider."
  },
  "Documentation/deployment/docker_deployment.html": {
    "href": "Documentation/deployment/docker_deployment.html",
    "title": "Docker Deployment | Microsoft Orleans Documentation",
    "keywords": "Docker Deployment Note : Even if you are very familiar with Docker and/or Orleans, as any other Orleans documentation, I recommend you to read it to the end in order to avoid problems you may face that we already worked around. Note : This article and its sample are a work in progress. Any feedback, PR or suggestion is very welcome. Deploying Orleans solutions to Docker Deploying Orleans to Docker can be tricky given the way Docker orchestrators and clustering stacks was designed. The most complicated thing is to understand the concept of Overlay Network from Docker Swarm and Kubernets Networking model. Docker containers and networking model were designed to run mostly stateless and immutable containers. So, spinning up a cluster running node.js or nginx applications, is pretty easy. However, if you try to use something more elaborate, like a real clustered or distributed application (like Orleans-based ones) you will eventually have trouble setting it up. It is possible, but not as simple as web-based applications. Docker clustering consists of putting together multiple hosts to work as a single pool of resources, managed using a Container Orchestrator . Docker Inc. provide Swarm as their option for Container Orchestration while Google has Kubernetes (aka K8s ). There are other Orchestrators like DC/OS , Mesos , etc., but in this document we will talk about Swarm and K8s as they are more widely used. The same grain interfaces and implementation which run anywhere Orleans is already supported, will run on Docker containers as well, so no special considerations are needed in order to be able to run your application in Docker containers. The Orleans-Docker sample provides a working example of how to run two console applications. One as Orleans Client and another as Silo, and the details are described below. The concepts discussed here, can be used on both .Net Core and .Net 4.6.1 flavors of Orleans but to ilustrate the cross-platform nature of Docker and .Net Core, we are going to focus on the example considering you are using .Net Core. Platform-specific (Windows/Linux/OSX) details may be provide along this article. Pre-requisites This article assume that you have the following prerequisites installed: Docker - Docker4X has a easy-to-use installer for the major supported platforms. It contains Docker engine and also Docker Swarm. Kubernetes (K8s) - Google's offer for Container Orchestration. It contains a guidance to install Minikube (a local deployment of K8s) and kubectl along with all its dependencies. .Net Core - Cross-platform flavor of .Net Visual Studio Code (VSCode) - You can use whatever IDE you want. VSCode is cross-platform so we are using it to ensure it works on all platforms. Once you installed VSCode, install the C# extension . Note : You are not required to have Kubernetes installed if you are not going to use it. Docker4X installer already includes Swarm so no extra installation is required to use it. Note for Windows Users : On Windows, Docker installer will enable Hyper-V at installation process. As this article and its examples are using .Net Core, the container images used are based on Windows Server NanoServer . If you don't plan to use .Net Core and will target .Net 4.6.1 full framework, the image used should be Windows Server Core and the 1.4+ version of Orleans (which supports only .net full framework). Creating Orleans Solution The following instructions show how to create a regular Orleans solution using the new dotnet tooling. Note : Please adapt the commands to whatever is appropriate in your platform. Also, the directory structure is just a suggestion. Please adapt it to your needs. mkdir Orleans-Docker cd Orleans-Docker dotnet new sln mkdir -p src/OrleansSilo mkdir -p src/OrleansClient mkdir -p src/OrleansGrains mkdir -p src/OrleansGrainInterfaces dotnet new console -o src/OrleansSilo --framework netcoreapp1.1 dotnet new console -o src/OrleansClient --framework netcoreapp1.1 dotnet new classlib -o src/OrleansGrains --framework netstandard1.5 dotnet new classlib -o src/OrleansGrainInterfaces --framework netstandard1.5 dotnet sln add src/OrleansSilo/OrleansSilo.csproj dotnet sln add src/OrleansClient/OrleansClient.csproj dotnet sln add src/OrleansGrains/OrleansGrains.csproj dotnet sln add src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansClient/OrleansClient.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansSilo/OrleansSilo.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansGrains/OrleansGrains.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansSilo/OrleansSilo.csproj reference src/OrleansGrains/OrleansGrains.csproj What we did so far was just boilerplate code to create the solution structure, projects, and add references between projects. Nothing different than a regular Orleans project. By the time this article was written, Orleans 2.0 (which is the only version which support .Net Core and cross-platform) is in Technology Preview so its nugets are hosted in a MyGet feed and not published to Nuget.org official feed. In order to install the preview nugets, we will use dotnet cli forcing the source feed and version from MyGet: dotnet add src/OrleansClient/OrleansClient.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansGrains/OrleansGrains.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansSilo/OrleansSilo.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansSilo/OrleansSilo.csproj package Microsoft.Orleans.OrleansRuntime -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet restore Ok, now you have all the basic dependencies to run a simple Orleans application. Note that so far, nothing changed from your regular Orleans application. Now, lets add some code so we can do something with it. Implementing your Orleans Application Assuming that you are using VSCode , from the solution directory, run code . . That will open the directory in VSCode and load the solution. This is the solution structure we just created previously. We also added Program.cs , OrleansHostWrapper , IGreetingGrain and GreetingGrain files to the interfaces and grain projects respectively and here is the code for those files: IGreetingGrain.cs : using System; using System.Threading.Tasks; using Orleans; namespace OrleansGrainInterfaces { public interface IGreetingGrain : IGrainWithGuidKey { Task<string> SayHello(string name); } } GreetingGrain.cs : using System; using System.Threading.Tasks; using OrleansGrainInterfaces; namespace OrleansGrains { public class GreetingGrain : Grain, IGreetingGrain { public Task<string> SayHello(string name) { return Task.FromResult($\"Hello from Orleans, {name}\"); } } } OrleansHostWrapper.cs : using System; using System.Net; using Orleans.Runtime; using Orleans.Runtime.Configuration; using Orleans.Runtime.Host; namespace OrleansSilo { public class OrleansHostWrapper { private readonly SiloHost siloHost; public OrleansHostWrapper(ClusterConfiguration config) { siloHost = new SiloHost(Dns.GetHostName(), config); siloHost.LoadOrleansConfig(); } public int Run() { if (siloHost == null) { return 1; } try { siloHost.InitializeOrleansSilo(); if (siloHost.StartOrleansSilo()) { Console.WriteLine($\"Successfully started Orleans silo '{siloHost.Name}' as a {siloHost.Type} node.\"); return 0; } else { throw new OrleansException($\"Failed to start Orleans silo '{siloHost.Name}' as a {siloHost.Type} node.\"); } } catch (Exception exc) { siloHost.ReportStartupError(exc); Console.Error.WriteLine(exc); return 1; } } public int Stop() { if (siloHost != null) { try { siloHost.StopOrleansSilo(); siloHost.Dispose(); Console.WriteLine($\"Orleans silo '{siloHost.Name}' shutdown.\"); } catch (Exception exc) { siloHost.ReportStartupError(exc); Console.Error.WriteLine(exc); return 1; } } return 0; } } } Program.cs (Silo): using System; using System.Collections.Generic; using System.Linq; using System.Net; using Orleans.Runtime.Configuration; namespace OrleansSilo { public class Program { private static OrleansHostWrapper hostWrapper; static int Main(string[] args) { int exitCode = InitializeOrleans(); Console.WriteLine(\"Press Enter to terminate...\"); Console.ReadLine(); exitCode += ShutdownSilo(); return exitCode; } private static int InitializeOrleans() { var config = new ClusterConfiguration(); config.Globals.DataConnectionString = \"[AZURE STORAGE CONNECTION STRING HERE]\"; config.Globals.DeploymentId = \"Orleans-Docker\"; config.Globals.LivenessType = GlobalConfiguration.LivenessProviderType.AzureTable; config.Globals.ReminderServiceType = GlobalConfiguration.ReminderServiceProviderType.AzureTable; config.Defaults.PropagateActivityId = true; config.Defaults.ProxyGatewayEndpoint = new IPEndPoint(IPAddress.Any, 10400); config.Defaults.Port = 10300; var ips = Dns.GetHostAddressesAsync(Dns.GetHostName()).Result; config.Defaults.HostNameOrIPAddress = ips.FirstOrDefault()?.ToString(); hostWrapper = new OrleansHostWrapper(config); return hostWrapper.Run(); } private static int ShutdownSilo() { if (hostWrapper != null) { return hostWrapper.Stop(); } return 0; } } } Program.cs (client): using System; using System.Net; using System.Threading; using System.Threading.Tasks; using Orleans; using Orleans.Runtime.Configuration; using OrleansGrainInterfaces; namespace OrleansClient { class Program { private static IClusterClient client; private static bool running; static void Main(string[] args) { Task.Run(() => InitializeOrleans()); Console.ReadLine(); running = false; } static async Task InitializeOrleans() { var config = new ClientConfiguration(); config.DeploymentId = \"Orleans-Docker\"; config.PropagateActivityId = true; var hostEntry = await Dns.GetHostEntryAsync(\"orleans-silo\"); var ip = hostEntry.AddressList[0]; config.Gateways.Add(new IPEndPoint(ip, 10400)); Console.WriteLine(\"Initializing...\"); client = new ClientBuilder().UseConfiguration(config).Build(); await client.Connect(); running = true; Console.WriteLine(\"Initialized!\"); var grain = client.GetGrain<IGreetingGrain>(Guid.Empty); while(running) { var response = await grain.SayHello(\"Gutemberg\"); Console.WriteLine($\"[{DateTime.UtcNow}] - {response}\"); await Task.Delay(1000); } client.Dispose(); } } } We are not going into details about the grain implementation here since it is out of the scope of this article. Please check other documents related to it. Those files are essentially a minimal Orleans application and we will start from it to move forward with the remaining of this article. Note : In this article we are using OrleansAzureUtils membership provider but you can use any other already supported by Orleans. Dockerfile In order to create your container, Docker uses images. For more details on how to create your own, you can check Docker documentation . In this article we are going to use official Microsoft images . Based on the target and development platforms, you need to pick the appropriate image. In this article, we are using microsoft/dotnet:1.1.2-sdk which is a linux-based image. You can use microsoft/dotnet:1.1.2-sdk-nanoserver for Windows for example. Pick one that suit your needs. Note for Windows users : As previously mentioned, to be cross-platform, we are using .Net Core and Orleans Technical preview 2.0 in this article. If you want to use Docker on Windows with the fully released Orleans 1.4+, you need to use the images that are based on Windows Server Core since NanoServer and Linux based images, only support .Net Core. Dockerfile.debug : FROM microsoft/dotnet:1.1.2-sdk ENV NUGET_XMLDOC_MODE skip WORKDIR /vsdbg RUN apt-get update \\ && apt-get install -y --no-install-recommends \\ unzip \\ && rm -rf /var/lib/apt/lists/* \\ && curl -sSL https://aka.ms/getvsdbgsh | bash /dev/stdin -v latest -l /vsdbg WORKDIR /app ENTRYPOINT [\"tail\", \"-f\", \"/dev/null\"] This dockerfile essentially downloads and installs the VSdbg debugger and starts an empty container, keeping it alive forever so we don't need tear down/up while debugging. Now, for production, the image is smaller since it contains only the .Net Core runtime and not the whole SDK, and the dockerfile is a bit simpler: Dockerfile : FROM microsoft/dotnet:1.1.2-runtime WORKDIR /app ENTRYPOINT [\"dotnet\", \"OrleansSilo.dll\"] COPY . /app docker-compose The docker-compose.yml file, essentially defines (within a project) a set of services and its dependencies at service level. Each service contains one or more instances of a given container, which is based on the images you selected on your Dockerfile. More details on the docker-compose can be found on docker-compose documentation . For an Orleans deployment, a common use case is to have a docker-compose.yml which contains two services. One for Orleans Silo, and other for Orleans Client. The Client would have a dependency on the Silo and that means, it will only start after the Silo service is up. Another case is to add a storage/database service/container, like for example SQL Server, which should start first before the client and the silo, so both services should take a dependency on it. Note : Before you read further (and eventually get crazy with it), please note that identation matters in docker-compose files. So pay attention to it if you have any problem. Here is how we will describe our services for this article: docker-compose.override.yml (Debug): version: '3.1' services: orleans-client: image: orleans-client:debug build: context: ./src/OrleansClient/bin/PublishOutput/ dockerfile: Dockerfile.Debug volumes: - ./src/OrleansClient/bin/PublishOutput/:/app - ~/.nuget/packages:/root/.nuget/packages:ro depends_on: - orleans-silo orleans-silo: image: orleans-silo:debug build: context: ./src/OrleansSilo/bin/PublishOutput/ dockerfile: Dockerfile.Debug volumes: - ./src/OrleansSilo/bin/PublishOutput/:/app - ~/.nuget/packages:/root/.nuget/packages:ro docker-compose.yml (production): version: '3.1' services: orleans-client: image: orleans-client depends_on: - orleans-silo orleans-silo: image: orleans-silo Note that in production, we don't map the local directory and neither we have the build: action. The reason is that in production, the images should be built and pushed to your own Docker Registry. Put everything together Now we have all the moving parts required to run your Orleans Application, we are going to put it together so we can run our Orleans solution inside Docker (Finally!). Note : The following commands should be performed from the solution directory. First, lets make sure we restore all NuGet packages from our solution. You only need to do it once. You are only required to do it again if you change any package dependency on your project. # dotnet restore Now, let's build our solution using dotnet CLI as usual and publish it to an output directory: # dotnet publish -o ./bin/PublishOutput Note : We are using publish here instead of build, to avoid problems with our dynamicaly loaded assemblied in Orleans. We are still looking for a better solution for it. With the application built and published, you need to build your Dockerfile images. This step is only required to be performed once per project and should be only performed again if you change the Dockerfile, docker-compose, or for any reason you cleaned up your local image registry. # docker-compose build All the images used in both Dockerfile and docker-compose.yml are pulled from the registry and cached on your development machine. Your images are built, and you are all set to run. Now lets run it! # docker-compose up -d Creating network \"orleansdocker_default\" with the default driver Creating orleansdocker_orleans-silo_1 ... Creating orleansdocker_orleans-silo_1 ... done Creating orleansdocker_orleans-client_1 ... Creating orleansdocker_orleans-client_1 ... done # Now if you run a docker-compose ps , you will see 2 containers running for the orleansdocker project: # docker-compose ps Name Command State Ports ------------------------------------------------------------------ orleansdocker_orleans-client_1 tail -f /dev/null Up orleansdocker_orleans-silo_1 tail -f /dev/null Up Note for Windows users : If you are on Windows, and your container is using a Windows image as base, the Command column will show you the Powershell relative command to a tail on *NIX systems so the container will keep up the same way. Now that you have your containers up, you don't need to stop it every time you want to start your Orleans application. All you need is to integrate your IDE to debug the application inside the container which was previously mapped in your docker-compose.yml . Scaling Once you have your compose project running, you can easily scale up or down your application using docker-compose scale command: # docker-compose scale orleans-silo=15 Starting orleansdocker_orleans-silo_1 ... done Creating orleansdocker_orleans-silo_2 ... Creating orleansdocker_orleans-silo_3 ... Creating orleansdocker_orleans-silo_4 ... Creating orleansdocker_orleans-silo_5 ... Creating orleansdocker_orleans-silo_6 ... Creating orleansdocker_orleans-silo_7 ... Creating orleansdocker_orleans-silo_8 ... Creating orleansdocker_orleans-silo_9 ... Creating orleansdocker_orleans-silo_10 ... Creating orleansdocker_orleans-silo_11 ... Creating orleansdocker_orleans-silo_12 ... Creating orleansdocker_orleans-silo_13 ... Creating orleansdocker_orleans-silo_14 ... Creating orleansdocker_orleans-silo_15 ... Creating orleansdocker_orleans-silo_6 Creating orleansdocker_orleans-silo_5 Creating orleansdocker_orleans-silo_3 Creating orleansdocker_orleans-silo_2 Creating orleansdocker_orleans-silo_4 Creating orleansdocker_orleans-silo_9 Creating orleansdocker_orleans-silo_7 Creating orleansdocker_orleans-silo_8 Creating orleansdocker_orleans-silo_10 Creating orleansdocker_orleans-silo_11 Creating orleansdocker_orleans-silo_15 Creating orleansdocker_orleans-silo_12 Creating orleansdocker_orleans-silo_14 Creating orleansdocker_orleans-silo_13 Few seconds later, you will see the services scaled to the specific number of instances you requested. # docker-compose ps Name Command State Ports ------------------------------------------------------------------ orleansdocker_orleans-client_1 tail -f /dev/null Up orleansdocker_orleans-silo_1 tail -f /dev/null Up orleansdocker_orleans-silo_10 tail -f /dev/null Up orleansdocker_orleans-silo_11 tail -f /dev/null Up orleansdocker_orleans-silo_12 tail -f /dev/null Up orleansdocker_orleans-silo_13 tail -f /dev/null Up orleansdocker_orleans-silo_14 tail -f /dev/null Up orleansdocker_orleans-silo_15 tail -f /dev/null Up orleansdocker_orleans-silo_2 tail -f /dev/null Up orleansdocker_orleans-silo_3 tail -f /dev/null Up orleansdocker_orleans-silo_4 tail -f /dev/null Up orleansdocker_orleans-silo_5 tail -f /dev/null Up orleansdocker_orleans-silo_6 tail -f /dev/null Up orleansdocker_orleans-silo_7 tail -f /dev/null Up orleansdocker_orleans-silo_8 tail -f /dev/null Up orleansdocker_orleans-silo_9 tail -f /dev/null Up Note : The Command column on those examples are showing the tail command just because we are using the debugger container. If we were in production, it would be showing dotnet OrleansSilo.dll for example. Docker Swarm Docker clustering stack is called Swarm and you can find more by reading its documentation here . To run this article in a Swarm cluster, you don't have any extra work. When you run docker-compose up -d in a Swarm node, it will schedule containers based on the configured rules. The same applies to other Swarm-based services like Docker Datacenter , Azure ACS (in Swarm mode), AWS ECS Container Service and so on. All you need to do is to deploy your Swarm cluster before deploy your dockerized Orleans application. Note : If you are using a Docker engine with the Swarm mode that already have support to stack , deploy and compose v3, a better approach to deploy your solution would be docker stack deploy -c docker-compose.yml <name> . Just keep in mind that it requires v3 compose file support at your Docker engine and the majority of hosted services like Azure and AWS still use v2 and older engines. Google Kubernetes (K8s) If you plan to use Kubernetes to host Orleans, there is a community-maintained clustering provider available at OrleansContrib\\Orleans.Clustering.Kubernetes and there you can find documentation and samples on how to host Orleans in Kubernetes seamlessly using the provider. [Bonus topic] Debugging Orleans inside Containers Well, now that you know how to run Orleans in a container from scratch, would be good to leverage one of the most important principles in Docker. Containers are immutable. And they should have (almost) the same image, dependencies, and runtime in development as in production. This ensures the good old statement \"It works on my machine!\" never happens again. To make that possible, you need to have a way to develop inside the container and that includes have a debugger attached to your application inside the container. There are multiple ways to achieve that using multiple tools. After evaluating several, by the time I wrote this article, I ended up choosing one that looks more simple and is less intrusive in the application. As mentioned ealier in this article, we are using VSCode to develop the sample, so here is how to get the debugger attached to your Orleans Application inside the container. First, change two files inside your .vscode directory in your solution: tasks.json : { \"version\": \"0.1.0\", \"command\": \"dotnet\", \"isShellCommand\": true, \"args\": [], \"tasks\": [ { \"taskName\": \"publish\", \"args\": [ \"${workspaceRoot}/Orleans-Docker.sln\", \"-c\", \"Debug\", \"-o\", \"./bin/PublishOutput\" ], \"isBuildCommand\": true, \"problemMatcher\": \"$msCompile\" } ] } This file essentially tells VSCode that whenever you build the project, it will actually execute the publish command as we manually did earlier. launch.json : { \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Silo\", \"type\": \"coreclr\", \"request\": \"launch\", \"cwd\": \"/app\", \"program\": \"/app/OrleansSilo.dll\", \"sourceFileMap\": { \"/app\": \"${workspaceRoot}/src/OrleansSilo\" }, \"pipeTransport\": { \"debuggerPath\": \"/vsdbg/vsdbg\", \"pipeProgram\": \"/bin/bash\", \"pipeCwd\": \"${workspaceRoot}\", \"pipeArgs\": [ \"-c\", \"docker exec -i orleansdocker_orleans-silo_1 /vsdbg/vsdbg --interpreter=vscode\" ] } }, { \"name\": \"Client\", \"type\": \"coreclr\", \"request\": \"launch\", \"cwd\": \"/app\", \"program\": \"/app/OrleansClient.dll\", \"sourceFileMap\": { \"/app\": \"${workspaceRoot}/src/OrleansClient\" }, \"pipeTransport\": { \"debuggerPath\": \"/vsdbg/vsdbg\", \"pipeProgram\": \"/bin/bash\", \"pipeCwd\": \"${workspaceRoot}\", \"pipeArgs\": [ \"-c\", \"docker exec -i orleansdocker_orleans-client_1 /vsdbg/vsdbg --interpreter=vscode\" ] } } ] } Now you can just build the solution from VSCode (which will publish) and start both the Silo and the Client. It will send a docker exec command to the running docker-compose service instance/container to start the debugger to the application and thats it. You have the debugger attached to the container and use it as if it was a locally running Orleans application. The difference now is that it is inside the container, and once you are done, you can just publish the container to your registry and pull it on your Docker hosts in production."
  },
  "Documentation/deployment/troubleshooting_azure_cloud_services_deployments.html": {
    "href": "Documentation/deployment/troubleshooting_azure_cloud_services_deployments.html",
    "title": "Troubleshooting Deployments | Microsoft Orleans Documentation",
    "keywords": "Troubleshooting Deployments This page gives some general guidelines for troubleshooting any issues that occur while deploying to Azure Cloud Services. These are very common issues to watch out for. Be sure to check the logs for more information. Getting a SiloUnavailableException First check to make sure that you are actually starting the silos before attempting to initialize the client. Sometimes the silos take a long time to start so it can be beneficial to try to initialize the client multiple times. If it still throws an exception, then there might be another issue with the silos. Check the silo configuration and make sure that the silos are starting up properly. Common Connection String Issues Using the local connection string when deploying to Azure  the website will fail to connect Using different connection strings for the silos and the front end (web and worker roles)  the website will fail to initialize the client because it cannot connect to the silos The connection string configuration can be checked in the Azure Portal. The logs may not display properly if the connection strings are not set up correctly. Modifying the Configuration Files Improperly Make sure that the proper endpoints are configured in the ServiceDefinition.csdef file or else the deployment will not work. It will give errors saying that it cannot get the endpoint information. Missing Logs Make sure that the connection strings are set up properly. It is likely that the Web.config file in the web role or the app.config file in the worker role were modified improperly. Incorrect versions in these files can cause issues with the deployment. Be careful when dealing with updates. Version Issues Make sure that the same version of Orleans is used in every project in the solution. Not doing this can lead to the worker role recycling. Check the logs for more information. Visual Studio provides some silo startup error messages in the deployment history. Role Keeps Recycling Check that all the appropriate Orleans assemblies are in the solution and have Copy Local set to True. Check the logs to see if there is an unhandled exception while initializing. Make sure that the connection strings are correct. Check the Azure Cloud Services troubleshooting pages for more information. How to Check Logs Use the cloud explorer in Visual Studio to navigate to the appropriate storage table or blob in the storage account. The WADLogsTable is a good starting point for looking at the logs. You might only be logging errors. If you want informational logs as well, you will need to modify the configuration to set the logging severity level. Programmatic configuration: When creating a ClusterConfiguration object, set config.Defaults.DefaultTraceLevel = Severity.Info . When creating a ClientConfiguration object, set config.DefaultTraceLevel = Severity.Info . Declarative configuration: Add <Tracing DefaultTraceLevel=\"Info\" /> to the OrleansConfiguration.xml and/or the ClientConfiguration.xml files. In the diagnostics.wadcfgx file for the web and worker roles, make sure to set the scheduledTransferLogLevelFilter attribute in the Logs element to Information , as this is an additional layer of trace filtering that defines which traces are sent to the WADLogsTable in Azure Storage. You can find more information about this in the Configuration Guide. Compatibility with ASP.NET The razor view engine included in ASP.NET uses the same code generation assemblies as Orleans ( Microsoft.CodeAnalysis and Microsoft.CodeAnalysis.CSharp ). This can present a version compatibility problem at runtime. To resolve this, try upgrading Microsoft.CodeDom.Providers.DotNetCompilerPlatform (this is the NuGet package ASP.NET uses to include the above assemblies) to the latest version, and setting binding redirects like this: <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis.CSharp\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly> <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly>"
  },
  "Documentation/deployment/grain_versioning/backward_compatibility_guidelines.html": {
    "href": "Documentation/deployment/grain_versioning/backward_compatibility_guidelines.html",
    "title": "Backward compatibility guidelines | Microsoft Orleans Documentation",
    "keywords": "Backward compatibility guidelines Writing backward compatible code can be hard and difficult to test. Never change the signature of existing methods Because of the way on how Orleans serializer work, you should never change the signature of existing methods. The following example is correct: [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 Task MyMethod(int arg); // New method added in V2 Task MyNewMethod(int arg, obj o); } This is not correct: [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 Task MyMethod(int arg, obj o); } NOTE : you should not do this change in your code, as it's an example of a bad practice that leads to very bad side-effects. This is an example of what can happen if you just rename the parameter names: let's say that we have the two following interface version deployed in the cluster: [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // return a - b Task<int> Substract(int a, int b); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // return y - x Task<int> Substract(int y, int x); } This methods seems identical. But if the client was called with V1, and the request is handled by a V2 activation: var grain = client.GetGrain<IMyGrain>(0); var result = await grain.Substract(5, 4); // Will return \"-1\" instead of expected \"1\" This is due to how the internal Orleans serializer works. Avoid changing existing method logic It can seems obvious, but you should be very careful when changing the body of an existing method. Unless you are fixing a bug, it is better to just add a new method if you need to modify the code. Example: // V1 public interface MyGrain : IMyGrain { // First method Task MyMethod(int arg) { SomeSubRoutine(arg); } } // V2 public interface MyGrain : IMyGrain { // Method inherited from V1 // Do not change the body Task MyMethod(int arg) { SomeSubRoutine(arg); } // New method added in V2 Task MyNewMethod(int arg) { SomeSubRoutine(arg); NewRoutineAdded(arg); } } Do not remove methods from grain interfaces Unless you are sure that they are no longer used, you should not remove methods from the grain interface. If you want to remove methods, this should be done in 2 steps: Deploy V2 grains, with V1 method marked as Obsolete [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 [Obsolete] Task MyMethod(int arg); // New method added in V2 Task MyNewMethod(int arg, obj o); } When you are sure that no V1 calls are made (effectively V1 is no longer deployed in the running cluster), deploy V3 with V1 method removed [Version(3)] public interface IMyGrain : IGrainWithIntegerKey { // New method added in V2 Task MyNewMethod(int arg, obj o); }"
  },
  "Documentation/deployment/multi-cluster_support/GlobalSingleInstance.html": {
    "href": "Documentation/deployment/multi-cluster_support/GlobalSingleInstance.html",
    "title": "Global-Single-Instance Grains | Microsoft Orleans Documentation",
    "keywords": "Grain Coordination Attributes Developers can indicate when and how clusters should coordinate their grain directories with respect to a particular grain class. The [GlobalSingleInstance] attribute means we want the same behavior as when running Orleans in a single global cluster: that is, route all calls to a single activation of the grain. Conversely, the [OneInstancePerCluster] attribute indicates that each cluster can have its own independent activation. This is appropriate if communication between clusters is undesired. The attributes are placed on grain implementations. For example: using Orleans.MultiCluster; [GlobalSingleInstance] public class MyGlobalGrain : Orleans.Grain, IMyGrain { ... } [OneInstancePerCluster] public class MyLocalGrain : Orleans.Grain, IMyGrain { ... } If a grain class does not specify either one of those attributes, it defaults to [OneInstancePerCluster] , or [GlobalSingleInstance] if the configuration parameter UseGlobalSingleInstanceByDefault is set to true. Protocol for Global-Single-Instance Grains When a global-single-instance (GSI) grain is accessed, and no activation is known to exist, a special GSI activation protocol is executed before activating a new instance. Specifically, a request is sent to all other clusters in the current multi-cluster configuration to check if they already have an activation for this grain. If all responses are negative, a new activation is created in this cluster. Otherwise, the remote activation is used (and a reference to it is cached in the local directory). Protocol for One-Instance-Per-Cluster Grains There is no inter-cluster communication for One-Instance-Per-Cluster grains. They simply use the standard Orleans mechanism independently within each cluster. Inside the Orleans framework itself, the following grain classes are marked with the [OneInstancePerCluster] attribute: ManagementGrain , GrainBasedMembershipTable , and GrainBasedReminderTable . Doubtful Activations If the GSI protocol does not receive conclusive responses from all clusters after 3 retries (or whatever number is specified by the configuration parameter GlobalSingleInstanceNumberRetries ), it creates a new local \"doubtful\" activation optimistically, favoring availability over consistency. Doubtful activations may be duplicates (because some remote cluster that did not respond during the GSI protocol activation may nevertheless have an activation of this grain). Therefore, periodically every 30 seconds (or whatever interval is specified by the configuration parameter GlobalSingleInstanceRetryInterval ) the GSI protocol is run again for all doubtful activations. This ensures that once communication between clusters is restored, duplicate activations can be detected and removed."
  },
  "Documentation/deployment/multi-cluster_support/GossipChannels.html": {
    "href": "Documentation/deployment/multi-cluster_support/GossipChannels.html",
    "title": "Multi-Cluster Communication | Microsoft Orleans Documentation",
    "keywords": "Multi-Cluster Communication The network must be configured in such a way that any Orleans silo can connect to any other Orleans silo via TCP/IP, regardless of where in the world it is located. Exactly how this is achieved is outside of the scope of Orleans, as it depends on how and where silos are deployed. For example, on Windows Azure, we can use VNETs to connect muliple deployments within a region, and gateways to connect VNETs across different regions. Cluster Id Each cluster has its own unique cluster id. The cluster id must be specified in the global configuration. Cluster ids may not be empty, nor may they contain commas. Also, if using Azure Table Storage, cluster ids may not contain the characters forbidden for row keys (/, , #, ?). We recommend using very short strings for the cluster ids, because cluster ids are transmitted frequently and may be stored in storage by some log-view providers. Cluster Gateways Each cluster automatically designates a subset of its active silos to serve as cluster gateways . Cluster gateways directly advertise their IP addresses to other clusters, and can thus serve as \"points of first contact\". By default, at most 10 silos (or whatever number is configured as MaxMultiClusterGateways ) are designated as cluster gateways. Communication between silos in different clusters does not always pass through a gateway. Once a silo has learned and cached the location of a grain activation (no matter in what cluster), it sends messages to that silo directly, even if the silo is not a cluster gateway. Gossip Gossip is a mechanism for clusters to share configuration and status information. As the name suggests, gossip is decentralized and bidirectional: each silo communicates directly with other silos, both in the same cluster and in other clusters, to exchange information in both directions. Content . Gossip contains some or all of the following information: The current time-stamped multi-cluster configuration . A dictionary that contains information about cluster gateways. The key is the silo address, and the value contains (1) a timestamp, (2) the cluster id, and (3) a status, which is either active or inactive. Fast & Slow Propagation . When a gateway changes its status, or when an operator injects a new configuration, this gossip information is immediately sent to all silos, clusters, and gossip channels. This happens fast, but is not reliable. Should the message be lost due to any reasons (e.g. races, broken sockets, silo failures), our periodic background gossip ensures that the information eventually spreads, albeit more slowly. All information is eventually propagated everywhere, and is highly resilient to occasional message loss and failures. All gossip data is timestamped, which ensures that newer information replaces older information regardless of the relative timing of messages. For example, newer multi-cluster configurations replace older ones, and newer information about a gateway replaces older information about that gateway. For more details on the representation of gossip data, see the MultiClusterData class. It has a Merge method that combines gossip data, resolving conflicts using timestamps. Gossip Channels When a silo is first started, or when it is restarted after a failure, it needs to have a way to bootstrap the gossip . This is the role of the gossip channel , which can be configured in the Silo Configuration . On startup, a silo fetches all the information from the gossip channels. After startup, a silo keeps gossiping periodically, every 30 seconds or whatever is configured as BackgroundGossipInterval . Each time it synchronizes its gossip information with a partner randomly selected from all cluster gateways and gossip channels. Notes: Though not strictly required, we recommend to always configure at least two gossip channels, in distinct regions, for better availability. Latency of communication with gossip channels is not critical. Multiple different services can use the same gossip channel without interference, as long as the ServiceId Guid (as specified by their respective configuration) is distinct. There is no strict requirement that all silos use the same gossip channels, as long as the channels are sufficient to let a silo initially connect with the \"gossiping community\" when it starts up. But if a gossip channel is not part of a silo's configuration, and that silo is a gateway, it does not push its status updates to the channel (fast propagation), so it may take longer before those reach the channel via periodic background gossip (slow propagation). Azure-Table-Based Gossip Channel We have already implemented a gossip channel based on Azure Tables. The configuration specifies standard connection strings used for Azure accounts. For example, a configuration could specify two gossip channels with separate Azure storage accounts usa and europe as follows: var silo = new SiloHostBuilder() [...] .Configure<MultiClusterOptions>(options => { [...] options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=usa;AccountKey=...\"); options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=europe;AccountKey=...\") [...] }) [...] Multiple different services can use the same gossip channel without interference, as long as the ServiceId guid specified by their respective configuration is distinct. Other Gossip Channel Implementations We are working on other gossip channel providers, similar to how membership and reminders are packaged for many different storage back-ends."
  },
  "Documentation/deployment/multi-cluster_support/MultiClusterConfiguration.html": {
    "href": "Documentation/deployment/multi-cluster_support/MultiClusterConfiguration.html",
    "title": "Multi-Cluster Configuration | Microsoft Orleans Documentation",
    "keywords": "Multi-Cluster Configuration The multi-cluster configuration determines which clusters are currently part of the multi-cluster. It does not change automatically, but is controlled by the operator. Thus, it is quite different from the membership mechanism used within a cluster, which automatically determines the set of silos that are part of the cluster. We use the following terminology for the clusters in a service: A cluster is active if it has at least one active silo, and inactive otherwise A cluster is joined if it is part of the current multi-cluster configuration, and non-joined otherwise Being active/inactive is independent from being joined/non-joined: all four combinations are possible. All the clusters for a particular service are connected by a gossip network . The gossip network propagates configuration and status information. Injecting a configuration An operator issues configuration changes by injecting them into the multi-cluster network. The configurations can be injected into any cluster, and spread from there to all active clusters. Each new configuration consists of a list of cluster ids that form the multi-cluster. It also has a UTC timestamp that is used to track its propagation through the gossip network. Initially, the multi-cluster configuration is null, which means the multi-cluster list is empty (contains no clusters). Thus, the operator must initially inject a multi-cluster configuration. Once injected, this configuration persists in all connected silos (while running) and in all specified gossip channels (if those channels are persistent). We pose some restrictions on the injection of new configurations that an operator must follow: Each new configuration may add a number of clusters, or remove a number of clusters (but not both at the same time). An operator should not issue a new configuration while a previous configuration change is still being processed. These restrictions ensure that protocols such as the single-instance-protocol can correctly maintain mutual exclusion of activations even under configuration changes. Via Management Grain Multi-cluster configurations can be injected on any node in any cluster, using the Orleans Management Grain. For example, to inject a multi-cluster configuration that consists of the three clusters { us1, eu1, us2 }, we can pass a string enumerable to the management grain: var clusterlist = \"us1,eu1,us2\".Split(','); var mgtGrain = client.GetGrain<IManagementGrain>(0); mgtGrain.InjectMultiClusterConfiguration(clusterlist, \"my comment here\")); The first argument to InjectMultiClusterConfiguration is an enumerable of cluster ids, which is going to define the new multi-cluster configuration. The second argument is an (optional) comment string that can be used to tag configurations with arbitrary information, such as who injected them why. There is an optional third argument, a boolean called checkForLaggingSilosFirst , which defaults to true. It means that the system performs a best-effort check to see if there are any silos anywhere that have not caught up to the current configuration yet, and rejects the change if it finds such a silo. This helps to detect violations of the restriction that only one configuration change should be pending at a time (though it cannot guarantee it under all circumstances). Via Default Configuration In situations where the multi-cluster configuration is known in advance and the deployment is fresh every time (e.g. for testing), we may want to supply a default configuration. The global configuration supports an optional attribute DefaultMultiCluster which takes a comma-separated list of cluster ids: var silo = new SiloHostBuilder() [...] .Configure<MultiClusterOptions>(options => { [...] options.DefaultMultiCluster = new[] { \"us1\", \"eu1\", \"us2\" }; [...] }) [...] After a silo is started with this setting, it checks to see if the current multi-cluster configuration is null, and if so, injects the given configuration with the current UTC timestamp. WARNING. Persistent multi-cluster gossip channels (e.g. based on AzureTable) retain the last injected configuration unless they are deleted explicitly. In that case, specifying a DefaultMulticluster has no effect when re-deploying a cluster because the configuration stored in the gossip channels is not null.> Via Gossip Channel An operator can also inject the configuration directly into the gossip channel. Changes in the channel are picked up and propagated automatically by the periodic background gossip, though possibly very slowly (using the management grain is much faster). A rough estimate on the propagation time is 30 seconds (or whatever gossip interval is specified in the global configuration) times the binary logarithm of the total number of silos in all clusters. But since the gossip pairs are selected randomly, it can be both much quicker or much slower. If using the Azure Table-Based Gossip Channel, operators can inject a new configuration simply by editing the configuration record in the OrleansGossipTable , e.g. using some tool for editing data in Azure tables. The configuration record has the following format: Name Type Value PartitionKey String the ServiceId RowKey String \"CONFIG\" Clusters String comma-separated list of cluster IDs, e.g. \"us1,eu1,us2\" Comment String optional comment GossipTimestamp DateTime UTC timestamp for the configuration NOTE . When editing this record in storage, the GossipTimestamp must also be set to a newer value than it has currently (otherwise the change is ignored). The most convenient and recommended way to do this is to delete the GossipTimestamp field - our gossip channel implementation then automatically replaces it with a correct, current Timestamp (it uses the Azure Table Timestamp). Cluster Addition/Removal Procedures Adding or removing a cluster from the multi-cluster often needs to be coordinated within some larger context. We recommend to always follow the procedures described below when adding/removing clusters from the multi-cluster. Procedure for adding a cluster Start a new Orleans cluster and wait till all silos are up and running. Inject a configuration that contains the new cluster. Start routing user requests to the new cluster. Procedure for removing a cluster Stop routing new user requests to the cluster. Inject a configuration that no longer contains the cluster. Stop all silos of the cluster. Once a cluster has been removed in this way, it can be re-added by following the procedure for adding a new cluster. Activity on Non-Joined Clusters There can be brief, temporary periods of time where a cluster is both active and non-joined: A freshly started cluster may start executing code before it is in the multicluster configuration (between steps 1 and 2 of the procedure for adding a cluster) A cluster that is being decommissioned may still execute code before the silos are shut down (between steps 2 and 3 of the procedure for removing a cluster). During those intermediate situations, the following are possible: For global-single-instance grains: A grain may have a duplicate activation on a non-joined cluster. For versioned grains: activations on non-joined clusters do not receive notifications when the grain state changes."
  },
  "Documentation/deployment/multi-cluster_support/Overview.html": {
    "href": "Documentation/deployment/multi-cluster_support/Overview.html",
    "title": "Multi-Cluster Support | Microsoft Orleans Documentation",
    "keywords": "Multi-Cluster Support Orleans v.1.3.0 added support for federating several Orleans clusters into a loosely connected multi-cluster that acts like a single service. Multi-clusters facilitate geo-distribution of a service, that is, make it easier to run an Orleans application in multiple data-centers around the world. Also, a multi-cluster can be run within a single datacenter to get better failure and performance isolation. All mechanisms are designed with particular attention to (1) minimize communication between clusters, and (2) let each cluster run autonomously even if other clusters fail or become unreachable. Configuration and Operation Below we document how to configure and operate a multi-cluster. Communication . Clusters communicate via the same silo-to-silo connections that are used within a cluster. To exchange status and configuration information, Clusters use a gossip mechanism and gossip channel implementations. Silo Configuration . Silos need to be configured so they know which cluster they belong to (each cluster is identified by a unique string). Also, each silo needs to be configured with connection strings that allow them to connect to one or more gossip channels on startup. Multi-Cluster Configuration Injection . At runtime, the service operator can specify and/or change the multi-cluster configuration , which contains a list of cluster ids, to specify which clusters are part of the current multi-cluster. This is done by calling the management grain in any one of the clusters. Multi-Cluster Grains Below we document how to use multi-cluster functionality at the application level. Global-Single-Instance Grains . Developers can indicate when and how clusters should coordinate their grain directories with respect to a particular grain class. The [GlobalSingleInstance] attribute means we want the same behavior as as when running Orleans in a single global cluster: that is, route all calls to a single activation of the grain. Conversely, the [OneInstancePerCluster] attribute indicates that each cluster can have its own independent activation. This is appropriate if communication between clusters is undesired. Log-View Grains (not in v.1.3.0) . A special type of grain that uses a new API, similar to event sourcing, for synchronizing or persisting grain state. It can be used to automatically and efficiently synchronize the state of a grain between clusters and with storage. Because its synchronization algorithms are safe to use with reentrant grains, and are optimized to use batching and replication, it can perform better than standard grains when a grain is frequently accessed in multiple clusters, and/or when it is written to storage frequently. Support for log-view grains is not part of the master branch yet. We have a prerelease including samples and a bit of documentation in the geo-orleans branch . It is currently being evaluated in production by an early adopter."
  },
  "Documentation/deployment/multi-cluster_support/SiloConfiguration.html": {
    "href": "Documentation/deployment/multi-cluster_support/SiloConfiguration.html",
    "title": "Multi-Cluster Silo Configuration | Microsoft Orleans Documentation",
    "keywords": "Orleans Silo Configuration To get a quick overview, we show all relevant configuration parameters (including optional ones) in XML syntax below: <?xml version=\"1.0\" encoding=\"utf-8\"?> <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <MultiClusterNetwork ClusterId=\"clusterid\" DefaultMultiCluster=\"uswest,europewest,useast\" BackgroundGossipInterval=\"30s\" UseGlobalSingleInstanceByDefault=\"false\" GlobalSingleInstanceRetryInterval=\"30s\" GlobalSingleInstanceNumberRetries=\"3\" MaxMultiClusterGateways=\"10\"> <GossipChannel Type=\"...\" ConnectionString=\"...\"/> <GossipChannel Type=\"...\" ConnectionString=\"...\"/> </MultiClusterNetwork> <SystemStore ... ServiceId=\"some-guid\" .../> </Globals> </OrleansConfiguration> var silo = new SiloHostBuilder() [...] .Configure<ClusterInfo>(options => { options.ClusterId = \"us3\"; options.ServiceId = \"myawesomeservice\"; }) .Configure<MultiClusterOptions>(options => { options.HasMultiClusterNetwork = true; options.DefaultMultiCluster = new[] { \"us1\", \"eu1\", \"us2\" }; options.BackgroundGossipInterval = TimeSpan.FromSeconds(30); options.UseGlobalSingleInstanceByDefault = false; options.GlobalSingleInstanceRetryInterval = TimeSpan.FromSeconds(30); options.GlobalSingleInstanceNumberRetries = 3; options.MaxMultiClusterGateways = 10; options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=usa;AccountKey=...\"); options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=europe;AccountKey=...\") [...] }) [...] As usual, all configuration settings can also be read and written programmatically, via the respective members of the GlobalConfiguration class. The Service Id is an arbitrary ID for identifying this service. It must be the same for all clusters and all silos. The MultiClusterNetwork section is optional - if not present, all multi-cluster support is disabled for this silo. The required parameters ClusterId and GossipChannel are explained in the section on Multi-Cluster Communication . The optional parameters MaxMultiClusterGateways and BackgroundGossipInterval are explained in the section on Multi-Cluster Communication . The optional parameter DefaultMultiCluster is explained in the section on Multi-Cluster Configuration . The optional parameters UseGlobalSingleInstanceByDefault , GlobalSingleInstanceRetryInterval and GlobalSingleInstanceNumberRetries are explained in the section on Global-Single-Instance Grains . Orleans Client Configuration No extra configuration is required for Orleans client. The same client may not connect to silos in different clusters (the silo refuses the connection in that situation)."
  },
  "Documentation/grains/event_sourcing/replicated_instances.html": {
    "href": "Documentation/grains/event_sourcing/replicated_instances.html",
    "title": "Replicated Grains | Microsoft Orleans Documentation",
    "keywords": "Replicated Grains Sometimes, there can be multiple instances of the same grain active, such as when operating a multi-cluster, and using the [OneInstancePerCluster] attribute. The JournaledGrain is designed to support replicated instances with minimal friction. It relies on log-consistency providers to run the necessary protocols to ensure all instances agree on the same sequence of events. In particular, it takes care of the following aspects: Consistent Versions : All versions of the grain state (except for tentative versions) are based on the same global sequence of events. In particular, if two instances see the same version number, then they see the same state. Racing Events : Multiple instances can simultaneously raise an event. The consistency provider resolves this race and ensures everyone agrees on the same sequence. Notifications/Reactivity : After an event is raised at one grain instance, the consistency provider not only updates storage, but also notifies all the other grain instances. For a general discussion of the consistency model see our TechReport and the GSP paper (Global Sequence Protocol). Conditional Events Racing events can be problematic if they have a conflict, i.e. should not both commit for some reason. For example, when withdrawing money from a bank account, two instances may independently determine that there are sufficient funds for a withdrawal, and issue a withdrawal event. But the combination of both events could overdraw. To avoid this, the JournaledGrain API supports a RaiseConditionalEvent method. bool success = await RaiseConditionalEvent(new WithdrawalEvent() { ... }); Conditional events double-check if the local version matches the version in storage. If not, it means the event sequence has grown in the meantime, which means this event has lost a race against some other event. In that case, the conditional event is not appended to the log, and RaiseConditionalEvent returns false. This is the analogue of using e-tags with conditional storage updates, and likewise provides a simple mechanism to avoid committing conflicting events. It is possible and sensible to use both conditional and unconditional events for the same grain, such as a DepositEvent and a WithdrawalEvent . Deposits need not be conditional: even if a DepositEvent loses a race, it does not have to be cancelled, but can still be appended to the global event sequence. Awaiting the task returned by RaiseConditionalEvent is sufficient to confirm the event, i.e. it is not necessary to also call ConfirmEvents . Explicit Synchronization Sometimes, it is desirable to ensure that a grain is fully caught up with the latest version. This can be enforced by calling await RefreshNow(); which both (1) confirms all unconfirmed events, and (2) loads the latest version from storage."
  },
  "Documentation/grains/grain_persistence/index.html": {
    "href": "Documentation/grains/grain_persistence/index.html",
    "title": "Grain Persistence | Microsoft Orleans Documentation",
    "keywords": "Grain Persistence Goals Allow different grain types to use different types of storage providers (e.g., one uses Azure table, and one uses an ADO.NET one) or the same type of storage provider but with different configurations (e.g., both use Azure table, but one uses storage account #1 and one uses storage account #2) Allow configuration of a storage provider instance to be swapped (e.g., Dev-Test-Prod) with just config file changes, and no code changes required. Provide a framework to allow additional storage providers to be written later, either by the Orleans team or others. Provide a minimal set of production-grade storage providers Storage providers have complete control over how they store grain state data in persistent backing store. Corollary: Orleans is not providing a comprehensive ORM storage solution, but allows custom storage providers to support specific ORM requirements as and when required. Grain Persistence API Grain types can be declared in one of two ways: Extend Grain if they do not have any persistent state, or if they will handle all persistent state themselves, or Extend Grain<T> if they have some persistent state that they want the Orleans runtime to handle. Stated another way, by extending Grain<T> a grain type is automatically opted-in to the Orleans system managed persistence framework. For the remainder of this section, we will only be considering Option #2 / Grain<T> because Option #1 grains will continue to run as now without any behavior changes. Grain State Storage Grain classes that inherit from Grain<T> (where T is an application-specific state data type that needs to be persisted) will have their state loaded automatically from a specified storage. Grains will be marked with a [StorageProvider] attribute that specifies a named instance of a storage provider to use for reading / writing the state data for this grain. [StorageProvider(ProviderName=\"store1\")] public class MyGrain<MyGrainState> ... { ... } The Orleans framework provides a mechanism to specify & register different storage providers and configure them using ISiloHostBuilder , var silo = new SiloHostBuilder() .AddMemoryGrainStorage(\"DevStore\") .AddAzureTableGrainStorage(\"store1\", options => options.ConnectionString = \"DefaultEndpointsProtocol=https;AccountName=data1;AccountKey=SOMETHING1\") .AddAzureBlobGrainStorage(\"store2\", options => options.ConnectionString = \"DefaultEndpointsProtocol=https;AccountName=data2;AccountKey=SOMETHING2\") .Build(); Configuring IGrainStorage Providers Orleans natively supports a range of IGrainStorage implementations, which you can use for your application to store grain state. In this section, we will go over how to configure AzureTableGrainStorage , AzureBlobGrainStorage , DynamoDBGrainStorage , MemoryGrainStorage , and AdoNetGrainStorage in a silo. Configuration of other IGrainStorage providers is similar. AzureTableGrainStorage Provider var silo = new SiloHostBuilder() .AddAzureTableGrainStorage(\"TableStore\", options => options.ConnectionString = \"UseDevelopmentStorage=true\") ... .Build(); The following settings are available for configuring AzureTableGrainStorage providers, through AzureTableGrainStorageOptions : /// <summary> /// Configuration for AzureTableGrainStorage /// </summary> public class AzureTableStorageOptions { /// <summary> /// Azure table connection string /// </summary> [RedactConnectionString] public string ConnectionString { get; set; } /// <summary> /// Table name where grain stage is stored /// </summary> public string TableName { get; set; } = DEFAULT_TABLE_NAME; public const string DEFAULT_TABLE_NAME = \"OrleansGrainState\"; /// <summary> /// Indicates if grain data should be deleted or reset to defaults when a grain clears it's state. /// </summary> public bool DeleteStateOnClear { get; set; } = false; /// <summary> /// Stage of silo lifecycle where storage should be initialized. Storage must be initialzed prior to use. /// </summary> public int InitStage { get; set; } = DEFAULT_INIT_STAGE; public const int DEFAULT_INIT_STAGE = ServiceLifecycleStage.ApplicationServices; #region json serialization public bool UseJson { get; set; } public bool UseFullAssemblyNames { get; set; } public bool IndentJson { get; set; } public TypeNameHandling? TypeNameHandling { get; set; } #endregion json serialization } Note: State size should not exceed 64KB, a limit imposed by Azure Table Storage. AzureBlobGrainStorage Provider var silo = new SiloHostBuilder() .AddAzureBlobGrainStorage(\"BlobStore\", options => options.ConnectionString = \"UseDevelopmentStorage=true\") ... .Build(); The following settings are available for configuring AzureBlobGrainStorage providers, through AzureBlobStorageOptions : public class AzureBlobStorageOptions { /// <summary> /// Azure connection string /// </summary> [RedactConnectionString] public string ConnectionString { get; set; } /// <summary> /// Container name where grain stage is stored /// </summary> public string ContainerName { get; set; } = DEFAULT_CONTAINER_NAME; public const string DEFAULT_CONTAINER_NAME = \"grainstate\"; /// <summary> /// Stage of silo lifecycle where storage should be initialized. Storage must be initialzed prior to use. /// </summary> public int InitStage { get; set; } = DEFAULT_INIT_STAGE; public const int DEFAULT_INIT_STAGE = ServiceLifecycleStage.ApplicationServices; #region json serialization public bool UseJson { get; set; } public bool UseFullAssemblyNames { get; set; } public bool IndentJson { get; set; } public TypeNameHandling? TypeNameHandling { get; set; } #endregion json serialization } DynamoDBGrainStorage Provider var silo = new SiloHostBuilder() .AddDynamoDBGrainStorage(\"DDBStore\", options => { options.AccessKey = \"MY_ACCESS_KEY\"; options.SecretKey = \"MY_SECRET_KEY\"; options.Service = \"us-wes-1\"; }) ... .Build(); The following settings are available for configuring DynamoDBGrainStorage providers, through DynamoDBStorageOptions : public class DynamoDBStorageOptions { /// <summary> /// Gets or sets a unique identifier for this service, which should survive deployment and redeployment. /// </summary> public string ServiceId { get; set; } = string.Empty; /// <summary> /// AccessKey string for DynamoDB Storage /// </summary> [Redact] public string AccessKey { get; set; } /// <summary> /// Secret key for DynamoDB storage /// </summary> [Redact] public string SecretKey { get; set; } /// <summary> /// DynamoDB Service name /// </summary> public string Service { get; set; } /// <summary> /// Read capacity unit for DynamoDB storage /// </summary> public int ReadCapacityUnits { get; set; } = DynamoDBStorage.DefaultReadCapacityUnits; /// <summary> /// Write capacity unit for DynamoDB storage /// </summary> public int WriteCapacityUnits { get; set; } = DynamoDBStorage.DefaultWriteCapacityUnits; /// <summary> /// DynamoDB table name. /// Defaults to 'OrleansGrainState'. /// </summary> public string TableName { get; set; } = \"OrleansGrainState\"; /// <summary> /// Indicates if grain data should be deleted or reset to defaults when a grain clears it's state. /// </summary> public bool DeleteStateOnClear { get; set; } = false; /// <summary> /// Stage of silo lifecycle where storage should be initialized. Storage must be initialzed prior to use. /// </summary> public int InitStage { get; set; } = DEFAULT_INIT_STAGE; public const int DEFAULT_INIT_STAGE = ServiceLifecycleStage.ApplicationServices; #region JSON Serialization public bool UseJson { get; set; } public bool UseFullAssemblyNames { get; set; } public bool IndentJson { get; set; } public TypeNameHandling? TypeNameHandling { get; set; } #endregion } ADO.NET Grain Storage Provider The ADO .NET Grain Storage provider allows you to store grain state in relational databases. Currently following databases are supported: SQL Server MySQL/MariaDB PostgreSQL Oracle First, install the base package: Install-Package Microsoft.Orleans.Persistence.AdoNet After you restore on the nuget package for your project, you will find different SQL scripts for the supported database vendors, which are copied to project directory \\OrleansAdoNetContent where each of supported ADO.NET extensions has its own directory.You can also get them from the Orleans.Persistence.AdoNet repository . Create a database, and then run the appropriate script to create the tables. The next steps are to install a second NuGet package (see table below) specific to the database vendor you want, and to configure the storage provider either programmatically or via XML configuration. Database Script NuGet Package AdoInvariant Remarks SQL Server SQLServer-Persistence.sql System.Data.SqlClient System.Data.SqlClient MySQL / MariaDB MySQL-Persistence.sql MySql.Data MySql.Data.MySqlClient PostgreSQL PostgreSQL-Persistence.sql Npgsql Npgsql Oracle Oracle-Persistence.sql ODP.net Oracle.DataAccess.Client No .net Core support The following is an example of how to configure an ADO.NET storage provider via ISiloHostBuilder : var siloHostBuilder = new SiloHostBuilder() .AddAdoNetGrainStorage(\"OrleansStorage\", options=> { options.Invariant = \"<Invariant>\"; options.ConnectionString = \"<ConnectionString>\"; options.UseJsonFormat = true; }); Essentially, you only need to set the database-vendor-specific connection string and an Invariant (see table above) that identifies the vendor. You may also choose the format in which the data is saved, which may be either binary (default), JSON, or XML. While binary is the most compact option, it is opaque and you will not be able to read or work with the data. JSON is the recommended option. You can set the following properties via AdoNetGrainStorageOptions : /// <summary> /// Options for AdonetGrainStorage /// </summary> public class AdoNetGrainStorageOptions { /// <summary> /// Connection string for AdoNet storage. /// </summary> [Redact] public string ConnectionString { get; set; } /// <summary> /// Stage of silo lifecycle where storage should be initialized. Storage must be initialzed prior to use. /// </summary> public int InitStage { get; set; } = DEFAULT_INIT_STAGE; /// <summary> /// Default init stage in silo lifecycle. /// </summary> public const int DEFAULT_INIT_STAGE = ServiceLifecycleStage.ApplicationServices; /// <summary> /// The default ADO.NET invariant used for storage if none is given. /// </summary> public const string DEFAULT_ADONET_INVARIANT = AdoNetInvariants.InvariantNameSqlServer; /// <summary> /// The invariant name for storage. /// </summary> public string Invariant { get; set; } = DEFAULT_ADONET_INVARIANT; #region json serialization related settings /// <summary> /// Whether storage string payload should be formatted in JSON. /// <remarks>If neither <see cref=\"UseJsonFormat\"/> nor <see cref=\"UseXmlFormat\"/> is set to true, then BinaryFormatSerializer will be configured to format storage string payload.</remarks> /// </summary> public bool UseJsonFormat { get; set; } public bool UseFullAssemblyNames { get; set; } public bool IndentJson { get; set; } public TypeNameHandling? TypeNameHandling { get; set; } #endregion /// <summary> /// Whether storage string payload should be formatted in Xml. /// <remarks>If neither <see cref=\"UseJsonFormat\"/> nor <see cref=\"UseXmlFormat\"/> is set to true, then BinaryFormatSerializer will be configured to format storage string payload.</remarks> /// </summary> public bool UseXmlFormat { get; set; } } The ADO.NET persistence has functionality to version data and define arbitrary (de)serializers with arbitrary application rules and streaming, but currently there is no method to expose them to application code. More information in ADO.NET Persistence Rationale . MemoryGrainStorage MemoryGrainStorage is a simple grain storage implementation which does not really use a persistent data store underneath. It is convenient to learn to work with Grain Storages quickly, but is not intended to be used in production scenarios. Note: This provider persists state to volatile memory which is erased at silo shut down. Use only for testing. Here's how to set up a memory storage provider via ISiloHostBuilder var siloHostBuilder = new SiloHostBuilder() .AddMemoryGrainStorage(\"OrleansStorage\", options=>options.NumStorageGrains = 10); You can set the following configuration properties via MemoryGrainStorageOptions /// <summary> /// Options for MemoryGrainStorage /// </summary> public class MemoryGrainStorageOptions { /// <summary> /// Default number of queue storage grains. /// </summary> public const int NumStorageGrainsDefaultValue = 10; /// <summary> /// Number of store grains to use. /// </summary> public int NumStorageGrains { get; set; } = NumStorageGrainsDefaultValue; /// <summary> /// Stage of silo lifecycle where storage should be initialized. Storage must be initialzed prior to use. /// </summary> public int InitStage { get; set; } = DEFAULT_INIT_STAGE; /// <summary> /// Default init stage /// </summary> public const int DEFAULT_INIT_STAGE = ServiceLifecycleStage.ApplicationServices; } Notes on Storage Providers If there is no [StorageProvider] attribute specified for a Grain<T> grain class, then a provider named Default will be searched for instead. If not found then this is treated as a missing storage provider. If a storage provider referenced by a grain class is not added to silo at configuration time, grains of that type will fail to activate at run time, and calls to them will be failing an Orleans.Storage.BadProviderConfigException error specifying that the grain type is not loaded. But the rest of the grain types will not be affected. Different grain types can use different configured storage providers, even if both are the same type: for example, two different Azure table storage provider instances, connected to different Azure storage accounts (see config file example above). All configuration details for storage providers is defined through ISiloHostBuilder. There are no mechanisms provided at this time to dynamically update or change the list of storage providers used by a silo. However, this is a prioritization / workload constraint rather than a fundamental design constraint. State Persitence API There are two parts to the state persistence APIs: grain state API and storage provider API. Grain State API The grain state storage functionality in the Orleans Runtime will provide read and write operations to automatically populate / save the GrainState data object for that grain. Under the covers, these functions will be connected (within the code generated by Orleans client-gen tool) through to the appropriate persistence provider configured for that grain. Grain State Read / Write Functions Grain state will automatically be read when the grain is activated, but grains are responsible for explicitly triggering the write for any changed grain state as and when necessary. See the Failure Modes section below for details of error handling mechanisms. GrainState will be read automatically (using the equivalent of base.ReadStateAsync() ) before the OnActivateAsync() method is called for that activation. GrainState will not be refreshed before any method calls to that grain, unless the grain was activated for this call. During any grain method call, a grain can request the Orleans runtime to write the current grain state data for that activation to the designated storage provider by calling base.WriteStateAsync() . The grain is responsible for explicitly performing write operations when they make significant updates to their state data. Most commonly, the grain method will return the base.WriteStateAsync() Task as the final result Task returned from that grain method, but it is not required to follow this pattern. The runtime will not automatically update stored grain state after any grain methods. During any grain method or timer callback handler in the grain, the grain can request the Orleans runtime to re-read the current grain state data for that activation from the designated storage provider by calling base.ReadStateAsync() . This will completely overwrite any current state data currently stored in the grain state object with the latest values read from persistent store. An opaque provider-specific Etag value ( string ) may be set by a storage provider as part of the grain state metadata populated when state was read. Some providers may choose to leave this as null if they do not use Etag s. Conceptually, the Orleans Runtime will take a deep copy of the grain state data object for its own use during any write operations. Under the covers, the runtime may use optimization rules and heuristics to avoid performing some or all of the deep copy in some circumstances, provided that the expected logical isolation semantics are preserved. Sample Code for Grain State Read / Write Operations Grains must extend the Grain<T> class in order to participate in the Orleans grain state persistence mechanisms. The T in the above definition will be replaced by an application-specific grain state class for this grain; see the example below. The grain class should also be annotated with a [StorageProvider] attribute that tells the runtime which storage provider (instance) to use with grains of this type. public class MyGrainState { public int Field1 { get; set; } public string Field2 { get; set; } } [StorageProvider(ProviderName=\"store1\")] public class MyPersistenceGrain : Grain<MyGrainState>, IMyPersistenceGrain { ... } Grain State Read The initial read of the grain state will occur automatically by the Orleans runtime before the grains OnActivateAsync() method is called; no application code is required to make this happen. From that point forward, the grains state will be available through the Grain<T>.State property inside the grain class. Grain State Write After making any appropriate changes to the grains in-memory state, the grain should call the base.WriteStateAsync() method to write the changes to the persistent store via the defined storage provider for this grain type. This method is asynchronous and returns a Task that will typically be returned by the grain method as its own completion Task. public Task DoWrite(int val) { State.Field1 = val; return base.WriteStateAsync(); } Grain State Refresh If a grain wishes to explicitly re-read the latest state for this grain from backing store, the grain should call the base.ReadStateAsync() method. This will reload the grain state from persistent store, via the defined storage provider for this grain type, and any previous in-memory copy of the grain state will be overwritten and replaced when the ReadStateAsync() Task completes. public async Task<int> DoRead() { await base.ReadStateAsync(); return State.Field1; } Failure Modes for Grain State Persistence Operations Failure Modes for Grain State Read Operations Failures returned by the storage provider during the initial read of state data for that particular grain will result in the activate operation for that grain to be failed; in this case, there will not be any call to that grains OnActivateAsync() life cycle callback method. The original request to that grain which caused the activation will be faulted back to the caller the same way as any other failure during grain activation. Failures encountered by the storage provider to read state data for a particular grain will result in the ReadStateAsync() Task to be faulted. The grain can choose to handle or ignore that faulted Task , just like any other Task in Orleans. Any attempt to send a message to a grain which failed to load at silo startup time due to a missing / bad storage provider config will return the permanent error Orleans.BadProviderConfigException . Failure Modes for Grain State Write Operations Failures encountered by the storage provider to write state data for a particular grain will result in the WriteStateAsync() Task to be faulted. Usually, this will mean the grain call will be faulted back to the client caller provided the WriteStateAsync() Task is correctly chained in to the final return Task for this grain method. However, it will be possible for certain advanced scenarios to write grain code to specifically handle such write errors, just like they can handle any other faulted Task . Grains that execute error-handling / recovery code must catch exceptions / faulted WriteStateAsync() Task s and not re-throw to signify that they have successfully handled the write error. Storage Provider API There is a service provider API for writing additional persistence providers  IGrainStorage . The Persistence Provider API covers read and write operations for GrainState data. /// <summary> /// Interface to be implemented for a storage able to read and write Orleans grain state data. /// </summary> public interface IGrainStorage { /// <summary>Read data function for this storage instance.</summary> /// <param name=\"grainType\">Type of this grain [fully qualified class name]</param> /// <param name=\"grainReference\">Grain reference object for this grain.</param> /// <param name=\"grainState\">State data object to be populated for this grain.</param> /// <returns>Completion promise for the Read operation on the specified grain.</returns> Task ReadStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); /// <summary>Write data function for this storage instance.</summary> /// <param name=\"grainType\">Type of this grain [fully qualified class name]</param> /// <param name=\"grainReference\">Grain reference object for this grain.</param> /// <param name=\"grainState\">State data object to be written for this grain.</param> /// <returns>Completion promise for the Write operation on the specified grain.</returns> Task WriteStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); /// <summary>Delete / Clear data function for this storage instance.</summary> /// <param name=\"grainType\">Type of this grain [fully qualified class name]</param> /// <param name=\"grainReference\">Grain reference object for this grain.</param> /// <param name=\"grainState\">Copy of last-known state data object for this grain.</param> /// <returns>Completion promise for the Delete operation on the specified grain.</returns> Task ClearStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); } Storage Provider Semantics Any attempt to perform a write operation when the storage provider detects an Etag constraint violation should cause the write Task to be faulted with transient error Orleans.InconsistentStateException and wrapping the underlying storage exception. public class InconsistentStateException : AggregateException { /// <summary>The Etag value currently held in persistent storage.</summary> public string StoredEtag { get; private set; } /// <summary>The Etag value currently held in memory, and attempting to be updated.</summary> public string CurrentEtag { get; private set; } public InconsistentStateException( string errorMsg, string storedEtag, string currentEtag, Exception storageException ) : base(errorMsg, storageException) { this.StoredEtag = storedEtag; this.CurrentEtag = currentEtag; } public InconsistentStateException(string storedEtag, string currentEtag, Exception storageException) : this(storageException.Message, storedEtag, currentEtag, storageException) { } } Any other failure conditions from a write operation should cause the write Task to be broken with an exception containing the underlying storage exception. Data Mapping Individual storage providers should decide how best to store grain state  blob (various formats / serialized forms) or column-per-field are obvious choices. The basic storage provider for Azure Table encodes state data fields into a single table column using Orleans binary serialization. ADO.NET Persistence Rationale The principles for ADO.NET backed persistence storage are: Keep business critical data safe an accessible while data, the format of data and code evolve. Take advantenge of vendor and storage specific functionality. In practice this means adhering to ADO.NET implementation goals and some added implementation logic in ADO.NET specific storage provider that allow evolving the shape of the data in the storage. In addition to the usual storage provider capabilities, the ADO.NET provider has built-in capability to Change storage data format from one format to another format (e.g. from JSON to binary) when roundtripping state. Shape the type to be saved or read from the storage in arbitrary ways. This helps to evolve the version state. Stream data out of the database. Both 1. and 2. can be applied on arbitrary decision parameters, such as grain ID , grain type , payload data . This happen so that one chooses a format, e.g. Simple Binary Encoding (SBE) and implements IStorageDeserializer and IStorageSerializer . The built-in (de)serializers have been built using this method. The OrleansStorageDefault (De)Serializer can be used as examples on how to implement other formats. When the (de)serializers have been implemented, they need to ba added to the StorageSerializationPicker property in AdoNetGrainStorage . This is an implementation of IStorageSerializationPicker . By default StorageSerializationPicker will be used. And example of changing data storage format or using (de)serializers can be seen at RelationalStorageTests . Currently there is no method to expose this to Orleans application consumption as there is no method to access the framework created AdoNetGrainStorage ."
  },
  "Documentation/grains/grain_persistence/relational_storage.html": {
    "href": "Documentation/grains/grain_persistence/relational_storage.html",
    "title": "Relational Storage | Microsoft Orleans Documentation",
    "keywords": "Relational Storage Relational storage backend code in Orleans is built on generic ADO.NET functionality and is consequently database vendor agnostic. The Orleans data storage layout has been explained already in Runtime Tables. Setting up the connection strings are done as explained in Orleans Configuration Guide and SQL Tables . To make Orleans code function with a given relational database backend, the following is required: Appropriate ADO.NET library must be loaded to the process (multiple can exist in GAC or otherwise). This should be defined as usual, e.g. via DbProviderFactories element in application configuration. Configure the ADO.NET invariant via AdoInvariant attribute in the element defining the connection string, by default it is System.Data.SqlClient The database needs to exist and be compatible with the code. This is done by running a vendor specific database creation script. The scripts are found in the OrleansSqlUtils NuGet package and are published with every Orleans release. Currently there are two database scripts: SQL Server - CreateOrleansTables_SqlServer.sql . AdoInvariant is System.Data.SqlClient . MySQL - CreateOrleansTables_MySql.sql . AdoInvariant is MySql.Data.MySqlClient . If you need setup scripts for other ADO.NET supported databases, open an issue or please, stop by at Orleans Gitter . Goals of the design 1. Allow use of any backend that has a ADO.NET provider This should cover the broadest possible set of backends available for .NET, which is a factor in on-premises installations. Some providers are listed at ADO.NET Data Providers MSDN page , but for the sake of a remark, not all are listed, such as Teradata . 2. Maintain the potential to tune queries and database structure as appropriate, even while a deployment is running In many cases, the servers and databases are hosted by a third party in contractual relation with the client. It is not an unusual situation the hosting environment is virtualized and performance fluctuates due to unforeseen factors, such as noisy neighbors or faulty hardware. It may not be possible to alter and re-deploy either Orleans binaries (contractual reasons) or even application binaries, but usually it is possible to tweak the database deployment. Altering standard components , such as Orleans binaries, requires a lenghtier procedure as to what is afforded in a given situation. 3. Allow one to make use of vendor and version specific abilities Vendors have implemented different extensions and features within their products. It is sensible to make use of these features when they are available. These features are such as native UPSERT or PipelineDB in PostgreSQL, PolyBase or natively compiled tables and stored procedures in SQL Server  and myriads of other features. 4. Make it possible to optimize hardware resources When designing an application, it is often possible to anticipate which data needs to be inserted faster than other data and which data could be more likely put into cold storage which is cheaper (e.g. splitting data between SSD and HDD). As for an example, further considerations are that the physical location of some data could be more expensive (e.g. SSD RAID viz HDD RAID), more secured or some other decision attribute used. Related to point 3. Some databases offer special partitioning schemes, such as SQL Server Partitioned Tables and Indexes . This principle applies also throughout the application life-cycle. Considering one of the principles of Orleans itself is a high-availability system, it should be possible to adjust storage system without interruption to Orleans deployment or that it should be possible to adjust the queries according to data and other application parameters. One example of changes is in Brian Harry's blog post When a table is small, it almost doesnt matter what the query plan is. When its medium an OK query plan is fine. When it's huge (millions upon millions or billions of rows) a tiny, slight variation in query plan can kill you. So, we hint our sensitive queries heavily. This is true in general. 5. No assumptions on what tools, libraries or deployment processes are used in organizations Many organizations have familiarity with a certain set of database tools, examples being Dacpac or Red Gate . It may be so that deploying a database requires either a permission or a person, such as someone in a DBA role, to do it. Usually this means also having the target database layout and a rough sketch of the queries the application will produce to the database to be used estimate the load. There might be processes, perhaps influenced by industry standards, which mandate script based deployment. Having the queries and database structures in an external script makes this possible. 6. Use the minimum set needed of interface functionality to load the ADO.NET libraries and functionality This is both fast and has less surface to be exposed to ADO.NET library implementation discrepancies. 7. Make the design shardable When it makes sense, for instance in relational storage provider, make the design readily shardable. This means for instance no database dependent data (e.g. IDENTITY ) and basically it means the information that distinguishes row data should build on only data from the actual parameters. 8. Make the design easy to test Creating a new backend should be ideally as easy as translating one of the deployment scripts and adding a new connection string to tests assuming default parameters, check if a given database is installed and then run the tests against it. 9. Taking into account the previous points, make both porting scripts for new backends and modifying already deployed backend scripts as transparent as possible Realization of the goals Orleans framework does not have knowledge of deployment specific hardware (which may change during active deployment), the change of data during the deployment life-cycle and some vendor specific features are usable in only some situations. For this reason, the interface between relational database and Orleans should adhere a minimum set of abstractions and rules to meet the goals but to make it also robust against misuse and easy to test if needed. Runtime Tables, Cluster Management and the concrete membership protocol implementation . Also, the SQL Server implementation contains SQL Server edition specific tuning. The interface contract between the database and Orleans is defined as follows: The general idea is that data is read and written through Orleans specific queries. Orleans operates on column names and types when reading and on parameter names and types when writing. The implementations must preserve input and output names and types. Orleans uses these parameters to reads query results by name and type. Vendor and deployment specific tuning is allowed and contributions are encouraged as long as the interface contract is maintained. The implementation across vendor specific scripts should preserve the constraint names. This simplifies troubleshooting by virtue of uniform naming across concrete implementations. Version  or ETag in application code  for Orleans represents a unique version. The type of its actual implementation is not important as long as it represents a unique version. In the implementation Orleans code excepts a signed 32-bit integer. For the sake of being explicit and removing ambiguity, Orleans expects some queries to return either TRUE as > 0 value or FALSE as = 0 value. That is, affected rows or such does not matter. If an error is raised or an exception is thrown the query must ensure the entire transaction is rolled back and may either return FALSE or propagate the exception. Currently all but one query are single row inserts or updates (note, one could replace UPDATE queries with INSERT ones provided the associated SELECT queries would provide the last write) except for statistic inserts. Statistic insert, as defined by InsertOrleansStatisticsKey writes the statistics in batches of predefined maximum size using UNION ALL for all databases except for Oracle, for which a UNION ALL FROM DUAL construct is used. InsertOrleansStatisticsKey is the only query that defines a kind of a template parameters of which Orleans multiplies as many times as there are parameters with differing values. Database engines support in-database programming, this is is similar to an idea of loading an executable script and invoke it to execute database operations. In pseudocode it could be depicted as const int Param1 = 1; const DateTime Param2 = DateTime.UtcNow; const string queryFromOrleansQueryTableWithSomeKey = \"SELECT column1, column2 FROM <some Orleans table> where column1 = @param1 AND column2 = @param2;\"; TExpected queryResult = SpecificQuery12InOrleans<TExpected>(query, Param1, Param2); These principles are also included in the database scripts . Some ideas on applying customized scripts Alter scripts in OrleansQuery for grain persistence with IF ELSE so that some state is saved using the default INSERT while some grain state uses, for instance, memory optimized tables . The SELECT queries need to be altered accordingly. The idea in 1. can be used to take advantage of other deployment or vendor specific aspects. Such as splitting data between SSD or HDD , putting some data on encrypted tables, or perhaps inserting statistics data via SQL Server to Hadoop or even linked servers . The altered scripts can be tested running the Orleans test suite or straight in the database using, for instance, SQL Server Unit Test Project . Guidelines for adding new ADO.NET providers Add a new database setup script according to the Realization of the goals section above. Add the vendor ADO invariant name to AdoNetInvariants and ADO.NET provider specific data to DbConstantsStore . These are (potentially) used in some query operations. e.g. to select the correct statistics insert mode (i.e. the UNION ALL with or without FROM DUAL ). Orleans has comprehensive tests for all system stores: membership, reminders and statistics. Adding tests for the new database script is done by copy-pasting existing test classes and changing the ADO invariant name. Also, derive from RelationalStorageForTesting in order to define test functionality for the ADO invariant."
  },
  "Documentation/resources/orleans_thinking_big_and_small.html": {
    "href": "Documentation/resources/orleans_thinking_big_and_small.html",
    "title": "Orleans - Thinking Big and Small | Microsoft Orleans Documentation",
    "keywords": "TL;DR: You dont need hundreds of servers to benefit from Orleans. A handful is enough. As we just announced availability of the Project Orleans as a public preview ( Available Now: Preview of Project Orleans  Cloud Services at Scale ), some of the initial questions and discussions at //build/ were around what type of services the Orleans programming model is suitable for. I heard statements that Orleans is for super-high scale systems. While technically correct, they felt incomplete to me, and compelled me to write this post. Applicability Spectrum One extreme of the Orleans applicability spectrum is a single machine application. Some people see isolation of actors and safe concurrency as big enough benefits that they are worth the price of message passing. Thats not the use case we optimized for while building Orleans, but its a legitimate usage pattern, just not very interesting in the cloud context. At the other end of the spectrum we find massive deployments that span thousands of servers. We tested Orleans on deployments of hundreds of servers, and Im sure it will run fine on thousands, even if that will require some configuration tweaks. However, Im personally rather skeptical about how many products actually need a single cloud service spanning thousands of servers as opposed to running multiple related services interacting with each other where each service instance is deployed on tens or hundreds of servers. Distributed system  same problems regardless of the size The moment a system moves from a single server to multiple servers, developers face very much the same set of challenges, regardless of its size -- whether it's a 3-5, 30-50 or 300-500 server system. They now have to deal with distribution of their computations, coordination between them, scalability, fault tolerance and reconfigurations, diagnostics, etc. They are building a distributed system now, which is never easy. And building a stateful distributed system is even harder. Orleans was designed to help with building such systems by providing an easy to use set of abstractions that greatly simplifies developers lives and helps them avoid common distributed systems pitfalls. The distributed runtime was built to perform most of the heavy lifting. Developers can equally benefit from these features of Orleans when building services of different sizes because the problems Orleans solves for them are really the same. The abstraction of grains simplifies reasoning about your system while encouraging fine-grain partitioning of state for scalability. The virtual actor feature helps with resource management and fault tolerance. Automatic propagation of exceptions minimizes error handling code without losing failures. The distributed runtime takes care of server failures, messaging, routing, single-threaded execution, and other system level guarantees. You dont need hundreds of servers to start reaping the developer productivity gains. Elasticity Predicting load for your future system is hard and often simply impossible. Every startup dreams of getting slashdotted one day, which is a blessing for the business and a curse for the system. Or your CMO may like your BI data so much that she suddenly wants to have it in 5 second aggregates instead of 30 minutes. Building for high load that may never materialize is expensive. The Orleans model helps solve the elasticity problem by encouraging designing your system in a scalable way, so that you can start with a small deployment and stay small or scale out big if needed without changing your application code. Bottom Line You should be able to benefit from Orleans the moment you go from a single-server setup to a distributed system, whether its 2 or 3 servers or thousands of them. You can even start building your single-server solution with Orleans if you believe you may need one day scale it out or make fault tolerant. The beauty here is that your code wont need to change. Just add more servers and your grains will spread across them. -Sergey Bykov"
  },
  "Documentation/resources/orleans_architecture_principles_and_approach_I.html": {
    "href": "Documentation/resources/orleans_architecture_principles_and_approach_I.html",
    "title": "Orleans Architecture - Principles and Approach I | Microsoft Orleans Documentation",
    "keywords": "Now that Orleans is (finally) available as open source, it's important to be clear about the goals and principles that has motivated the design decisions behind Orleans so that new changes either fit within that framework or explicitly and intentionally revise those goals and principles. About the time I joined the Orleans project, we agreed that the goal was to produce a framework that would allow mainstream developers to easily build scalable distributed (cloud) applications. To break this down a bit: The target audience shouldn't exclude programmers who haven't done distributed systems development . We want to enable all developers, whether cloud experts or cloud beginners, to focus on their application logic and features -- which is to say, what actually provides business value -- rather than on generic distributed systems issues. The goal is to allow them to build cloud applications easily . Easily means that they shouldn't have to think about distribution any more than is absolutely required. Easily also means that Orleans should present as familiar a faade to the developer as possible; in a .NET context, that means C# objects and interfaces. Those applications should be \"scalable by default\" . Since our target users aren't necessarily distributed systems experts, we want to provide them a framework that will lead them to build scalable applications without explicitly thinking about it. This means that the framework has to make a lot of decisions for them in order to guarantee an acceptable degree of scalability, even if that means that the scalability isn't optimal for every application. We supplemented this goal with a set of architectural principles: We're focused on the 80% case . There are certainly applications that Orleans isn't appropriate for; that's OK. There are applications that Orleans is a reasonable fit for, but where you can get somewhat better performance by a bunch of hand-tuning that Orleans doesn't allow; that's OK too. The 80% that Orleans fits well and performs well enough on covers a lot of interesting applications, and we'd rather do a great job on 80% than a lousy job on 99%. Scalability is paramount . We'll trade off raw performance if that gets us better scaling. Availability is paramount . A cloud application should be like a utility: always there when you want it. Detect and fix problems , don't assume you can 100% prevent them. At cloud scale, bad things happen often, and even impossible bad things happen, just less often. This has led us to what is often termed \"recovery-oriented computing\", rather than trying to be fault-tolerant; our experience has shown that fault tolerance is fragile and often illusory. Even mathematically proven protocols are no protection against random bit flips in memory or disk controllers that fail while reporting success -- both real examples I've seen in production in my career. The above has led us to certain practices: API-first design : if we don't know how we're going to expose a feature to the developer, then we don't build it. Of course, the best way is for a feature have no developer exposure at all... Make it easy to do the right thing : keep things as simple as possible (but no simpler), don't provide a hammer if a screwdriver is the right tool. As one of our early adopters put it, we try to help our customers \"fall into the pit of success\". If there is a standard pattern that will work well for 80% of the applications out there, then don't worry about enabling every possible alternative. Orleans' embrace of asynchrony is a good example of this. Make it easy for developers to extend the framework without breaking it . Custom serialization and persistence providers are a couple of examples of this. Some sort of custom task scheduling extension would be an anti-example. Follow the principle of least surprise : as much as possible, things should be as familiar, but everything should behave the way it looks. The next post will start applying these principles to the current Orleans design and walk through the motivations for some specific decisions we made. Thanks for reading! Alan Geller Alan Geller, http://research.microsoft.com/en-us/people/ageller/ , works on quantum computing at Microsoft Research. He was one of the primary architects of Orleans from 2008 until 2012. Earlier, he was the platform architect for Amazon Web Services from 2004 to 2008, and before that built a wide variety of large-scale production distributed systems in telecommunications and financial services."
  },
  "Documentation/grains/external_tasks_and_grains.html": {
    "href": "Documentation/grains/external_tasks_and_grains.html",
    "title": "External Tasks and Grains | Microsoft Orleans Documentation",
    "keywords": "External Tasks and Grains By design, any sub-Tasks spawned from grain code (for example, by using await or ContinueWith or Task.Factory.StartNew ) will be dispatched on the same per-activation TPL Task Scheduler as the parent task and therefore inherit the same single-threaded execution model as the rest of grain code. This is the main point behind single threaded execution of grain turn based concurency . In some cases grain code might need to break out of the Orleans task scheduling model and do something special, such as explicitly pointing a Task to a different task scheduler or using the .NET Thread pool. An example of such cases is when grain code has to execute a synchronous remote blocking call (such as remote IO). Doing that in the grain context will block the grain as well as one of the Orleans threads and thus should never be made. Instead, the grain code can execute this piece of blocking code on the thread pool thread and join ( await ) the completion of that execution and proceed in the grain context. We expect that escaping from the Orleans scheduler will be a very advanced and seldom required usage scenario beyond the normal usage patterns. Task based APIs: 1) await , Task.Factory.StartNew , Task.ContinuewWith , Task.WhenAny , Task.WhenAll , Task.Delay all respect the current Task Scheduler. That means that using them in the default way, without passing a different TaskScheduler, will cause them to execute in the grain context. 2) Both Task.Run and the endMethod delegate of Task.Factory.FromAsync do NOT respect the current task Scheduler. They both use the TaskScheduler.Default scheduler, which is the .NET thread pool task Scheduler. Therefore, the code inside Task.Run and the endMethod will ALWAYS run on the .NET thread pool outside of the single-threaded execution model for Orleans grains, as detailed here . However, any code after the await Task.Run or await Task.Factory.FromAsync will run back under the scheduler at the point the task was created, which is the grain scheduler. 3) configureAwait(false) is an explicit API to escape the current task Scheduler. It will cause the code after an awaited Task to be executed on the TaskScheduler.Default scheduler, which is the .NET thread pool, and will thus break the single-threaded execution of the Orleans grain. You should in general never ever use configureAwait(false) directly in grain code. 4) Methods with signature async void should not be used with grains. They are intended for graphical user interface event handlers. Example: Below is sample code that demonstrates the usage of TaskScheduler.Current , Task.Run and a special custom scheduler to escape from Orlean grain context and how to get back to it. public async Task MyGrainMethod() { // Grab the Orleans task scheduler var orleansTs = TaskScheduler.Current; await TaskDelay(10000); // Current task scheduler did not change, the code after await is still running in the same task scheduler. Assert.AreEqual(orleansTs, TaskScheduler.Current); Task t1 = Task.Run( () => { // This code runs on the thread pool scheduler, not on Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); Assert.AreEqual(TaskScheduler.Default, TaskScheduler.Current); } ); await t1; // We are back to the Orleans task scheduler. // Since await was executed in Orleans task scheduler context, we are now back to that context. Assert.AreEqual(orleansTS, TaskScheduler.Current); // Example of using ask.Factory.StartNew with a custom scheduler to escape from the Orleans scheduler Task t2 = Task.Factory.StartNew(() => { // This code runs on the MyCustomSchedulerThatIWroteMyself scheduler, not on the Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); Assert.AreEqual(MyCustomSchedulerThatIWroteMyself, TaskScheduler.Current); }, CancellationToken.None, TaskCreationOptions.None, scheduler: MyCustomSchedulerThatIWroteMyself); await t2; // We are back to Orleans task scheduler. Assert.AreEqual(orleansTS, TaskScheduler.Current); } Advanced Example - making a grain call from code that runs on a thread pool An even more advanced scenario is a piece of grain code that needs to break out of the Orleans task scheduling model and run on a thread pool (or some other, non-Orleans context), but still needs to call another grain. If you try to make a grain call but are not within an Orleans context, you will get an exception that says you are \"trying to send a message on a silo not from within a grain and not from within a system target (RuntimeContext is not set to SchedulingContext)\". Below is code that demonstrates how a grain call can be made from a piece of code that runs inside a grain but not in the grain context. public async Task MyGrainMethod() { // Grab the Orleans task scheduler var orleansTs = TaskScheduler.Current; Task<int> t1 = Task.Run(async () => { // This code runs on the thread pool scheduler, not on Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); // You can do whatever you need to do here. Now let's say you need to make a grain call. Task<Task<int>> t2 = Task.Factory.StartNew(() => { // This code runs on the Orleans task scheduler since we specified the scheduler: orleansTs. Assert.AreEqual(orleansTS, TaskScheduler.Current); return GrainFactory.GetGrain<IFooGrain>(0).MakeGrainCall(); }, CancellationToken.None, TaskCreationOptions.None, scheduler: orleansTs); int res = await (await t2); // double await, unrelated to Orleans, just part of TPL APIs. // This code runs back on the thread pool scheduler, not on the Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); return res; } ); int result = await t1; // We are back to the Orleans task scheduler. // Since await was executed in the Orleans task scheduler context, we are now back to that context. Assert.AreEqual(orleansTS, TaskScheduler.Current); } Dealing with libraries Some external libraries that your code is using might be using ConfigureAwait(false) internally. In fact, it is a good and correct practice in .NET to use ConfigureAwait(false) when implementing general purpose libraries . This is not a problem in Orleans. As long as the code in the grain that invokes the library method is awaiting the library call with a regular await , the grain code is correct. The result will be exactly as desired -- the library code will run continuations on the Default scheduler (which happens to be ThreadPoolTaskScheduler but it does not guarantee that the continuations will definitely run on a ThreadPool thread, as continuations are often inlined in the previous thread), while the grain code will run on the Orleans scheduler. Another frequently-asked question is whether there is a need to execute library calls with Task.Run -- that is, whether there is a need to explicitly offload the library code to ThreadPool (for grain code to do Task.Run(()=> myLibrary.FooAsync()) ). The answer is No. There is no need to offload any code to ThreadPool, except for the case of library code that is making a blocking synchronous calls. Usually, any well-written and correct .NET async library (methods that return Task and are named with an Async suffix) do not make blocking calls. Thus there is no need to offload anything to ThreadPool, unless you suspect the async library is buggy or if you are deliberately using a synchronous blocking library. Summary What are you trying to do? How to do it Run background work on .NET thread-pool threads. No grain code or grain calls allowed. Task.Run Grain interface call Method return types = Task or Task<T> Run worker task from grain code with Orleans turn-based concurrency guarantees. Task.Factory.StartNew Timeouts for executing work items Task.Delay + Task.WhenAny Use with async / await The normal .NET Task-Async programming model. Supported & recommended ConfigureAwait(false) Do not use inside grain code. Allowed only inside libraries. Calling async library await the library call"
  },
  "Documentation/grains/index.html": {
    "href": "Documentation/grains/index.html",
    "title": "Overview - Grains | Microsoft Orleans Documentation",
    "keywords": "This is the overview page about Grains ///TODO"
  },
  "Documentation/grains/interceptors.html": {
    "href": "Documentation/grains/interceptors.html",
    "title": "Grain Call Filters | Microsoft Orleans Documentation",
    "keywords": "Grain Call Filters Grain call filters provide a means for intercepting grain calls. Filters can execute code both before and after a grain call. Multiple filters can be installed simultaneously. Filters are asynchronous and can modify RequestContext , arguments, and the return value of the method being invoked. Filters can also inspect the MethodInfo of the method being invoked on the grain class and can be used to throw or handle exceptions. Some example usages of grain call filters are: Authorization: a filter can inspect the method being invoked and the arguments or some authorization information in the RequestContext to determine whether or not to allow the call to proceed. Logging/Telemetry: a filter can log information and capture timing data and other statistics about method invocation. Error Handling: a filter can intercept exceptions thrown by a method invocation and transform it into another exception or handle the exception as it passes through the filter. Filters come in two flavors: Incoming call filters Outgoing call filters Incoming call filters are executed when receiving a call. Outgoing call filters are executed when making a call. Incoming Call Filters Incoming grain call filters implement the IIncomingGrainCallFilter interface, which has one method: public interface IIncomingGrainCallFilter { Task Invoke(IIncomingGrainCallContext context); } The IIncomingGrainCallContext argument passed to the Invoke method has the following shape: public interface IIncomingGrainCallContext { /// <summary> /// Gets the grain being invoked. /// </summary> IAddressable Grain { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the interface method being invoked. /// </summary> MethodInfo InterfaceMethod { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the implementation method being invoked. /// </summary> MethodInfo ImplementationMethod { get; } /// <summary> /// Gets the arguments for this method invocation. /// </summary> object[] Arguments { get; } /// <summary> /// Invokes the request. /// </summary> Task Invoke(); /// <summary> /// Gets or sets the result. /// </summary> object Result { get; set; } } The IIncomingGrainCallFilter.Invoke(IIncomingGrainCallContext) method must await or return the result of IIncomingGrainCallContext.Invoke() to execute the next configured filter and eventually the grain method itself. The Result property can be modified after awaiting the Invoke() method. The ImplementationMethod property returns the MethodInfo of the implementation class. The MethodInfo of the interface method can be accessed using the InterfaceMethod property. Grain call filters are called for all method calls to a grain and this includes calls to grain extensions (implementations of IGrainExtension ) which are installed in the grain. For example, grain extensions are used to implement Streams and Cancellation Tokens. Therefore, it should be expected that the value of ImplementationMethod is not always a method in the grain class itself. Configuring Incoming Grain Call Filters Implementations of IIncomingGrainCallFilter can either be registered as silo-wide filters via Dependency Injection or they can be registered as grain-level filters via a grain implementing IIncomingGrainCallFilter directly. Silo-wide Grain Call Filters A delegate can be registered as a silo-wide grain call filters using Dependency Injection like so: siloHostBuilder.AddIncomingGrainCallFilter(async context => { // If the method being called is 'MyInterceptedMethod', then set a value // on the RequestContext which can then be read by other filters or the grain. if (string.Equals(context.InterfaceMethod.Name, nameof(IMyGrain.MyInterceptedMethod))) { RequestContext.Set(\"intercepted value\", \"this value was added by the filter\"); } await context.Invoke(); // If the grain method returned an int, set the result to double that value. if (context.Result is int resultValue) context.Result = resultValue * 2; }); Similarly, a class can be registered as a grain call filter using the AddIncomingGrainCallFilter helper method. Here is an example of a grain call filter which logs the results of every grain method: public class LoggingCallFilter : IIncomingGrainCallFilter { private readonly Logger log; public LoggingCallFilter(Factory<string, Logger> loggerFactory) { this.log = loggerFactory(nameof(LoggingCallFilter)); } public async Task Invoke(IIncomingGrainCallContext context) { try { await context.Invoke(); var msg = string.Format( \"{0}.{1}({2}) returned value {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), context.Result); this.log.Info(msg); } catch (Exception exception) { var msg = string.Format( \"{0}.{1}({2}) threw an exception: {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), exception); this.log.Info(msg); // If this exception is not re-thrown, it is considered to be // handled by this filter. throw; } } } This filter can then be registered using the AddIncomingGrainCallFilter extension method: siloHostBuilder.AddIncomingGrainCallFilter<LoggingCallFilter>(); Alternatively, the filter can be registered without the extension method: siloHostBuilder.ConfigureServices( services => services.AddSingleton<IIncomingGrainCallFilter, LoggingCallFilter>()); Per-grain Grain Call Filters A grain class can register itself as a grain call filter and filter any calls made to it by implementing IIncomingGrainCallFilter like so: public class MyFilteredGrain : Grain, IMyFilteredGrain, IIncomingGrainCallFilter { public async Task Invoke(IIncomingGrainCallContext context) { await context.Invoke(); // Change the result of the call from 7 to 38. if (string.Equals(context.InterfaceMethod.Name, nameof(this.GetFavoriteNumber))) { context.Result = 38; } } public Task<int> GetFavoriteNumber() => Task.FromResult(7); } In the above example, all calls to the GetFavoriteNumber method will return 38 instead of 7 , because the return value has been altered by the filter. Another use case for filters is in access control, as in this example: [AttributeUsage(AttributeTargets.Method)] public class AdminOnlyAttribute : Attribute { } public class MyAccessControlledGrain : Grain, IMyFilteredGrain, IIncomingGrainCallFilter { public Task Invoke(IIncomingGrainCallContext context) { // Check access conditions. var isAdminMethod = context.ImplementationMethod.GetCustomAttribute<AdminOnlyAttribute>(); if (isAdminMethod && !(bool) RequestContext.Get(\"isAdmin\")) { throw new AccessDeniedException($\"Only admins can access {context.ImplementationMethod.Name}!\"); } return context.Invoke(); } [AdminOnly] public Task<int> SpecialAdminOnlyOperation() => Task.FromResult(7); } In the above example, the SpecialAdminOnlyOperation method can only be called if \"isAdmin\" is set to true in the RequestContext . In this way, grain call filters can be used for authorization. In this example, it is the responsibility of the caller to ensure that the \"isAdmin\" value is set correctly and that authentication is performed correctly. Note that the [AdminOnly] attribute is specified on the grain class method. This is because the ImplementationMethod property returns the MethodInfo of the implementation, not the interface. The filter could also check the InterfaceMethod property. Ordering of Grain Call Filters Grain call filters follow a defined ordering: IIncomingGrainCallFilter implementations configured in the dependency injection container, in the order in which they are registered. Grain-level filter, if the grain implements IIncomingGrainCallFilter . Grain method implementation or grain extension method implementation. Each call to IIncomingGrainCallContext.Invoke() encapsulates the next defined filter so that each filter has a chance to execute code before and after the next filter in the chain and eventually the grain method itself. Outgoing Call Filters Outgoing grain call filters are similar to incoming grain call filters with the major difference being that they are invoked on the caller (client) rather than the callee (grain). Outgoing grain call filters implement the IOutgoingGrainCallFilter interface, which has one method: public interface IOutgoingGrainCallFilter { Task Invoke(IOutgoingGrainCallContext context); } The IOutgoingGrainCallContext argument passed to the Invoke method has the following shape: public interface IOutgoingGrainCallContext { /// <summary> /// Gets the grain being invoked. /// </summary> IAddressable Grain { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the interface method being invoked. /// </summary> MethodInfo InterfaceMethod { get; } /// <summary> /// Gets the arguments for this method invocation. /// </summary> object[] Arguments { get; } /// <summary> /// Invokes the request. /// </summary> Task Invoke(); /// <summary> /// Gets or sets the result. /// </summary> object Result { get; set; } } The IOutgoingGrainCallFilter.Invoke(IOutgoingGrainCallContext) method must await or return the result of IOutgoingGrainCallContext.Invoke() to execute the next configured filter and eventually the grain method itself. The Result property can be modified after awaiting the Invoke() method. The MethodInfo of the interface method being called can be accessed using the InterfaceMethod property. Outgoing grain call filters are invoked for all method calls to a grain and this includes calls to system methods made by Orleans. Configuring Outgoing Grain Call Filters Implementations of IOutgoingGrainCallFilter can either be registered on both silos and clients using Dependency Injection. A delegate can be registered as a call filter like so: builder.AddOutgoingGrainCallFilter(async context => { // If the method being called is 'MyInterceptedMethod', then set a value // on the RequestContext which can then be read by other filters or the grain. if (string.Equals(context.InterfaceMethod.Name, nameof(IMyGrain.MyInterceptedMethod))) { RequestContext.Set(\"intercepted value\", \"this value was added by the filter\"); } await context.Invoke(); // If the grain method returned an int, set the result to double that value. if (context.Result is int resultValue) context.Result = resultValue * 2; }); In the above code, builder may be either an instance of ISiloHostBuilder or IClientBuilder . Similarly, a class can be registered as an outgoing grain call filter. Here is an example of a grain call filter which logs the results of every grain method: public class LoggingCallFilter : IOutgoingGrainCallFilter { private readonly Logger log; public LoggingCallFilter(Factory<string, Logger> loggerFactory) { this.log = loggerFactory(nameof(LoggingCallFilter)); } public async Task Invoke(IOutgoingGrainCallContext context) { try { await context.Invoke(); var msg = string.Format( \"{0}.{1}({2}) returned value {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), context.Result); this.log.Info(msg); } catch (Exception exception) { var msg = string.Format( \"{0}.{1}({2}) threw an exception: {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), exception); this.log.Info(msg); // If this exception is not re-thrown, it is considered to be // handled by this filter. throw; } } } This filter can then be registered using the AddOutgoingGrainCallFilter extension method: builder.AddOutgoingGrainCallFilter<LoggingCallFilter>(); Alternatively, the filter can be registered without the extension method: builder.ConfigureServices( services => services.AddSingleton<IOutgoingGrainCallFilter, LoggingCallFilter>()); As with the delegate call filter example, builder may be an instance of either ISiloHostBuiler or IClientBuilder . Use Cases Exception Conversion When an exception which has been thrown from the server is getting deserialized on the client, you may sometimes get the following exception instead of the actual one: TypeLoadException: Could not find Whatever.dll. This happens if the assembly containing the exception is not available to the client. For example, say you are using Entity Framework in your grain implementations; then it is possible that an EntityException is thrown. The client on the other hand does not (and should not) reference EntityFramework.dll since it has no knowledge about the underlying data access layer. When the client tries to deserialize the EntityException , it will fail due to the missing DLL; as a consequence a TypeLoadException is thrown hiding the original EntityException . One may argue that this is pretty okay, since the client would never handle the EntityException ; otherwise it would have to reference EntityFramework.dll . But what if the client wants at least to log the exception? The problem is that the original error message is lost. One way to workaround this issue is to intercept server-side exceptions and replace them by plain exceptions of type Exception if the exception type is presumably unknown on the client side. However, there is one important thing we have to keep in mind: we only want to replace an exception if the caller is the grain client . We don't want to replace an exception if the caller is another grain (or the Orleans infrastructure which is making grain calls, too; e.g. on the GrainBasedReminderTable grain). On the server side this can be done with a silo-level interceptor: public class ExceptionConversionFilter : IIncomingGrainCallFilter { private static readonly HashSet<string> KnownExceptionTypeAssemblyNames = new HashSet<string> { typeof(string).Assembly.GetName().Name, \"System\", \"System.ComponentModel.Composition\", \"System.ComponentModel.DataAnnotations\", \"System.Configuration\", \"System.Core\", \"System.Data\", \"System.Data.DataSetExtensions\", \"System.Net.Http\", \"System.Numerics\", \"System.Runtime.Serialization\", \"System.Security\", \"System.Xml\", \"System.Xml.Linq\", \"MyCompany.Microservices.DataTransfer\", \"MyCompany.Microservices.Interfaces\", \"MyCompany.Microservices.ServiceLayer\" }; public async Task Invoke(IIncomingGrainCallContext context) { var isConversionEnabled = RequestContext.Get(\"IsExceptionConversionEnabled\") as bool? == true; if (!isConversionEnabled) { // If exception conversion is not enabled, execute the call without interference. await context.Invoke(); return; } RequestContext.Remove(\"IsExceptionConversionEnabled\"); try { await context.Invoke(); } catch (Exception exc) { var type = exc.GetType(); if (KnownExceptionTypeAssemblyNames.Contains(type.Assembly.GetName().Name)) { throw; } // Throw a base exception containing some exception details. throw new Exception( string.Format( \"Exception of non-public type '{0}' has been wrapped.\" + \" Original message: <<<<----{1}{2}{3}---->>>>\", type.FullName, Environment.NewLine, exc, Environment.NewLine)); } } } This filter can then be registered on the silo: siloHostBuilder.AddIncomingGrainCallFilter<ExceptionConversionFilter>(); Enable the filter for calls made by the client by adding an outgoing call filter: clientBuilder.AddOutgoingGrainCallFilter(context => { RequestContext.Set(\"IsExceptionConversionEnabled\", true); return context.Invoke(); }); This way the client tells the server that it wants to use exception conversion. Calling Grains from Interceptors It is possible to make grain calls from an interceptor by injecting IGrainFactory into the interceptor class: private readonly IGrainFactory grainFactory; public CustomCallFilter(IGrainFactory grainFactory) { this.grainFactory = grainFactory; } public async Task Invoke(IIncomingGrainCallContext context) { // Hook calls to any grain other than ICustomFilterGrain implementations. // This avoids potential infinite recursion when calling OnReceivedCall() below. if (!(context.Grain is ICustomFilterGrain)) { var filterGrain = this.grainFactory.GetGrain<ICustomFilterGrain>(context.Grain.GetPrimaryKeyLong()); // Perform some grain call here. await filterGrain.OnReceivedCall(); } // Continue invoking the call on the target grain. await context.Invoke(); }"
  },
  "Documentation/resources/index.html": {
    "href": "Documentation/resources/index.html",
    "title": "Resources | Microsoft Orleans Documentation",
    "keywords": "This is section is about everything else: community contributions and guidlines, links, etc."
  },
  "Documentation/resources/Student-Projects.html": {
    "href": "Documentation/resources/Student-Projects.html",
    "title": "Student Projects | Microsoft Orleans Documentation",
    "keywords": "Student Projects We suggest 2 types of projects for students: The first type includes exploratory, open-ended, research-oriented projects with the goal of enabling new capabilities in Orleans. These projects would usually have broad scope and would be suitable for M.S. or Ph.D. student or advanced undergraduate students in their last year of studies. The end goal of these projects would be to contribute ideas and design to Orleans. We do not necessarily expect the code produced in these projects to be directly contributed to this repository, however this would be nice. The second type includes ideas for student education . These are either ideas for interesting applications that can be built on top of Orleans or some new capabilities for Orleans. These projects are suitable to be given in advanced undergraduate or graduate courses, where students learn about Cloud Computing and modern distributed technologies and want to gain real-world hands-on experience in building Cloud applications. We do not expect the code produced in these projects to be contributed directly to this repository. Research projects: Auto-scale. In this project students can start by exploring the existing auto-scaling mechanisms for controlling resource allocation in Windows Azure ( Autoscaling Application Block ). The next step involves exploring various statistics and resource consumption metrics collected by Orleans, and using them as an input for Azure Autoscaling. An advanced stage of this project may involve improving the internal Orleans mechanisms for reacting to elasticity changes, for example by implementing live actor migration to reduce the time taken to utilize new resources. Auto-generated front-ends for Orleans-based cloud services . This project seamlessly extends the Orleans actor model into the HTTP world. The ramp-up part of the project includes dynamically generating HTTP endpoints for actors based on their .NET interfaces and metadata. The main part involves automatically generating front-ends to support web sockets and bi-directional streaming of data, which requires complex code generation with optimizations for high performance. It also requires attention to fault tolerance, to maintain high availability of streaming sessions across server reboots and client reconnects and migration -- a significant research challenge. Storage provider for Entity Framework . This project involves enabling Orleans objects to store their state in a database and to subsequently query it. This might include adding support for Orleans object persistence on SQL Azure Database using Entity Framework (EF), which is Microsoft's open-source object-relational mapper for .NET, and exposing that data via LINQ queries. The implementation can be evaluated and tuned using standard database benchmarks and/or custom Orleans' applications. Distributed system benchmark . Define a list of benchmarks suitable for distributed systems like Orleans. The benchmark applications may be analogous in spirit to the TPC database benchmark or UCB \"Parallel Dwarfs\" implemented here and may be used to characterize the performance and scalability of distributed frameworks. Consider developing a new benchmark targeted for Orleans, for example, to compare the performance of storage providers. Declarative dataflow language over streams . Define and build a Trident-Storm like declarative language over Orleans streams. Develop an optimizer that configures the stream processing to minimize overall cost. Programming model for client devices . Extend Orleans to client devices, such as sensors, phones, tablets, and desktops. Enable grain logic to execute on the client. Potentially support tier splitting, that is, dynamically deciding which parts of the code execute on the device and which is offloaded to the cloud. Queries over grain/actor classes, secondary indices . Build a distributed, scalable, and reliable grain index. This includes formally defining the query model and implementing the distributed index. The index itself can be implemented as Orleans grains and/or stored in a database. Large scale simulations . Orleans is a great fit for building large scale simulations. Explore the usage of Orleans for different simulations, for example, protein interactions, network simulations, simulated annealing, etc. Course projects: Internet Of Things applications . For example, the application could enable sensors/devices to report their state to the cloud, where each device is represented in the cloud by an Orleans actor. Users can connect to the actor that represents their device via a web browser and check its status or control it. This project involves mastering a number of modern cloud technologies, including Windows Azure , Orleans, WebApi or ASP.NET, SignalR for streaming commands back from the cloud to the device, and writing a sensor/device/phone app. Twitter-like large scalable chat service in the cloud based on Orleans . Each user could be represented by an Orleans Actor, which contains its list of followers. Faceboook-like social app based on Orleans . Each user could be represented by an Orleans Actor, which includes a list of friends and wall on which friends can write. Simple storage provider . Add a storage provider for a storage system, such as a key-value store or database system. A simple one could use the Orleans serializer , as in the existing Azure Table storage provider . A more sophisticated one would map state variables of an Orleans class to fine-grained structures of the storage system. A complex one is the Entity Framework storage provider mentioned above under Research Projects . Compare the performance of different storage providers for different types and sizes of actor state. Comparison with other distributed application frameworks . Take a sample application written for another application framework, such as Google App Engine or Akka , and translate it into Orleans. Summarize the relative strengths and weaknesses of each framework by comparing the apps. Concluded Research projects: Below are a number of examples of previous successful research projects. Distributed log analysis, correlation and debugging . Debugging large-scale distributed systems is a challenging task due to enormous amounts of data and complex dynamic interactions between the distributed components, running on different processes and different machines. The goal of this project was to analyze prior art on this topic, propose a solution, and then implement prototype tools for collecting, correlating and analyzing application error log file data across a multi-machine distributed application runtime environment. This involved exploring the problem space from a variety of perspectives, including: a. Approaches to efficient logging, collection and analysis of failure information from various log-capture mechanisms in a distributed Orleans runtime environment. b. Possible applications of machine learning to find log patterns that signal serious production issues, and then detecting these patterns in near real time as a production monitoring utility. c. Ways to help individual developers perform real-time debugging of run-time issues with their applications. This project was performed successfully and result in a published paper PAD: Performance Anomaly Detection in Multi-Server Distributed Systems and a proof of concept implementation of a distributed log analysis tool. Horton - Distributed Graph Database . Horton was a research project with a goal to build a system to store, manage and query large-scale distributed graphs. It was implemented entirely as an Orleans application. The project resulted in a number of publications and a number of very successful student projects."
  },
  "Documentation/resources/Migration/Codegen.html": {
    "href": "Documentation/resources/Migration/Codegen.html",
    "title": "Code Generation in Orleans 2.0 | Microsoft Orleans Documentation",
    "keywords": "Code Generation in Orleans 2.0 Code generation has been improved in Orleans 2.0, improving startup times and providing a more deterministic, debuggable experience. As with earlier versions, Orleans provides both build-time and run-time code generation. During Build - This is the recommended option and only supports C# projects. In this mode, code generation will run every time your project is compiled. A build task is injected into your project's build pipeline and the code is generated in the project's intermediate output directory. To activate this mode, add the package Microsoft.Orleans.OrleansCodeGenerator.Build to all projects which contain Grains, Grain interfaces, serializers, or types which require serializers. Additional diagnostics can be emitted at build-time by specifying value for OrleansCodeGenLogLevel in the target project's csproj file. For example, <OrleansCodeGenLogLevel>Trace</OrleansCodeGenLogLevel> . During Configuration - This is the only supported option for F#, Visual Basic, and other non-C# projects. This mode generates code during the configuration phase. To access this, see the Configuration documentation. Both modes generate the same code, however run-time code generation can only generate code for publicly accessible types."
  },
  "Documentation/resources/Migration/index.html": {
    "href": "Documentation/resources/Migration/index.html",
    "title": "Migration | Microsoft Orleans Documentation",
    "keywords": "Migration Information ///TODO: after migration information is evaluated, write up a page about what is going to be kept, etc."
  },
  "Documentation/tutorials_and_samples/Hello-World.html": {
    "href": "Documentation/tutorials_and_samples/Hello-World.html",
    "title": "Hello World | Microsoft Orleans Documentation",
    "keywords": "Hello World Run the Hello World sample One way to run this sample is to download a local copy of HelloWorld from the Samples/2.0/HelloWorld/ folder . Open two Command Prompt windows and navigate to the HelloWorld folder in each one. Build the project. Start the silo in one window with the command: dotnet run --project src\\SiloHost After the silo is running, start the client in the other window with this: dotnet run --project src\\OrleansClient The silo and client windows will display greetings to each other. How Orleans says Hello In this sample, a client connects with a grain, sends it a greeting and receives a greeting back. The client then prints that greeting and that's that. Simple enough in theory, but since there's distribution involved, there's a bit more to it. There are four projects involved -- one for declaring the grain interfaces, one for the grain implementations, and one for the client, one for the silo host There's one grain interface, in IHello.cs: public interface IHello : Orleans.IGrainWithIntegerKey { Task<string> SayHello(string greeting); } This is simple enough, and we can see that all replies must be represented as a Task or Task in communication interfaces. The implementation, found in HelloGrain.cs, is similarly trivial: public class HelloGrain : Orleans.Grain, HelloWorldInterfaces.IHello { Task<string> HelloWorldInterfaces.IHello.SayHello(string greeting) { return Task.FromResult($\"You said: '{greeting}', I say: Hello!\"); } } The class inherits from the base class Grain , and implements the communication interface defined earlier. Since there is nothing that the grain needs to wait on, the method is not declared async and instead returns its value using Task.FromResult() . The client, which orchestrates the grain code and is found in OrleansClient project, looks like this: //configure the client with proper cluster options, logging and clustering client = new ClientBuilder() .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"HelloWorldApp\"; }) .ConfigureLogging(logging => logging.AddConsole()) .Build(); //connect the client to the cluster, in this case, which only contains one silo await client.Connect(); ... // example of calling grains from the initialized client var friend = client.GetGrain<IHello>(0); var response = await friend.SayHello(\"Good morning, my friend!\"); Console.WriteLine(\"\\n\\n{0}\\n\\n\", response); The silo host, which configures and starts the silo, in SiloHost project looks like this: //define the cluster configuration var builder = new SiloHostBuilder() //configure the cluster with local host clustering .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"HelloWorldApp\"; }) .Configure<EndpointOptions>(options => options.AdvertisedIPAddress = IPAddress.Loopback) .ConfigureLogging(logging => logging.AddConsole()); //build the silo var host = builder.Build(); //start the silo await host.StartAsync();"
  },
  "Documentation/tutorials_and_samples/index.html": {
    "href": "Documentation/tutorials_and_samples/index.html",
    "title": "Samples Overview | Microsoft Orleans Documentation",
    "keywords": "Samples Overview What do I need? The samples are self-contained, except where noted. You will need An Azure subscription will help with some of the samples, but is not required. For the Azure-based samples, you will need to install the SDK. The samples themselves can be downloaded from GitHub . Hello World This is the Orleans version of an old classic. It demonstrates that while there is no such thing as \"trivial\" when you are dealing with distributed computing, Orleans makes it pretty straight-forward. MathGrains This is a simple calculator that uses Orleans core components to encapsulate the functionality. Adventure Before there was graphical user interfaces, before the era of game consoles and massive-multiplayer games, there were VT100 terminals and there was Colossal Cave Adventure . Possibly lame by today's standards, back then it was a magical world of monsters, chirping birds, and things you could pick up. It's the inspiration for this sample."
  },
  "Documentation/tutorials_and_samples/MathGrains.html": {
    "href": "Documentation/tutorials_and_samples/MathGrains.html",
    "title": "MathGrains | Microsoft Orleans Documentation",
    "keywords": "MathGrains A calculator that encapsulates functionality into specialized grains."
  },
  "Documentation/frequently_asked_questions.html": {
    "href": "Documentation/frequently_asked_questions.html",
    "title": "Frequently Asked Questions | Microsoft Orleans Documentation",
    "keywords": "///TODO: after files are rearranged and checked for accuracy, put links back Frequently Asked Questions Availability Can I freely use Orleans in my project? Absolutely. The source code has been released under the MIT license . NuGet packages are published on nuget.org . Is Orleans production ready? I heard it's a research project. Orleans, indeed, initially started as a research project within Microsoft Research. It later grew into a product and has been used in production within Microsoft since 2011, and by other companies after it was publicly released in 2015. Orleans is definitely production ready, and powers many highly available systems and cloud services. Does Microsoft support Orleans? Source code of Orleans has been released under an MIT license on GitHub . Microsoft continues to invest in Orleans and accepts community contributions to the codebase. Positioning Is Orleans a server product? How do I run Orleans? Orleans is a framework, a set of libraries, that helps you build an application. Orleans-based applications can be run in various hosting environments, in the Cloud or on on-premises clusters or even on a single machine. It is the responsibility of application developer to build, deploy, and run an Orleans-based application in their target hosting environment. Where can I run Orleans? Orleans can run in any environment where .NET application can run. Prior to Orleans 2.0, it required full .NET Framework. Starting with 2.0, Orleans conforms to .NET Standard 2.0, and hence can run on .NET Core in Windows and non-Windows environments that support .NET Core. Is Orleans built for Azure? No. We believe that you should be able to run Orleans anywhere you need, the way you need. Orleans is very flexible, and has a number of optional providers that help host it in cloud environment, such as Azure, AWS or GCP, or on on-premises clusters, with a choice of technologies to support Orleans' clustering protocol. What is the difference between Orleans and other actor languages and frameworks, such as Erlang or Akka? While based on the same base principles of the Actor Model, Orleans took a step forward, and introduced a notion of Virtual Actors that greatly simplifies developer's experience and is much more suitable for cloud services and high-scale systems. Microsoft has another actor model implementation - Azure Service Fabric Reliable Actors. How do I choose between the two? Reliable Actors are tightly integrated with Service Fabric to leverage its core features, such as replicated in-cluster storage. Orleans has a reacher feature set, is not tied to any particular hosting platform, and can run in almost any environment. Orleans provides an optional integration package for hosting Orleans applications in Service Fabric. In the end, it's the application developer's decision of how much they would benefit from the tight integration of Reliable Actors with the underlying platform of Service Fabric versus the flexibility to run anywhere and the feature set of Orleans. Design How big or how small should a grain be in my application? The grain isolation model makes them very good at representing independent isolated contexts of state and computation. In most cases, grains naturally map to such application entities as users, sessions, accounts. Those entities are generally isolated from each other, can be accessed and updated independently, and expose a well defined set of supported operations. This works well with the intuitive \"one entity - one grain\" modeling. An application entity may be too big to be efficiently represented by a single grain if it encapsulates too much state, and as a result has to handle a high rate of requests to it. Even though a single grain can generally handle up to a few thousand trivial calls per second, the rule of thumb is to be wary of individual grain receiving hundreds of requests per second. That may be a sign of the grain being too large, and decomposing it into a set of smaller grains may lead to a more stable and balanced system. An application entity may be too small to be a grain if that would cause constant interaction of other grains with it, and as a result, cause too much of a messaging overhead. In such cases, it may make more sense to make those closely interacting entities part of a single grain, so that they would invoke each other directly. How should you avoid grain hot spots? The throughput of a grain is limited by a single thread that its activation can execute on. Therefore, it is advisable to avoid designs where a single grain receives a disproportionate share of requests or is involved in processing requests to other grains. There are various patterns that help prevent overloading of a single grain even when logically it is a central point of communication. For example, if a grain is an aggregator of some counters or statistics that are reported by a large number of grains on a regular basis, one proven approach is to add a controlled number of intermediate aggregator grains and assign each of the reporting grains (using a modulo on a key or a hash) to an intermediate aggregator, so that the load is more or less evenly distributed across all intermediate aggregator grains that in their turn periodically report partial aggregates to the central aggregator grain. Can a single Orleans cluster run across multiple datacenters? Orleans clusters are currently limited to a single data center per cluster. Instead, since 1.3.0, you can consider a multi-cluster deployment where clusters deployed to different datacenters form a single multi-cluster. In what cases can a split brain (same grain activated in multiple silos at the same time) happen? During normal operations the Orleans runtime guarantees that each grain will have at most one instance in the cluster. The only time this guarantee can be violated is when a silo crashes or gets killed without a proper shutdown. In that case, there is a ~30 second (based on configuration) window where a grain can potentially get temporarily instantiated in more than one silo. Convergence to a single instance per grain is guaranteed, and duplicate activations will be deactivated when this window closes. Also you can take a look at Orleans' paper for a more detailed information, however you don't need to understand it fully to be able to write your application code. You just need to consider the rare possibility of having two instances of an actor while writing your application. The persistence model guarantees that no writes to storage are blindly overwritten in such a case. How To How do I tear down a grain? In general there is no need for application logic to force deactivation of a grain, as the Orleans runtime automatically detects and deactivates idle activations of a grain to reclaim system resources. Letting Orleans do that is more efficient because it batches deactivation operations instead of executing them one by one. In the rare cases when you think you do need to expedite deactivation of a grain, the grain can do that by calling the base.DeactivateOnIdle() method. Can I tell Orleans where to activate a grain? It is possible to do so using restrictive placement strategies, but we generally consider this a rather advanced pattern that requires careful consideration. By doing what the question suggests, the application would take on the burden of resource management without necessarily having enough information about the global state of the system to do so well. This is especially counter-productive in cases of silo restarts, which in cloud environments may happen on a regular basis for OS patching. Thus, specific placement may have a negative impact on your application's scalability as well as resilience to system failure. That being said, for the rare cases where the application indeed knows where a particular grain should be activated, for example, if it has a knowledge of the locality of grain's persistent state, in 1.5.0 we introduced custom placement policies and directors. How do you version grains or add new grain classes and interfaces? You can add silos with new grain classes or new versions of existing grain classes to a running cluster. Can I Connect to Orleans silos from the public Internet? Orleans is designed to be hosted as the back-end part of a service, and you are expected to create a front-end tier to which external clients will connect. It can be an HTTP based Web API project, a socket server, a SignalR server or anything else fits the needs of the application. You can connect to Orleans from the Internet if you expose TCP endpoints of silos to it, but it is not a good practice from the security point of view. What happens if a silo fails before my grain call returns a response for my call? In case of a silo failure in the middle of a grain call, you'll receive an exception that you can catch in your code and retry or do something else to handle the error according to your application logic. The grain that failed with the silo will get automatically re-instantiated upon a next call to it. The Orleans runtime does not eagerly recreate grains from a failed silo because many of them may not be needed immediately or at all. Instead, the runtime recreates such grains individually and only when a new request arrives for a particular grain. For each grain it picks one of the available silos as a new host. The benefit of this approach is that the recovery process is performed only for grains that are actually being used and it is spread in time and across all available silos, which improves the responsiveness of the system and the speed of recovery. Note also that there is a delay between the time when a silo fails and when the Orleans cluster detects the failure. The delay is a configurable tradeoff between the speed of detection and the probability of false positives. During this transition period all calls to the grain will fail, but after the detection of the failure the grain will be created, upon a new call to it, on another silo, so it will be eventually available. What happens if a grain call takes too long to execute? Since Orleans uses a cooperative multi-tasking model, it will not preempt the execution of a grain automatically but Orleans generates warnings for long executing grain calls so you can detect them. Cooperative multi-tasking has a much better throughput compared to preemptive multi-tasking. Keep in mind that grain calls should not execute any long running tasks like IO operations synchronously and should not block on other tasks to complete. All waiting should be done asynchronously using the await keyword or other asynchronous waiting mechanisms. Grains should return as soon as possible to let other grains execute for maximum throughput."
  },
  "Documentation/clusters_and_clients/developing_a_client.html": {
    "href": "Documentation/clusters_and_clients/developing_a_client.html",
    "title": "Developing a Client | Microsoft Orleans Documentation",
    "keywords": "What Is Grain Client? The term \"Client\" or sometimes \"Grain Client\" is used for application code that interacts with grains but itself is not part of a grain logic. Client code runs outside of the cluster of Orleans servers called silos where grains are hosted. Hence, a client acts as a connector or conduit to the cluster and to all grains of the application. Usually, clients are used on the frontend web servers to connect to an Orleans cluster that serves as a middle tier with grains executing business logic. In a typical setup, a frontend web server: Receives a web request Performs necessary authentication and authorization validation Decides which grain(s) should process the request Uses Grain Client to make one or more method call to the grain(s) Handles successful completion or failures of the grain calls and any returned values Sends a response for the web request Initialization of Grain Client Before a grain client can be used for making calls to grains hosted in an Orleans cluster, it needs to be configured, initialized, and connected to the cluster. Configuration is provided via a ClientConfiguration object that contains a hierarchy of configuration properties for programmatically configuring a client. There is also a way to configure a client via a XML file, but that option will be deprecated in the future. More information is in the Client Configuration guide . Here we will simply use a helper method that creates a configuration object hardcoded for connecting to a local silo running as localhost . ClientConfiguration clientConfig = ClientConfiguration.LocalhostSilo(); Once we have a configuration object, we can build a client via the ClientBuilder class. IClusterClient client = new ClientBuilder().UseConfiguration(clientConfig).Build(); Lastly, we need to call Connect() method on the constructed client object to make it connect to the Orleans cluster. It's an asynchronous method that returns a Task . So we need to wait for its completion with an await or .Wait() . await client.Connect(); Making Calls to Grains Making calls to grain from a client is really no different from making such calls from within grain code . The same GetGrain<T>(key) method, where T is the target grain interface, is used in both cases to obtain grain references . The slight difference is in through what factory object we invoke GetGrain . In client code we do that through the connected client object. IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); Task t = player.JoinGame(game) await t; A call to a grain method returns a Task or a Task<T> as required by the grain interface rules . The client can use the await keyword to asynchronously await the returned Task without blocking the thread, or in some cases the Wait() method to block the current thread of execution. The major difference between making calls to grains from client code and from within another grain is the single-threaded execution model of grains. Grains are constrained to be single-threaded by the Orleans runtime, while clients may be multi-threaded. Orleans does not provide any such guarantee on the client side, and so it is up to the client to manage its own concurrency using whatever synchronization constructs are appropriate for its environment  locks, events, Tasks , etc. Receiving notifications There are situations in which a simple request-response pattern is not enough, and the client needs to receive asynchronous notifications. For example, a user might want to be notified when a new message has been published by someone that she is following. Observers is one such mechanism that enables exposing client side objects as grain-like targets to get invoked by grains. Calls to observers do not provide any indication of success or failure, as they are sent as one-way best effort message. So it is a responsibility of the application code to build a higher level reliability mechanism on top of observers where necessary. Another mechanism that can be used for delivering asynchronous messages to clients is Streams . Streams expose indications of success or failure of delivery of individual messages, and hence enable reliable communication back to the client. Example Here is an extended version of the example given above of a client application that connects to Orleans, finds the player account, subscribes for updates to the game session the player is part of with an observer, and prints out notifications until the program is manually terminated. namespace PlayerWatcher { class Program { /// <summary> /// Simulates a companion application that connects to the game /// that a particular player is currently part of, and subscribes /// to receive live notifications about its progress. /// </summary> static void Main(string[] args) { RunWatcher().Wait(); // Block main thread so that the process doesn't exit. // Updates arrive on thread pool threads. Console.ReadLine(); } static async Task RunWatcher() { try { // Connect to local silo var config = ClientConfiguration.LocalhostSilo(); var client = new ClientBuilder().UseConfiguration(config).Build(); await client.Connect(); // Hardcoded player ID Guid playerId = new Guid(\"{2349992C-860A-4EDA-9590-000000000006}\"); IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); IGameGrain game = null; while (game == null) { Console.WriteLine(\"Getting current game for player {0}...\", playerId); try { game = await player.GetCurrentGame(); if (game == null) // Wait until the player joins a game { await Task.Delay(5000); } } catch (Exception exc) { Console.WriteLine(\"Exception: \", exc.GetBaseException()); } } Console.WriteLine(\"Subscribing to updates for game {0}...\", game.GetPrimaryKey()); // Subscribe for updates var watcher = new GameObserver(); await game.SubscribeForGameUpdates( await client.CreateObjectReference<IGameObserver>(watcher)); Console.WriteLine(\"Subscribed successfully. Press <Enter> to stop.\"); } catch (Exception exc) { Console.WriteLine(\"Unexpected Error: {0}\", exc.GetBaseException()); } } } /// <summary> /// Observer class that implements the observer interface. Need to pass a grain reference to an instance of this class to subscribe for updates. /// </summary> class GameObserver : IGameObserver { // Receive updates public void UpdateGameScore(string score) { Console.WriteLine(\"New game score: {0}\", score); } } } }"
  },
  "Documentation/clusters_and_clients/powershell_client.html": {
    "href": "Documentation/clusters_and_clients/powershell_client.html",
    "title": "PowerShell Client Module | Microsoft Orleans Documentation",
    "keywords": "PowerShell Client Module The Orleans PowerShell Client Module is a set of PowerShell Cmdlets that wraps GrainClient in a set of convenient commands making possible to interact with not just ManagementGrain but any IGrain just as a regular Orleans application can by using Powershell scripts. These Cmdlets enable a series of scenarios from start maintenance tasks, tests, monitoring or any other kind of automation by leveraging Powershell scripts. Here is how to use it: Installing the module From Source You can build from source the OrleansPSUtils project and just import it with: PS> Import-Module .\\projectOutputDir\\Orleans.psd1 Althought you can do that, there is a much easier and interesting way for doing that by installing it from PowerShell Gallery . From PowerShell Gallery Powershell modules today are easily shared just as Nuget packages but instead of nuget.org, they are hosted on PowerShell Gallery . To install it on a specific folder just run: PS> Save-Module -Name OrleansPSUtils -Path <path> To install it on your PowerShell modules path ( the recommended way ), just run: PS> Install-Module -Name OrleansPSUtils If you plan to use this module on an Azure Automation , just click on the button bellow: Using the module Regardless of the way you decide to install it, the first thing you need to do in order to actually use it is import the module on the current PowerShell session so the Cmdlets get available by running this: PS> Import-Module OrleansPSUtils Note : In case of building from source, you must import it as suggested on the Install section by using the path to the .psd1 instead of using the module name since it will not be on the $env:PSModulePath PowerShell runtime variable. Again, it is highly recommended that you install from PowerShell Gallery instead. After the module is imported (which means it is loaded on PowerShell session), you will have the following Cmdlets available: Start-GrainClient Stop-GrainClient Get-Grain Start-GrainClient This module is a wrapper around GrainClient.Initialize() and its overloads. Usage : Start-GrainClient The same as call GrainClient.Initialize() which will look for the known Orleans Client configuration file names Start-GrainClient [-ConfigFilePath] <string> [[-Timeout] <timespan>] Will use the provided file path as in GrainClient.Initialize(filePath) Start-GrainClient [-ConfigFile] <FileInfo> [[-Timeout] <timespan>] Use an instance of the System.FileInfo class representing the config file just as GrainClient.Initialize(fileInfo) Start-GrainClient [-Config] <ClientConfiguration> [[-Timeout] <timespan>] Use an instance of a Orleans.Runtime.Configuration.ClientConfiguration like in GrainClient.Initialize(config) Start-GrainClient [-GatewayAddress] <IPEndPoint> [[-OverrideConfig] <bool>] [[-Timeout] <timespan>] Takes a Orleans Cluster Gateway Address Endpoint Note : The Timeout parameter is optional and if it is informed and greater than System.TimeSpan.Zero , it will call Orleans.GrainClient.SetResponseTimeout(Timeout) internally. Stop-GrainClient Takes no parameters and when called, if the GrainClient is initialized will gracefuly uninitialize. Get-Grain Wrapper around GrainClient.GrainFactory.GetGrain<T>() and its overloads. The mandatory parameter is -GrainType and the -XXXKey for the current Grain key types supported by Orleans ( string , Guid , long ) and also the -KeyExtension that can be used on Grains with compound keys. This Cmdlet return a grain reference of the type passed by as parameter on -GrainType . Example: A simple example on calling MyInterfacesNamespace.IMyGrain.SayHeloTo grain method: PS> Import-Module OrleansPSUtils PS> $configFilePath = Resolve-Path(\".\\ClientConfig.xml\").Path PS> Start-GrainClient -ConfigFilePath $configFilePath PS> Add-Type -Path .\\MyGrainInterfaceAssembly.dll PS> $grainInterfaceType = [MyInterfacesNamespace.IMyGrain] PS> $grainId = [System.Guid]::Parse(\"A4CF7B5D-9606-446D-ACE9-C900AC6BA3AD\") PS> $grain = Get-Grain -GrainType $grainInterfaceType -GuidKey $grainId PS> $message = $grain.SayHelloTo(\"Gutemberg\").Result PS> Write-Output $message Hello Gutemberg! PS> Stop-GrainClient We plan to update this page as we introduce more Cmdlets like use Observers, Streams and other Orleans core features more natively on Powershell. We hope that this help people as a starting point for automation. As always, this is a work-in-progress and we love contributions! :) Please note that the intent is not to reimplement the whole client on PowerShell but instead, give IT and DevOps teams a way to interact with the Grains without need to implement a .Net application."
  },
  "Documentation/clusters_and_clients/configuration_guide/configuring_.NET_garbage_collection.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/configuring_.NET_garbage_collection.html",
    "title": "Configuring .NET Garbage Collection | Microsoft Orleans Documentation",
    "keywords": "Configuring .NET Garbage Collection For good performance, it is important to configure .NET garbage collection for the silo process the right way. The best combination of settings we found is to set gcServer=true and gcConcurrent=true. These are easy to set via the application csproj file. See below as an example: .NET Framework and .NET Core // .csproj <PropertyGroup> <ServerGarbageCollection>true</ServerGarbageCollection> <ConcurrentGarbageCollection>true</ConcurrentGarbageCollection> </PropertyGroup> .NET Framework with old .csproj project format // App.config <configuration> <runtime> <gcServer enabled=\"true\"/> <gcConcurrent enabled=\"true\"/> </runtime> </configuration> However, this is not as easy to do if a silo runs as part of an Azure Worker Role, which by default is configured to use workstation GC. This blog post shows how to set the same configuration for an Azure Worker Role - https://blogs.msdn.microsoft.com/cclayton/2014/06/05/server-garbage-collection-mode-in-microsoft-azure/ IMPORTANT NOTE Server garbage collection is available only on multiprocessor computers . Therefore, even if you configure the Garbage Collection either via application csproj file or via the scripts on the referred blog post, if the silo is running on a (virtual) machine with a single core, you will not get the benefits of gcServer=true ."
  },
  "Documentation/clusters_and_clients/configuration_guide/list_of_options_classes.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/list_of_options_classes.html",
    "title": "List of Options Classes | Microsoft Orleans Documentation",
    "keywords": "List of Options Classes All Options classes used to configure Orleans should be in the Orleans.Configuration namespace. Many of them have helper methods in the Orleans.Hosting namespace. Common core options for IClientBuilder and ISiloHostBuilder Option type Used for ClusterOptions Setting the ClusterId and the ServiceId NetworkingOptions Setting timeout values for sockets and opened connections SerializationProviderOptions Setting the serialization providers TypeManagementOptions Setting the refresh period of the Type Map (see Heterogeneous silos and Versioning) IClientBuilder specific options Option type Used for ClientMessagingOptions Setting the number of connection to keep open, and specify what network interface to use ClientStatisticsOption Setting various setting related to statistics output GatewayOptions Setting the refresh period of the list of available gateways ISiloHostBuilder specific options Option type Used for ClusterMembershipOptions Settings for cluster membership ConsistentRingOptions Configuration options for consistent hashing algorithm, used to balance resource allocations across the cluster. EndpointOptions Setting the Silo endpoint options GrainCollectionOptions Options for grain garbage collection GrainVersioningOptions Governs grain implementation selection in heterogeneous deployments LoadSheddingOptions Settings for load shedding configuration MultiClusterOptions Options for configuring multi-cluster support PerformanceTuningOptions Performance tuning options (networking, number of threads) ProcessExitHandlingOptions Configure silo behavior on process exit SchedulingOptions Configuring scheduler behavior SiloMessagingOptions Configuring global messaging options that are silo related. SiloOptions Setting the name of the Silo SiloStatisticsOptions Setting various setting related to statistics output TelemetryOptions Setting telemetry consumer settings"
  },
  "Documentation/clusters_and_clients/configuration_guide/load_balancing.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/load_balancing.html",
    "title": "Load Balancing | Microsoft Orleans Documentation",
    "keywords": "Load Balancing Load balancing, in a broad sense, is one of the pillars of the Orleans runtime . Orleans runtime tries to make everything balanced, since balancing allows to maximize resource usage and avoid hotspots, which leads to better performance, as well as helps with elasticity. Load balancing in Orleans applies in multiple places. Below is a non-exhaustive list of places where the runtime performs balancing: Default actor placement strategy is random - new activations are placed randomly across silos. That results in a balanced placement and prevents hotspots for most scenarios. A more advanced ActivationCountPlacement tries to equalize the number of activations on all silos, which results in a more even distribution of activations across silos. This is especially important for elasticity. Grain Directory service is built on top of a Distributed Hash Table, which inherently is balanced. The directory service maps grains to activations, each silo owns part of the global mapping table, and this table is globally partitioned in a balanced way across all silos. We use consistent hashing with virtual buckets for that. Clients connect to all gateways and spread their requests across them, in a balanced way. Reminder service is a distributed partitioned runtime service. The assignment of which silo is responsible to serve which reminder is balanced across all silos via consistent hashing, just like in grain directory. Performance critical components within a silo are partitioned, and the work across them is locally balanced . That way the silo runtime can fully utilize all available CPU cores and not create in-silo bottlenecks. This applies to all local resources: allocation of work to threads, sockets, dispatch responsibilities, queues, etc. StreamQueueBalance balances the responsibility of pulling events from persistence queues across silos in the cluster. Also notice that balancing, in a broad sense, does not necessarily mean loss of locality . One can be balanced and still maintain a good locality. For example, when balancing means sharding/partitioning, you can partition responsibility for a certain logical task, while still maintaining locality within each partition. That applies both for local and distributed balancing. Refer to this presentation on [Balancing Techniques in Orleans]( http://dotnet.github.io/orleans/Presentations/Balancing Techniques in Orleans.pptx) for more details."
  },
  "Documentation/clusters_and_clients/configuration_guide/startup_tasks.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/startup_tasks.html",
    "title": "Startup Tasks | Microsoft Orleans Documentation",
    "keywords": "Startup Tasks In many cases, some task needs to be performed automatically as soon as a silo becomes available. Startup Tasks provide this functionality. Some use cases include, but are not limited to: Starting background timers to perform periodic housekeeping tasks Pre-loading some cache grains with data downloaded from external backing storage Any exceptions that are thrown from a startup task during startup will be reported in the silo log and will stop the silo. This fail-fast approach is the standard way that Orleans handles silo start-up issues, and is intended to allow any problems with silo configuration and/or bootstrap logic to be easily detected during testing phases rather than being silently ignored and causing unexpected problems later in the silo lifecycle. Configuring Startup Tasks Startup tasks can be configured using the ISiloHostBuilder either by registering a delegate to be invoked during startup or by registering a implementation of IStartupTask . Example: Registering a delegate siloHostBuilder.AddStartupTask( async (IServiceProvider services, CancellationToken cancellation) => { // Use the service provider to get the grain factory. var grainFactory = services.GetRequiredService<IGrainFactory>(); // Get a reference to a grain and call a method on it. var grain = grainFactory.GetGrain<IMyGrain>(0); await grain.Initialize(); }); Example: Registering an IStartupTask implementation First we must define an implementation of IStartupTask : public class CallGrainStartupTask : IStartupTask { private readonly IGrainFactory grainFactory; public CallGrainStartupTask(IGrainFactory grainFactory) { this.grainFactory = grainFactory; } public async Task Execute(CancellationToken cancellationToken) { var grain = this.grainFactory.GetGrain<IMyGrain>(0); await grain.Initialize(); } } Then that implementation must be registered with the ISiloHostBuilder : siloHostBuilder.AddStartupTask<CallGrainStartupTask>();"
  },
  "Documentation/clusters_and_clients/monitoring/index.html": {
    "href": "Documentation/clusters_and_clients/monitoring/index.html",
    "title": "Runtime Monitoring | Microsoft Orleans Documentation",
    "keywords": "Runtime Monitoring Orleans output its runtime statistics and metrics through the ITelemetryConsumer interface. Application can register one or more telemetry consumers with for their silos and clients, to receives statistics and metrics that Orleans runtime periotically publishes. These can be consumers for popular telemetry analytics solutions or custom ones for any other destination and purpose. Three telemetry consumer are currently included in the Orleans codebase. They are released as separate NuGet packages: Microsoft.Orleans.OrleansTelemetryConsumers.AI for publishing to Application Insights . Microsoft.Orleans.OrleansTelemetryConsumers.Counters for publishing to Windows performance counters. The Orleans runtime continually updates a number of them. CounterControl.exe tool, included in the Microsoft.Orleans.CounterControl NuGet package, helps register necessary performance counter categories. It has to run with elevated privileges. The performance counters can be monitored using any of the standard monitoring tools. Microsoft.Orleans.OrleansTelemetryConsumers.NewRelic , for publishing to New Relic . To configure your silo and client to use telemetry consumers, silo configuration code looks like this: var siloHostBuilder = new SiloHostBuilder(); //configure the silo with AITelemetryConsumer siloHostBuilder.Configure<TelemetryOptions>(options => options.AddConsumer<AITelemetryConsumer>); client configuration code look like this: var clientBuilder = new ClientBuilder(); //configure the clientBuilder with AITelemetryConsumer clientBuilder.Configure<TelemetryOptions>(options => options.AddConsumer<AITelemetryConsumer>);"
  },
  "Documentation/clusters_and_clients/monitoring/silo_error_code_monitoring.html": {
    "href": "Documentation/clusters_and_clients/monitoring/silo_error_code_monitoring.html",
    "title": "Silo Error Code Monitoring | Microsoft Orleans Documentation",
    "keywords": "Silo Error Code Monitoring Group Log Type Log Code Values Threshold Description Azure Problems Warning or Error 100800 - 100899 Any Error or Warning Transient problems reading or writing to Azure table store will be logged as Warning. Transient read errors will automatically be retried. A final Error log message means there is a real problem connecting to Azure table storage. Membership Connectivity Problems Warning or Error 100600 - 100699 Any Error or Warning Warning logs are an early indication of network connectivity problems and/or silo restart / migration. Ping timeouts and silo-dead votes will show up as Warning messages. Silo detesting it was voted dead will show as Error message. Grain call timeouts Warning 100157 Multiple Warnings logged in short space of time Grain-call timeout problems are generally caused by temporary network connectivity issues or silo restart / reboot problems. The system should recover after a short time (depending on Liveness config settings) at which point Timeouts should clear. Ideally, monitoring for just the bulk log code 600157 variety of these warnings should be sufficient. Silo Restart / Migration Warning 100601 or 100602 Any Warning Warning printed when silo detects it was restarted on same machine {100602) or migrated to different machine (100601) Network Socket Problems Warning or Error 101000 to 101999, 100307,100015, 100016 Any Error or Warning Socket disconnects are logged as Warning messages. Problems opening sockets or during message transmission are logged as Errors. Bulk log message compaction Any 500000 or higher Message summary based on bulk message threshold settings If multiple logs of the same log code occur within a designated time interval (the default is >5 within 1 minute) then additional log messages with that log code are suppressed and output as a \"bulk\" entry with log code equal to the original log code + 500000. So for example, multiple 100157 entries will show in the logs as 5 x 100157 + 1 x 600157 log entry per minute. Grain problems Warning or Error 101534 Any Error or Warning Detection of stuck requests for non-reentrant grains . The error code is reported every time a request takes longer than 5x request timeout time to execute."
  },
  "Documentation/resources/Links.html": {
    "href": "Documentation/resources/Links.html",
    "title": "Links | Microsoft Orleans Documentation",
    "keywords": "Links By Orleans team Orleans Architecture: Principles and Approach I Episode 142: Microsoft Research project Orleans simplify development of scalable cloud services Orleans: Thinking Big and Small Available Now: Preview of Project Orleans  Cloud Services at Scale Orleans: Distributed Virtual Actors for Programmability and Scalability By others Introducing Orleans Microsoft Orleans v2.0 - A comprehensive guide for beginners and experts alike (PowerPoint) A First Look at Project Orleans A Second Look at Project Orleans Project Orleans: An Introduction Introduction To Project Orleans Introduction to Orleans Project Orleans: Different Than Erlang, Designed for a Broad Group of Developers Two Reasons You May Want to Use Microsofts Project Orleans Hatay Tuna & Christian Martinez - Applied Actor Model with Orleans Actor Programming with Orleans: Whats Different? Orleans  a cloud native runtime built for #azure Project Orleans - Actor Model framework A look at Microsoft Orleans through Erlang-tinted glasses Using Codename Orleans in Enterprise Applications Beyond the introduction Grains, Grains and more Grains Fine-graining your Orleans Grains inside the IoT universe Monitorable Grains Aggregating Results in Orleans Creating RESTful Services using Orleans Tackle Distribution, High Throughput and Low-Latency with Orleans  A cloud native Runtime Built for #Azure Saving state only once in a while in #ProjectOrleans Using Orleans for building scalable cloud applications Orleans in an IoT universe Orleans Preview & Halo 4 Using Project Orleans in Halo Orleans & Thinking Outside the Box John Azariah & Mahesh Krishnan - Immutability, State and Scale - Functional, Distributed Applications in Azure last edited: 5 June 2018"
  },
  "Documentation/whats_new_in_orleans.html": {
    "href": "Documentation/whats_new_in_orleans.html",
    "title": "What's new in Orleans | Microsoft Orleans Documentation",
    "keywords": "What's new in Orleans? v2.0.0 March 28th 2018 Major changes (since 2.0.0-rc2) All included providers obtain ServiceId and ClusterId from the global ClusterOptions and do not have those properties on their own options classes (#4235, #4277, 4290) Use string for ServiceId instead of Guid (#4262) v2.0.0-rc2 March 12th 2018 Major changes (since 2.0.0-rc1) A new \"facade\" API for easier configuration of various aspects of stream providers: Persistent stream configurators v2.0.0-rc1 February 27th 2018 Major changes (since 2.0.0-beta3) New provider lifecycle model to replace the old one Builder pattern and options-based configuration of components and extension v2.0.0-beta3 December 21st 2017 Community Virtual Meetup #15 Orleans 2.0 with the core team December 13th 2017 Presentation v2.0.0-beta2 December 12th 2017 v1.5.3 December 8th 2017 v2.0.0-beta1 October 26th 2017 Major new features Most packages are now targetting .NET Standard 2.0 (which mean they can be used from either .NET Framework or .NET Core 2.0) and on non-Windows platforms. v1.5.2 October 17th 2017 v1.5.1 August 28th 2017 v1.5.0 July 6th 2017 Major new features Non-static grain client via ClientBuilder enables connecting to multiple Orleans cluster from the same app domain and connecting to other clusters from within a silo. Support for versioning of grain interfaces for non-downtime upgrades. Support for custom grain placement strategies and directors. Support for hash-based grain placement. v1.4.2 June 9th 2017 v1.4.1 March 27th 2017 Community Virtual Meetup #14 Orleans FSM with John Azariah March 22nd 2017 v1.4.0 February 21st 2017 Major new features Revamped JournaledGrain for event sourcing with support for geo-distributed log-based consistency providers. Abstraction of Grain Services with fixed-placed per-silo application components with their workload partitioned via cluster consistency ring. Support for heterogeneous silos with non-uniform distribution of available grain classes. Cluster membership provider for Service Fabric. Community Virtual Meetup #13 Upgrading Orleans Applications with Sergey Bykov and team February 8th 2017 Presentation v1.4.0-beta February 1st 2017 Major new features Revamped JournaledGrain for event sourcing with support for geo-distributed log-based consistency providers. Abstraction of Grain Services with fixed-placed per-silo application components with their workload partitioned via cluster consistency ring. Support for heterogeneous silos with non-uniform distribution of available grain classes. Cluster membership provider for Service Fabric. Community Virtual Meetup #12 Deploying Orleans with Jakub Konecki December 8th 2016 Presentation v1.3.1 November 15th 2016 Community Virtual Meetup #11 A monitoring and visualisation show with Richard Astbury , Dan Vanderboom and Roger Creyke October 13th 2016 v1.3.0 October 11th 2016 v1.2.4 October 5th 2016 v1.3.0-beta2 September 27th 2016 Notable new features Support for geo-distributed multi-cluster deployments #1108 #1109 #1800 Added new Amazon AWS basic Orleans providers #2006 Support distributed cancellation tokens in grain methods #1599 Community Virtual Meetup #10 The roadmap to Orleans 2.0 with the core team August 25th 2016 v1.2.3 July 11th 2016 v1.2.2 June 15th 2016 v1.2.1 May 19th 2016 v1.2.0 May 4th 2016 v1.2.0-beta April 18th 2016 Major improvements Added an EventHub stream provider based on the same code that is used in Halo 5. Increased throughput by between 5% and 26% depending on the scenario. Migrated all but 30 functional tests to GitHub. Grain state doesn't have to extend GrainState anymore (marked as [Obsolete] ) and can be a simple POCO class. Added support for per-grain-class and global server-side interceptors. Added support for using Consul 0.6.0 as a Membership Provider. Support C# 6. Switched to xUnit for testing as a step towards CoreCLR compatibility. v1.1.3 March 9th 2016 Community Virtual Meetup #9 Nehme Bilal and Reuben Bond talk about deploying Orleans with YAMS and Service Fabric Fabruary 26st 2016 Community Virtual Meetup #8.5 Networking discussion hosted by Jason Bragg February 11th 2016 Community Virtual Meetup #8 Orleans core team present the roadmap January 21st 2016 v1.1.2 January 20th 2016 v1.1.1 January 11th 2016 Community Virtual Meetup #7 Christmas Special - Yevhen Bobrov on Orleankka December 17th 2015 v1.1.0 December 14nd 2015 Community Virtual Meetup #6 MSR PhDs on Geo Distributed Orleansp October 23rd 2015 v1.0.10 September 22nd 2015 v1.0.9 July 15th 2015 v1.0.8 May 26th 2015 Community Virtual Meetup #5 Gabriel Kliot on the new Orleans Streaming API May 22nd 2015 v1.0.7 May 15th 2015 Community Virtual Meetup #4 Reuben Bond on using Orleans at FreeBay April 15th 2015 v1.0.5 March 30th 2015 Community Virtual Meetup #3 Yevhen Bobrov on a Uniform API for Orleans March 6th 2015 Community Virtual Meetup #2 Orleans team live Q&A and roadmap January 12th 2015 Orleans Open Source v1.0 Update (January 2015) Community Virtual Meetup #1 Jakub Konecki on Event Sourced Grains December 18th 2014"
  },
  "Documentation/core_concepts/what_is_a_grain.html": {
    "href": "Documentation/core_concepts/what_is_a_grain.html",
    "title": "What is a grain | Microsoft Orleans Documentation",
    "keywords": "What is a grain? Grains are the key primitives of the Orleans programming model. Grains are the building blocks of an Orleans application, they are atomic units of isolation, distribution, and persistence. Grains are objects that represent application entities. Just like in the classic Object Oriented Programming, a grain encapsulates state of an entity and encodes its behavior in the code logic. Grains can hold references to each other and interact by invoking each others methods exposed via interfaces. Orleans aims to greatly simplify building a scalable application and eliminate most of the concurrency challenges By not sharing data between grains instances except via message passing. By providing the single-threaded execution guarantee to each individual grain. A typical grain encapsulates state and behavior of a single entity (e.g. a specific user or a device or a session). Grain Identity An individual grain is a uniquely addressable instance of a grain type (class). Each grain has a unique identity, also referred to as a grain key, within its type. Grain identity within its type can be a long integer, a GUID, a string, or a combination of a long+string or GUID+string. Accessing a Grain A grain class implements one or more grain interfaces, formal code contracts for interacting with grains of that type. To invoke a grain, a caller needs to know the grain interface that the grain class implements that includes the method that the caller wants to call and the unique identity (key) of the target grain. For example, here's how a user profile grain can be called to update user's address if email is used as a user identity. var user = grainFactory.GetGrain<IUserProfile>(userEmail); await user.UpdateAddress(newAddress); A call to GetGrain is an inexpensive local operation of constructing a grain reference with an embedded identity and type of the target grain. Note that there is no need to create or instantiate the target grain. We make a call to it to update user's address as if the user's grain is already instantiated for us. This is one of the biggest advantages of the Orleans programming model - we never need to create, instantiate or delete grains. We can write our code as if all possible grains, for example millions of user profiles, are always in memory waiting for us to call them. Behind the scenes, the Orleans runtime performs all the heavy lifting of managing resources to transparently bring grains to memory when needed. Behind the Scenes - Grain Lifecycle Grains live in execution containers called silos. Silos form a cluster that combines resources of multiple physical or virtual machines. When there is work (request) for a grain, Orleans ensures there is an instance of the grain on one of the Silos in the cluster. If there is no instance of the grain on any silo, the Orleans runtime creates one. This process is called Activation. In the case that a grain is using Grain Persistence, the runtime automatically reads the state from the backing store upon activation. Once activated on a silo, a grain processes incoming requests (method calls) from other grains or from outside of the cluster (usually from frontend web servers). In the course of processing a request a grain may call other grains or some external services. If a grain stops receiving requests and stays idle, after a configurable period of inactivity Orleans removes the grain from memory (deactivates it) to free up resources for other grains. If and when there's a new request for that grain, Orleans will activate it again, potentially on a different silo, so the caller gets the impression that the grain stayed in memory the whole time. A grain goes through the lifecycle from existing only as its persisted state (if it has any) in storage to being instantiated in memory to being removed from memory. Orleans controls the process of activating and deactivating grains transparently. When coding a grain, a developer assumes all grains are always activated. The sequence of key events in grain lifecycle looks like this. Another grain or a client makes a call to a method of the grain (via a grain reference) The grain gets activated (if it is not already activated somewhere in the cluster) and an instance of the grain class, called a grain activation, is created Constructor of the grain is executed leveraging Dependency Injection, if applicable If Declarative Persistence is used, the grain state is read from storage If overridden, OnActivateAsync is called The grain processes incoming requests The grain remains idle for some time Silo runtime decides to deactivate the grain Silo runtime calls OnDeactivateAsync , if overridden Silo runtime removes the grain from memory Upon a graceful shutdown of a silo, all grain activations it holds get deactivated. Any requests waiting to be processed in grains' queues get forwarded to other silos in the cluster, where new activations of deactivated grains get created on an as-needed basis. If a silo shuts down or dies ungracefully, other silos in the cluster detect the failure, and start creating new activations of grains lost on the failed silo, as new requests for those grains arrive. Note that detection of a silo failure takes some time (configurable), and hence the process of reactivating lost grains isn't instantaneous. Grain Execution A grain activation performs work in chunks and finishes each chunk before it moves on to the next. Chunks of work include method invocations in response to requests from other grains or external clients, and closures scheduled on completion of a previous chunk. The basic unit of execution corresponding to a chunk of work is known as a turn. While Orleans may execute many turns belonging to different activations in parallel, each activation will always execute its turns one at a time. This means that there is no need to use locks or other synchronization methods to guard against data races and other multi-threading hazards."
  },
  "Documentation/deployment/index.html": {
    "href": "Documentation/deployment/index.html",
    "title": "Running the Application | Microsoft Orleans Documentation",
    "keywords": "Orleans Application A typical Orleans application consists of a cluster of server processes (silos) where grains live, and a set of client processes, usually web servers, that receive external requests, turn them into grain method calls, and return results back. Hence, the first thing one needs to do to run an Orleans application is to start a cluster of silos. For testing purposes, a cluster can consist of a single silo. For a reliable production deployment, we obviously want more than one silos in a cluster for fault tolerance and scale. Once the cluster is running, we can start one or more client processes that connect to the cluster and can send requests to the grains. Clients connect to a special TCP endpoint on silos - gateway. By default, every silo in a cluster has a client gateway enabled. So clients can connect to all silos in parallel for better performance and resilience. Configuring and Starting a Silo A silo is configured programmatically via a ClusterConfiguration object. It can be instantiated and populated directly, load settings from a file, or created with several available helper methods for different deployment environments. For local testing, the easiest way to go is to use ClusterConfiguration.LocalhostPrimarySilo() helper method. The configuration object is then passed to a new instance of SiloHost class, that can be initialized and started after that. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for hosting a silo. Add the Microsoft.Orleans.Server NuGet meta-package to the project. PM> Install-Package Microsoft.Orleans.Server Here is an example of how a local silo can be started: var siloConfig = ClusterConfiguration.LocalhostPrimarySilo(); var silo = new SiloHost(\"Test Silo\", siloConfig); silo.InitializeOrleansSilo(); silo.StartOrleansSilo(); Console.WriteLine(\"Press Enter to close.\"); // wait here Console.ReadLine(); // shut the silo down after we are done. silo.ShutdownOrleansSilo(); Configuring and Connecting a Client Client for connecting to a cluster of silos and sending requests to grains is configured programmatically via a ClientConfiguration object and a ClientBuilder . ClientConfiguration object can be instantiated and populated directly, load settings from a file, or created with several available helper methods for different deployment environments. For local testing, the easiest way to go is to use ClientConfiguration.LocalhostSilo() helper method. The configuration object is then passed to a new instance of ClientBuilder class. ClientBuilder exposes more methods for configuring additional client features. After that Build method of the ClientBuilder object is called to get an implementation of IClusterClient interface. Finally, we call Connect() method on the returned object to connect to the cluster. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for running a client or reuse the console application project you created for hosting a silo. Add the Microsoft.Orleans.Client NuGet meta-package to the project. PM> Install-Package Microsoft.Orleans.Client Here is an example of how a client can connect to a local silo: var config = ClientConfiguration.LocalhostSilo(); var builder = new ClientBuilder().UseConfiguration(config). var client = builder.Build(); await client.Connect(); Production Configurations The configuration examples we used here are for testing silos and clients running on the same machine as localhost . In production, silos and clients usually run on different servers and are configured with one of the reliable cluster configuration options. You can find more about that in the Configuration Guide](../clusters_and_clients/configuration_guide/index.md) and in the description of Cluster Management ."
  },
  "Documentation/deployment/grain_versioning/compatible_grains.html": {
    "href": "Documentation/deployment/grain_versioning/compatible_grains.html",
    "title": "Compatible grains | Microsoft Orleans Documentation",
    "keywords": "Compatible grains When an existing grain activation is about to process a request, the runtime will check if the version in the request and the actual version of the grain are compatible. Orleans does not infer at runtime which policy to use , The default behavior to determine if two versions are compatible is determined by GrainVersioningOptions.CompatibilityStrategy Backward compatible (default) Definition A grain interface version Vn can be be backward compatible with Vm if: The name of the interface didn't change (or the overridden typecode) All public methods present in the Vm version are in the Vn version. It is important that the signatures of the methods inherited from Vm are not modified : since Orleans use an internal built-in serializer, modifying/renaming a field (even private) can make the serialization to break. Since Vn can have added methods compared to Vm, Vm is not compatible with Vn. Example If in the cluster we have two versions of a given interface, V1 and V2 and that V2 is backward compatible with V1: If the current activation is a V2 and the requested version is V1, the current activation will be able to process the request normally If the current activation is a V1 and the requested version is V2, the current activation will be deactivated and a new activation compatible with V2 will be created (see version selector strategy ). Fully compatible Definition A grain interface version Vn can be fully compatible with Vm if: Vn is backward compatible with Vm No public methods where added in the Vn version If Vn is fully compatible with Vm then Vm is also fully compatible with Vn. Example If in the cluster we have two versions of a given interface, V1 and V2 and that V2 is fully compatible with V1: If the current activation is a V2 and the requested version is V1, the current activation will be able to process the request normally If the current activation is a V2 and the requested version is V1, the current activation will also be able to process the request normally"
  },
  "Documentation/deployment/grain_versioning/deploying_new_versions_of_grains.html": {
    "href": "Documentation/deployment/grain_versioning/deploying_new_versions_of_grains.html",
    "title": "Deploy new version of grains | Microsoft Orleans Documentation",
    "keywords": "Deploy new version of grains Rolling upgrade In this method you deploy newer silos directly on your environment. This is the simplest method, but it can be difficult to interrupt an on-going deployment and to rollback. Recommended configuration: DefaultCompatibilityStrategy set to BackwardCompatible DefaultVersionSelectorStrategy set to AllCompatibleVersions var silo = new SiloHostBuilder() [...] .Configure<GrainVersioningOptions>(options => { options.DefaultCompatibilityStrategy = nameof(BackwardCompatible); options.DefaultVersionSelectorStrategy = nameof(AllCompatibleVersions); }) [...] When using this configuration, \"old\" clients will be able to talk to activations on both versions of silos. Newer clients and silos will only trigger new activations on newer silos. Using a staging environment In this method you will need a second environment (Staging environment), on which you will deploy newer silos before stopping the Production environment. The Production and the Staging silos and clients will be part of the same cluster . It is important that silos from both environment can talk to each other. Recommended configuration: DefaultCompatibilityStrategy set to BackwardCompatible DefaultVersionSelectorStrategy set to MinimumVersion var silo = new SiloHostBuilder() [...] .Configure<GrainVersioningOptions>(options => { options.DefaultCompatibilityStrategy = nameof(BackwardCompatible); options.DefaultVersionSelectorStrategy = nameof(MinimumVersion); }) [...] Suggested deployment steps: \"V1\" silos and clients are deployed and are running in the Production slot. \"V2\" silos and clients begin to start in the Staging slot. They will join the same cluster as the Production slot. No \"V2\" activations will be created so far. Once the deployment in the Staging slot is finished, the developper can redirect some traffic on the V2 clients (smoke tests, targeted beta users, ect.). This will create V2 activations, but since Grains are backward compatibles and that all silos are in the same cluster, no duplicate activations will be created. If the validation is successful, proceed to VIP swap. If not, you can safely shutdown the Staging cluster: existing V2 activations will be destroyed and V1 activations will be created if needed. V1 activations will naturally \"migrate\" to V2 silos eventually. You can safely shutdown V1 silos. Warning Remember that stateless workers are not versioned and that streaming agents will also start in the staging environment."
  },
  "Documentation/deployment/grain_versioning/grain_versioning.html": {
    "href": "Documentation/deployment/grain_versioning/grain_versioning.html",
    "title": "Grain versioning | Microsoft Orleans Documentation",
    "keywords": "Grain versioning Warning This page describes how to use grain interface versioning. The versioning of Grain state is out of scope. Overview On a given cluster, silos can support different versions of a grain type. In this example the client and Silo{1,2,3} were compiled with grain interface A version 1. Silo 4 was compiled with A version 2. Limitations: No versioning on stateless worker Streaming interfaces are not versioned Enable versioning By default, grains are not versioned. You can version grain by using the VersionAttribute on the grain interface: [Version(X)] public interface IVersionUpgradeTestGrain : IGrainWithIntegerKey {} Where X is the version number of the grain interface, which is typically monotonically increasing. Grain version compatibility and placement When a call from a versioned grain arrive in a cluster: If no activation exists, a compatible activation will be created If an activation exists: If the current one is not compatible, it will be deactivated and new compatible will be created (see version selector strategy ) If the current one is compatible (see compatible grains), the call will be handled normally. By default: All versioned grains are supposed to be backward-compatible only (see backward compatibility guidelines) and compatible grains(Compatible-grains.md)). That means that a v1 grain can make calls to a v2 grain, but a v2 grain cannot call a v1. When multiple versions exist in the cluster, the new activation will be randomly placed on a compatible silo. You can change this default behavior via the option GrainVersioningOptions : var silo = new SiloHostBuilder() [...] .Configure<GrainVersioningOptions>(options => { options.DefaultCompatibilityStrategy = nameof(BackwardCompatible); options.DefaultVersionSelectorStrategy = nameof(MinimumVersion); }) [...]"
  },
  "Documentation/deployment/grain_versioning/version_selector_strategy.html": {
    "href": "Documentation/deployment/grain_versioning/version_selector_strategy.html",
    "title": "Version selector strategy | Microsoft Orleans Documentation",
    "keywords": "Version selector strategy When several versions of the same grain interface exist in the cluster, and a new activation has to be created, a compatible version will be chosen according to the strategy defined in GrainVersioningOptions.DefaultVersionSelectorStrategy . Orleans out of the box supports the following strategies: All compatible versions (default) Using this strategy, the version of the new activation will be chosen randomly across all compatible versions. For example if we have 2 versions of a given grain interface, V1 and V2: V2 is backward compatible with V1 In the cluster there are 2 silos that support V2, 8 support V1 The request was made from a V1 client/silo In this case, there is a 20% chance that the new activation will be a V2 and 80% chance that it will be a V1. Latest version Using this strategy, the version of the new activation will always be the latest compatible version. For example if we have 2 versions of a given grain interface, V1 and V2 (V2 is backward or fully compatible with V1) then all new activations will be V2. Minimum version Using this strategy, the version of the new activation will always be the requested or the minimum compatible version. For example if we have 2 versions of a given grain interface, V2, V3, all fully compatibles: If the request was made from a V1 client/silo, the new activation will be a V2 If the request was made from a V3 client/silo, the new activation will be a V2 too"
  },
  "Documentation/Benefits.html": {
    "href": "Documentation/Benefits.html",
    "title": "Main Benefits | Microsoft Orleans Documentation",
    "keywords": "Benefits The main benefits of Orleans are: developer productivity , even for non-expert programmers; and transparent scalability by default with no special effort from the programmer. We expand on each of these benefits below. Developer Productivity The Orleans programming model raises productivity of both expert and non-expert programmers by providing the following key abstractions, guarantees and system services. Familiar object-oriented programming (OOP) paradigm . Actors are .NET classes that implement declared .NET actor interfaces with asynchronous methods. Thus actors appear to the programmer as remote objects whose methods can be directly invoked. This provides the programmer the familiar OOP paradigm by turning method calls into messages, routing them to the right endpoints, invoking the target actors methods and dealing with failures and corner cases in a completely transparent way. Single-threaded execution of actors . The runtime guarantees that an actor never executes on more than one thread at a time. Combined with the isolation from other actors, the programmer never faces concurrency at the actor level, and hence never needs to use locks or other synchronization mechanisms to control access to shared data. This feature alone makes development of distributed applications tractable for non-expert programmers. Transparent activation . The runtime activates an actor as-needed, only when there is a message for it to process. This cleanly separates the notion of creating a reference to an actor, which is visible to and controlled by application code, and physical activation of the actor in memory, which is transparent to the application. In many ways, this is similar to virtual memory in that it decides when to page out (deactivate) or page in (activate) an actor; the application has uninterrupted access to the full memory space of logically created actors, whether or not they are in the physical memory at any particular point in time. Transparent activation enables dynamic, adaptive load balancing via placement and migration of actors across the pool of hardware resources. This features is a significant improvement on the traditional actor model, in which actor lifetime is application-managed. Location transparency . An actor reference (proxy object) that the programmer uses to invoke the actors methods or pass to other components only contains the logical identity of the actor. The translation of the actors logical identity to its physical location and the corresponding routing of messages are done transparently by the Orleans runtime. Application code communicates with actors oblivious to their physical location, which may change over time due to failures or resource management, or because an actor is deactivated at the time it is called. Transparent integration with persistent store . Orleans allows for declarative mapping of actors in-memory state to persistent store. It synchronizes updates, transparently guaranteeing that callers receive results only after the persistent state has been successfully updated. Extending and/or customizing the set of existing persistent storage providers available is straight-forward. Automatic propagation of errors . The runtime automatically propagates unhandled errors up the call chain with the semantics of asynchronous and distributed try/catch. As a result, errors do not get lost within an application. This allows the programmer to put error handling logic at the appropriate places, without the tedious work of manually propagating errors at each level. Transparent Scalability by Default The Orleans programming model is designed to guide the programmer down a path of likely success in scaling their application or service through several orders of magnitude. This is done by incorporating the proven best practices and patterns, and providing an efficient implementation of the lower level system functionality. Here are some key factors that enable scalability and performance. Implicit fine grain partitioning of application state . By using actors as directly addressable entities, the programmer implicitly breaks down the overall state of their application. While the Orleans programming model does not prescribe how big or small an actor should be, in most cases it makes sense to have a relative large number of actors  millions or more  with each representing a natural entity of the application, such as a user account, a purchase order, etc. With actors being individually addressable and their physical location abstracted away by the runtime, Orleans has enormous flexibility in balancing load and dealing with hot spots in a transparent and generic way without any thought from the application developer. Adaptive resource management . With actors making no assumption about locality of other actors they interact with and because of the location transparency, the runtime can manage and adjust allocation of available HW resources in a very dynamic way by making fine grain decisions on placement/migration of actors across the compute cluster in reaction to load and communication patterns without failing incoming requests. By creating multiple replicas of a particular actor the runtime can increase throughput of the actor if necessary without making any changes to the application code. Multiplexed communication . Actors in Orleans have logical endpoints, and messaging between them is multiplexed across a fixed set of all-to-all physical connections (TCP sockets). This allows the runtime to host a very large number (millions) of addressable entities with low OS overhead per actor. In addition, activation/deactivation of an actor does not incur the cost of registering/unregistering of a physical endpoint, such as a TCP port or a HTTP URL, or even closing a TCP connection. Efficient scheduling . The runtime schedules execution of a large number of single-threaded actors across a custom thread pool with a thread per physical processor core. With actor code written in the non-blocking continuation based style (a requirement of the Orleans programming model) application code runs in a very efficient cooperative multi-threaded manner with no contention. This allows the system to reach high throughput and run at very high CPU utilization (up to 90%+) with great stability. The fact that a growth in the number of actors in the system and the load does not lead to additional threads or other OS primitives helps scalability of individual nodes and the whole system. Explicit asynchrony . The Orleans programming model makes the asynchronous nature of a distributed application explicit and guides programmers to write non-blocking asynchronous code. Combined with asynchronous messaging and efficient scheduling, this enables a large degree of distributed parallelism and overall throughput without the explicit use of multi-threading."
  },
  "Documentation/who_is_using_orleans.html": {
    "href": "Documentation/who_is_using_orleans.html",
    "title": "Who Is Using Orleans? | Microsoft Orleans Documentation",
    "keywords": "Who Is Using Orleans? Orleans has been used extensively by several Microsoft projects and product groups, most notably by 343 Industries as a platform for all of Halo 4 and Halo 5 cloud services. There are various other internal projects at Microsoft which are using Orleans, but we are not able to talk publicly about many of those yet. There are many more companies and projects which are also using Orleans, and this page provides a partial list of some that we know about.... Feel free to send us a pull request on GitHub to add your company / project to this list. Companies Companies currently using Orleans in production: Gassumo Microsoft Skype , Azure , others Microsoft Studios 343 Studios ( Halo ), Age of Empires , BigPark , Black Tusk , others Microsoft Research Naekoly.CZ Trustev Mailcloud Limited Gigya Honeywell Mesh Systems MESHVista Smart Cloud IoT Platform leverages Orleans for back-end services monitoring device state and business logic Applicita Limited A number of client projects where extreme scale and performance is required Drawboard Cloud collaboration and synchronisation platform YouScan Social media monitoring & analytics provider. Orleans is used for stateful stream processing at scale, reliable execution of long running jobs and as a main application server. Visa PagoLivre Mobile and Social Payment platform invertirOnline.com Argentinian-based electronic brokerage firm Lebara Nomnio Nomnio IoT Platform and industry projects where reliability and performance is required Real Artists Ship 2.0 Fast, native, comprehensive issue tracking for GitHub Manufacturing Resources International MRI designs, engineers, and fabricates BoldVu LCD displays used in out of home advertising networks. Orleans powers our IOT infrastructure to help monitor and maintain our displays Projects and Applications Projects, websites and applications powered by Orleans, or provide extensions to Orleans. Claw (Clash Of Animal Warriors) is a real-time multiplayer mobile game which uses Orleans for its MatchMaker software which should handle many players at the same time and respond to them as fast as possible. Halo 4 - 343 Industries Microsoft BigPark Studio Orleans-Contrib Community contribution projects, including Orleans Monitoring, Design Patterns, Storage Provider, etc. Pegasus Mission More Info here and here Sync.Today 2015 .NET Business Processes Automation Platform. More info here Microdot A microservices framework by Gigya, for writing Orleans based microservices"
  },
  "Documentation/clusters_and_clients/configuration_guide/activation_garbage_collection.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/activation_garbage_collection.html",
    "title": "Activation Garbage Collection | Microsoft Orleans Documentation",
    "keywords": "Activation Garbage Collection As described in the Core Concepts section, a grain activation is an in-memory instance of a grain class that gets automatically created by the Orleans runtime on an as-needed basis as a temporary physical embodiment of a grain. Activation Garbage Collection (Activation GC) is the process of removal from memory of unused grain activations. It is conceptually similar to how garbage collection of memory works in .NET. However, Activation GC only takes into consideration how long a particular grain activation has been idle. Memory usage is not used as a factor. How Activation GC Works The general process of Activation GC involves Orleans runtime in a silo periodically scanning for grain activations that have not been used at all for the configured period of time (Collection Age Limit). Once a grain activation has been idle for that long, it gets deactivated. The deactivation process begins by the runtime calling the grains OnDeactivateAsync() method, and completes by removing references to the grain activation object from all data structures of the silo, so that the memory is reclaimed by the .NET GC. As a result, with no burden put on the application code, only recently used grain activations stay in memory while activations that aren't used anymore get automatically removed, and system resources used by them get reclaimed by the runtime. What counts as being active for the purpose of grain activation collection receiving a method call receiving a reminder receiving an event via streaming What does NOT count as being active for the purpose of grain activation collection performing a call (to another grain or to an Orleans client) timer events arbitrary IO operations or external calls not involving Orleans framework Collection Age Limit This period of time after which an idle grain activation becomes subject to Activation GC is called Collection Age Limit. The default Collection Age Limit is 2 hours, but it can be changed globally or for individual grain classes. Explicit Control of Activation Garbage Collection Delaying Activation GC A grain activation can delay its own Activation GC, by calling this.DelayDeactivation() method: protected void DelayDeactivation(TimeSpan timeSpan) This call will ensure that this activation is not deactivated for at least the specified time duration. It takes priority over Activation Garbage Collection settings specified in the config, but does not cancel them. Therefore, this call provides an additional hook to delay the deactivation beyond what is specified in the Activation Garbage Collection settings . This call can not be used to expedite Activation Garbage Collection. A positive timeSpan value means prevent GC of this activation for that time span. A negative timeSpan value means cancel the previous setting of the DelayDeactivation call and make this activation behave based on the regular Activation Garbage Collection settings. Scenarios: 1) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(20)) , it will cause this activation to not be collected for at least 20 min. 2) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(5)) , the activation will be collected after 10 min, if no extra calls were made. 3) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(5)) , and after 7 minutes there is another call on this grain, the activation will be collected after 17 min from time zero, if no extra calls were made. 4) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(20)) , and after 7 minutes there is another call on this grain, the activation will be collected after 20 min from time zero, if no extra calls were made. Note that DelayDeactivation does not 100% guarantee that the grain activation will not get deactivated before the specified period of time expires. There are certain failure cases that may cause 'premature' deactivation of grains. That means that DelayDeactivation cannot not be used as a means to 'pin' a grain activation in memory forever or to a specific silo . DelayDeactivation is merely an optimization mechanism that can help reduce the aggregate cost of a grain getting deactivated and reactivated over time, if that matters. In most cases there should be no need to use DelayDeactivation at all. Expediting Activation GC A grain activation can also instruct the runtime to deactivate it next time it becomes idle by calling this.DeactivateOnIdle() method: protected void DeactivateOnIdle() A grain activation is considered idle if it is not processing any message at the moment. If you call DeactivateOnIdle while a grain is processing a message, it will get deactivated as soon as processing of the current message is finished. If there are any requests queued for the grain, they will be forwarded to the next activation. DeactivateOnIdle take priority over any Activation Garbage Collection settings specified in the config or DelayDeactivation . Note that this setting only applies to the grain activation from which it has been called and it does not apply to other grain activation of this type. Configuration Grain garbage collection can be configured using the GrainCollectionOptions options: mySiloHostBuilder.Configure<GrainCollectionOptions>(options => { // Set the value of CollectionAge to 10 minutes for all grain options.CollectionAge = TimeSpan.FromMinutes(10); // Override the value of CollectionAge to 5 minutes for MyGrainImplementation options.ClassSpecificCollectionAge[typeof(MyGrainImplementation).FullName] = TimeSpan.FromMinutes(5); })"
  },
  "Documentation/clusters_and_clients/configuration_guide/index.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/index.html",
    "title": "Orleans Configuration Guide | Microsoft Orleans Documentation",
    "keywords": "Orleans Configuration Guide This Configuration Guide explains the key configuration parameters and how they should be used for most typical usage scenarios. Orleans can be used in a variety of configurations that fit different usage scenarios, such as local single node deployment for development and testing, cluster of servers, multi-instance Azure worker role, etc. This guide provides instructions for the key configuration parameters that are necessary to make Orleans run in one of the target scenarios. There are also other configuration parameters that primarily help fine tune Orleans for better performance. Silos and Clients are configured programmatically via a SiloHostBuilder and ClientBuilder respectively and a number of supplemental option classes. Option classes in Orleans follow the ASP.NET Options pattern, and can be loaded via files, environment variables etc. Please refer to the Options pattern documentation for more information. If you want to configure a silo and a client for local development, look at the Local Development Configuration section. The Server Configuration and Client Configuration sections of the guide cover configuring silos and clients, respectively. The section on Typical Configurations provides a summary of a few common configurations. A list of important core options that can be configured can be found on this section . Important : Make sure you properly configure .NET Garbage Collection as detailed in Configuring .NET Garbage Collection ."
  },
  "Documentation/clusters_and_clients/configuration_guide/messaging_delivery_guarantees.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/messaging_delivery_guarantees.html",
    "title": "Messaging Delivery Guarantees | Microsoft Orleans Documentation",
    "keywords": "Messaging Delivery Guarantees Orleans messaging delivery guarantees are at-most-once , by default. Optionally, if configured to do retries upon timeout, Orleans provides at-least-once delivery instead. In more details: Every message in Orleans has automatic timeout (the exact timeout can be configured). If the reply does not arrive on time the return Task is broken with timeout exception. Orleans can be configured to do automatic retries upon timeout. By default we do NOT do automatic retries. Application code of course can also pick to do retries upon timeout. If the Orleans system is configured not to do automatic retries (default setting) and application is not resending  Orleans provides at most once message delivery . A message will either be delivered once or not at all. It will never be delivered twice. In the system with retries (either by the runtime or by the application) the message may arrive multiple times. Orleans currently does nothing to durably store which messages already arrived and suppress the second delivery (we believe this would be pretty costly). So in the system with retries Orleans does NOT guarantee at most once delivery. If you keep retrying potentially indefinitely , the message will eventually arrive , thus providing at least once delivery guarantee. Notice that will eventually arrive is something that the runtime needs to guarantee. It does not come for free just by itself even if you keep retrying. Orleans provides eventually delivery since grains never go into any permanent failure state and a failed grain will for sure eventually be re-activated on another silo. So to summarize : in the system without retries Orleans guarantees at most once message delivery. In the system with infinite retries Orleans guarantee at least once (and does NOT guarantee at most once). Note : In the Orleans technical report we accidentally only mentioned the 2nd option with automatic retries and forgot to mention that by default with no retries, Orleans provides at most once delivery."
  },
  "Documentation/clusters_and_clients/configuration_guide/server_configuration.html": {
    "href": "Documentation/clusters_and_clients/configuration_guide/server_configuration.html",
    "title": "Server Configuration | Microsoft Orleans Documentation",
    "keywords": "Note If you just want to start a local silo and a local client for development purpose, look at the Local Development Configuration page Server Configuration A silo is configured programmatically via a SiloHostBuilder and a number of supplemental option classes. Option classes in Orleans follow the ASP.NET Options pattern, and can be loaded via files, environment variables etc. Please refer to the Options pattern documentation for more information. There are several key aspects of silo configuration: Orleans clustering information Clustering provider Endpoints to use for silo-to-silo and client-to-silo communications Application parts Example of a silo configuration that defines cluster information, uses Azure clustering and configure the application parts: var silo = new SiloHostBuilder() // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"MyAwesomeOrleansService\"; }) // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) // Endpoints .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) // Application parts: just reference one of the grain implementations that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(ValueGrain).Assembly).WithReferences()) // Now create the silo! .Build(); Let's breakdown the steps used in this sample: Orleans clustering information [...] // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"orleans-docker\"; options.ServiceId = \"AspNetSampleApp\"; }) [...] Here we set two things: the ClusterId to \"my-first-cluster\" : this is a unique ID for the Orleans cluster. All clients and silo that uses this ID will be able to directly talk to each other. Some will choose to use a different ClusterId for each deployments for example. the ServiceId to \"AspNetSampleApp\" : this is a unique ID for your application, that will be used by some provider (for example for persistence providers). This ID should be stable (not change) accross deployments . Clustering provider [...] // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) [...] Usually, a service built on Orleans is deployed on a cluster of nodes, either on dedicated hardware or in Azure. For development and basic testing, Orleans can be deployed in a single node configuration. When deployed to a cluster of nodes, Orleans internally implements a set of protocols to discover and maintain membership of Orleans silos in the cluster, including detection of node failures and automatic reconfiguration. For reliable management of cluster membership, Orleans uses Azure Table, SQL Server or Apache ZooKeeper for synchronization of nodes. In this sample we are using Azure Table as the membership provider. Endpoints var silo = new SiloHostBuilder() [...] // Endpoints .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) [...] An Orleans silo typically configure two endpoints: the silo-to-silo endpoints, used for communication between silo in the same cluster the client-to-silo endpoints (or gateway), use for communication between clients and silos in the same cluster. In the sample we are using the helper method .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) that set the port used for silo-to-silo communication and the port for the gateway to 11111 and 30000 respectively. This method will detect on which interface listen. This method should be sufficient in most cases, but you can customize it further if you need it. Here is for example if you want to use an external IP address with some port-forwarding: [...] .Configure<EndpointOptions>(options => { // Port to use for Silo-to-Silo options.SiloPort = 11111; // Port to use for the gateway options.GatewayPort = 30000; // IP Address to advertise in the cluster options.AdvertisedIPAddress = IPAddress.Parse(\"172.16.0.42\"); // The socket used for silo-to-silo will bind to this endpoint options.GatewayListeningEndpoint = new IPEndPoint(IPAddress.Any, 40000); // The socket used by the gateway will bind to this endpoint options.SiloListeningEndpoint = new IPEndPoint(IPAddress.Any, 50000); }) [...] Internally, the silo will listen on 0.0.0.0:40000 and 0.0.0.0:50000 but the value published in the membership provider will be 172.16.0.42:11111 and 172.16.0.42:30000 . Application parts [...] // Application parts: just reference one of the grain implementations that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(ValueGrain).Assembly).WithReferences()) [...]; Although this step is not technically required (if not configured, Orleans will scan all assembly in the current folder), developers are encouraged to configure this. This step will help Orleans to load user assemblies and types. These assemblies are referred to as Application Parts. All Grains, Grain Interfaces, and Serializers are discovered using Application Parts. Application Parts are configured using an IApplicationPartsManager , which can be accessed using the ConfigureApplicationParts extension method on IClientBuilder and ISiloHostBuilder . The ConfigureApplicationParts method accepts a delegate, Action<IApplicationPartManager> . The following extension methods on IApplicationPartManager support common uses: AddApplicationPart(assembly) a single assembly can be added using this extension method. AddFromAppDomain() adds all assemblies currently loaded in the AppDomain . AddFromApplicationBaseDirectory() loads and adds all assemblies in the current base path (see AppDomain.BaseDirectory ). Assemblies added by the above methods can be supplemented using the following extension methods on their return type, IApplicationPartManagerWithAssemblies : WithReferences() adds all referenced assemblies from the added parts. This immediately loads any transitively referenced assemblies. Assembly loading errors are ignored. WithCodeGeneration() generates support code for the added parts and adds it to the part manager. Note that this requires the Microsoft.Orleans.OrleansCodeGenerator package to be installed, and is commonly referred to as runtime code generation. Type discovery requires that the provided Application Parts include specific attributes. Adding the build-time code generation package ( Microsoft.Orleans.OrleansCodeGenerator.Build ) to each project containing Grains, Grain Interfaces, or Serializers is the recommended approach for ensuring that these attributes are present. Build-time code generation only supports C#. For F#, Visual Basic, and other .NET languages, code can be generated during configuration time via the WithCodeGeneration() method described above."
  },
  "Documentation/grains/cancellation_tokens.html": {
    "href": "Documentation/grains/cancellation_tokens.html",
    "title": "Grain cancellation tokens | Microsoft Orleans Documentation",
    "keywords": "Grain cancellation tokens The Orleans runtime provides mechanism called grain cancellation token, that enables the developer to cancel an executing grain operation. Description GrainCancellationToken is a wrapper around standard .NET System.Threading.CancellationToken , which enables cooperative cancellation between threads, thread pool work items or Task objects, and can be passed as grain method argument. A GrainCancellationTokenSource is a object that provides a cancellation token through its Token property and sends a cancellation message by calling its Cancel method. Usage Instantiate a CancellationTokenSource object, which manages and sends cancellation notification to the individual cancellation tokens. var tcs = new GrainCancellationTokenSource(); Pass the token returned by the GrainCancellationTokenSource.Token property to each grain method that listens for cancellation. var waitTask = grain.LongIoWork(tcs.Token, TimeSpan.FromSeconds(10)); A cancellable grain operation needs to handle underlying CancellationToken property of GrainCancellationToken just like it would do in any other .NET code. public async Task LongIoWork(GrainCancellationToken tc, TimeSpan delay) { while(!tc.CancellationToken.IsCancellationRequested) { await IoOperation(tc.CancellationToken); } } Call the GrainCancellationTokenSource.Cancel method to initiate cancellation. await tcs.Cancel(); Call the Dispose method when you are finished with the GrainCancellationTokenSource object. tcs.Dispose(); Important Considerations: The GrainCancellationTokenSource.Cancel method returns Task , and in order to ensure cancellation the cancel call must be retried in case of transient communication failure. Callbacks registered in underlying System.Threading.CancellationToken are subjects to single threaded execution guarantees within the grain activation on which they were registered. Each GrainCancellationToken can be passed through multiple methods invocations."
  },
  "Documentation/grains/developing_a_grain.html": {
    "href": "Documentation/grains/developing_a_grain.html",
    "title": "Developing a Grain | Microsoft Orleans Documentation",
    "keywords": "Setup Before you write code to implement a grain class, create a new Class Library project targeting .NET 4.6.1 or higher in Visual Studio and add the Microsoft.Orleans.OrleansCodeGenerator.Build NuGet package to it. PM> Install-Package Microsoft.Orleans.OrleansCodeGenerator.Build Grain Interfaces and Classes Grains interact with each other and get called from outside by invoking methods declared as part of the respective grain interfaces. A grain class implements one or more previously declared grain interfaces. All methods of a grain interface must return a Task (for void methods) or a Task<T> (for methods returning values of type T ). The following is an excerpt from the Orleans version 1.5 Presence Service sample: //an example of a Grain Interface public interface IPlayerGrain : IGrainWithGuidKey { Task<IGameGrain> GetCurrentGame(); Task JoinGame(IGameGrain game); Task LeaveGame(IGameGrain game); } //an example of a Grain class implementing a Grain Interface public class PlayerGrain : Grain, IPlayerGrain { private IGameGrain currentGame; // Game the player is currently in. May be null. public Task<IGameGrain> GetCurrentGame() { return Task.FromResult(currentGame); } // Game grain calls this method to notify that the player has joined the game. public Task JoinGame(IGameGrain game) { currentGame = game; Console.WriteLine( \"Player {0} joined game {1}\", this.GetPrimaryKey(), game.GetPrimaryKey()); return Task.CompletedTask; } // Game grain calls this method to notify that the player has left the game. public Task LeaveGame(IGameGrain game) { currentGame = null; Console.WriteLine( \"Player {0} left game {1}\", this.GetPrimaryKey(), game.GetPrimaryKey()); return Task.CompletedTask; } } Returning Values from Grain Methods A grain method that returns a value of type T is defined in a grain interface as returning a Task<T> . For grain methods not marked with the async keyword, when the return value is available, it is usually returned via the following statement: public Task<SomeType> GrainMethod1() { ... return Task.FromResult(<variable or constant with result>); } A grain method that returns no value, effectively a void method, is defined in a grain interface as returning a Task . The returned Task indicates asynchronous execution and completion of the method. For grain methods not marked with the async keyword, when a \"void\" method completes its execution, it needs to return the special value of Task.CompletedTask : public Task GrainMethod2() { ... return Task.CompletedTask; } A grain method marked as async returns the value directly: public async Task<SomeType> GrainMethod3() { ... return <variable or constant with result>; } A \"void\" grain methods marked as async that returns no value simply returns at the end of their execution: public async Task GrainMethod4() { ... return; } If a grain method receives the return value from another asynchronous method call, to a grain or not, and doesn't need to perform error handling of that call, it can simply return the Task it receives from that asynchronous call as its return value: public Task<SomeType> GrainMethod5() { ... Task<SomeType> task = CallToAnotherGrain(); return task; } Similarly, a \"void\" grain method can return a Task returned to it by another call instead of awaiting it. public Task GrainMethod6() { ... Task task = CallToAsyncAPI(); return task; } Grain Reference A Grain Reference is a proxy object that implements the same grain interface as the corresponding grain class. It encapsulates a logical identity (type and unique key) of the target grain. A grain reference is what is used for making calls to the target grain. Each grain reference is for a single grain (a single instance of the grain class), but one can create multiple independent references for the same grain. Since a grain reference represents a logical identity of the target grain, it is independent from the physical location of the grain, and stays valid even after a complete restart of the system. Developers can use grain references like any other .NET object. It can be passed to a method, used as a method return value, etc., and even saved to persistent storage. A grain reference can be obtained by passing the identity of a grain to the GrainFactory.GetGrain<T>(key) method, where T is the grain interface and key is the unique key of the grain within the type. The following are examples of how to obtain a grain reference of the IPlayerGrain interface defined above. From inside a grain class: //construct the grain reference of a specific player IPlayerGrain player = GrainFactory.GetGrain<IPlayerGrain>(playerId); From Orleans Client code. Prior to 1.5.0: IPlayerGrain player = GrainClient.GrainFactory.GetGrain<IPlayerGrain>(playerId); Since 1.5.0: IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); Grain Method Invocation The Orleans programming model is based on the Asynchronous Programming with Async and Await . Using the grain reference from the previous example, here's how one performs a grain method invocation: //Invoking a grain method asynchronously Task joinGameTask = player.JoinGame(this); //The await keyword effectively makes the remainder of the method execute asynchronously at a later point (upon completion of the Task being awaited) without blocking the thread. await joinGameTask; //The next line will execute later, after joinGameTask is completed. players.Add(playerId); It is possible to join two or more Tasks ; the join operation creates a new Task that is resolved when all of its constituent Task s are completed. This is a useful pattern when a grain needs to start multiple computations and wait for all of them to complete before proceeding. For example, a front-end grain that generates a web page made of many parts might make multiple back-end calls, one for each part, and receive a Task for each result. The grain would then await the join of all of these Tasks ; when the join Task is resolved, the individual Task s have been completed, and all the data required to format the web page has been received. Example: List<Task> tasks = new List<Task>(); Message notification = CreateNewMessage(text); foreach (ISubscriber subscriber in subscribers) { tasks.Add(subscriber.Notify(notification)); } // WhenAll joins a collection of tasks, and returns a joined Task that will be resolved when all of the individual notification Tasks are resolved. Task joinedTask = Task.WhenAll(tasks); await joinedTask; // Execution of the rest of the method will continue asynchronously after joinedTask is resolve. Virtual methods A grain class can optionally override OnActivateAsync and OnDeactivateAsync virtual methods that get invoked by the Orleans runtime upon activation and deactivation of each grain of the class. This gives the grain code a chance to perform additional initialization and cleanup operations. An exception thrown by OnActivateAsync fails the activation process. While OnActivateAsync , if overridden, is always called as part of the grain activation process, OnDeactivateAsync is not guaranteed to get called in all situations, for example, in case of a server failure or other abnormal events. Because of that, applications should not rely on OnDeactivateAsync for performing critical operations, such as persistence of state changes, and only use it for best effort operations."
  },
  "Documentation/resources/Migration/Migration1.5.html": {
    "href": "Documentation/resources/Migration/Migration1.5.html",
    "title": "Migration from Orleans 1.5 to 2.0 | Microsoft Orleans Documentation",
    "keywords": "Migration from Orleans 1.5 to 2.0 The bulk of the Orleans APIs stayed unchanged in 2.0 or implementation of those APIs were left in legacy classes for backward compatibility. At the same time, the newly introduced APIs provide some new capabilities or better ways of accomplishing those tasks. There are also more subtle differences when it comes to .NET SDK tooling and Visual Studio support that helps to be aware of. This document provides guidance for migrating application code from to Orleans 2.0. Visual Studio and Tooling requirements Orleans 2.0.0 is built on top of .NET Standard 2.0. Because of that, you need to upgrade development tools to ensure yourself a pleasant developing experience. We recommend to use Visual Studio 2017 or above to develop Orleans 2.0.0 applications. Based on our experience, version 15.5.2 and above works best. .NET Standard 2.0.0 is compatible with .NET 4.6.1 and above, .NET Core 2.0, and a list of other frameworks. Orleans 2.0.0 inherited that compatibility. For more information on .NET Standard compatibility with other framework, please refer to .NET Standard documentation : If you are developing a .NET Core or .NET application using Orleans, you will need to follow certain steps to set up your environment, such as installing .NET Core SDK. For more information, please refer to their documentation . Available options for configuration code Hosting Configuring and Starting a Silo (using the new SiloBuilder API and legacy ClusterConfiguration object) There's a number of new option classes in Orleans 2.0 that provide a new way for configuring a silo. To ease migration to the new API, there is a optional backward compatibility package, Microsoft.Orleans.Runtime.Legacy , that provides a bridge from the old 1.x configuration API to the new one. If you add Microsoft.Orleans.Runtime.Legacy package, a silo can still be configured programmatically via the legacy ClusterConfiguration object that can then be passed to SiloHostBuilder to build and start a silo. You still need to specify grain class assemblies via the ConfigureApplicationParts call. Here is an example of how a local silo can be configured in the legacy way: public class Program { public static async Task Main(string[] args) { try { var host = await StartSilo(); Console.WriteLine(\"Press Enter to terminate...\"); Console.ReadLine(); await host.StopAsync(); return 0; } catch (Exception ex) { Console.WriteLine(ex); return 1; } } private static async Task<ISiloHost> StartSilo() { // define the cluster configuration (temporarily required in the beta version, // will not be required by the final release) var config = ClusterConfiguration.LocalhostPrimarySilo(); // add providers to the legacy configuration object. config.AddMemoryStorageProvider(); var builder = new SiloHostBuilder() .UseConfiguration(config) // Add assemblies to scan for grains and serializers. // For more info read the Application Parts section .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(HelloGrain).Assembly) .WithReferences()) // Configure logging with any logging framework that supports Microsoft.Extensions.Logging. // In this particular case it logs using the Microsoft.Extensions.Logging.Console package. .ConfigureLogging(logging => logging.AddConsole()); var host = builder.Build(); await host.StartAsync(); return host; } } Configuring and Connecting a Client (using the new ClientBuilder API and legacy ClientConfiguration object) There's a number of new option classes in Orleans 2.0 that provide a new way for configuring a client. To ease migration to the new API, there is a optional backward compatibility package, Microsoft.Orleans.Core.Legacy , that provides a bridge from the old 1.x configuration API to the new one. If you added Microsoft.Orleans.Core.Legacy package, a client can still be configured programmatically via the legacy ClientConfiguration object that can then be passed to ClientBuilder to build and connect the client. You still need to specify grain interface assemblies via the ConfigureApplicationParts call. Here is an example of how a client can connect to a local silo, using legacy configuration: // define the client configuration (temporarily required in the beta version, // will not be required by the final release) var config = ClientConfiguration.LocalhostSilo(); var builder = new ClientBuilder() .UseConfiguration(config) // Add assemblies to scan for grains interfaces and serializers. // For more info read the Application Parts section .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IHello).Assembly)) .ConfigureLogging(logging => logging.AddConsole()) var client = builder.Build(); await client.Connect(); Logging Orleans 2.0 uses the same logging abstractions as ASP.NET Core 2.0. You can find replacement for most Orleans logging feature in ASP.NET Core logging. Orleans specific logging feature, such as ILogConsumer and message bulking, is still maintained in Microsoft.Orleans.Logging.Legacy package, so that you still have the option to use them. But how to configure your logging with Orleans changed in 2.0. Let me walk you through the process of migration. In 1.5, logging configuration is done through ClientConfiguration and NodeConfiguration . You can configure DefaultTraceLevel , TraceFileName , TraceFilePattern , TraceLevelOverrides , TraceToConsole , BulkMessageLimit , LogConsumers , etc through it. In 2.0, logging configuration is consistent with ASP.NET Core 2.0 logging, which means most of the configuration is done through Microsoft.Extensions.Logging.ILoggingBuilder . To configure DefaultTraceLevel and TraceLevelOverrides , you need to apply log filtering to ILoggingBuilder . For example, to set trace level to 'Debug' on orleans runtime, you can use sample below, siloBuilder.AddLogging(builder=>builder.AddFilter(\"Orleans\", LogLevel.Debug)); You can configure log level for you application code in the same way. If you want to set a default minimum trace level to be Debug, use sample below siloBuilder.AddLogging(builder=>builder.SetMinimumLevel(LogLevel.Debug); For more information on log filtering, please see their docs on https://docs.microsoft.com/en-us/aspnet/core/fundamentals/logging ; To configure TraceToConsole to be true , you need to reference Microsoft.Extensions.Logging.Console package and then use AddConsole() extension method on ILoggingBuilder . The same with TraceFileName and TraceFilePattern , if you want to log messages to a file, you need to use AddFile(\"file name\") method on ILoggingBuilder . If you still want to use Message Bulking feature, You need to configure it through ILoggingBuilder as well. Message bulking feature lives in Microsoft.Orleans.Logging.Legacy package. So you need to add dependency on that package first. And then configure it through ILoggingBuilder . Below is an example on how to configure it with ISiloHostBuilder siloBuiler.AddLogging(builder => builder.AddMessageBulkingLoggerProvider(new FileLoggerProvider(\"mylog.log\"))); This method would apply message bulking feature to the FileLoggerProvider , with default bulking config. Since we are going to eventually deprecate and remove LogConsumer feature support in the future, we highly encourage you to migrate off this feature as soon as possible. There's couple approaches you can take to migrate off. One option is to maintain your own ILoggerProvider , which creates ILogger who logs to all your existing log consumers. This is very similar to what we are doing in Microsoft.Orleans.Logging.Legacy package. You can take a look at LegacyOrleansLoggerProvider and borrow logic from it. Another option is replace your ILogConsumer with existing implementation of ILoggerProvider on nuget which provides identical or similar functionality, or implement your own ILoggerProvider which fits your specfic logging requirement. And configure those ILoggerProvider s with ILoggingBuilder . But if you cannot migrate off log consumer in the short term, you can still use it. The support for ILogConsumer lives in Microsoft.Orleans.Logging.Legacy package. So you need to add dependency on that package first, and then configure Log consumers through extension method AddLegacyOrleansLogging on ILoggingBuilder . There's native AddLogging method on IServiceCollection provided by ASP.NET for you to configure ILoggingBuilder . We also wrap that method under extension method on ISiloHostBuilder and IClientBuilder . So you can call AddLogging method on silo builder and client builder as well to configure ILoggingBuilder . below is an example: var severityOverrides = new OrleansLoggerSeverityOverrides(); severityOverrides.LoggerSeverityOverrides.Add(typeof(MyType).FullName, Severity.Warning); siloBuilder.AddLogging(builder => builder.AddLegacyOrleansLogging(new List<ILogConsumer>() { new LegacyFileLogConsumer($\"{this.GetType().Name}.log\") }, severityOverrides)); You can use this feature if you invested in custom implementation of ILogConsumer and cannot convert them to implementation of ILoggerProvider in the short term. Logger GetLogger(string loggerName) method on Grain base class and IProviderRuntime , and Logger Log { get; } method on IStorageProvider are still maintained as a deprecated feature in 2.0. You can still use it in your process of migrating off orleans legacy logging. But we recommend you to migrate off them as soon as possible. Provider Configuration In Orleans 2.0, configuration of the included providers has been standardized to obtain Service ID and Cluster ID from the ClusterOptions configured for the silo or client. Service ID is a stable identifier of the service or application that the cluster represents. Service ID does not change between deployments and upgrades of clusters that implement the service over time. Unlike Service ID, Cluster ID stays the same only through the lifecycle of a cluster of silos. If a running cluster gets shut down, and a new cluster for the same service gets deployed, the new cluster will have a new and unique Cluster ID, but will maintain the Service ID of the old cluster. Service ID is often used as part of a key for persisting data that needs to have continuity throughout the life of the service. Examples are grain state, reminders, and queues of persistent streams. On the other hand, data within a cluster membership table only makes sense within the scope of its cluster, and hence is normally keyed off Cluster ID. Prior to 2.0, behavior of Orleans providers was sometimes inconsistent with regards to using Service ID and Cluster ID (that was also previously called Deployment ID). Because of this unifications and the overall change of provider configuration API, data written to storage by some providers may change location or key. An example of a provider that is sensitive to this change is Azure Queue stream provider. If you are migrating an existing service from 1.x to 2.0, and need to maintain backward compatibility with regards to location or keys of data persisted by the providers you are using in the service, please verify that the data will be where your service or provider expects it to be. If your service happen to depend on the incorrect usage of Service ID and Cluster ID by a 1.x provider, you can override ClusterOptions for that specific provider by calling ISiloHostBuilder.AddProviderClusterOptions() or IClientBuilder.AddProviderClusterOptions() and force it to read/write data from/to the 1.x location in storage"
  },
  "Documentation/resources/Migration/MigrationAzure2.0.html": {
    "href": "Documentation/resources/Migration/MigrationAzure2.0.html",
    "title": "Migration from Orleans 1.5 to 2.0 when using Azure | Microsoft Orleans Documentation",
    "keywords": "Migration from Orleans 1.5 to 2.0 when using Azure In Orleans 2.0, the configuration of silos and clients has changed. In Orleans 1.5 we used to have a monolith object that handled all the configuration pieces Providers were added to that configuration object, too. In Orleans 2.0, the configuration process is organizes around SiloHostBuilder , similar to how it is done in ASP.NET Core with the WebHostBuilder . In Orleans 1.5, the configuration for Azure looked like this: var config = AzureSilo.DefaultConfiguration(); config.AddMemoryStorageProvider(); config.AddAzureTableStorageProvider(\"AzureStore\", RoleEnvironment.GetConfigurationSettingValue(\"DataConnectionString\")); The AzureSilo class exposes a static method named DefaultConfiguration() that was used for loading configuration XML file. This way of configuring a silo is deprecated but still supported via the legacy support package . In Orleans 2.0, configuration is completely programmatic. The new configuration API looks like this: //Load the different settings from the services configuration var proxyPort = RoleEnvironment.CurrentRoleInstance.InstanceEndpoints[\"OrleansProxyEndpoint\"].IPEndpoint.Port; var siloEndpoint = RoleEnvironment.CurrentRoleInstance.InstanceEndpoints[\"OrleansSiloEndpoint\"].IPEndpoint; var connectionString = RoleEnvironment.GetConfigurationSettingValue(\"DataConnectionString\"); var deploymentId = RoleEnvironment.DeploymentId; var builder = new SiloHostBuilder() //Set service ID and cluster ID .Configure<ClusterOptions>(options => { options.ClusterId = deploymentId; options.ServiceIs = \"my-app\"; }) // Set silo name .Configure<SiloOptions>(options => options.SiloName = this.Name) //Then, we can configure the different endpoints .ConfigureEndpoints(siloEndpoint.Address, siloEndpoint.Port, proxyPort) //Then, we set the connection string for the storage .UseAzureStorageClustering(options => options.ConnectionString = connectionString) //If reminders are needed, add the service, the connection string is required .UseAzureTableReminderService(connectionString) //If Queues are needed, add the service, set the name and the Adapter, the one shown here //is the one provided with Orleans, but it can be a custom one .AddAzureQueueStreams<AzureQueueDataAdapterV2>(\"StreamProvider\", configurator => configurator.Configure(configure => { configure.ConnectionString = connectionString; })) //If Grain Storage is needed, add the service and set the name .AddAzureTableGrainStorage(\"AzureTableStore\"); AzureSilo to ISiloHost In Orleans 1.5, the AzureSilo class was the recommended way to host a silo in an Azure Worker Role. This is still supported via the Microsoft.Orleans.Hosting.AzureCloudServices NuGet package . public class WorkerRole : RoleEntryPoint { AzureSilo silo; public override bool OnStart() { // Do other silo initialization  for example: Azure diagnostics, etc return base.OnStart(); } public override void OnStop() { silo.Stop(); base.OnStop(); } public override void Run() { var config = AzureSilo.DefaultConfiguration(); config.AddMemoryStorageProvider(); config.AddAzureTableStorageProvider(\"AzureStore\", RoleEnvironment.GetConfigurationSettingValue(\"DataConnectionString\")); // Configure storage providers silo = new AzureSilo(); bool ok = silo.Start(config); silo.Run(); // Call will block until silo is shutdown } } Orleans 2.0 provides a more flexible and modular API for configuring and hosting a silo via SiloHostBuilder and ISiloHost . public class WorkerRole : RoleEntryPoint { private ISiloHost host; private ISiloHostBuilder builder; private readonly CancellationTokenSource cancellationTokenSource = new CancellationTokenSource(); private readonly ManualResetEvent runCompleteEvent = new ManualResetEvent(false); public override void Run() { try { this.RunAsync(this.cancellationTokenSource.Token).Wait(); runCompleteEvent.WaitOne(); } finally { this.runCompleteEvent.Set(); } } public override bool OnStart() { //builder is the SiloHostBuilder from the first section // Build silo host, so that any errors will restart the role instance this.host = this.builder.Build(); base.OnStart(); } public override void OnStop() { this.cancellationTokenSource.Cancel(); this.runCompleteEvent.WaitOne(); this.host.StopAsync().Wait(); base.OnStop(); } private Task RunAsync(CancellationToken cancellationToken) { return this.host.StartAsync(cancellationToken); } }"
  },
  "Documentation/resources/Presentations/index.html": {
    "href": "Documentation/resources/Presentations/index.html",
    "title": "Orleans Presentations | Microsoft Orleans Documentation",
    "keywords": "Orleans Best Practices A collection of tips and trick to help design, build, and run an Orleans-based application. Orleans Presentation from the 28th International Symposium on Distributed Computing (DISC 2014) Orleans Presentation from the 15th International Workshop on High Performance Transaction Systems (HPTS 2013) [Balancing Techniques in Orleans]( http://dotnet.github.io/orleans/Presentations/Balancing Techniques in Orleans.pptx) [Uniform API is 42 - Virtual Meetup #3]( http://dotnet.github.io/orleans/Presentations/(VM03 ) Uniform Api is 42.pptx) [Orleans at FreeBay - Virtual Meetup #4]( http://dotnet.github.io/orleans/Presentations/VM-4 - Using Orleans at FreeBay.pptx) [Orleans Streaming - Virtual Meetup #5 - May 2015]( http://dotnet.github.io/orleans/Presentations/Orleans Streaming - Virtual meetup - 5-22-2015.pptx) [Geo Distributed Orleans - Virtual Meetup #6 - October 2015]( http://dotnet.github.io/orleans/Presentations/VM-6 - Orleans-Geo-Replication.pptx) [Orleankka Functional API for Orleans - Virtual Meetup #7]( http://dotnet.github.io/orleans/Presentations/(VM07 ) Orleankka Functional API for Orleans.pptx) [Orleans Roadmap - Virtual Meetup #8 - January 2016]( http://dotnet.github.io/orleans/Presentations/Orleans Roadmap 1-21-2016.pptx) [Orleans Networking discussion- Virtual Meetup #8.5 - February 2016]( http://dotnet.github.io/orleans/Presentations/VM-8.5 - Orleans Networking.pptx) [Orleans on Service Fabric - Virtual Meetup #9 Part 1 - February 2016]( http://dotnet.github.io/orleans/Presentations/VM-9 - Part.1 Orleans-on-Service-Fabric.pptx) [Orleans with YAMS - Virtual Meetup #9 Part 2 - February 2016]( http://dotnet.github.io/orleans/Presentations/VM-9 - Part.2 Orleans-with-YAMS.pptx) [Walk In Distributed Systems Park With Orleans]( http://dotnet.github.io/orleans/Presentations/(FWDAYSKIEV2016 ) Walk.In.Distributed.Systems.Park.With.Orleans.pptx)"
  },
  "index.html": {
    "href": "index.html",
    "title": "Microsoft Orleans | Microsoft Orleans Documentation",
    "keywords": ""
  }
}